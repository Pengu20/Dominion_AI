 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.19125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500  10  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 585 

action type: buy - action -1
Learning step: 28.533918380737305
desired expected reward: 42.85555648803711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[311.04944]
 [322.0975 ]
 [318.31223]
 [289.77118]
 [329.1027 ]
 [319.11133]
 [316.26944]
 [334.90454]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.519537925720215
desired expected reward: 325.68182373046875



buy possibilites: [-1] 
expected returns: [[305.107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -9.090658187866211
desired expected reward: 310.0206298828125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.8166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.372600555419922
desired expected reward: 296.7344055175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[295.21082]
 [305.0946 ]
 [300.3502 ]
 [274.6955 ]
 [299.1508 ]
 [309.55533]
 [302.6407 ]
 [304.15308]
 [283.98312]
 [298.39468]
 [295.31784]
 [312.8674 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.73979663848877
desired expected reward: 301.6046142578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[306.93198]
 [295.60437]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.885089874267578
desired expected reward: 303.9822692871094



action possibilites: [-1] 
expected returns: [[304.09113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 1
Learning step: -9.618704795837402
desired expected reward: 326.59637451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[276.71768]
 [282.9593 ]
 [256.19537]
 [284.95325]
 [297.16882]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.365809440612793
desired expected reward: 295.7253112792969



buy possibilites: [-1] 
expected returns: [[323.32965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -20.734853744506836
desired expected reward: 235.46055603027344






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [0. 0. 0. 3. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 3. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 8. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.4306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -11.235307693481445
desired expected reward: 312.0943298339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[278.0855 ]
 [290.57443]
 [286.35846]
 [262.59683]
 [254.4367 ]
 [283.31653]
 [298.09982]
 [287.08246]
 [308.2031 ]
 [289.72913]
 [266.13565]
 [275.09537]
 [283.8153 ]
 [260.88705]
 [280.2773 ]
 [305.4375 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.797308921813965
desired expected reward: 284.9216003417969



buy possibilites: [-1] 
expected returns: [[294.78235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 8. 3. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -23.3392333984375
desired expected reward: 231.09747314453125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[285.1343 ]
 [271.66663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14] -> size -> 14 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -10.63782787322998
desired expected reward: 284.14453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[260.08798]
 [266.82434]
 [238.75111]
 [268.28156]
 [281.74924]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14] -> size -> 14 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -10.402121543884277
desired expected reward: 275.2424621582031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [14.  0.  0.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.22888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -9.32258415222168
desired expected reward: 272.42669677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.33633]
 [297.12292]
 [293.4345 ]
 [268.14484]
 [303.53186]
 [294.12527]
 [291.23492]
 [309.23303]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -11.064574241638184
desired expected reward: 300.7078552246094



buy possibilites: [-1] 
expected returns: [[266.36383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -10.954769134521484
desired expected reward: 253.00433349609375






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[242.84642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -10.106027603149414
desired expected reward: 256.2578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[217.39467]
 [227.555  ]
 [224.26523]
 [198.94221]
 [221.67322]
 [233.98401]
 [224.65585]
 [226.88371]
 [208.13647]
 [222.19295]
 [219.32059]
 [239.4205 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 6 6 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -9.1966552734375
desired expected reward: 233.56619262695312



buy possibilites: [-1] 
expected returns: [[230.64488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -13 

action type: buy - action 15.0
Learning step: -6.426520824432373
desired expected reward: 212.8940887451172






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[236.6198 ]
 [223.54889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [15.  0.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.645906448364258
desired expected reward: 221.9989776611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[216.40541]
 [227.10434]
 [222.76587]
 [196.0178 ]
 [232.83871]
 [224.2951 ]
 [220.7028 ]
 [237.0548 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [15.  0.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -8.661253929138184
desired expected reward: 222.8863525390625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  3.  0. 16.  8.  8.  3.  0.  0.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[258.4486 ]
 [242.50278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_down_to_3_cards - action 3
Learning step: -6.723045349121094
desired expected reward: 197.30697631835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[232.29417]
 [207.82236]
 [259.5974 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -9.64228343963623
desired expected reward: 249.0946502685547



buy possibilites: [-1] 
expected returns: [[232.65427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [3. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -22.956396102905273
desired expected reward: 184.86595153808594






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3. 14.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [3. 3. 6. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[231.11974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3. 3. 6. 8. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -9.220476150512695
desired expected reward: 223.4337921142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[216.21388]
 [224.94739]
 [221.55928]
 [199.19032]
 [219.74423]
 [230.03192]
 [222.66489]
 [224.5548 ]
 [207.6457 ]
 [219.97679]
 [217.64073]
 [233.9892 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3. 3. 6. 8. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -9.277008056640625
desired expected reward: 222.3779754638672



buy possibilites: [-1] 
expected returns: [[231.60869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3. 3. 6. 8. 6. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 16.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -43.0 

action type: buy - action 3.0
Learning step: -8.016769409179688
desired expected reward: 213.5425262451172






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 16.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 16.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  5. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.  0.  0.] 
cards in discard: [ 0.  0.  3. 16.  3. 14.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 3. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[227.88538]
 [205.42963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.893293380737305
desired expected reward: 222.71539306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[205.57863]
 [218.24524]
 [213.05286]
 [181.25677]
 [224.61917]
 [214.84314]
 [210.44778]
 [229.14781]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -8.537069320678711
desired expected reward: 216.4982147216797



buy possibilites: [-1] 
expected returns: [[225.45427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -8.61648941040039
desired expected reward: 196.962158203125






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  0  8  3 14  8  8  8 16  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  3. 16.  3. 14.  8.  8. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[242.86674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0.  3. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.12861156463623
desired expected reward: 217.32565307617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.52899]
 [229.43466]
 [208.2735 ]
 [230.67914]
 [240.50037]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0.  3. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -8.980988502502441
desired expected reward: 230.75685119628906



buy possibilites: [-1] 
expected returns: [[198.37682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 0.  3. 15.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 3.0
Learning step: -8.30825424194336
desired expected reward: 221.1263885498047






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.  3.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.  3.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  3. 15.  0.  0.  0.  3.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[199.70341]
 [183.856  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 0.  3. 15.  0.  0.  0.  3.  0.  3.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16. 14.  8.  0.  3.] 
adversary cards in discard: [0. 3. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.2505035400390625
desired expected reward: 191.12631225585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[169.73979]
 [180.84575]
 [177.17873]
 [151.21281]
 [187.96468]
 [177.72322]
 [174.89043]
 [194.4605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 0.  3. 15.  0.  0.  0.  3.  0.  3.  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16. 14.  8.  0.  3.] 
adversary cards in discard: [0. 3. 3. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.419285774230957
desired expected reward: 190.49147033691406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [16. 14.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  8.  0.  3.] 
cards in discard: [0. 3. 3. 8. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 14.  8.  0.  3.] 
cards in discard: [0. 3. 3. 8. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[228.56105]
 [209.99294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  8.  0.  3. 16. 14.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.362016201019287
desired expected reward: 188.0985107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[206.6667 ]
 [189.22112]
 [226.41788]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  8.  0.  3. 16. 14.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.303863525390625
desired expected reward: 221.3927459716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  0.] 
cards in discard: [ 0.  3.  3.  8.  0.  3. 16. 14.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8  8 16  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  4. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  3.  8.  0.  3. 16. 14.  8.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  3.  3.  8.  0.  3. 16. 14.  8.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[182.17128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.  3.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  8. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -8.949795722961426
desired expected reward: 217.46807861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[165.87323]
 [174.28938]
 [171.42354]
 [150.32219]
 [169.3494 ]
 [179.61214]
 [171.97693]
 [173.86565]
 [157.97198]
 [169.8341 ]
 [167.53331]
 [183.95845]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.  3.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [16.  8. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.768502712249756
desired expected reward: 174.169189453125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [16.  8. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 16.  0.  8.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[179.24425]
 [171.67967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.881022930145264
desired expected reward: 177.07742309570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.72601]
 [175.82495]
 [172.44048]
 [155.66016]
 [179.20462]
 [174.12003]
 [171.2107 ]
 [181.4846 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.74285364151001
desired expected reward: 173.7245330810547



buy possibilites: [-1] 
expected returns: [[208.02434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [15.  3.  6.  0.  3.  0.  0.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 10.0
Learning step: -4.679986000061035
desired expected reward: 166.53067016601562






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[231.93178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -6.901956081390381
desired expected reward: 201.12237548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[215.00893]
 [220.76167]
 [196.01328]
 [222.21906]
 [233.74757]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  7.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.176712036132812
desired expected reward: 222.9015350341797



buy possibilites: [-1] 
expected returns: [[182.78613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -22.937976837158203
desired expected reward: 173.07528686523438






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  3. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0. 16.  8. 16.  0.  8.  0.  3.  0.  8.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [6. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[176.91524]
 [161.52745]
 [158.65762]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 15.  0.] 
cards in discard: [6. 0. 6. 0. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -7.586941719055176
desired expected reward: 175.19918823242188



action possibilites: [-1] 
expected returns: [[149.9288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [6. 0. 6. 0. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 15.0
Learning step: -5.136939525604248
desired expected reward: 140.06980895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[134.82571]
 [143.61703]
 [140.43845]
 [123.24885]
 [117.25115]
 [138.64456]
 [148.32018]
 [141.458  ]
 [155.13394]
 [143.07967]
 [125.73125]
 [132.2678 ]
 [138.8569 ]
 [121.77079]
 [136.19232]
 [152.81284]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [6. 0. 6. 0. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -5.458660125732422
desired expected reward: 144.4701385498047



buy possibilites: [-1] 
expected returns: [[119.86691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 6.  0.  6.  0.  6.  6. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -17.0 

action type: buy - action 29.0
Learning step: -5.306977272033691
desired expected reward: 137.77267456054688






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.00175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  8.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.505828857421875
desired expected reward: 113.361083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.896194]
 [58.36643 ]
 [78.18504 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 0.] 
cards in discard: [ 6.  0.  6.  0.  6.  6. 29. 15. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  8.] 
adversary cards in discard: [0. 8. 8. 0.] 
adversary owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.468573093414307
desired expected reward: 72.75440216064453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  8.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  3 14  8  8 16  0  8  0  8  0  0  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 8. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[117.31987]
 [109.61091]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  6  0 15  6  3  0  3 10  6 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.5926785469055176
desired expected reward: 74.59236145019531



action possibilites: [-1] 
expected returns: [[111.51167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.4914722442626953
desired expected reward: 102.51822662353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.54955 ]
 [102.96729 ]
 [ 85.91115 ]
 [103.45074 ]
 [113.503654]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.863727569580078
desired expected reward: 107.64794921875






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  6.  6.  0.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [0. 8. 8. 0. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.26894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  0. 15.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0    0    0    0    0    0    0    0 -900
   41    0] 
sum of rewards: -893 

action type: discard_down_to_3_cards - action 2
Learning step: -47.662166595458984
desired expected reward: 48.94956588745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[65.46887 ]
 [70.58566 ]
 [51.274475]
 [70.960205]
 [81.39248 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  0. 15.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -4.0609049797058105
desired expected reward: 76.75787353515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 14  8  8  0  8  0  8  0  0  8  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  8.  0.  8.  0.  0. 29. 14.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3. 29. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[156.66862]
 [148.51387]
 [142.84503]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  6.  0.] 
cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -1.3396084308624268
desired expected reward: 80.0528564453125



action possibilites: [-1. 10.] 
expected returns: [[191.73007]
 [171.96489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  0.  3.] 
cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 29.0
Learning step: -2.9013619422912598
desired expected reward: 145.18206787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[169.37755]
 [178.27185]
 [146.43344]
 [178.02284]
 [194.78874]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.  3.] 
cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  6.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.14448356628418
desired expected reward: 186.58558654785156



buy possibilites: [-1] 
expected returns: [[181.74124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.  3.] 
cards in discard: [ 8.  0.  0. 15.  6.  6.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -18.27121353149414
desired expected reward: 128.16224670410156






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  8  0  8  0  8  0  0  8  0 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[125.57293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -7.534065246582031
desired expected reward: 174.20718383789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.5608 ]
 [105.15339]
 [100.71524]
 [ 69.45426]
 [112.33484]
 [101.33266]
 [ 98.21244]
 [117.135  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.0403642654418945
desired expected reward: 119.53726196289062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [0. 8. 3. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[201.94531]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 14.  0.] 
adversary cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -2.5903706550598145
desired expected reward: 114.54464721679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[183.98863]
 [192.1106 ]
 [188.74269]
 [168.26105]
 [196.91994]
 [189.96597]
 [187.25433]
 [200.65477]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 14.  0.] 
adversary cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -6.908477306365967
desired expected reward: 193.81954956054688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 14.  0.] 
cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  8. 15.  6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  3.] 
cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  8. 15.  6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0. 8. 3. 1. 0. 8. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  1.  0.  8.  0.  0.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15.  6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[165.26108]
 [150.4213 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6.] 
cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -20     0     0     0     0     0     0     0     0
     0 -1200    33     0] 
sum of rewards: -1192 

action type: discard_down_to_3_cards - action 4
Learning step: -62.5580940246582
desired expected reward: 70.04086303710938



action possibilites: [-1] 
expected returns: [[135.10162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 15.0
Learning step: -4.797915935516357
desired expected reward: 146.9561309814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.36019]
 [ 93.91355]
 [131.53165]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [0. 3. 0. 3. 0. 3. 0. 6. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -4.258460998535156
desired expected reward: 130.84317016601562






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  6. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  6. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [ 0.  6. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[80.57449 ]
 [72.555115]
 [68.51322 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [15.  0.  8.  8.  1.  0.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -6.157752513885498
desired expected reward: 125.3738784790039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.252  ]
 [66.71914]
 [45.66489]
 [67.85566]
 [77.50615]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  5.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [15.  0.  8.  8.  1.  0.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.5377724170684814
desired expected reward: 74.05815887451172



buy possibilites: [-1] 
expected returns: [[144.3485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29. 10.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [29.  0.  0.  0. 15.] 
adversary cards in discard: [15.  0.  8.  8.  1.  0.] 
adversary owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -336.0 

action type: buy - action 6.0
Learning step: -15.835403442382812
desired expected reward: 29.829498291015625






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 15.] 
cards in discard: [15.  0.  8.  8.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [15.  0.  8.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  0  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [15.  0.  8.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15.  0.  8.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15.  0.  8.  8.  1.  0. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[116.90383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6. 29. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  0.  3.  3. 14.] 
adversary cards in discard: [15.  0.  8.  8.  1.  0. 22. 29. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -6.427387237548828
desired expected reward: 137.92111206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.84533]
 [112.47139]
 [110.94353]
 [ 99.01558]
 [115.56536]
 [111.1735 ]
 [110.03017]
 [118.37063]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6. 29. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  0.  3.  3. 14.] 
adversary cards in discard: [15.  0.  8.  8.  1.  0. 22. 29. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.978806495666504
desired expected reward: 110.13398742675781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 14.] 
cards in discard: [15.  0.  8.  8.  1.  0. 22. 29. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  3. 14.] 
cards in discard: [15.  0.  8.  8.  1.  0. 22. 29. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0.  6. 29. 10.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.52631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 6.  0.  6. 29. 10.  0.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.932344913482666
desired expected reward: 112.43828582763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.8827  ]
 [43.977356]
 [79.27677 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 6.  0.  6. 29. 10.  0.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.209301948547363
desired expected reward: 75.17676544189453



buy possibilites: [-1] 
expected returns: [[133.21024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 3.] 
cards in discard: [ 6.  0.  6. 29. 10.  0.  3.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -2.860318899154663
desired expected reward: 52.022369384765625






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [15.  0. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14.  8.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 15 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[141.1307  ]
 [124.079475]
 [128.38591 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  1.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -5.4768242835998535
desired expected reward: 127.73341369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.130356]
 [123.6934  ]
 [106.67042 ]
 [124.44548 ]
 [136.14905 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 15.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  1.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0] -> size -> 17 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.774553298950195
desired expected reward: 131.80581665039062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 0.  8.  0. 14.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 0.  8.  0. 14.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 27. 30.  8.  4.  8. 10.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [ 0.  8.  0. 14.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[143.85513]
 [130.81654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  3.] 
cards in discard: [ 0.  0.  3. 15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 22.  0. 29.  8.] 
adversary cards in discard: [ 0.  8.  0. 14.  1. 11.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.504519939422607
desired expected reward: 130.64453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.12885 ]
 [132.46725 ]
 [109.681145]
 [133.2594  ]
 [143.63449 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  3.] 
cards in discard: [ 0.  0.  3. 15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 22.  0. 29.  8.] 
adversary cards in discard: [ 0.  8.  0. 14.  1. 11.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.7852277755737305
desired expected reward: 135.31658935546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 22.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 29.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 29.  8.] 
cards in discard: [ 0.  8.  0. 14.  1. 11.  0.  0. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  8.  0.  3.] 
cards in discard: [ 0.  8.  0. 14.  1. 11.  0.  0. 15.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.  8.  0.  3.] 
cards in discard: [ 0.  8.  0. 14.  1. 11.  0.  0. 15.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 29.  6.  0.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[125.02205]
 [115.2529 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  6.  0.] 
cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 14. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -6.390450954437256
desired expected reward: 137.24403381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.59705 ]
 [116.50308 ]
 [ 99.86759 ]
 [115.984116]
 [127.507805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  6.  0.] 
cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 14. 22.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.953474044799805
desired expected reward: 112.5226058959961



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 22.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 22.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  8.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.91041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 14.  0. 22.  8.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -30     0     0     0   -30     0     0     0     0
     0 -1500    17     0] 
sum of rewards: -1549 

action type: discard_down_to_3_cards - action 1
Learning step: -76.52355194091797
desired expected reward: -57.40425109863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.825676]
 [50.596745]
 [84.92147 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  4.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 14.  0. 22.  8.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.26885986328125
desired expected reward: 79.39366149902344



buy possibilites: [-1] 
expected returns: [[39.05286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 0.  0.  3. 15.  8.  6. 10.  0.  0.  3.  0.  6. 29.  6.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 14.  0. 22.  8.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: buy - action 6.0
Learning step: -19.001148223876953
desired expected reward: 31.59558868408203






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 14.  0. 22.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 14.  0. 22.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[118.07575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [ 0. 14.  0. 22.  8.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -1.7039848566055298
desired expected reward: 37.348876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.0085  ]
 [112.56517 ]
 [109.07714 ]
 [ 93.02577 ]
 [115.32158 ]
 [111.09853 ]
 [108.010925]
 [116.97121 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  0.] 
adversary cards in discard: [ 0. 14.  0. 22.  8.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.582459449768066
desired expected reward: 109.91346740722656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 11.  0.] 
cards in discard: [ 0. 14.  0. 22.  8.  3.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 15.  0.  6.] 
adversary cards in discard: [6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0. 11.  0.] 
cards in discard: [ 0. 14.  0. 22.  8.  3.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 27. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 15.  0.  6.] 
adversary cards in discard: [6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0. 11.  0.] 
cards in discard: [ 0. 14.  0. 22.  8.  3.  0.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6. 15.  0.  6.] 
adversary cards in discard: [6. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[113.537285]
 [ 95.51777 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  6.] 
cards in discard: [6. 6. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -6.3845133781433105
desired expected reward: 110.58668518066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.244896]
 [106.87937 ]
 [ 85.6891  ]
 [107.76844 ]
 [119.955765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  6.] 
cards in discard: [6. 6. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.686782360076904
desired expected reward: 101.51006317138672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  2. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  8.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.441124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 8.  0.  0. 15.  8.  8.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -7.091968059539795
desired expected reward: 112.86381530761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[65.486946]
 [50.887047]
 [81.969795]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 8.  0.  0. 15.  8.  8.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.085775375366211
desired expected reward: 72.95071411132812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 14.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  1. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.52465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -50     0     0     0     0     0     0     0     0
     0 -1800    13     0] 
sum of rewards: -1844 

action type: discard_down_to_3_cards - action 1
Learning step: -91.73133087158203
desired expected reward: -67.11872100830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.23892 ]
 [44.447372]
 [76.983376]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.071309566497803
desired expected reward: 70.45333862304688



buy possibilites: [-1] 
expected returns: [[63.49632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  6.  0.  0.  0.  0.  6. 15.  0.  6.  3.  3.  3.  6.  0. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -6.033278942108154
desired expected reward: 56.205631256103516






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 11.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  8.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8.  0.  0. 15.  8.  8.  8. 14.  0.  0.  1.  3.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[27.048628]
 [16.462881]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -5.465156078338623
desired expected reward: 58.03116226196289



action possibilites: [-1.] 
expected returns: [[98.84579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: discard_n_cards - action 1
Learning step: -0.4454685151576996
desired expected reward: 15.944503784179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[83.78054 ]
 [89.33595 ]
 [88.569145]
 [72.577774]
 [86.24001 ]
 [94.53378 ]
 [89.483574]
 [79.40882 ]
 [87.53923 ]
 [86.2676  ]
 [99.93399 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 29. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -4.688515663146973
desired expected reward: 94.15727233886719



buy possibilites: [-1] 
expected returns: [[69.46215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [3. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -32.5 

action type: buy - action 1.0
Learning step: -4.528900146484375
desired expected reward: 84.80706787109375






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 22.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  0  8  0  0  8  0 29  0  0  1 15 22  0 11  0  3  8  8 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  8.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  8.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  8.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  8.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [15.  6.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[71.52926 ]
 [56.80585 ]
 [59.784218]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  0.  8.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 15.  3. 14.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -4.848398685455322
desired expected reward: 64.61375427246094



action possibilites: [-1] 
expected returns: [[83.76804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 15.  3. 14.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -2.7123100757598877
desired expected reward: 52.22950744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[74.31545 ]
 [80.43595 ]
 [77.4583  ]
 [62.584644]
 [83.35024 ]
 [76.349884]
 [85.53385 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 15.  3. 14.  1.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -4.20819091796875
desired expected reward: 79.55985260009766






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 14.  1.] 
cards in discard: [0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 14.  1.] 
cards in discard: [0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 14.  1.] 
cards in discard: [0. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.07458 ]
 [20.632158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  0. 29. 29. 11.] 
adversary cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -7.061028957366943
desired expected reward: 78.47280883789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[17.15841 ]
 [20.090277]
 [11.58045 ]
 [26.489153]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 25. 30.  8.  3.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  0. 29. 29. 11.] 
adversary cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.187824249267578
desired expected reward: 22.766334533691406



buy possibilites: [-1] 
expected returns: [[57.91898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  0. 29. 29. 11.] 
adversary cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1.] 
adversary owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -18.175846099853516
desired expected reward: -6.59539794921875






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 29. 11.] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  8.] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  8  8  8  0 29  0  0  1 15  0 11  0  3  8  8 29  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 3. 6.] 
adversary cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.043324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29. 29.  8.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.097474098205566
desired expected reward: 51.82150650024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[13.585194]
 [16.821424]
 [ 5.786466]
 [23.67593 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 6.] 
cards in discard: [ 3.  1. 29.  0.  0.  6.  0. 15.  6.  3.  8.  6. 10.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29. 29.  8.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.873244285583496
desired expected reward: 23.287452697753906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  9.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [ 0.  8.  3.  3. 15.  3. 14.  1. 29. 29.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  8.  9.  7.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.831757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.306756496429443
desired expected reward: 19.369173049926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.790138]
 [21.321138]
 [37.781853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.879553318023682
desired expected reward: 29.655569076538086



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 15.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[65.119225]
 [56.903164]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  6.  0.] 
cards in discard: [3. 3. 3. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 29. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.424682140350342
desired expected reward: 33.35717010498047



action possibilites: [-1] 
expected returns: [[58.57487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [3. 3. 3. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 29. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action 15.0
Learning step: -4.306739807128906
desired expected reward: 50.18675231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[53.419155]
 [58.73761 ]
 [57.076878]
 [42.408943]
 [61.022484]
 [56.09539 ]
 [62.548615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [3. 3. 3. 6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 29. 15.  3. 29.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -4.496140480041504
desired expected reward: 54.078731536865234






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8. 29. 15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 15.  3. 29.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  3.] 
cards in discard: [10.  3.  0.  3.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  3.] 
cards in discard: [10.  3.  0.  3.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.286053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  1.  0. 10.  8.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0. 15. 29.  8.  3. 29.  3.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -6.406622409820557
desired expected reward: 56.141990661621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[21.606852]
 [23.157343]
 [14.289129]
 [27.091557]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  1.  0. 10.  8.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0. 15. 29.  8.  3. 29.  3.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.732476711273193
desired expected reward: 22.859004974365234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 10.  8.] 
cards in discard: [10.  3.  0.  3.  0.  0. 15. 29.  8.  3. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0. 10.  8.] 
cards in discard: [10.  3.  0.  3.  0.  0. 15. 29.  8.  3. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0. 10.  8.] 
cards in discard: [10.  3.  0.  3.  0.  0. 15. 29.  8.  3. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.  0.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  1.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[37.20755 ]
 [27.094667]
 [26.58622 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 10.] 
cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.  0.  3.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0] -> size -> 22 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.495118141174316
desired expected reward: 22.596439361572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[24.021147]
 [29.35202 ]
 [28.577612]
 [17.346811]
 [26.528131]
 [34.326084]
 [28.951044]
 [20.189281]
 [27.500813]
 [26.10865 ]
 [38.58672 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  8. 10.] 
cards in discard: [ 3.  3.  3.  6.  0. 15.  6.  6.  6.  0.  3.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0] -> size -> 22 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -5.0178656578063965
desired expected reward: 32.18967819213867



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 25. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8. 14.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 6.  6.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[32.552963]
 [27.08619 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1.0
Learning step: -5.670982837677002
desired expected reward: 32.915733337402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[18.88566 ]
 [22.440714]
 [ 8.980352]
 [29.366402]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.] 
adversary owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -5.377027988433838
desired expected reward: 25.253772735595703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10. 10.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  8.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 0. 3. 6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [1. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.684261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3. 6.] 
cards in discard: [ 6.  6.  0.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.] 
adversary owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 22 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -4.446731090545654
desired expected reward: 24.919660568237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[ 8.395168 ]
 [16.606932 ]
 [14.832785 ]
 [-3.7105422]
 [23.475573 ]
 [13.009848 ]
 [29.677343 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3. 6.] 
cards in discard: [ 6.  6.  0.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.] 
adversary owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 22 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -3.8385086059570312
desired expected reward: 14.898754119873047



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 29  0  0  1 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  3.  8.  3. 10.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  3.  8.  3. 10.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  3.  8.  3. 10.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[45.200493]
 [36.94961 ]
 [34.936996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 10.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8.  0.  3. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
adversary owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -4.001124382019043
desired expected reward: 25.676223754882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.239677]
 [26.708342]
 [46.447342]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 10.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 24. 30.  8.  2.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8.  0.  3. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
adversary owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -4.574163913726807
desired expected reward: 37.41575622558594



buy possibilites: [-1] 
expected returns: [[43.183212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 10.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8.  0.  3. 15.] 
adversary cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
adversary owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -379.0 

action type: buy - action 6.0
Learning step: -19.099184036254883
desired expected reward: 3.316926956176758






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [29.  8.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  3. 15.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 29  0 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 29.  0.  0.  8. 14.  0. 10.  8. 10.  3.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  3. 15.  0.  6.] 
adversary cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[36.355984]
 [28.946577]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  0.  6.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [14.  8.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -5.332805633544922
desired expected reward: 37.850406646728516



action possibilites: [-1] 
expected returns: [[7.522331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [14.  8.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action 15.0
Learning step: -4.228076934814453
desired expected reward: 24.718505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[3.5378525 ]
 [5.640728  ]
 [4.9605713 ]
 [0.34503102]
 [7.1599236 ]
 [4.57504   ]
 [8.233278  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6.] 
cards in discard: [ 6.  6.  0.  0. 29.  1.  6.  0.  3.  6.  6.  0.  3.  8.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [14.  8.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -3.1781013011932373
desired expected reward: 4.344229698181152






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [14.  8.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 15  0  0  3  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[42.23849 ]
 [36.406773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -2.937544107437134
desired expected reward: 5.295736312866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[35.032425]
 [39.708233]
 [37.480824]
 [26.272484]
 [42.516773]
 [36.713978]
 [44.6173  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 24. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -4.660407543182373
desired expected reward: 38.01995086669922



buy possibilites: [-1] 
expected returns: [[72.75739]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 23. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -56.0 

action type: buy - action 3.0
Learning step: -3.0369999408721924
desired expected reward: 34.443824768066406






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 23. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 29.  6.] 
adversary cards in discard: [3. 8. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 23. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 29.  6.] 
adversary cards in discard: [3. 8. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 0.  8. 14.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 29.  6.] 
adversary cards in discard: [3. 8. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[47.85712 ]
 [45.129025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 29.  6.] 
cards in discard: [3. 8. 0. 6. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 19 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -6.039971351623535
desired expected reward: 66.71742248535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.35265 ]
 [30.803036]
 [47.75621 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 29.  6.] 
cards in discard: [3. 8. 0. 6. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  1.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 19 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -4.669463634490967
desired expected reward: 40.38436508178711



buy possibilites: [-1] 
expected returns: [[62.642147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 29.  6.] 
cards in discard: [3. 8. 0. 6. 0. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
adversary owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -379 

action type: buy - action 6.0
Learning step: -19.080703735351562
desired expected reward: 11.722339630126953






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  0  0  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  8. 14.  0.  3.  8. 10.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[15.053944]
 [ 9.32503 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -6.801293849945068
desired expected reward: 55.84085464477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 7.0680113]
 [ 9.39345  ]
 [14.181805 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 10. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1.0
Learning step: -4.3717041015625
desired expected reward: 9.552021026611328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  8 29  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 15.  6.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 15.  6.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  6.  0. 15.  6.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 6.  6.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-4.330686]
 [-3.335332]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 15.  6.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.] 
adversary owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1.0
Learning step: -4.739730358123779
desired expected reward: 9.44206428527832



action possibilites: [-1] 
expected returns: [[-0.8953197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.] 
adversary owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action 15.0
Learning step: -2.803377866744995
desired expected reward: -6.13871431350708





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.7662904 ]
 [-1.2573961 ]
 [-1.5449051 ]
 [-1.0254098 ]
 [-1.6710594 ]
 [-0.97578585]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 22. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.] 
adversary owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.9316606521606445
desired expected reward: -3.8269803524017334



buy possibilites: [-1] 
expected returns: [[21.680374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  6.  3.  3.  3. 29.  6. 10.  0.  0.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.] 
adversary owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -46.0 

action type: buy - action 3.0
Learning step: -1.6173607110977173
desired expected reward: -3.1622653007507324






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  8.] 
cards in discard: [ 8.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  8  0  0  3 10 10  0  3  0  0  0  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 6. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.30144143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -4.012154579162598
desired expected reward: 17.66822052001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-0.5187905 ]
 [-0.6953161 ]
 [-0.20613861]
 [-0.5907701 ]
 [-0.0245471 ]
 [-0.25822735]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -2.8420517444610596
desired expected reward: -4.092514514923096



buy possibilites: [-1] 
expected returns: [[9.805324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 1.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  8.] 
adversary cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -40 

action type: buy - action 10.0
Learning step: -1.7781528234481812
desired expected reward: -1.8026989698410034






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  8.] 
cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  8.] 
cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 21. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  8.] 
cards in discard: [ 8.  0.  0. 10.  0.  8.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [3. 3. 6. 6. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.3310585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [10.  0.  3.  6.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -3.900054693222046
desired expected reward: 5.905268669128418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.5138197 ]
 [-0.12755609]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [10.  0.  3.  6.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -3.3945329189300537
desired expected reward: -3.829582452774048



buy possibilites: [-1] 
expected returns: [[9.773208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 3.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action 0.0
Learning step: -4.554412364959717
desired expected reward: -7.068232536315918






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
adversary owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[5.449334 ]
 [0.8206842]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  6  0 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6
  3 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -3.804293155670166
desired expected reward: 5.96891450881958



action possibilites: [-1] 
expected returns: [[-1.2516142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.0557899475097656
desired expected reward: -1.5032167434692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.13468027]
 [ 3.0556002 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.8366036415100098
desired expected reward: -4.088217735290527






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  6.  6.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  6.  6.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  6.  6.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [15.  6.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-7.333847 ]
 [-6.9692507]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  6.  6.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1.0
Learning step: -4.261638164520264
desired expected reward: -1.2060294151306152



action possibilites: [-1] 
expected returns: [[-10.565341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action 15.0
Learning step: -2.8392577171325684
desired expected reward: -9.808507919311523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.484611]
 [-10.592556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0.] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -2.6650805473327637
desired expected reward: -13.23042106628418






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6. 29.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6. 15.  6.  3.  6.
  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  6.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6. 29.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6. 15.  6.  3.  6.
  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [10.  0.  3.  0.  0.  8.  0.  8.  3.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6. 29.] 
adversary cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6. 15.  6.  3.  6.
  6.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[4.609227  ]
 [0.87235975]
 [1.3105159 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6. 29.] 
cards in discard: [10.  0.  3.  6.  6.  1.  0.  3.  3.  6.  6.  3.  8.  6. 15.  6.  3.  6.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1.0
Learning step: -3.3430333137512207
desired expected reward: -13.935590744018555



action possibilites: [-1.] 
expected returns: [[4.566865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: discard_n_cards - action 5
Learning step: -2.6604506969451904
desired expected reward: -4.91585636138916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[4.275853 ]
 [5.3116226]
 [4.729356 ]
 [5.593755 ]
 [4.621237 ]
 [5.5320005]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  9.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.059040069580078
desired expected reward: 1.5078248977661133



buy possibilites: [-1] 
expected returns: [[-7.568164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  6. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: -2.499971389770508
desired expected reward: 3.0937843322753906






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8  0  0 10 10  0  3  0  0  0  3  0  0  3  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0
 11] -> size -> 25 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0
 11] -> size -> 25 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 6. 15.  6.  6.  0.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0
 11] -> size -> 25 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [ 6. 15.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-22.92892]
 [-24.99708]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  6.  0.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  0  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 14. 10.  3. 10.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -3.5553359985351562
desired expected reward: -11.123499870300293



action possibilites: [-1] 
expected returns: [[-7.568164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 14. 10.  3. 10.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action 15.0
Learning step: -1.4677263498306274
desired expected reward: -24.51887321472168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-7.78176  ]
 [-8.099625 ]
 [-7.224001 ]
 [-7.4612484]
 [-7.118945 ]
 [-7.568163 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  5.  9.  7.] 
adversary cards in hand: [ 0. 14. 10.  3. 10.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -2.236528158187866
desired expected reward: -9.804692268371582



buy possibilites: [-1] 
expected returns: [[-9.464144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 14. 10.  3. 10.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -31 

action type: buy - action 10.0
Learning step: -1.4069960117340088
desired expected reward: -8.525941848754883






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  3. 10.] 
cards in discard: [ 8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 8. 1. 6. 6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [ 8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 1. 6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [ 8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  8.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 1. 6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [ 8. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 1. 6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
adversary victory points: -4
player victory points: 2 





Player: 0 
cards in hand: [8. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-7.568163]
 [-8.152023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10 11] -> size -> 17 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[   -5     0    -4   -60     0     0     0     0     0     0     0     0
     0 -2700    62     0] 
sum of rewards: -2707 

action type: discard_down_to_3_cards - action 4
Learning step: -135.2281036376953
desired expected reward: -141.1374969482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-7.785427 ]
 [-7.2221365]
 [-7.5762577]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 20. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10 11] -> size -> 17 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -3.2375283241271973
desired expected reward: -10.805692672729492



buy possibilites: [-1] 
expected returns: [[-7.2721233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
adversary owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10 11] -> size -> 17 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -50 

action type: buy - action 3.0
Learning step: -2.302516222000122
desired expected reward: -9.524651527404785






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8 10 10  0  0  0  0  3  0  0  3  0 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 10. 11. 14.  0. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-7.952634]
 [-7.691581]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  6.  6.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -2.7104873657226562
desired expected reward: -9.982610702514648



action possibilites: [-1.] 
expected returns: [[-8.246104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -37 

action type: take_action - action 10.0
Learning step: -1.6520172357559204
desired expected reward: -9.322420120239258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.410774]
 [-8.59974 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [10.  6. 11. 29.  0.  0.  3. 10. 15.  6.  6.  6.  3.  6.  3.  8.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -1.6857484579086304
desired expected reward: -9.931852340698242






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  8 10 10  3  0  0  3  0 10 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [15.  0.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [15.  0.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [15.  0.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [15.  0.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[6.7050962]
 [3.5480964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8. 10. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -1.8315504789352417
desired expected reward: -10.431289672851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[3.2385013]
 [6.509098 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8. 10. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.6187455654144287
desired expected reward: 4.317521095275879



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10. 10.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1.  8. 10. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 11.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10. 11.] 
cards in discard: [8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [15.  0.  3.  3.  6.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.394945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [15.  0.  3.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -2.6231637001037598
desired expected reward: 3.8859314918518066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-1.8867997 ]
 [-0.37454677]
 [-0.6167691 ]
 [-1.3274215 ]
 [ 1.5567088 ]
 [-0.25482368]
 [-2.521224  ]
 [-0.77762115]
 [-1.0781645 ]
 [ 3.4791822 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [15.  0.  3.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  8.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.4324347972869873
desired expected reward: -1.0859711170196533



buy possibilites: [-1] 
expected returns: [[-5.9604034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [15.  0.  3.  3.  6. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -16 

action type: buy - action 16.0
Learning step: -0.8677382469177246
desired expected reward: -2.1951565742492676






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  6. 10.  6.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 19. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  6. 10.  6.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 14.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  6. 10.  6.  6.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [ 6.  6. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-8.700817]
 [-8.047432]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  6.  6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 10. 10. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  3. 14.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -2.775953769683838
desired expected reward: -8.736356735229492



action possibilites: [-1.  8.] 
expected returns: [[-9.803342]
 [-9.147318]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 8.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6 15  6  3  3 10  6 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11
 10  3 16] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 10. 10. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  3. 14.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action 10.0
Learning step: -1.7432972192764282
desired expected reward: -9.067410469055176



action possibilites: [-1.] 
expected returns: [[-5.3661733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 10. 10. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  3. 14.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.9833237528800964
desired expected reward: -6.097929000854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.8400292]
 [-4.627194 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 10. 10. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  3. 14.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.9274827241897583
desired expected reward: -4.438690662384033



buy possibilites: [-1] 
expected returns: [[-9.308219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 8.  8. 10. 10. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  3. 14.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: -0.7674335837364197
desired expected reward: -4.607460975646973






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10. 10. 11.] 
cards in discard: [ 3.  0. 10.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  6.  3.  6. 11.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10. 10. 11.] 
cards in discard: [ 3.  0. 10.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  6.  3.  6. 11.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10. 10. 11.] 
cards in discard: [ 3.  0. 10.  0.  3. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  6.  3.  6. 11.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0] -> size -> 25 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [29.  6.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-11.302869]
 [-19.961922]
 [-14.378743]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6. 11.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  7.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -1.1021785736083984
desired expected reward: -10.41039752960205



action possibilites: [-1] 
expected returns: [[0.71462464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: gain_card_n - action 5
Learning step: 1.8273060321807861
desired expected reward: -23.397233963012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.6348867]
 [ 0.5430989]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  6.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3.  3. 10. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -0.2913776934146881
desired expected reward: 0.42324694991111755






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [10.  3.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 6.  6. 10.  3. 10.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29. 11. 29.
  6.  3.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29. 11. 29.
  6.  3.  6.  6.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29. 11. 29.
  6.  3.  6.  6.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 10.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29. 11. 29.
  6.  3.  6.  6.  6.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-9.725629 ]
 [-7.5621247]
 [-7.5621247]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [15.  0.  3.  3.  6. 16.  0.  0.  1.  3.  3.  0. 10.  8.  6. 29. 11. 29.
  6.  3.  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 3. 14. 10.  3.  3. 10.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -30     0     0     0   -30     0     0     0     0
     0 -1800    89     0] 
sum of rewards: -1776 

action type: discard_down_to_3_cards - action 4
Learning step: -88.6391372680664
desired expected reward: -95.42164611816406



action possibilites: [-1. 10. 15.] 
expected returns: [[3.6614323]
 [2.3979053]
 [2.0524745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 3. 14. 10.  3.  3. 10.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -0.30027735233306885
desired expected reward: -7.862401008605957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.493876]
 [2.939787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [ 3. 14. 10.  3.  3. 10.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -0.8750553131103516
desired expected reward: 2.7863807678222656






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [ 3. 14. 10.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 1.] 
adversary cards in discard: [10.  3. 10. 15.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 3. 14. 10.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  7.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 1.] 
adversary cards in discard: [10.  3. 10. 15.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 14. 10.  3.  3. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  6.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 1.] 
adversary cards in discard: [10.  3. 10. 15.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 14. 10.  3.  3. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  6.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 1.] 
adversary cards in discard: [10.  3. 10. 15.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 14. 10.  3.  3. 10. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [3. 6. 3. 6. 1.] 
adversary cards in discard: [10.  3. 10. 15.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-9.356614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 1.] 
cards in discard: [10.  3. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -2.0496137142181396
desired expected reward: -0.25515317916870117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-9.081355 ]
 [-8.5234165]
 [-9.424489 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 1.] 
cards in discard: [10.  3. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -1.4808216094970703
desired expected reward: -10.809290885925293



buy possibilites: [-1] 
expected returns: [[-9.139842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 1.] 
cards in discard: [10.  3. 10. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -3.0015788078308105
desired expected reward: -12.08293342590332






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16.  0.  3. 11.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 16.  0.  3. 11.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1.] 
adversary owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 16.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-2.5926614]
 [-3.0412793]
 [-2.5649726]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3. 11.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16
  0 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  5.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [14.  3.  8. 10.  3.] 
adversary cards in discard: [ 3. 11.  0. 11.  8.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -1.345945954322815
desired expected reward: -10.485788345336914



action possibilites: [-1] 
expected returns: [[-7.678522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [14.  3.  8. 10.  3.] 
adversary cards in discard: [ 3. 11.  0. 11.  8.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -17 

action type: gain_card_n - action 4
Learning step: -0.7913702726364136
desired expected reward: -5.4193010330200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-11.18984  ]
 [ -9.062096 ]
 [ -7.0151567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [14.  3.  8. 10.  3.] 
adversary cards in discard: [ 3. 11.  0. 11.  8.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -1.0972329378128052
desired expected reward: -8.775754928588867






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [14.  3.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 10.  3.] 
cards in discard: [ 3. 11.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  3.  8.  6.  3.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.] 
cards in discard: [ 3. 11.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  8.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  3.] 
cards in discard: [ 3. 11.  0. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [29.  8.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [29.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-8.799591]
 [-8.737138]
 [-8.751682]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0. 10.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 11.  8. 14.  3.  8. 10.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -40     0     0     0   -60     0     0     0     0
     0 -1800    81     0] 
sum of rewards: -1825 

action type: discard_down_to_3_cards - action 4
Learning step: -91.10228729248047
desired expected reward: -97.99480438232422



action possibilites: [-1.  8.] 
expected returns: [[-7.188656 ]
 [-8.2428055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0. 10.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 11.  8. 14.  3.  8. 10.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: discard_n_cards - action 0
Learning step: -1.0558397769927979
desired expected reward: -9.292465209960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.008696]
 [-7.385166]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0. 10.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 11.  8. 14.  3.  8. 10.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -1.1102389097213745
desired expected reward: -8.298892974853516



buy possibilites: [-1] 
expected returns: [[2.0235097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  0. 10.  0. 10.] 
adversary cards in discard: [ 3. 11.  0. 11.  8. 14.  3.  8. 10.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -56.0 

action type: buy - action 0.0
Learning step: -2.354036331176758
desired expected reward: -10.36273193359375






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [11.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0. 10.] 
cards in discard: [ 3. 11.  0. 11.  8. 14.  3.  8. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 17. 30.  8.  0.  7.  4.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-8.799591]
 [-7.777074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  3. 14.  8. 10.] 
adversary cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -2.5819079875946045
desired expected reward: -0.5583982467651367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-8.236626]
 [-7.979203]
 [-8.799591]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 17. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  3. 14.  8. 10.] 
adversary cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -2.0435922145843506
desired expected reward: -10.843183517456055



buy possibilites: [-1] 
expected returns: [[-9.554228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [10.  3. 10. 15.  0.  3.  6.  3.  6.  1. 11. 16.  0.  0. 11.  3.  3.  6.
  6.  0. 29.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [11.  3. 14.  8. 10.] 
adversary cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 3.0
Learning step: -1.1433943510055542
desired expected reward: -9.574912071228027






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [11.  3. 14.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.  8. 10.] 
cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 15.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  8. 10.] 
cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 15.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  8. 10.] 
cards in discard: [ 1. 11. 10. 10. 11.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 3.  0. 15.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 15.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[-9.034878 ]
 [-7.1617956]
 [-9.023787 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  6. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  0  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0
 29  0 11  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 10. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -1.4398001432418823
desired expected reward: -10.994028091430664



action possibilites: [-1] 
expected returns: [[0.7588029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 10. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: -0.3902962803840637
desired expected reward: -7.242909908294678





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-0.9841665 ]
 [ 0.21492696]
 [-0.6286881 ]
 [ 0.5900929 ]
 [-0.7967979 ]
 [ 0.32407665]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 30. 16. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 10. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -0.7836976051330566
desired expected reward: -0.02489471435546875



buy possibilites: [-1] 
expected returns: [[-7.689188]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [10. 10. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -2.0 

action type: buy - action 3.0
Learning step: -0.24157178401947021
desired expected reward: -0.8702706098556519






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [10. 10. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 10. 11.  8. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 11.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0] -> size -> 18 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  1.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [14  8  8 10 10  0  3  0 10 11  3  0  3 11 11  1 11  0  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11.  8.] 
owned cards: [14  8  8 10 10  0  0 10  3  0  3 11 11  1 11  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10. 11.  8.] 
owned cards: [14  8  8 10 10  0  0 10  3  0  3 11 11  1 11  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 14. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  8. 11. 16. 11.] 
adversary cards in discard: [ 3. 15.  3.  6. 29.] 
adversary owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
adversary victory points: 1
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 1 
Workshop: 1 
Chapel: 1 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  8. 11. 16. 11.] 
cards in discard: [ 3. 15.  3.  6. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  3  3 10 29  6  6  6  0  1  6  6  3  6  3 10  0 11 10  3 16  0 29
  0 11  0  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 14. 30.  8.  0.  7.  3.  0. 10.  6.  9. 10.  4.  9.  7.] 
adversary cards in hand: [1.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [14  8  8 10 10  0  0 10  3  0  3 11 11  1 11  0  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -20    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -524 

action type: buy - action -1
Learning step: -25.815540313720703
desired expected reward: -33.504730224609375



