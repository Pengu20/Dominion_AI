 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[92.68519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -300        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000305 

action type: buy - action -1
Learning step: -120009.9609375
desired expected reward: -120066.0859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 78.853714]
 [ 97.255135]
 [ 87.96994 ]
 [ 55.930634]
 [ 91.37327 ]
 [100.24637 ]
 [ 90.82855 ]
 [108.85531 ]
 [ 67.488396]
 [ 81.62691 ]
 [ 85.80627 ]
 [ 92.367966]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.15363311767578



buy possibilites: [-1] 
expected returns: [[94.261696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 108.85529327392578






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.33967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.2616958618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 85.57927 ]
 [105.45476 ]
 [ 95.40327 ]
 [ 62.65755 ]
 [108.5964  ]
 [ 98.492485]
 [ 88.54292 ]
 [100.22057 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.42945861816406



buy possibilites: [-1] 
expected returns: [[87.81616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.59637451171875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 93.66366]
 [101.65537]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.816162109375



action possibilites: [-1] 
expected returns: [[82.16494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.7079849243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[64.2768  ]
 [82.863144]
 [73.18144 ]
 [41.481785]
 [85.868095]
 [76.109566]
 [66.983894]
 [77.70067 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.1649398803711



buy possibilites: [-1] 
expected returns: [[76.59582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.86809539794922






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [16.  3.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[71.90184]
 [87.18171]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.59581756591797



action possibilites: [-1.] 
expected returns: [[92.31489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.8504638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.28888 ]
 [ 99.419815]
 [ 90.81588 ]
 [ 60.98692 ]
 [ 93.99971 ]
 [102.018265]
 [ 93.491264]
 [109.11315 ]
 [ 71.66746 ]
 [ 84.88735 ]
 [ 88.79839 ]
 [ 94.93185 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.31488800048828



buy possibilites: [-1] 
expected returns: [[92.59434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.11315155029297






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [16.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.76293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.5943374633789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.384586]
 [75.565094]
 [66.43472 ]
 [36.973343]
 [69.80684 ]
 [78.32299 ]
 [69.27285 ]
 [85.8475  ]
 [47.13746 ]
 [60.142467]
 [64.29486 ]
 [70.81917 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.54361724853516



buy possibilites: [-1] 
expected returns: [[75.034775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.84749603271484






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[122.77445]
 [139.50134]
 [139.50134]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.03477478027344



action possibilites: [-1. 29.] 
expected returns: [[124.375175]
 [143.0382  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.33612060546875



action possibilites: [-1. 11.] 
expected returns: [[148.66745]
 [156.75392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 143.0382080078125



action possibilites: [-1] 
expected returns: [[151.15874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 167.1167449951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[143.51405]
 [160.0082 ]
 [151.7201 ]
 [122.77506]
 [154.77574]
 [162.59256]
 [154.2919 ]
 [169.63283]
 [133.40665]
 [146.01755]
 [149.78448]
 [155.7085 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.1587371826172



buy possibilites: [-1] 
expected returns: [[162.11348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 169.63284301757812






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[59.17037 ]
 [71.1979  ]
 [50.616474]
 [65.16316 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 162.1134796142578



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[71.76449 ]
 [64.462166]
 [77.85308 ]
 [83.9809  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.62854766845703



action possibilites: [-1. 10. 11.] 
expected returns: [[91.384346]
 [84.03094 ]
 [97.62857 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.98090362548828



action possibilites: [-1] 
expected returns: [[111.99186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 105.27864074707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[106.041954]
 [119.37603 ]
 [112.68692 ]
 [ 96.02357 ]
 [ 89.83158 ]
 [115.14394 ]
 [121.40803 ]
 [114.76305 ]
 [137.19911 ]
 [126.918205]
 [ 97.986275]
 [111.507996]
 [108.07394 ]
 [ 98.35494 ]
 [111.12708 ]
 [115.960075]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.99185943603516



buy possibilites: [-1] 
expected returns: [[128.74576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 137.19911193847656






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[134.35577 ]
 [124.064095]
 [149.33023 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29.  3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 16.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.74575805664062



action possibilites: [-1. 10. 11.] 
expected returns: [[174.56927]
 [164.71448]
 [181.59352]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 16.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 145.0054168701172



action possibilites: [-1] 
expected returns: [[173.47287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 16.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 191.1680908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[165.83315]
 [173.8865 ]
 [145.80234]
 [176.40552]
 [177.8432 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 16.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 173.47286987304688






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 16.] 
cards in discard: [8. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 16  0  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[68.67899 ]
 [81.843994]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 10.  0.  0. 10. 29. 11.  3.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 177.84320068359375



action possibilites: [-1. 11.] 
expected returns: [[101.847275]
 [107.01223 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.52950286865234



action possibilites: [-1] 
expected returns: [[99.384636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.84888458251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.01671 ]
 [106.654884]
 [100.23738 ]
 [ 78.13259 ]
 [102.537476]
 [108.73023 ]
 [102.181435]
 [114.35032 ]
 [ 86.2976  ]
 [ 95.92049 ]
 [ 98.779205]
 [103.30581 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.38463592529297



buy possibilites: [-1] 
expected returns: [[178.04001]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.3503189086914






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  9.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  0. 10. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 29.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10.] 
expected returns: [[148.82642]
 [140.28578]
 [161.1733 ]
 [140.28578]
 [140.28578]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 10. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 178.04000854492188



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[146.49983]
 [136.60995]
 [136.60995]
 [136.60995]
 [160.20833]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 157.611328125



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[165.01233]
 [155.1279 ]
 [155.1279 ]
 [155.1279 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 160.20834350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[155.93791]
 [172.64287]
 [164.26323]
 [134.68188]
 [175.18929]
 [166.8648 ]
 [158.48486]
 [168.36957]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  8.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 165.01234436035156



buy possibilites: [-1] 
expected returns: [[195.73428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 175.18930053710938






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  0  8  0 29  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  7.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  7.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  6.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 87.85247]
 [ 93.02029]
 [107.90405]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 25.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  9.  6.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 195.73428344726562



action possibilites: [-1] 
expected returns: [[100.819496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  6.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.90406036376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.97265 ]
 [106.65252 ]
 [ 98.18911 ]
 [ 69.52745 ]
 [109.265656]
 [100.75443 ]
 [ 92.48603 ]
 [102.25057 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  6.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.81949615478516



buy possibilites: [-1] 
expected returns: [[100.73125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  0. 29.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11. 29. 29. 10.  0. 10. 10.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 109.26565551757812






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  5.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0. 15. 11. 29. 16.  0.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[93.661674]
 [85.45379 ]
 [85.45379 ]
 [85.45379 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.73124694824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[84.08247 ]
 [90.981575]
 [67.28118 ]
 [93.17387 ]
 [94.50251 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.47740173339844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 29. 10. 11. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 29. 10. 11. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  4.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 29. 10. 11. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 29. 10. 11. 25.] 
adversary cards in discard: [ 0. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11. 29. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 11. 25.] 
expected returns: [[124.80598]
 [131.068  ]
 [137.80023]
 [116.30084]
 [131.068  ]
 [150.58867]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 11. 25.] 
cards in discard: [ 0. 10.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  9.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.50251007080078



action possibilites: [-1] 
expected returns: [[108.45385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 11. 11. 10.] 
cards in discard: [ 0. 10.  0. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 147.43655395507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 91.339355]
 [ 74.19557 ]
 [101.98705 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 10. 11. 11. 10.] 
cards in discard: [ 0. 10.  0. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.45384979248047






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 15.  0.  8.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 15.  0.  8.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[74.56403]
 [84.50068]
 [84.50068]
 [84.50068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.9870376586914



action possibilites: [-1. 29. 29.] 
expected returns: [[70.143555]
 [80.34583 ]
 [80.34583 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  3.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.50066375732422



action possibilites: [-1. 29.] 
expected returns: [[ 96.778  ]
 [108.17241]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.3458480834961



action possibilites: [-1. 11.] 
expected returns: [[132.21811]
 [138.16858]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.17240142822266



action possibilites: [-1] 
expected returns: [[133.87712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 145.45608520507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[123.5407  ]
 [138.67352 ]
 [117.554474]
 [130.63823 ]
 [114.34644 ]
 [108.35998 ]
 [133.6403  ]
 [141.08563 ]
 [133.14262 ]
 [160.06601 ]
 [147.72528 ]
 [116.14669 ]
 [129.24255 ]
 [125.34031 ]
 [116.51801 ]
 [128.74489 ]
 [134.38394 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.8771209716797



buy possibilites: [-1] 
expected returns: [[153.57544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 11.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 160.06600952148438






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 11.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8.  9.  3.  8.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25. 29. 29. 29. 11.
  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  8.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25. 29. 29. 29. 11.
  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  8.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25. 29. 29. 29. 11.
  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25. 29. 29. 29. 11.
  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[66.932945]
 [76.49642 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [ 0. 10.  0. 10. 10. 25. 11. 29. 10. 11. 11. 10. 10. 25. 29. 29. 29. 11.
  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.575439453125



action possibilites: [-1. 10.] 
expected returns: [[118.03485]
 [110.71728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.49642181396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[110.584335]
 [123.059395]
 [116.79156 ]
 [ 95.278625]
 [124.962   ]
 [118.73875 ]
 [112.47187 ]
 [119.84518 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  3.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.03486633300781



buy possibilites: [-1] 
expected returns: [[134.92749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  2.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 124.96195220947266






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  0.  0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15 11  6 11 11  6  1
  1  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  2.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10. 11. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10. 11. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10. 11. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 15.  0.  8.  0.  6.  1.  0.  0.  0.  0.  6.  1.  8. 11. 29.  0.  3.
  0. 11.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  8.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10. 11. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25. 10. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 11. 29.] 
expected returns: [[ 87.67242 ]
 [109.65906 ]
 [ 79.949165]
 [ 79.949165]
 [ 93.18896 ]
 [ 98.83305 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10. 11. 29.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  8.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 11.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.927490234375



action possibilites: [-1] 
expected returns: [[75.13743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 29.  0.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 11.  8.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.65906524658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.148926]
 [72.59378 ]
 [52.798336]
 [74.691124]
 [75.82307 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 29.  0.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 1. 11.  8.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.1374282836914






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8.  8.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8.  8.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8.  8.  3.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  3. 29.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[69.82729]
 [60.65015]
 [76.33048]
 [82.85993]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 29.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  1.  0.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.82306671142578



action possibilites: [-1. 10. 11.] 
expected returns: [[102.36373 ]
 [ 94.231865]
 [108.363106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  1.  0.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.85993194580078



action possibilites: [-1] 
expected returns: [[88.821304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  1.  0.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.49296569824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.126114]
 [93.57656 ]
 [85.82098 ]
 [64.82059 ]
 [96.03972 ]
 [88.19067 ]
 [80.9372  ]
 [89.55223 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  1.  7.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  1.  0.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.82130432128906



buy possibilites: [-1] 
expected returns: [[84.00346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  1.  0.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 96.03971099853516






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  1.  0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  1
  8 11  1  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 29. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 10.] 
expected returns: [[54.264378]
 [47.09741 ]
 [65.65118 ]
 [65.65118 ]
 [47.09741 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 10.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.00346374511719



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[55.879623]
 [48.437542]
 [48.437542]
 [61.08508 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.50880813598633



action possibilites: [-1] 
expected returns: [[76.40131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0. 29. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.79928588867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[67.81785 ]
 [73.60222 ]
 [53.035645]
 [75.42404 ]
 [76.370316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [11. 29.  3.  0.  3.  0. 10. 25. 10. 10. 11. 29.  0.  0. 10. 11. 29. 11.
  0. 10.  3.  0. 29. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.40131378173828






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  3.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  3.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[69.59568]
 [74.58642]
 [88.98305]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  7.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.37032318115234



action possibilites: [-1] 
expected returns: [[91.86967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.98307037353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[83.114075]
 [97.57279 ]
 [90.31985 ]
 [65.23167 ]
 [92.570786]
 [85.317825]
 [93.87765 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.86966705322266



buy possibilites: [-1] 
expected returns: [[83.43904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0. 29.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 6.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 97.57280731201172






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 10. 25.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 6.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [29. 10. 25.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25. 10.] 
expected returns: [[ 87.1214  ]
 [ 96.54437 ]
 [ 80.3912  ]
 [105.362755]
 [ 80.3912  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 25.  0. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  6.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.43904113769531



action possibilites: [-1] 
expected returns: [[58.108585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 10.  3.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.36276245117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.41468 ]
 [55.672337]
 [33.421524]
 [57.63289 ]
 [58.73287 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0. 10.  3.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 8. 15.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.108585357666016






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0. 11.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8 15  6 11 11  6  1  8
 11  1  6  0 10  3  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  1. 11.  8.  8.  3. 10.  3. 16.  0.  0.  0.  6.  0.  0. 11.  3.
  6.  0.  0.  0.  1.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 29. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [10. 29. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10. 11.] 
expected returns: [[ 90.32318]
 [ 82.2949 ]
 [102.54352]
 [ 96.28204]
 [ 82.2949 ]
 [ 96.28204]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 10. 11.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.73289108276367



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[88.042114]
 [94.30216 ]
 [80.26794 ]
 [94.30216 ]
 [80.26794 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 94.06070709228516



action possibilites: [-1] 
expected returns: [[89.64304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 102.22525024414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.25717 ]
 [62.79987 ]
 [89.615204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.6430435180664






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 29. 10.  0. 29.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 29. 10.  0. 29.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [15. 29. 10.  0. 29.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [15. 29. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10. 29.] 
expected returns: [[63.468845]
 [60.163265]
 [71.68689 ]
 [58.030293]
 [71.68689 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 10.  0. 29.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.61521911621094



action possibilites: [-1. 15. 10.] 
expected returns: [[78.06609]
 [73.96952]
 [71.41469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 65.97195434570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[69.15759 ]
 [80.44477 ]
 [74.71339 ]
 [55.063915]
 [76.45201 ]
 [70.86113 ]
 [77.49305 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.06611633300781



buy possibilites: [-1] 
expected returns: [[73.87092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 80.44478607177734






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 11. 11. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1] -> size -> 34 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  7.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 11. 11. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1] -> size -> 34 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [11.  3. 11. 11. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1] -> size -> 34 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [11.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[67.2005  ]
 [70.87837 ]
 [70.87837 ]
 [70.87837 ]
 [62.054874]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  7.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.87091827392578



action possibilites: [-1] 
expected returns: [[50.421734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.7089614868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.252697]
 [34.19621 ]
 [50.159008]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 11.  0. 29. 25. 29. 10.  0. 10.  3.  0. 10. 15. 29.
 11. 10. 11. 10. 29.  1. 29. 15. 10.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.42173385620117






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  1.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  0.  1.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[66.70846 ]
 [60.619427]
 [60.619427]
 [70.93527 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [6. 1. 8. 8. 6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.15901565551758



action possibilites: [-1] 
expected returns: [[80.43975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [6. 1. 8. 8. 6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.15792083740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.33942 ]
 [77.008255]
 [56.862167]
 [78.87114 ]
 [79.94774 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [6. 1. 8. 8. 6.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.43975067138672






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 1. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 8. 8. 6.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 8. 8. 6.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 8. 8. 6.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [29. 11.  0. 29. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [29. 11.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 11.] 
expected returns: [[ 98.51695 ]
 [110.078125]
 [104.25635 ]
 [110.078125]
 [104.25635 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29. 11.] 
cards in discard: [15. 11. 10. 10.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.94774627685547



action possibilites: [-1. 11. 11.] 
expected returns: [[118.33079]
 [123.31159]
 [123.31159]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 102.10819244384766



action possibilites: [-1] 
expected returns: [[128.00986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.63644409179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[117.695305]
 [132.15904 ]
 [124.64918 ]
 [100.12404 ]
 [126.86448 ]
 [119.80318 ]
 [128.24327 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.00985717773438



buy possibilites: [-1] 
expected returns: [[90.65362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 132.15904235839844






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [10.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  1. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  1. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  3.  0.  1. 11.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0.  3.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 95.30964]
 [100.44752]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 11.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3.  6.  0. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.65361785888672



action possibilites: [-1] 
expected returns: [[112.75126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  6.  0. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 106.75081634521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.87982 ]
 [115.94752 ]
 [108.09664 ]
 [ 84.09317 ]
 [110.99217 ]
 [110.537094]
 [124.80578 ]
 [ 92.648285]
 [102.90499 ]
 [106.26682 ]
 [111.911545]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  4. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  6.  0. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.75125885009766



buy possibilites: [-1] 
expected returns: [[138.44714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11.  3.  6.  0. 11.] 
adversary cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 124.80579376220703






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [11.  3.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0. 11.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  3. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11. 10. 11.  3. 25.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11. 10. 11.  3. 25.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 11.] 
cards in discard: [ 1.  0.  3.  0.  0. 29.  8.  0.  0.  6.  3.  0.  8. 16.  0.  0.  1.  0.
  6.  1.  8.  8.  6.  1. 10.  0.  6.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [11. 10. 11.  3. 25.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [11. 10. 11.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 25.] 
expected returns: [[46.804325]
 [50.0763  ]
 [42.14438 ]
 [50.0763  ]
 [62.65257 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  3. 25.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  5.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  0.  8. 16.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.4471435546875



action possibilites: [-1] 
expected returns: [[44.71059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  3. 29. 10.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  0.  8. 16.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.6525764465332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.438156]
 [25.96732 ]
 [44.220715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  3. 29. 10.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 6.  0.  8. 16.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.71059036254883






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  8. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 16.  6.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  8  0 29  0  8  6 11  6  1  8 11  1  6
  0 10  3  6  6  0  1  8  0  1 29  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  2. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 25. 15. 15.  0.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 6. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 25. 15. 15.  0.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 6. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 25. 15. 15.  0.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 6. 29.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 25. 15. 15.  0.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 1. 25. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15.] 
expected returns: [[33.805637]
 [43.14958 ]
 [31.694607]
 [31.694607]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15. 15.  0.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 28. 30.  8.  4.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.22071838378906



action possibilites: [-1] 
expected returns: [[11.808192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.  0. 15. 10.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.14958572387695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 7.378357  ]
 [13.34084   ]
 [10.349738  ]
 [-0.04842043]
 [11.282451  ]
 [ 8.291355  ]
 [11.808185  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 15. 10.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.808192253112793



buy possibilites: [-1] 
expected returns: [[10.650918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 15. 10.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 13.340838432312012






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0
 10  3  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1. 25.  1. 15. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1. 25.  1. 15. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1. 25.  1. 15. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29. 29.] 
adversary cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1. 25.  1. 15. 15.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [10.  3. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[32.270557]
 [29.04808 ]
 [29.04808 ]
 [36.971523]
 [36.971523]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 29. 29.] 
cards in discard: [15. 11. 10. 10.  0.  0. 29. 15.  1. 29. 11.  0. 11.  0. 15. 29. 11.  0.
  3.  0.  1. 25. 11. 10. 11.  3. 29. 10.  1. 25.  1. 15. 15.  0. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.650918006896973



action possibilites: [-1. 10. 10. 29. 15.] 
expected returns: [[69.587944]
 [64.251755]
 [64.251755]
 [76.999596]
 [66.318825]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 15.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.792755126953125



action possibilites: [-1. 10. 10.] 
expected returns: [[83.769196]
 [78.44716 ]
 [78.44716 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1.] 
cards in discard: [ 3. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.89212799072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[77.51813 ]
 [86.633995]
 [81.932724]
 [66.70033 ]
 [83.6257  ]
 [83.361176]
 [92.35885 ]
 [72.25718 ]
 [78.81004 ]
 [80.86155 ]
 [84.180244]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.] 
cards in discard: [ 3. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  1. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 83.7691879272461



buy possibilites: [-1] 
expected returns: [[95.14587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1.] 
cards in discard: [ 3. 15. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  0.  1.  0. 29.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -70   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 92.35884094238281






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  0. 29.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 3. 11. 15. 10. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  0. 29.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 21. 30. 28. 30.  8.  3.  9.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 3. 11. 15. 10. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  0. 29.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 3. 11. 15. 10. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [ 3. 11. 15. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 29.] 
expected returns: [[ 94.497955]
 [ 99.23261 ]
 [ 90.26183 ]
 [ 87.58956 ]
 [104.05077 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15. 10. 29.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  6.  8.  8. 10.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.14586639404297



action possibilites: [-1. 15. 10.] 
expected returns: [[102.887566]
 [ 98.7976  ]
 [ 96.20186 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  6.  8.  8. 10.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 105.07080841064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.09395 ]
 [100.74066 ]
 [ 81.423195]
 [102.5107  ]
 [103.50873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 1.  6.  8.  8. 10.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.8875961303711






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  8.  8. 10.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 15.  0.  1. 15.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8. 8. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0  8  6 11  6  1  8 11  1  6  0 10  3
  6  6  0  1  8  0  1 29  6 29  0  6  0 16] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 15.  0.  1. 15.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 15.  0.  1. 15.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 15.  0.  1. 15.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [10. 15.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[74.28794 ]
 [67.72861 ]
 [70.278725]
 [70.278725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  1. 15.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.50875854492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[67.78995]
 [79.15768]
 [73.39679]
 [53.98722]
 [75.1901 ]
 [69.48625]
 [76.17435]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  1. 15.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 21. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.28794860839844



buy possibilites: [-1] 
expected returns: [[50.29298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  1. 15.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 79.1576919555664






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 25. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 25. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 20. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 25. 10. 10.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0.  1. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[25.801579]
 [41.10317 ]
 [21.339577]
 [21.339577]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 10. 10.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 28. 30.  8.  3.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1.  3.  3.  6.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.2929801940918



action possibilites: [-1] 
expected returns: [[36.786594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10. 10.  3. 11.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1.  3.  3.  6.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.10317611694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[30.085285]
 [37.43717 ]
 [33.61057 ]
 [21.063416]
 [34.720604]
 [31.163033]
 [35.338657]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10. 10.  3. 11.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 20. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1.  3.  3.  6.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.78659439086914



buy possibilites: [-1] 
expected returns: [[23.510517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10. 10.  3. 11.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29.  1.  3.  3.  6.] 
adversary cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 37.43716812133789






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [29.  1.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  3.  6.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 29. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  3.  6.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 29. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  3.  3.  6.] 
cards in discard: [ 6. 29.  0. 16.  6.  0.  6.  6.  0.  8.  0.  0. 16.  1.  0.  1.  0. 29.
 10.  8.  0.  0.  6.  3.  0.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 29. 11.  0.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [29. 15. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 11.] 
expected returns: [[11.2389765]
 [15.7322645]
 [ 9.2803335]
 [15.7322645]
 [13.473435 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 29. 11.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.510517120361328



action possibilites: [-1. 15. 25.] 
expected returns: [[ 7.007663 ]
 [ 4.8966665]
 [16.351376 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 25.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 19. 30. 28. 30.  8.  2.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 16.202503204345703



action possibilites: [-1] 
expected returns: [[12.59271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 19. 30. 28. 30.  8.  1.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.35137939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 7.9980164 ]
 [14.326644  ]
 [11.057561  ]
 [ 0.22448683]
 [12.03712   ]
 [ 8.928985  ]
 [12.59269   ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 19. 30. 28. 30.  8.  1.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.5927095413208



buy possibilites: [-1] 
expected returns: [[22.933502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.  0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 18. 30. 28. 30.  8.  1.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [16.  0.  0. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6] -> size -> 39 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  210    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 14.32666301727295






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [16.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11. 11.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 18. 30. 28. 30.  8.  1.  8.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 15.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 6. 16.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 15.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 6. 16.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 15.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 11.] 
cards in discard: [ 6. 16.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  1. 15.  0. 29.] 
adversary cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [ 0.  1. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[4.2795534]
 [2.54844  ]
 [8.316384 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  0. 29.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.933502197265625



action possibilites: [-1.] 
expected returns: [[27.729542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.5548505783081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.304333]
 [29.742195]
 [25.970741]
 [16.612976]
 [12.907622]
 [27.360966]
 [27.1278  ]
 [39.87258 ]
 [17.730724]
 [25.331215]
 [23.422169]
 [17.959332]
 [25.1026  ]
 [27.729538]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  8.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.729541778564453



buy possibilites: [-1] 
expected returns: [[19.559471]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3. 15. 29. 29. 29. 10. 10.  1.  3. 11. 29. 15. 10.  0.  1. 10. 15.  0.
  1. 15.  1. 25.  0.  1. 10. 10.  3. 11. 29. 11.  1. 29. 25. 15.  0. 11.
  0. 15. 11. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -110    0    0
  250    0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 39.87258529663086






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [29. 15. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 11. 10.] 
expected returns: [[41.02254 ]
 [48.74724 ]
 [37.62027 ]
 [44.862514]
 [44.862514]
 [35.468586]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.559471130371094



action possibilites: [-1. 11. 10.] 
expected returns: [[41.92893 ]
 [46.260616]
 [35.888653]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.] 
cards in discard: [15. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 18. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.431026458740234



action possibilites: [-1] 
expected returns: [[63.396343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.] 
cards in discard: [15. 11.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 17. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 44.582576751708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[56.16587 ]
 [65.6259  ]
 [60.881023]
 [45.83639 ]
 [62.354603]
 [57.609745]
 [63.210842]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [15. 11.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 17. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.39634323120117



buy possibilites: [-1] 
expected returns: [[116.87202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.] 
cards in discard: [15. 11.  1.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 65.62590026855469






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 29.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 10. 15. 25. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 29.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 16. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 10. 15. 25. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 29.] 
cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 16. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [10. 10. 15. 25. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [10. 10. 15. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15. 25. 29.] 
expected returns: [[68.241516]
 [62.783306]
 [62.783306]
 [64.90839 ]
 [83.78398 ]
 [76.14025 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15. 25. 29.] 
cards in discard: [15. 11.  1.  1. 29. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 28. 30.  8.  1.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [6. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.  0.  0.  0.  6.
  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0  0] -> size -> 43 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.87201690673828



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 3 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 10. 15. 29. 29.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11. 10.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 29 10 29 10 25 10 10 29 11
 11 10 25 11 10 11 15  1 15  1 15 15 15  1 15 29  1 29  1  1  1 25  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 28. 30.  8.  0.  7.  0.  6.  7.  0. 10. 10.  2. 10.  3.] 
adversary cards in hand: [6. 6. 1. 0. 0.] 
adversary cards in discard: [ 6. 16.  0. 11. 16.  0.  0. 11.  0.  0. 16.  3.  0.  6.  0.  0.  0.  6.
  0. 29.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  0  0  0 29  0 11  6  8 11  1  6  0 10  3  6  6  0
  1  8  0  1 29  6 29  0  6  0 16  0  6  0  6 16  0  0  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     240       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000255 

action type: take_action - action 25.0
Learning step: 120006.84375
desired expected reward: 120090.625



