 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[336.38745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -4  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -569 

action type: buy - action -1.0
Learning step: -35.42230987548828
desired expected reward: 104.02387237548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[318.66345]
 [318.73932]
 [318.71573]
 [318.66345]
 [320.06668]
 [322.18652]
 [320.45798]
 [327.04147]
 [322.06155]
 [320.4327 ]
 [323.81537]
 [334.76266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.624119758605957
desired expected reward: 328.9671630859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[360.0213]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.692697525024414
desired expected reward: 326.07000732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[342.24765]
 [342.32355]
 [342.29993]
 [342.24765]
 [345.7707 ]
 [344.04214]
 [344.01688]
 [358.34692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.270463943481445
desired expected reward: 351.7489929199219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.00522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.60926342010498
desired expected reward: 347.7376708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[309.4347 ]
 [309.5106 ]
 [309.48697]
 [309.49188]
 [309.4347 ]
 [310.83792]
 [312.95776]
 [311.2292 ]
 [316.1839 ]
 [317.8127 ]
 [312.83276]
 [314.19534]
 [311.20395]
 [312.4415 ]
 [314.58664]
 [325.5339 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.364174842834473
desired expected reward: 319.8839416503906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11.  3.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.82465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.094854354858398
desired expected reward: 317.4390869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[350.32034]
 [350.3726 ]
 [350.32034]
 [352.11484]
 [366.41956]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.38517951965332
desired expected reward: 357.69671630859375



buy possibilites: [-1] 
expected returns: [[367.6231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -10.844497680664062
desired expected reward: 339.475830078125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[360.93845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.303793907165527
desired expected reward: 357.3193054199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[346.2302 ]
 [346.30606]
 [346.2824 ]
 [346.2302 ]
 [349.75323]
 [348.02463]
 [347.99936]
 [362.3294 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.251799583435059
desired expected reward: 353.1864929199219



buy possibilites: [-1] 
expected returns: [[365.33875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -8.295180320739746
desired expected reward: 338.0108642578125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  8 11  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[384.88373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -9.197460174560547
desired expected reward: 356.14129638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[370.577  ]
 [370.65964]
 [370.63406]
 [370.577  ]
 [372.10715]
 [374.42075]
 [372.5348 ]
 [379.71503]
 [374.28378]
 [372.50784]
 [376.19672]
 [388.44443]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -10.2665433883667
desired expected reward: 375.0435485839844



buy possibilites: [-1] 
expected returns: [[388.48477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -10.88794231414795
desired expected reward: 359.6890563964844






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  9.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  9.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[369.4695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [ 8. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -10.65761947631836
desired expected reward: 377.8271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[352.1663 ]
 [352.2422 ]
 [352.2185 ]
 [352.1663 ]
 [353.5695 ]
 [355.68933]
 [353.96075]
 [360.54428]
 [355.56436]
 [353.93552]
 [357.3182 ]
 [368.2655 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [ 8. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -10.033227920532227
desired expected reward: 361.8164978027344



buy possibilites: [-1] 
expected returns: [[342.46133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [ 8. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 12.5 

action type: buy - action 10.0
Learning step: -8.293261528015137
desired expected reward: 324.1795349121094






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [ 8. 11. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [ 8. 11. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [ 8. 11. 11.  0.  0.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.22772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -8.899596214294434
desired expected reward: 333.5617370605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[332.45016]
 [332.51984]
 [332.49487]
 [332.45016]
 [335.87686]
 [334.19925]
 [334.16345]
 [348.16626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -9.2809476852417
desired expected reward: 338.4288635253906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.1077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [15.  3. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15  3] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.843701362609863
desired expected reward: 338.3226013183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[320.21072]
 [320.279  ]
 [320.21072]
 [320.25464]
 [320.25778]
 [320.21072]
 [321.53433]
 [323.5471 ]
 [321.9123 ]
 [326.63242]
 [328.17877]
 [323.4235 ]
 [324.7154 ]
 [321.87717]
 [323.0455 ]
 [325.0934 ]
 [335.5187 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [15.  3. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15  3] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.705431938171387
desired expected reward: 330.9440612792969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [15.  3. 11.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 11  0  8  0  8 11  8 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  3. 11.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  3. 11.  8.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  3. 11.  8.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[327.90622]
 [312.40564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 1. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -9.082219123840332
desired expected reward: 326.43646240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[312.68954]
 [312.7578 ]
 [312.73346]
 [312.68954]
 [316.0259 ]
 [314.39108]
 [314.35602]
 [329.40936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [0. 0. 0. 1. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.707602500915527
desired expected reward: 318.91375732421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.79694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 15.  3.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  8.] 
adversary owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.68750286102295
desired expected reward: 320.7218933105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.377  ]
 [310.43765]
 [310.41617]
 [310.377  ]
 [313.36856]
 [311.90262]
 [311.87195]
 [324.26782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 15.  3.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  8.] 
adversary owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.824860572814941
desired expected reward: 319.3070373535156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 15.  3.] 
cards in discard: [ 0.  0.  0.  8. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [ 0.  0.  0.  8. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 0.  0.  0.  8. 11.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  1.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[331.59958]
 [317.9581 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 10.  0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.416373252868652
desired expected reward: 315.8514099121094



action possibilites: [-1.] 
expected returns: [[343.27966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -6.734034061431885
desired expected reward: 311.4224853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[324.46954]
 [324.5378 ]
 [324.51346]
 [324.51657]
 [324.46954]
 [325.7931 ]
 [327.8059 ]
 [326.1711 ]
 [330.8913 ]
 [332.63086]
 [327.6823 ]
 [328.9742 ]
 [326.136  ]
 [327.3043 ]
 [329.3522 ]
 [340.9714 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -8.223395347595215
desired expected reward: 335.0562744140625



buy possibilites: [-1] 
expected returns: [[349.0513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 78 

action type: buy - action 25.0
Learning step: -4.790909767150879
desired expected reward: 326.100341796875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 11  0  8  0  8 11  8 15  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  8 11  8 15  3  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  8 11  8 15  3  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.40036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3  8  8  8 11  8 15  3  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -9.494830131530762
desired expected reward: 339.55645751953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[313.8945 ]
 [313.97107]
 [313.9439 ]
 [313.8945 ]
 [315.39972]
 [317.6834 ]
 [315.8266 ]
 [322.9471 ]
 [317.54376]
 [315.78705]
 [319.44012]
 [331.2877 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3  8  8  8 11  8 15  3  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -9.077983856201172
desired expected reward: 326.8213806152344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  8 11  8 15  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0. 10.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 11  8 15  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0. 10.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 11  8 15  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0. 10.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[344.045  ]
 [333.12198]
 [327.27744]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0. 10.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -8.50821590423584
desired expected reward: 322.7794494628906



action possibilites: [-1] 
expected returns: [[399.7899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 15. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  0  6] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 29 

action type: take_action - action 25.0
Learning step: -5.469884395599365
desired expected reward: 312.833251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[394.0556 ]
 [394.12952]
 [394.099  ]
 [394.0556 ]
 [395.56662]
 [397.878  ]
 [396.007  ]
 [403.2263 ]
 [397.73096]
 [395.95453]
 [399.65442]
 [411.67892]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 15. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  0  6] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -9.46561336517334
desired expected reward: 390.32427978515625



buy possibilites: [-1] 
expected returns: [[352.33102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.  0.] 
cards in discard: [ 0.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 15. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  0  6] -> size -> 10 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 32.5 

action type: buy - action 11.0
Learning step: -10.341452598571777
desired expected reward: 387.5365295410156






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 15. 11.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8 11  8 15  3  0  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 11  8 15  3  0  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 11  8 15  3  0  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.] 
cards in discard: [6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 11  8 15  3  0  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[308.80246]
 [299.35733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  6  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -9.76648998260498
desired expected reward: 342.5645446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[291.7649 ]
 [291.83078]
 [291.8035 ]
 [291.7649 ]
 [293.1107 ]
 [295.16238]
 [293.49802]
 [299.94196]
 [295.03302]
 [293.45016]
 [296.7453 ]
 [307.87512]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8 11  8 15  3  0  6  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.848632335662842
desired expected reward: 303.1171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8 11  8 15  3  0  6  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11  8 15  6] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11  8 15  6] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.0155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  6.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8  8 11  8 15  6] -> size -> 6 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: -6.4713311195373535
desired expected reward: 301.40380859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[295.1    ]
 [295.16006]
 [295.13495]
 [295.1    ]
 [296.35806]
 [298.3486 ]
 [296.7372 ]
 [302.95764]
 [298.2223 ]
 [296.69113]
 [299.8798 ]
 [310.23666]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 15.  6.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8  8 11  8 15  6] -> size -> 6 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: -6.8445658683776855
desired expected reward: 305.2632751464844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  6.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  8. 11.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 11  8 15  6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[292.75388]
 [278.95297]
 [277.02957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 10.] 
cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -7.640469551086426
desired expected reward: 302.59619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[276.71973]
 [276.76312]
 [276.71973]
 [278.67105]
 [294.34302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 10.] 
cards in discard: [ 0. 25.  0.  1.  3.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -6.714999675750732
desired expected reward: 285.2901306152344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[298.8031 ]
 [283.73886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -6.664781093597412
desired expected reward: 287.6781921386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[279.37918]
 [279.44388]
 [279.41714]
 [279.42007]
 [279.37918]
 [280.72427]
 [282.77512]
 [281.11273]
 [286.11932]
 [287.85507]
 [282.64526]
 [283.9658 ]
 [281.0662 ]
 [282.25684]
 [284.3646 ]
 [296.10745]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.021988868713379
desired expected reward: 292.0110778808594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3.  0.] 
adversary cards in discard: [10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3.  0.] 
adversary cards in discard: [10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3.  0.] 
adversary cards in discard: [10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[324.99484]
 [315.36423]
 [312.0045 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3.  0.] 
cards in discard: [10.  1.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -6.165721416473389
desired expected reward: 289.9417419433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[307.59644]
 [307.6373 ]
 [307.59644]
 [309.43192]
 [324.17023]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  3.  0.] 
cards in discard: [10.  1.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.6915154457092285
desired expected reward: 317.4299011230469



buy possibilites: [-1] 
expected returns: [[308.63034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  3.  0.] 
cards in discard: [10.  1.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 47 

action type: buy - action 3.0
Learning step: -6.087684154510498
desired expected reward: 301.5496520996094






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[273.6064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -7.334626197814941
desired expected reward: 301.29571533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[257.3361 ]
 [257.40018]
 [257.3735 ]
 [257.3361 ]
 [258.63788]
 [260.62842]
 [259.01706]
 [265.2375 ]
 [260.50217]
 [258.97092]
 [262.15967]
 [272.5165 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  1.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -5.697775363922119
desired expected reward: 267.49737548828125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[276.20355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -4.970347881317139
desired expected reward: 258.6354675292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[263.07553]
 [263.1058 ]
 [263.07553]
 [264.71393]
 [277.9557 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 28. 30.  8.  9. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -5.823075771331787
desired expected reward: 272.3965759277344



buy possibilites: [-1] 
expected returns: [[249.97722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -272.0 

action type: buy - action 6.0
Learning step: -21.129289627075195
desired expected reward: 241.9462432861328






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  1.  3.  0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[304.53662]
 [295.96948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  3.  0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -4.264338970184326
desired expected reward: 245.71287536621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[292.71588]
 [292.77484]
 [292.7463 ]
 [292.71588]
 [293.9728 ]
 [295.90198]
 [294.3444 ]
 [300.39767]
 [295.77875]
 [294.29068]
 [297.39005]
 [307.4767 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  3.  0.] 
cards in discard: [6. 0. 0. 3. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.081519603729248
desired expected reward: 298.5852966308594



buy possibilites: [-1] 
expected returns: [[288.04327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  3.  0.] 
cards in discard: [6. 0. 0. 3. 3. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 32.5 

action type: buy - action 1.0
Learning step: -6.532768249511719
desired expected reward: 286.2420654296875






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[288.45837]
 [277.1595 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -6.5601677894592285
desired expected reward: 281.48309326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[278.32712]
 [278.38498]
 [278.35703]
 [278.32712]
 [279.55402]
 [281.43564]
 [279.91452]
 [285.8252 ]
 [281.3155 ]
 [279.86194]
 [282.88925]
 [292.73456]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 6.  0.  0.  3.  3.  3.  1.  0. 25.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -6.568612098693848
desired expected reward: 282.26171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[254.84013]
 [243.16893]
 [241.54506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -7.554649353027344
desired expected reward: 285.1799011230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[241.59274]
 [241.62303]
 [241.59274]
 [243.23114]
 [256.4729 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -5.757859706878662
desired expected reward: 250.49021911621094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 6. 3.] 
adversary cards in discard: [11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[313.39276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [11.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -4.3673624992370605
desired expected reward: 252.1055450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[299.7948 ]
 [299.85263]
 [299.82477]
 [299.7948 ]
 [301.0393 ]
 [302.95084]
 [301.40784]
 [307.73618]
 [302.82794]
 [301.35596]
 [304.45068]
 [315.47095]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [11.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 28. 30.  8.  8. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -7.3072404861450195
desired expected reward: 306.3053283691406



buy possibilites: [-1] 
expected returns: [[299.87717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 3.] 
cards in discard: [11.  0.  3. 10.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -22.392505645751953
desired expected reward: 277.40228271484375






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 25.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 1. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[276.13074]
 [268.4453 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3.  0.  0.] 
cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -7.963461399078369
desired expected reward: 291.9136962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[267.0756 ]
 [267.12793]
 [267.10263]
 [267.0756 ]
 [268.1832 ]
 [269.88226]
 [268.5093 ]
 [273.84766]
 [269.77396]
 [268.46158]
 [271.19464]
 [280.34894]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  3.  0.  0.] 
cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 28. 30.  8.  7. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -6.767988681793213
desired expected reward: 269.6483459472656



buy possibilites: [-1] 
expected returns: [[264.27594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  3.  0.  0.] 
cards in discard: [11.  0.  3. 10.  0.  6.  1.  0.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -294.0 

action type: buy - action 6.0
Learning step: -21.795324325561523
desired expected reward: 245.2802734375






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[267.7288]
 [259.2569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -6.935064792633057
desired expected reward: 257.34088134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[250.45479]
 [250.51125]
 [250.48376]
 [250.45479]
 [253.60582]
 [252.0662 ]
 [252.01183]
 [265.0587 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -7.236885070800781
desired expected reward: 260.37353515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  6.  1.] 
adversary cards in discard: [25.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  6.  1.] 
adversary cards in discard: [25.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10.  6.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[301.21353]
 [287.22662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  6.  1.] 
cards in discard: [25.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -6.254133701324463
desired expected reward: 258.8045654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[284.44986]
 [284.48154]
 [284.44986]
 [286.1788 ]
 [300.10684]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  6.  1.] 
cards in discard: [25.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  6. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -8.111903190612793
desired expected reward: 292.7312927246094



buy possibilites: [-1] 
expected returns: [[287.47086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  6.  1.] 
cards in discard: [25.  3.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -23.0044002532959
desired expected reward: 261.4454650878906






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[259.62643]
 [247.67102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -8.835258483886719
desired expected reward: 278.6355895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[244.61494]
 [244.67245]
 [244.64442]
 [244.61494]
 [245.8475 ]
 [247.74277]
 [246.21376]
 [252.24504]
 [247.61887]
 [246.15912]
 [249.2025 ]
 [259.5899 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.524684906005859
desired expected reward: 252.4112548828125



buy possibilites: [-1] 
expected returns: [[253.9427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -6.619244575500488
desired expected reward: 239.53985595703125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[245.3778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.  0.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -7.441806316375732
desired expected reward: 246.5009002685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[229.4721 ]
 [229.5288 ]
 [229.50119]
 [229.4721 ]
 [230.68529]
 [232.55157]
 [231.04631]
 [236.89845]
 [232.42949]
 [230.99252]
 [233.98854]
 [243.73755]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [25.  3.  0.  0.  0.  6.  3. 10.  6.  6.  1. 10.  0.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.1124725341796875
desired expected reward: 237.56884765625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[262.96478]
 [248.86691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -6.567572116851807
desired expected reward: 237.1699676513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[248.32164]
 [248.32164]
 [264.10013]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.613365173339844
desired expected reward: 256.3880615234375



buy possibilites: [-1] 
expected returns: [[238.85468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  6.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: -8.791852951049805
desired expected reward: 239.52980041503906






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[284.6919 ]
 [271.89835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -5.858066082000732
desired expected reward: 232.99661254882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[271.8698 ]
 [271.8987 ]
 [271.8698 ]
 [273.45096]
 [286.1902 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -8.142112731933594
desired expected reward: 276.2513122558594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.55194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -8.347833633422852
desired expected reward: 277.8423156738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[253.67557]
 [253.73479]
 [253.70987]
 [253.71127]
 [253.67557]
 [254.86728]
 [256.68912]
 [255.21553]
 [259.50867]
 [260.90814]
 [256.56998]
 [257.7404 ]
 [255.17043]
 [256.2217 ]
 [258.08865]
 [267.5606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.814697265625
desired expected reward: 261.7001037597656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  6.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  6.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  6.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[205.19135]
 [197.26999]
 [194.49637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  3. 11.  0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.  1.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -9.107317924499512
desired expected reward: 258.4532775878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[191.44029]
 [191.44029]
 [205.10027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  3. 11.  0.] 
cards in discard: [ 0.  0.  6.  6. 10.  6.  3. 10.  0.  3.  0.  1.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.911011695861816
desired expected reward: 197.77684020996094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 25.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 25.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 25.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 25.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 6. 25.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[256.73837]
 [248.42046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.727412223815918
desired expected reward: 200.37286376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[244.34442]
 [244.4042 ]
 [244.37923]
 [244.34442]
 [245.57701]
 [247.45589]
 [245.93414]
 [251.8144 ]
 [247.33327]
 [245.88858]
 [248.90057]
 [258.68765]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.4744157791137695
desired expected reward: 251.16258239746094



buy possibilites: [-1] 
expected returns: [[202.39738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  0.  1.  0.] 
cards in discard: [14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: -6.4627227783203125
desired expected reward: 240.87054443359375






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  6.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  6.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  6.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14] -> size -> 25 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 1. 11.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[235.47191]
 [225.68178]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  6.  0.] 
cards in discard: [14.  6. 25.  0.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -5.129947185516357
desired expected reward: 197.26744079589844



action possibilites: [-1] 
expected returns: [[259.7622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: -4.219147682189941
desired expected reward: 221.05679321289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[250.74515]
 [250.79364]
 [250.7732 ]
 [250.74515]
 [253.24384]
 [252.0233 ]
 [251.98671]
 [262.4369 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -6.429539680480957
desired expected reward: 253.33267211914062



buy possibilites: [-1] 
expected returns: [[257.76376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: -7.487571716308594
desired expected reward: 243.257568359375






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 10.  0.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[186.40675]
 [175.30998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -9.02798080444336
desired expected reward: 248.73577880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[173.86337]
 [173.91312]
 [173.89207]
 [173.86337]
 [176.38292]
 [175.15138]
 [175.11324]
 [186.10966]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10.  0.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.421119213104248
desired expected reward: 179.7290802001953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.  0.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[217.73618]
 [206.38237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.  0.  6.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.722506046295166
desired expected reward: 181.3871612548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[202.99832]
 [203.02827]
 [202.99832]
 [204.34532]
 [215.86403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [14.  6. 25.  0.  1.  0. 10.  0. 11.  1.  3.  6.  0.  0.  6.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -6.360980033874512
desired expected reward: 210.98721313476562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[263.327  ]
 [250.23637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.194637298583984
desired expected reward: 210.6693878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.0589 ]
 [247.1001 ]
 [247.0589 ]
 [248.69783]
 [261.76205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.4230546951293945
desired expected reward: 251.5379180908203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.97415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -6.350619792938232
desired expected reward: 255.41140747070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[295.828  ]
 [295.90567]
 [295.87756]
 [295.87946]
 [295.828  ]
 [297.3455 ]
 [299.64883]
 [297.78094]
 [303.18884]
 [304.95248]
 [299.4994 ]
 [300.97708]
 [297.73572]
 [299.064  ]
 [301.4125 ]
 [313.34674]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  0.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -8.864948272705078
desired expected reward: 301.6897888183594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  1. 11.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  1. 11.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  1. 11.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  1. 11.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [25. 10.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
expected returns: [[301.7105 ]
 [291.4492 ]
 [285.94302]
 [287.87442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  1. 11.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -9.211928367614746
desired expected reward: 304.1347961425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[290.50342]
 [290.58124]
 [290.55328]
 [290.50342]
 [294.3626 ]
 [292.47632]
 [292.43124]
 [308.1987 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0.  1. 11.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  7.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -8.584121704101562
desired expected reward: 293.87841796875



buy possibilites: [-1] 
expected returns: [[267.65854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0.  1. 11.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -8.04581356048584
desired expected reward: 286.3168029785156






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 3.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 3.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 3.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 3.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [0. 6. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[280.96585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 1. 3.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -7.308941841125488
desired expected reward: 260.349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.95093]
 [260.02365]
 [259.99747]
 [259.95093]
 [263.51614]
 [261.7723 ]
 [261.73   ]
 [276.30222]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1. 3.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -8.220922470092773
desired expected reward: 272.8450927734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[261.99658]
 [248.62251]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -8.270048141479492
desired expected reward: 268.0321350097656



action possibilites: [-1.] 
expected returns: [[267.17032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -5.596983432769775
desired expected reward: 241.56932067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[254.1179 ]
 [254.16049]
 [254.1179 ]
 [255.78903]
 [269.12375]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [10.  0.  0.  6.  3.  0.  0.  0.  0.  0. 11. 25. 10.  0.  1. 11.  0.  6.
  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -6.67024564743042
desired expected reward: 260.50006103515625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 10.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [10.  6. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
expected returns: [[249.88206]
 [236.78268]
 [236.78268]
 [238.26001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -8.193277359008789
desired expected reward: 260.93048095703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[234.42812]
 [234.42812]
 [249.13066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.  0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -7.204677104949951
desired expected reward: 242.03067016601562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [10.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [10.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [10.  6. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[259.11752]
 [247.74327]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  1.] 
cards in discard: [10.  6. 10.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -6.942058086395264
desired expected reward: 242.1885986328125



action possibilites: [-1. 11.] 
expected returns: [[254.88338]
 [243.7534 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  1. 11.] 
cards in discard: [10.  6. 10.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -5.939006805419922
desired expected reward: 241.421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[239.91042]
 [239.97429]
 [239.91042]
 [239.95094]
 [239.95232]
 [239.91042]
 [241.14284]
 [243.01628]
 [241.49837]
 [245.89235]
 [247.32602]
 [242.89465]
 [244.0944 ]
 [241.46098]
 [242.53911]
 [244.44995]
 [254.14626]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  1. 11.] 
cards in discard: [10.  6. 10.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -6.389447212219238
desired expected reward: 248.49392700195312



buy possibilites: [-1] 
expected returns: [[245.7204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  1. 11.] 
cards in discard: [10.  6. 10.  0. 14. 23.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 23.0
Learning step: -4.809295177459717
desired expected reward: 229.45077514648438






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23] -> size -> 29 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23] -> size -> 29 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[226.58322]
 [217.89955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -7.517964839935303
desired expected reward: 238.2024383544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[217.01788]
 [217.0502 ]
 [217.01788]
 [218.25552]
 [228.12326]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 28. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -6.45186710357666
desired expected reward: 218.50901794433594



buy possibilites: [-1] 
expected returns: [[211.25574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 14 

action type: buy - action 3.0
Learning step: -5.399257659912109
desired expected reward: 211.65097045898438






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  3.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 25.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[208.72385]
 [202.62883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  3.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -5.646519660949707
desired expected reward: 205.60922241210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[198.56252]
 [198.59319]
 [198.56252]
 [199.73457]
 [209.07414]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.  3.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.404120922088623
desired expected reward: 201.12237548828125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[192.58344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.84580135345459
desired expected reward: 203.2283477783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[176.94968]
 [176.992  ]
 [176.94968]
 [178.58687]
 [191.64403]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 27. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.075716972351074
desired expected reward: 186.38677978515625



buy possibilites: [-1] 
expected returns: [[205.40346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [10.  6. 10.  0. 14. 23. 10.  0.  0.  1.  1. 11.  3.  6. 11.  6.  0.  0.
  0. 25.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 25 

action type: buy - action 3.0
Learning step: -2.9780232906341553
desired expected reward: 174.0139923095703






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11. 23. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11. 23. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 23. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23. 10.] 
expected returns: [[245.07532]
 [234.0222 ]
 [235.09933]
 [232.47833]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 23. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -3.9899613857269287
desired expected reward: 201.4134979248047



action possibilites: [-1. 11. 23. 10.] 
expected returns: [[243.39774]
 [232.3446 ]
 [233.42177]
 [230.80077]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 23.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  5.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: -4.382632732391357
desired expected reward: 228.11199951171875



action possibilites: [-1. 23. 10.] 
expected returns: [[259.70053]
 [248.76634]
 [246.14532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  4.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 61 

action type: gain_card_n - action 6
Learning step: -2.651604413986206
desired expected reward: 226.60755920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[245.07463]
 [245.11496]
 [245.07463]
 [246.64767]
 [259.81863]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  4.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1.0
Learning step: -4.4042205810546875
desired expected reward: 255.2963104248047



buy possibilites: [-1] 
expected returns: [[260.89166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0. 10.] 
cards in discard: [8. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 65 

action type: buy - action 8.0
Learning step: -3.212322235107422
desired expected reward: 243.43536376953125






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  6.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[187.73372]
 [180.4819 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  1.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -8.03320026397705
desired expected reward: 252.85845947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[178.51749]
 [178.55534]
 [178.54228]
 [178.51749]
 [180.45859]
 [179.50076]
 [179.47997]
 [187.45528]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  6.  1.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.201920986175537
desired expected reward: 179.72103881835938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[165.74414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -4.810136318206787
desired expected reward: 182.6451416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[152.35977]
 [152.4082 ]
 [152.39139]
 [152.35977]
 [153.25269]
 [154.60423]
 [153.50647]
 [157.70761]
 [154.51768]
 [153.482  ]
 [155.63994]
 [162.665  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.821500778198242
desired expected reward: 161.18418884277344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[171.82347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.4396610260009766
desired expected reward: 159.2252960205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[161.3395 ]
 [161.36847]
 [161.3395 ]
 [162.40112]
 [170.837  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 26. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.921520948410034
desired expected reward: 166.90457153320312



buy possibilites: [-1] 
expected returns: [[161.73572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 36 

action type: buy - action 3.0
Learning step: -2.6293697357177734
desired expected reward: 158.73910522460938






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  3. 25.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  3. 25.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 14.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[135.5518 ]
 [127.59231]
 [129.53226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  3. 25.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -3.6836249828338623
desired expected reward: 158.05209350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.50103]
 [123.50103]
 [133.42247]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  3. 25.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.4419517517089844
desired expected reward: 133.10984802246094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[182.84947]
 [172.6237 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -1.2083126306533813
desired expected reward: 132.2141571044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.18333]
 [168.24373]
 [168.22293]
 [168.18333]
 [171.0415 ]
 [169.64304]
 [169.61229]
 [181.26727]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 8.  8. 10. 11. 23.  0.  0. 10.  0. 10.  6.  6.  1.  6.  0.  0.  6.  1.
  3.  0.  3.  3.  0.  3.  0. 14.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.771498918533325
desired expected reward: 179.07797241210938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[246.77641]
 [234.19029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -2.207383871078491
desired expected reward: 179.0598907470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[231.13715]
 [231.20168]
 [231.17973]
 [231.13715]
 [234.2245 ]
 [232.71362]
 [232.68155]
 [245.26765]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  3.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -5.462337017059326
desired expected reward: 239.83204650878906



buy possibilites: [-1] 
expected returns: [[235.65315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 30.0 

action type: buy - action 8.0
Learning step: -4.8334856033325195
desired expected reward: 227.88014221191406






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10. 11.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  6.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[232.2954 ]
 [221.06749]
 [221.06749]
 [222.41533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 10. 11.] 
cards in discard: [ 8.  0.  0.  6.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -5.275741100311279
desired expected reward: 230.37741088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[219.72955]
 [219.72955]
 [232.82703]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0. 10. 11.] 
cards in discard: [ 8.  0.  0.  6.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.980154514312744
desired expected reward: 225.64285278320312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 25.  6.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 25.  6.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 25.  6.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 8. 25.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[220.40504]
 [209.4933 ]
 [213.28113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  6.  3.  3.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -5.3642706871032715
desired expected reward: 227.46273803710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[207.14609]
 [207.14609]
 [219.42786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  6.  3.  3.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.682371139526367
desired expected reward: 214.06446838378906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[168.54662]
 [158.00995]
 [159.27275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -5.869603633880615
desired expected reward: 213.55825805664062



action possibilites: [-1] 
expected returns: [[181.94774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  30   0   0  20 -30   0   0   0  -1   0   0   0   0] 
sum of rewards: 17 

action type: gain_card_n - action 0
Learning step: -2.834820508956909
desired expected reward: 152.73806762695312





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[166.71786]
 [182.16682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -2.6761391162872314
desired expected reward: 179.2716064453125






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[181.1698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.632020950317383
desired expected reward: 178.53480529785156





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[164.15926]
 [164.10188]
 [164.1407 ]
 [164.14194]
 [164.10188]
 [165.16365]
 [166.77277]
 [165.46616]
 [169.22276]
 [170.53212]
 [166.6681 ]
 [167.69717]
 [165.44116]
 [166.36555]
 [167.99973]
 [177.08968]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.7770516872406006
desired expected reward: 177.3927459716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 23.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.  0.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 23.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.  0.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 23.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[142.76654]
 [133.87509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 23.  3.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.  0.  1.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -4.286844730377197
desired expected reward: 172.80282592773438





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[129.51387]
 [142.0809 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 23.  3.  0.] 
cards in discard: [ 8.  0.  0.  6.  0. 10. 10.  6.  0. 10. 11.  8. 25.  6.  3.  3.  0. 11.
  8.  3.  3.  0.  0.  1.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.6045548915863037
desired expected reward: 140.1619873046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[243.13962]
 [228.51001]
 [230.16467]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 14.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -0.34437867999076843
desired expected reward: 141.7365264892578



action possibilites: [-1] 
expected returns: [[297.26297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 14.0
Learning step: -2.378377676010132
desired expected reward: 226.95750427246094





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.29865]
 [277.2713 ]
 [277.21423]
 [278.8037 ]
 [281.2064 ]
 [279.2538 ]
 [286.7074 ]
 [281.05148]
 [279.2163 ]
 [283.04153]
 [295.4407 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9. 10.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -5.955606937408447
desired expected reward: 291.307373046875



buy possibilites: [-1] 
expected returns: [[225.68384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0 -2  0  0 32  0] 
sum of rewards: 78 

action type: buy - action 29.0
Learning step: -5.357485294342041
desired expected reward: 281.3499450683594






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 10. 25.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 10. 25.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 10. 25.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0 29] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  8.  3. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 25.] 
expected returns: [[185.85886]
 [175.1402 ]
 [175.11438]
 [178.8609 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10. 25.] 
cards in discard: [29. 14. 10.  0.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1  0 10 25 11  3  6  1  6  6  6 10  0
 14 10  0 11 23  3  3  8  8  3  8  0 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -5.813900947570801
desired expected reward: 219.86993408203125



action possibilites: [-1] 
expected returns: [[250.14534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 14. 10.  0.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.0540329217910767
desired expected reward: 169.4939727783203





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[238.77292]
 [252.26038]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14. 10.  0.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  5. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -5.049074649810791
desired expected reward: 245.0962677001953



buy possibilites: [-1] 
expected returns: [[250.99362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -274.0 

action type: buy - action 6.0
Learning step: -19.991291046142578
desired expected reward: 218.78164672851562






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 6.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 6.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 6.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[186.47917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 6.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -8.079127311706543
desired expected reward: 242.91448974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[172.73386]
 [184.86478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 6.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.869300365447998
desired expected reward: 180.48866271972656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[193.93396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -4.6217169761657715
desired expected reward: 180.24305725097656





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[181.07895]
 [181.05745]
 [181.00922]
 [182.28084]
 [184.20488]
 [182.63933]
 [188.5995 ]
 [184.0792 ]
 [182.61143]
 [185.67264]
 [195.58571]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.014556407928467
desired expected reward: 187.05308532714844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  0. 10.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  0. 10.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[190.57613]
 [176.24928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.283748149871826
desired expected reward: 190.3019561767578





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[182.00584]
 [181.98247]
 [181.98375]
 [181.92973]
 [183.335  ]
 [185.45674]
 [183.72905]
 [188.68974]
 [190.31032]
 [185.31895]
 [186.68327]
 [183.69838]
 [184.92493]
 [187.07735]
 [198.03093]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -4.851402282714844
desired expected reward: 184.81143188476562



buy possibilites: [-1] 
expected returns: [[172.10706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0 -1  0  0 50  0] 
sum of rewards: 55 

action type: buy - action 22.0
Learning step: -2.6238365173339844
desired expected reward: 182.3010711669922






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  0.  3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  0.  3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  0.  3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 6. 23.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[156.0317 ]
 [147.19792]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  0.  0.  3.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -4.838958263397217
desired expected reward: 167.26809692382812



action possibilites: [-1.  8.] 
expected returns: [[203.47264]
 [192.60909]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 8.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action 23.0
Learning step: -1.5362637042999268
desired expected reward: 145.66165161132812





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[192.72844]
 [192.71019]
 [192.67012]
 [195.35384]
 [194.04085]
 [194.01743]
 [206.10081]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 8.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -4.343989849090576
desired expected reward: 199.12864685058594






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  8. 11.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10. 23.  6.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  8. 11.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10. 23.  6.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  8. 11.] 
adversary cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10. 23.  6.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[283.6039 ]
 [270.50003]
 [268.75012]
 [270.50003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8. 11.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10. 23.  6.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -3.7269532680511475
desired expected reward: 202.3738250732422





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[268.33243]
 [285.27542]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  8. 11.] 
cards in discard: [29. 14. 10.  0.  0.  6.  6.  8.  0.  3.  0.  3.  6.  6.  0.  0.  3.  3.
  1. 22.  0.  0.  1.  0. 10. 23.  6.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -7.546501159667969
desired expected reward: 276.0574035644531



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3. 22.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
expected returns: [[249.08867]
 [237.03505]
 [235.95143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -8.460209846496582
desired expected reward: 276.8152160644531





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[232.84721]
 [247.44902]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -6.621136665344238
desired expected reward: 241.6885223388672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[197.48615]
 [186.89035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -7.411922454833984
desired expected reward: 234.3319549560547





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[186.34631]
 [186.30307]
 [187.76808]
 [199.77345]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 25. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.143640995025635
desired expected reward: 191.6754913330078



buy possibilites: [-1] 
expected returns: [[192.44656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: -3.837268114089966
desired expected reward: 182.50904846191406






         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3] -> size -> 37 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3] -> size -> 37 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[176.13918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.860012054443359
desired expected reward: 187.5865478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[164.58153]
 [164.5621 ]
 [164.56233]
 [164.5195 ]
 [165.6405 ]
 [167.34   ]
 [165.95949]
 [169.92357]
 [171.2184 ]
 [167.22798]
 [168.3159 ]
 [165.9331 ]
 [166.90901]
 [168.63484]
 [177.51447]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.950216054916382
desired expected reward: 169.93051147460938



buy possibilites: [-1] 
expected returns: [[166.26149]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 20.  0.  0.  0.  0.  0.  0.  0. -3.  0.  0.  8.  0.] 
sum of rewards: 22.0 

action type: buy - action 15.0
Learning step: -3.5908596515655518
desired expected reward: 165.0439910888672






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  3.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[146.06749]
 [137.72304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.240320205688477
desired expected reward: 162.0211639404297





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[136.8355 ]
 [136.80058]
 [137.97859]
 [147.34843]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 24. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -3.1656289100646973
desired expected reward: 141.9270477294922



buy possibilites: [-1] 
expected returns: [[162.9566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.  3.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 32 

action type: buy - action 3.0
Learning step: -1.5752514600753784
desired expected reward: 135.26023864746094






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  6.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[146.77373]
 [136.6108 ]
 [136.63245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  6.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -3.513331174850464
desired expected reward: 159.44326782226562





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[137.57616]
 [149.0287 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  6.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  4. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.642998218536377
desired expected reward: 144.1307373046875



buy possibilites: [-1] 
expected returns: [[138.68869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  6.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   20.    0.    0.    0.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -288.0 

action type: buy - action 6.0
Learning step: -18.158313751220703
desired expected reward: 119.41787719726562






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 10. 29.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 10. 29.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0.  6. 10. 29.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  6. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[121.976135]
 [111.768295]
 [116.21031 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 29.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -3.393397569656372
desired expected reward: 135.2952880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[110.61267 ]
 [110.57706 ]
 [111.789215]
 [121.976135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10. 29.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.586996555328369
desired expected reward: 119.3891372680664



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  1.  1. 23. 11.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.  0.  0.  6. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  1.  1. 23. 11.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.  0.  0.  6. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  1.  1. 23. 11.] 
adversary cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.  0.  0.  6. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 6.  1.  1. 23. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
expected returns: [[97.41344 ]
 [89.96891 ]
 [89.192764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  1. 23. 11.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.  0.  0.  6. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.10939884185791
desired expected reward: 118.86673736572266





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[87.42029 ]
 [87.40797 ]
 [87.38132 ]
 [88.10076 ]
 [89.192764]
 [88.308044]
 [92.34534 ]
 [89.12085 ]
 [88.29164 ]
 [90.233025]
 [97.41344 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  1. 23. 11.] 
cards in discard: [ 3. 22.  3.  6.  8.  3. 14.  0.  0.  3.  3. 15.  0.  0.  0.  0.  0.  3.
  0.  0.  6. 11.  3.  6.  3. 10.  8.  0.  6.  0.  0.  6. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.9076193571090698
desired expected reward: 95.50582122802734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [11.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [11.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [11.  3.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
expected returns: [[216.85332]
 [206.3926 ]
 [206.2754 ]
 [204.94997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.9944931268692017
desired expected reward: 93.67042541503906





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[203.4301 ]
 [216.83846]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -5.140456676483154
desired expected reward: 210.90060424804688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [11.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [11.  3.  0. 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[195.38692]
 [183.39116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 8.] 
cards in discard: [11.  3.  0. 14.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -5.683743000030518
desired expected reward: 211.1547088623047





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[180.4457 ]
 [193.95763]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 8.] 
cards in discard: [11.  3.  0. 14.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  3. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -4.561213970184326
desired expected reward: 189.58822631835938



buy possibilites: [-1] 
expected returns: [[188.81744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 8.] 
cards in discard: [11.  3.  0. 14.  8.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -300.0 

action type: buy - action 6.0
Learning step: -19.773893356323242
desired expected reward: 160.6717987060547






         -------------------- Turn: 77 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  3.  6. 10.  0.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  3.  6. 10.  0.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[129.72575]
 [120.37845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10.  0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -6.289656162261963
desired expected reward: 182.5277862548828





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[118.104065]
 [128.5172  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10.  0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -3.3015263080596924
desired expected reward: 125.51689147949219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 22.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 22.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[137.93367]
 [129.56895]
 [130.21147]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 22.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0
 11 23  3  3  8  8  3  8  0 29  6 22  3 15  3  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -3.0899994373321533
desired expected reward: 125.42720031738281



action possibilites: [-1] 
expected returns: [[201.31029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 5
Learning step: -0.5817520022392273
desired expected reward: 127.6429214477539





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[187.12933]
 [201.81291]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  2. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -4.298390865325928
desired expected reward: 197.01190185546875



buy possibilites: [-1] 
expected returns: [[168.57275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -5.
    0. -300.    0.    0.] 
sum of rewards: -290.0 

action type: buy - action 6.0
Learning step: -20.063581466674805
desired expected reward: 167.06576538085938






         -------------------- Turn: 79 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[184.39925]
 [171.96683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.592027187347412
desired expected reward: 163.98072814941406





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[171.14592]
 [171.09872]
 [172.6678 ]
 [185.07495]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.406899929046631
desired expected reward: 178.99237060546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 80 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 15.  6.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 15.  6.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6.  0.  3. 15.  6.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[138.52594]
 [130.92642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 15.  6.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -6.425041198730469
desired expected reward: 178.64993286132812





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[127.64296]
 [138.82289]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 15.  6.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.108870983123779
desired expected reward: 134.4170684814453



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 81 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[125.02283 ]
 [118.955635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.183028697967529
desired expected reward: 130.12904357910156





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[112.41041 ]
 [112.39372 ]
 [112.393974]
 [112.34719 ]
 [113.46227 ]
 [115.141014]
 [113.77303 ]
 [117.67852 ]
 [118.95563 ]
 [115.03168 ]
 [116.10736 ]
 [113.75457 ]
 [114.7209  ]
 [116.41812 ]
 [125.02282 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.7856109142303467
desired expected reward: 121.23721313476562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [23.  3.  0.  1. 11.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.  1. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [23.  3.  0.  1. 11.] 
adversary cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.  1. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [23.  3.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
expected returns: [[105.984505]
 [ 95.80497 ]
 [ 94.71606 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  1. 11.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.  1. 29.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.188225746154785
desired expected reward: 120.83460235595703





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.68154 ]
 [ 91.664024]
 [ 91.61491 ]
 [ 94.71606 ]
 [ 93.17181 ]
 [ 93.15163 ]
 [105.984505]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  1. 11.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.  1. 29.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  1. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.279113531112671
desired expected reward: 102.70539093017578



buy possibilites: [-1] 
expected returns: [[196.16129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  1. 11.] 
cards in discard: [11.  3.  0. 14.  8.  6.  3.  6.  0.  6.  8.  3.  3.  6. 10.  0.  6.  8.
  3.  0.  0.  3.  0.  6. 10.  6.  0.  3. 15.  6.  1. 29.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -16.26711654663086
desired expected reward: 75.34779357910156






         -------------------- Turn: 83 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[243.1769 ]
 [231.26718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -5.171932697296143
desired expected reward: 190.98934936523438





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[230.04428]
 [231.77512]
 [245.863  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.582071781158447
desired expected reward: 236.69717407226562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 84 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [14.  1.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [14.  1.  3.  0.  6.] 
adversary cards in discard: [ 0.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14.  1.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[198.05762]
 [187.60077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  0.  6.] 
cards in discard: [ 0.  3. 11.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -8.696139335632324
desired expected reward: 237.1668701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[181.59248]
 [181.57521]
 [184.45259]
 [183.01949]
 [183.00102]
 [194.7937 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.  0.  6.] 
cards in discard: [ 0.  3. 11.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -6.405745029449463
desired expected reward: 191.34857177734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 85 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  0.  3.  3. 29.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  0.  3.  3. 29.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[167.32362]
 [156.38911]
 [161.42282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 29.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -6.852691650390625
desired expected reward: 187.94100952148438





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[167.01538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  3. 29.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -5.360610485076904
desired expected reward: 161.00851440429688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 86 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[208.82214]
 [193.05319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.563210487365723
desired expected reward: 162.45216369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[188.55197]
 [190.25446]
 [204.76614]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -6.664323329925537
desired expected reward: 200.71157836914062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 87 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  6.  6.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  6.  6.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  6.  6.  6.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[199.66226]
 [186.94809]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  6.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -6.609692573547363
desired expected reward: 198.1564483642578



action possibilites: [-1.  8.] 
expected returns: [[205.00534]
 [191.7731 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 10.0
Learning step: -4.601169586181641
desired expected reward: 182.346923828125





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[205.41399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -5.4284515380859375
desired expected reward: 199.57687377929688






         -------------------- Turn: 88 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [6. 0. 3. 6. 1.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.8381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -6.889094829559326
desired expected reward: 185.46994018554688





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[145.07336]
 [145.05751]
 [147.78313]
 [146.42719]
 [146.4101 ]
 [158.45316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 1.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -5.179580211639404
desired expected reward: 151.6585235595703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 89 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6. 15. 11.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [ 6. 15. 11.  3.  0.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 15. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[165.36505]
 [156.82089]
 [155.55154]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 11.  3.  0.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -5.063343048095703
desired expected reward: 153.38980102539062



action possibilites: [-1] 
expected returns: [[164.0559]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  0.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0  -7   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 8
Learning step: -3.36836314201355
desired expected reward: 150.8240509033203





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[164.0559]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  0.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -4.311537265777588
desired expected reward: 159.74435424804688






         -------------------- Turn: 90 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15. 11.  6. 15.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15. 11.  6. 15.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [23. 10.  0.  0.  3.] 
adversary cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15. 11.  6. 15.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [23. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
expected returns: [[197.03166]
 [186.30408]
 [183.49165]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0.  0.  3.] 
cards in discard: [ 0.  3. 11.  3.  0. 14.  1.  3.  0.  6.  8.  0.  3.  3. 29.  6.  6.  0.
  0.  8. 10.  0.  6.  6.  6.  8.  6.  0.  3.  6.  1. 15. 11.  6. 15.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.6507487297058105
desired expected reward: 159.4051513671875



action possibilites: [-1. 10.] 
expected returns: [[235.93582]
 [224.3498 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 23.0
Learning step: -3.8647758960723877
desired expected reward: 182.4393310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[220.7779 ]
 [220.76172]
 [223.59305]
 [222.18413]
 [222.16705]
 [233.75308]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -6.436483860015869
desired expected reward: 229.4993438720703






         -------------------- Turn: 91 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15.  3. 29.  6.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15.  3. 29.  6.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15.  3. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[185.23936]
 [176.68141]
 [179.20149]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.  6.  0.] 
cards in discard: [23. 10.  0.  0.  3.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11
 23  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -8.406742095947266
desired expected reward: 225.34634399414062



action possibilites: [-1] 
expected returns: [[197.09392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6.] 
cards in discard: [23. 10.  0.  0.  3.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 15.0
Learning step: -4.114266872406006
desired expected reward: 170.8633270263672





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[183.34155]
 [183.32379]
 [186.33188]
 [184.83322]
 [184.81334]
 [197.14372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6.] 
cards in discard: [23. 10.  0.  0.  3.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -5.324443340301514
desired expected reward: 191.76947021484375






         -------------------- Turn: 92 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[127.28006 ]
 [118.978714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -7.850474834442139
desired expected reward: 189.2932586669922





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[116.760666]
 [117.77833 ]
 [126.11469 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  2.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -4.351274490356445
desired expected reward: 122.24247741699219



buy possibilites: [-1] 
expected returns: [[104.75361]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  3.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0  -7   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 8.0
Learning step: -4.281960487365723
desired expected reward: 113.49636840820312






         -------------------- Turn: 93 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [14. 11.  6.  6.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [14. 11.  6.  6.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14. 11.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[115.47007]
 [105.57574]
 [105.68456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  6.  6.  0.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.5054256916046143
desired expected reward: 101.24818420410156





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[111.05509]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  6.  6.  0.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.9317474365234375
desired expected reward: 108.67799377441406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 94 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 15.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 6.  3.  3. 15.  0.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[103.35195]
 [ 94.3552 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 15.  0.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.072471618652344
desired expected reward: 106.98262023925781





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[103.326805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 15.  0.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.642744779586792
desired expected reward: 99.70921325683594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 95 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  6.  3.  6.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[71.87354]
 [67.11443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  6.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -4.373061656951904
desired expected reward: 98.95374298095703





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[71.873535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  3.  6.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.776522397994995
desired expected reward: 69.09701538085938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 96 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8. 1. 1. 3. 3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8. 1. 1. 3. 3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8. 1. 1. 3. 3.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [8. 1. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[81.849594]
 [74.48069 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 1. 3. 3.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -2.5890302658081055
desired expected reward: 69.28450775146484





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[73.5927  ]
 [73.58291 ]
 [74.278534]
 [75.38042 ]
 [74.48069 ]
 [77.87545 ]
 [75.30873 ]
 [74.47214 ]
 [76.21816 ]
 [81.8496  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 1. 3. 3.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.1125285625457764
desired expected reward: 78.73706817626953



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 97 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.  8.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8. 0. 6. 0. 8.] 
adversary cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.  8.  1.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[43.283634]
 [36.91683 ]
 [36.91683 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 8.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.  8.  1.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1  0 11  3  6  1  6  6  6 10  0 14 10  0 11 23
  3  3  8  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.9611871242523193
desired expected reward: 77.8884048461914



action possibilites: [-1] 
expected returns: [[50.51869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.  8.  1.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.004928398411720991
desired expected reward: 37.6397705078125





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[50.51869]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [23. 10.  0.  0.  3.  6. 15.  3. 29.  6.  8.  0.  6. 10.  0.  3. 14. 11.
  6.  6.  0.  6.  3.  3. 15.  0.  0. 11.  6.  3.  6.  8.  1.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.639263927936554
desired expected reward: 49.879425048828125






         -------------------- Turn: 98 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [14. 10.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [14. 10.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14. 10.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[170.47769]
 [161.44235]
 [160.32074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0.9685136675834656
desired expected reward: 51.48720169067383





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[169.79214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.893304347991943
desired expected reward: 164.37924194335938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 99 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [14. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [14. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [6. 8. 3. 3. 0.] 
adversary cards in discard: [14. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [6. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[182.15923]
 [172.50061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [14. 10.  6.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.724451541900635
desired expected reward: 165.06768798828125





----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
expected returns: [[181.15358]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 3. 0.] 
cards in discard: [14. 10.  6.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.204326152801514
desired expected reward: 175.40130615234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 100 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 23.  8. 15.  6.] 
adversary cards in discard: [14. 10.  6.  6.  0.  6.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 23.  8. 15.  6.] 
adversary cards in discard: [14. 10.  6.  6.  0.  6.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [-1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 23.  8. 15.  6.] 
adversary cards in discard: [14. 10.  6.  6.  0.  6.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
adversary victory points: 0
player victory points: 0 


Game is draw!



Player 0 bought cards:
Copper: 4 
Silver: 2 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 1 
Poacher: 1 
Militia: 1 
Market: 1 
Village: 2 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 23.  8. 15.  6.] 
cards in discard: [14. 10.  6.  6.  0.  6.  8.  3.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1  0 11  3  1  6  6  6 10  0 14 10  0 11 23  3  3  8
  8  3  8  0 29  6  3 15  3  6  6  6  6 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 23. 30.  8.  0. 10.  6.  1.  9.  9.  9.  9.  7.  9.  7.] 
adversary cards in hand: [] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -9.307679176330566
desired expected reward: 171.8459014892578



