 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.2340975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000075 

action type: gain_card_n - action 0
Learning step: -120001.328125
desired expected reward: -120043.09375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  6.643182]
 [ 15.86022 ]
 [  8.836808]
 [-13.363602]
 [ 14.775829]
 [ 11.036523]
 [ 10.356382]
 [  9.150199]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.888371467590332



buy possibilites: [-1] 
expected returns: [[14.386377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 15.860214233398438






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.9531333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.386377334594727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  2.281854 ]
 [ 10.907684 ]
 [  4.471039 ]
 [-15.916965 ]
 [  6.8513336]
 [  9.91402  ]
 [  6.2547607]
 [ 16.93819  ]
 [  3.7939026]
 [  5.647751 ]
 [ 12.536966 ]
 [  4.584584 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.686480760574341



buy possibilites: [-1] 
expected returns: [[-5.369464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 16.938188552856445






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.61692 ]
 [27.506407]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.369463920593262



action possibilites: [-1.] 
expected returns: [[25.575287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.032949447631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.823917  ]
 [31.02209   ]
 [ 9.442153  ]
 [23.880178  ]
 [14.67886   ]
 [ 0.19215083]
 [26.84468   ]
 [30.338852  ]
 [26.787348  ]
 [35.04941   ]
 [37.251625  ]
 [23.237673  ]
 [30.696205  ]
 [25.947275  ]
 [14.20561   ]
 [32.73617   ]
 [24.413296  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.575286865234375



buy possibilites: [-1] 
expected returns: [[-3.4838681]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.251617431640625






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 16.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.] 
cards in discard: [16.  0.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.] 
cards in discard: [16.  0.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.150158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.48386812210083





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  4.433181 ]
 [ 14.040743 ]
 [  6.7715464]
 [-16.160427 ]
 [ 13.034601 ]
 [  9.037772 ]
 [  8.339738 ]
 [  7.108406 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 29.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.130240440368652



buy possibilites: [-1] 
expected returns: [[8.010496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29. 29.  0.  0.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 14.040740966796875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.775444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.010496139526367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.826195]
 [23.053305]
 [15.796976]
 [-8.471453]
 [18.947384]
 [22.331758]
 [18.795279]
 [29.173958]
 [15.224371]
 [18.004461]
 [24.734015]
 [16.568428]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.716985702514648



buy possibilites: [-1] 
expected returns: [[2.0797226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.1739501953125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [1. 0. 0. 0. 3. 3. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [29.  1.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-1.287414]
 [ 9.340045]
 [ 9.340045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0. 29.] 
cards in discard: [29.  1.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.0797226428985596



action possibilites: [-1. 29.] 
expected returns: [[15.703564]
 [27.661165]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 29.  0.] 
cards in discard: [29.  1.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.119437217712402



action possibilites: [-1.] 
expected returns: [[30.626045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29.  1.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.661161422729492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.482883]
 [38.08772 ]
 [18.58277 ]
 [31.496204]
 [23.488403]
 [10.29318 ]
 [34.15368 ]
 [37.051807]
 [33.49588 ]
 [41.70869 ]
 [43.92872 ]
 [30.935024]
 [37.83083 ]
 [32.94356 ]
 [22.849077]
 [39.656574]
 [31.985573]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29.  1.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.62604522705078



buy possibilites: [-1] 
expected returns: [[19.042545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29.  1.  0.  3.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 16. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 97.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.92872619628906






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 1. 16. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9. 10. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.  0.] 
cards in discard: [15.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 7.4919415]
 [18.480604 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.042545318603516



action possibilites: [-1.] 
expected returns: [[7.1624813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.369888305664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  6.4278727 ]
 [ 14.792538  ]
 [ -4.18804   ]
 [  8.460937  ]
 [  0.43809938]
 [-12.158578  ]
 [ 11.159094  ]
 [ 13.708801  ]
 [  9.96776   ]
 [ 18.217428  ]
 [ 20.199247  ]
 [  7.962017  ]
 [ 14.475904  ]
 [  9.626858  ]
 [ -0.0329268 ]
 [ 16.262802  ]
 [  9.099566  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.162481307983398



buy possibilites: [-1] 
expected returns: [[-2.0989945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.199249267578125






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 30. 30.  8.  9.  8.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-1.8808534]
 [ 8.849797 ]
 [ 8.849797 ]
 [ 8.849797 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 29.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.098994493484497



action possibilites: [-1. 29. 29.] 
expected returns: [[ 2.617367]
 [13.710915]
 [13.710915]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  0.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 7.827261924743652



action possibilites: [-1. 29.] 
expected returns: [[30.971516]
 [43.481728]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.710906982421875



action possibilites: [-1.] 
expected returns: [[48.596287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.48172378540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[47.66748 ]
 [57.095673]
 [35.695957]
 [49.86011 ]
 [41.082626]
 [26.587412]
 [52.784218]
 [55.956757]
 [52.076073]
 [61.056023]
 [63.49585 ]
 [49.25111 ]
 [56.81091 ]
 [51.468624]
 [40.375652]
 [58.812927]
 [50.413773]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.59628677368164



buy possibilites: [-1] 
expected returns: [[26.531055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29.  3.  1.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  1.] 
adversary cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 117.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 63.49586486816406






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [16.  3.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  1.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  1.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  1.] 
cards in discard: [15.  8. 11.  1. 16.  3.  0. 16.  0.  0.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-16.403837 ]
 [ -7.4085293]
 [ -7.4085293]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.531055450439453



action possibilites: [-1. 29.] 
expected returns: [[-1.420434]
 [ 8.553535]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -8.256925582885742



action possibilites: [-1. 29.] 
expected returns: [[17.764404]
 [29.02641 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.553537368774414



action possibilites: [-1.] 
expected returns: [[15.003193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.026405334472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.879692 ]
 [22.382679 ]
 [ 2.685055 ]
 [15.811289 ]
 [ 7.468519 ]
 [22.502954 ]
 [-5.8165627]
 [18.692055 ]
 [21.345783 ]
 [17.728094 ]
 [25.837622 ]
 [27.870935 ]
 [15.345747 ]
 [22.018887 ]
 [17.307955 ]
 [ 6.9857044]
 [23.869787 ]
 [16.616983 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.003192901611328



buy possibilites: [-1] 
expected returns: [[24.987331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 117.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.870941162109375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  9.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  6.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.  0.  3.] 
adversary cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.5599115]
 [13.402184 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  3.] 
cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  1.  0. 16.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.98733139038086



action possibilites: [-1. 29.] 
expected returns: [[26.924976]
 [38.462456]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 29.] 
cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  1.  0. 16.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 11.707853317260742



action possibilites: [-1.] 
expected returns: [[49.788795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  1.  0. 16.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.46246337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.005527]
 [56.65186 ]
 [36.85815 ]
 [49.99079 ]
 [41.765205]
 [28.30056 ]
 [52.811935]
 [55.544033]
 [51.896275]
 [60.187496]
 [62.35305 ]
 [49.49279 ]
 [56.33065 ]
 [51.445564]
 [41.177658]
 [58.183487]
 [50.694565]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  3. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  1.  0. 16.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.788795471191406



buy possibilites: [-1] 
expected returns: [[38.45297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29.  0.  1.  0.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 11.  1.  0. 16.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 97.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.353065490722656






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.  0. 16.] 
cards in discard: [11.  0.  0.  0. 15.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1  1 15  8 16  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  9. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 0.93005824]
 [10.953306  ]
 [10.953306  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 16.  3. 16.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.45296859741211



action possibilites: [-1. 29.] 
expected returns: [[ 0.8417499]
 [10.807021 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 16.  3. 16.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.806238174438477



action possibilites: [-1.] 
expected returns: [[2.090657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 16.  3. 16.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.807024002075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -0.24758029]
 [  8.557198  ]
 [  1.6875322 ]
 [ -7.0674515 ]
 [-19.989042  ]
 [  4.7191954 ]
 [  7.564351  ]
 [  3.9435575 ]
 [ 12.1542    ]
 [ 14.266342  ]
 [  1.2096341 ]
 [  8.167589  ]
 [  3.4320757 ]
 [ -7.5600834 ]
 [ 10.104742  ]
 [  2.5584753 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 16.  3. 16.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.0906569957733154



buy possibilites: [-1] 
expected returns: [[30.601143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 16.  3. 16.  0.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 97.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 14.266328811645508






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1. 16.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3. 16.  0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 11 16  6  1 15  8 16  1 11  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  7.  8.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  8.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  8.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-6.094618 ]
 [ 3.9796603]
 [ 3.9796603]
 [ 3.9796603]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.60114288330078



action possibilites: [-1. 29. 29.] 
expected returns: [[25.537907]
 [35.85589 ]
 [35.85589 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  3.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.158565521240234



action possibilites: [-1. 29.] 
expected returns: [[66.69759]
 [78.44354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.85589599609375



action possibilites: [-1.] 
expected returns: [[98.57141]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.44355010986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 99.5486  ]
 [108.91151 ]
 [ 86.97788 ]
 [101.56717 ]
 [ 92.35413 ]
 [109.10533 ]
 [ 77.649185]
 [104.76854 ]
 [107.85415 ]
 [104.10252 ]
 [112.74822 ]
 [115.066216]
 [101.05525 ]
 [108.515236]
 [103.50636 ]
 [ 91.76406 ]
 [110.569885]
 [102.4687  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 9 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.5714111328125



buy possibilites: [-1] 
expected returns: [[64.39201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 117.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 115.06622314453125






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11.  0.  0.  0. 15.  6.  8.  0. 16. 11.  1.  0. 16. 11. 16.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[64.75869]
 [74.36474]
 [74.36474]
 [74.36474]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  0. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.39201354980469



action possibilites: [-1. 29. 29.] 
expected returns: [[-3.1288834]
 [ 6.073578 ]
 [ 6.073578 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.69630432128906



action possibilites: [-1. 29.] 
expected returns: [[-4.022136]
 [ 6.805565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.7400829792022705



action possibilites: [-1.] 
expected returns: [[9.461005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -6.872879981994629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.2669935]
 [ 15.423292 ]
 [  9.043314 ]
 [  1.059911 ]
 [-11.545123 ]
 [ 11.906635 ]
 [ 14.357307 ]
 [ 10.935939 ]
 [ 18.65887  ]
 [  8.650709 ]
 [ 15.042892 ]
 [ 10.567006 ]
 [  0.5308857]
 [ 16.825344 ]
 [  9.970384 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8. 10.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.461005210876465



buy possibilites: [-1] 
expected returns: [[26.097137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 18.658870697021484






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  6. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 25. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  1. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[35.020508]
 [46.401093]
 [46.401093]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29.  0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 11.  1. 11.  0.] 
adversary cards in discard: [ 1. 15.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.097137451171875



action possibilites: [-1. 29.] 
expected returns: [[53.544647]
 [64.34247 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 11.  1. 11.  0.] 
adversary cards in discard: [ 1. 15.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.91115188598633



action possibilites: [-1.] 
expected returns: [[108.473236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 11.  1. 11.  0.] 
adversary cards in discard: [ 1. 15.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 59.03258514404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.52567 ]
 [113.603806]
 [106.511   ]
 [ 97.55802 ]
 [ 83.22365 ]
 [109.69644 ]
 [112.424   ]
 [108.60058 ]
 [117.211136]
 [106.071625]
 [113.17871 ]
 [108.194016]
 [ 97.01461 ]
 [115.16515 ]
 [107.538666]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  9.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 11.  1. 11.  0.] 
adversary cards in discard: [ 1. 15.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.47323608398438



buy possibilites: [-1] 
expected returns: [[110.191284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 11.  1. 11.  0.] 
adversary cards in discard: [ 1. 15.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 117.21112060546875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [16. 11.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  1. 11.  0.] 
cards in discard: [ 1. 15.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  1. 11.  0.] 
cards in discard: [ 1. 15.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  7.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  1. 11.  0.] 
cards in discard: [ 1. 15.  0.  6. 16. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  1.] 
adversary cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 8.496086]
 [17.099281]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  1.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.1912841796875



action possibilites: [-1. 29.] 
expected returns: [[51.390747]
 [60.6589  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.888900756835938



action possibilites: [-1.] 
expected returns: [[48.90503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.  1.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.136383056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[45.322575]
 [52.22671 ]
 [46.77006 ]
 [28.134804]
 [50.964176]
 [47.706886]
 [47.821404]
 [48.18532 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.  1.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 24. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.905029296875



buy possibilites: [-1] 
expected returns: [[54.428326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.  0. 25. 29. 29. 29.  0.  0.  1.  3. 25. 29. 29.  0.  0.  0.  1.
 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 52.226715087890625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 8.536346]
 [16.987747]
 [16.987747]
 [16.987747]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  1. 16.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.42832565307617



action possibilites: [-1. 29.] 
expected returns: [[10.637144]
 [21.38842 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  1. 16.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.681953430175781



action possibilites: [-1.] 
expected returns: [[16.196072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  1. 16.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.114171981811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.005184]
 [22.52005 ]
 [15.777512]
 [-5.431856]
 [21.522459]
 [17.88725 ]
 [17.413912]
 [16.739632]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 23. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  1. 16.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.19607162475586



buy possibilites: [-1] 
expected returns: [[22.029406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 22. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  1. 16.] 
adversary cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.520038604736328






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  1. 16.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 16  6  1 15  8 16  1 11  8  0 16 11  1 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 22. 30. 30. 30.  8.  9.  6.  6.  8.  8.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 1. 15.  0.  6. 16. 11. 16. 11.  1. 11.  0.  0.  8.  3.  0. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 29.  0. 29.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[33.813187]
 [44.94644 ]
 [44.94644 ]
 [44.94644 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 29.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 16.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.02940559387207



action possibilites: [-1. 29.] 
expected returns: [[52.79089 ]
 [63.656776]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 16.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.711700439453125



action possibilites: [-1.] 
expected returns: [[139.73108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 16.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 58.35811233520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[135.86806]
 [144.31303]
 [137.42986]
 [113.94249]
 [140.82455]
 [143.38428]
 [140.10751]
 [137.14612]
 [139.65184]
 [145.71396]
 [138.87582]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16. 16.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 139.7310791015625



buy possibilites: [-1] 
expected returns: [[71.921936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [16. 16.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 145.71392822265625






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [16. 16.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  9.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  0. 29. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  0. 29. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  3.  0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  0. 29. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[63.007477]
 [71.67245 ]
 [71.67245 ]
 [70.0484  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 29. 25.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 25.  8.  0. 16.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.92193603515625



action possibilites: [-1. 29. 25.] 
expected returns: [[55.871483]
 [64.593544]
 [63.01953 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 25.  8.  0. 16.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.428955078125



action possibilites: [-1.] 
expected returns: [[62.933502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  1. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 25.  8.  0. 16.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.18980407714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[57.816017]
 [64.65205 ]
 [59.20146 ]
 [51.90356 ]
 [40.310352]
 [62.082703]
 [63.52233 ]
 [60.36758 ]
 [67.02552 ]
 [59.08593 ]
 [64.12938 ]
 [60.422085]
 [51.665585]
 [65.67896 ]
 [60.661514]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  1. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  7.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 25.  8.  0. 16.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.933502197265625



buy possibilites: [-1] 
expected returns: [[33.783295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29.  1. 29. 29.  3.  0.  3. 29. 29. 15. 29. 29.  3.  0.  0.  1. 25.
 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 25.  8.  0. 16.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.02550506591797






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [15. 25.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.  8. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  8.  0. 16.] 
cards in discard: [ 6. 11. 16. 16.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  8.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25] -> size -> 28 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 16. 11. 11.] 
cards in discard: [ 6. 11. 16. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  7.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0. 16. 11. 11.] 
cards in discard: [ 6. 11. 16. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  7.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-5.1332912]
 [ 3.9944313]
 [ 2.1516535]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  1.  0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  7.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.783294677734375



action possibilites: [-1. 25. 25.] 
expected returns: [[ 7.0096016]
 [16.229172 ]
 [16.229172 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 25.] 
cards in discard: [6. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  7.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.3803262710571289



action possibilites: [-1] 
expected returns: [[14.927954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  0. 29.] 
cards in discard: [6. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.229162216186523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.200422 ]
 [22.449368 ]
 [16.080214 ]
 [ 8.525134 ]
 [-3.2218995]
 [18.756311 ]
 [21.431402 ]
 [18.00797  ]
 [25.849945 ]
 [15.592945 ]
 [22.152029 ]
 [17.531574 ]
 [ 7.942647 ]
 [23.922493 ]
 [16.720016 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  0. 29.] 
cards in discard: [6. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  8.  6.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.927953720092773



buy possibilites: [-1] 
expected returns: [[34.457138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  0. 29.] 
cards in discard: [ 6.  1. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  8.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  1.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.84994125366211






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  1.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  8.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  7.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 22. 30. 30. 30.  8.  6.  6.  6.  7.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.725515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.45713806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.56017   ]
 [23.925404  ]
 [18.182697  ]
 [11.044962  ]
 [ 0.21598268]
 [20.86586   ]
 [22.687216  ]
 [19.370222  ]
 [26.66484   ]
 [17.916786  ]
 [23.538448  ]
 [19.279692  ]
 [10.578711  ]
 [25.125277  ]
 [19.235592  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  5.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.725515365600586



buy possibilites: [-1] 
expected returns: [[30.953228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 6. 0. 8. 0.] 
adversary cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 26.664859771728516






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [1. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 8. 0.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 16  6 15  8 16  1 11  8  0 16 11  1 11  0 25  0  6
  6  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6. 11. 16. 16.  3.  0. 25. 15.  8.  0. 16. 11. 11.  6.  8.  3. 11.  0.
  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[42.353542]
 [50.14712 ]
 [50.14712 ]
 [50.14712 ]
 [50.14712 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.953227996826172



action possibilites: [-1. 29. 29.] 
expected returns: [[-1.074516 ]
 [ 7.1126614]
 [ 7.1126614]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  1.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.33601379394531



action possibilites: [-1. 29.] 
expected returns: [[26.214027]
 [35.38604 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.0882065296173096



action possibilites: [-1.] 
expected returns: [[6.0758295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.886058807373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  2.8409908]
 [ 10.186328 ]
 [  4.617571 ]
 [-13.648703 ]
 [  7.150215 ]
 [  8.855126 ]
 [  5.3110895]
 [  4.3136473]
 [  5.329915 ]
 [ 11.383184 ]
 [  5.5142927]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.07582950592041



buy possibilites: [-1] 
expected returns: [[-0.2332151]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 6. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 11.3831787109375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  7.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [29. 15. 29. 25.  0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [29. 15. 29. 25.  0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [29. 15. 29. 25.  0.] 
adversary cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29. 15. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 25.] 
expected returns: [[-1.7181331]
 [ 6.0915995]
 [ 3.2462475]
 [ 6.0915995]
 [ 4.5183754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 29. 25.  0.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.2332150936126709



action possibilites: [-1. 15. 25. 29.] 
expected returns: [[ 5.832489]
 [10.587185]
 [11.775388]
 [13.352816]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0. 29.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.2387373447418213



action possibilites: [-1. 15. 25.] 
expected returns: [[11.781807]
 [17.1488  ]
 [18.522831]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  0.] 
cards in discard: [ 6.  1. 25. 29. 25.  1.  0. 25.  0. 29. 25.  0.  0.  1.  3.  0. 29. 29.
  1. 15. 29. 29. 29.  0.  3. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 29. 30.  8.  6.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.626302719116211



action possibilites: [-1] 
expected returns: [[4.925598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 22. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.522825241088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  1.7961466]
 [  9.004465 ]
 [  3.4782832]
 [-14.215239 ]
 [  7.7503653]
 [  4.497941 ]
 [  4.406996 ]
 [  4.370019 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 29.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 22. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.92559814453125



buy possibilites: [-1] 
expected returns: [[5.148671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 29.  6.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3. 16.  3.  6. 25.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 9.004462242126465






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  3.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  6. 25.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25.  3. 29. 15. 29.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  6. 25.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25.  3. 29. 15. 29.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3. 29. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15. 29.] 
expected returns: [[24.972305]
 [32.223244]
 [33.96823 ]
 [30.719105]
 [33.96823 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 15. 29.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.1486711502075195



action possibilites: [-1. 25. 15. 29.] 
expected returns: [[24.255219]
 [32.205215]
 [30.533703]
 [34.0415  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 29.  3.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.547847747802734



action possibilites: [-1. 25. 15. 29.] 
expected returns: [[26.097113]
 [33.37996 ]
 [31.879486]
 [35.163876]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 29.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.250751495361328



action possibilites: [-1. 15.] 
expected returns: [[50.882175]
 [57.284534]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.70325469970703



action possibilites: [-1] 
expected returns: [[61.398026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 57.2845344543457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.263847]
 [66.23183 ]
 [59.836212]
 [38.197395]
 [65.13577 ]
 [61.75225 ]
 [61.549065]
 [61.28238 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 21. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.39802551269531



buy possibilites: [-1] 
expected returns: [[78.00239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 3.  1. 15.  8.  0.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 54  0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 66.23182678222656






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  8.  0.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 25.  0.  1.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  8.  0.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 20. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [29. 29. 25.  0.  1.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[14.108185]
 [22.344969]
 [22.344969]
 [20.716259]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0.  1.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  8.  6. 11.  8.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.00238800048828



action possibilites: [-1. 25.] 
expected returns: [[ 7.74041 ]
 [14.347973]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 20. 30. 29. 30.  8.  5.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  8.  6. 11.  8.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.29050636291504



action possibilites: [-1] 
expected returns: [[-8.502366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  8.  6. 11.  8.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.347963333129883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-12.572323 ]
 [ -5.721905 ]
 [-21.32278  ]
 [-10.990516 ]
 [-17.53028  ]
 [ -5.655008 ]
 [-28.34486  ]
 [ -8.468431 ]
 [ -7.07668  ]
 [-10.403954 ]
 [ -3.29233  ]
 [-11.192254 ]
 [ -6.1025496]
 [-10.285856 ]
 [-17.973642 ]
 [ -4.652875 ]
 [ -9.911838 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 8 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  4.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  8.  6. 11.  8.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.502366065979004



buy possibilites: [-1] 
expected returns: [[-9.652513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  8.  6. 11.  8.] 
adversary cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
adversary owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -3.2923316955566406






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  6. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 11.  8.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15  8 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.] 
cards in discard: [ 8. 16.  6. 11.  0.  6.  3. 16.  3.  6. 25.  3.  1. 15.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 1. 29. 25.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 1. 29. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-2.117098]
 [ 5.403713]
 [ 3.826288]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  1.  0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [16.  0. 11. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.652512550354004



action possibilites: [-1. 25.] 
expected returns: [[2.9217474]
 [9.748031 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  0.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 20. 30. 29. 30.  8.  4.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [16.  0. 11. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6] -> size -> 25 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.6767165660858154



action possibilites: [-1] 
expected returns: [[-2.0715647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29. 25.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 20. 30. 29. 30.  8.  3.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [16.  0. 11. 11. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 9.74802303314209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -4.7138915 ]
 [  1.6694019 ]
 [ -3.2754455 ]
 [ -9.348181  ]
 [-19.537668  ]
 [ -0.86470294]
 [  0.3233056 ]
 [ -2.7863598 ]
 [  3.8647516 ]
 [ -3.4231284 ]
 [  1.2945168 ]
 [ -2.6217132 ]
 [ -9.793929  ]
 [  2.6435258 ]
 [ -2.163538  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29. 25.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 20. 30. 29. 30.  8.  3.  6.  6.  6.  3.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [16.  0. 11. 11. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.0715646743774414



buy possibilites: [-1] 
expected returns: [[-4.6142626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29. 25.] 
cards in discard: [ 1. 29. 29. 25. 15.  0. 29.  6.  3.  3. 25.  1. 29. 29. 29. 15.  3. 29.
 25. 29. 25.  0.  1.  0.  1.  0.  1. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [16.  0. 11. 11. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 3.864745855331421






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [16.  0. 11. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11. 11. 16.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 29. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 16.] 
cards in discard: [6. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 20. 30. 28. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 16.] 
cards in discard: [6. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 20. 30. 28. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 16.] 
cards in discard: [6. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  1. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 0.  1. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-10.218274 ]
 [ -2.6374464]
 [ -0.7106962]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 8. 16.  3.  6. 25.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.] 
adversary owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.614262580871582



action possibilites: [-1. 25.] 
expected returns: [[16.122114]
 [23.348587]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  3.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 8. 16.  3.  6. 25.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.] 
adversary owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.40297794342041



action possibilites: [-1] 
expected returns: [[-8.485883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 15.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 20. 30. 28. 30.  8.  2.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 8. 16.  3.  6. 25.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.] 
adversary owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.348583221435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-11.145265 ]
 [ -3.4905572]
 [ -9.459313 ]
 [-27.697151 ]
 [ -6.9391727]
 [ -4.638011 ]
 [ -7.9759274]
 [ -9.800172 ]
 [ -8.292698 ]
 [ -2.133669 ]
 [ -8.676341 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 15.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 20. 30. 28. 30.  8.  2.  6.  6.  6.  2.  0. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 8. 16.  3.  6. 25.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.] 
adversary owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.485882759094238



buy possibilites: [-1] 
expected returns: [[-8.963109]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 15.] 
cards in discard: [ 1. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 8. 16.  3.  6. 25.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.] 
adversary owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -2.133662700653076






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  3.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  6. 25.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  6 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6
  6  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  2.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25. 25. 29.  0.  1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25. 25. 29.  0.  1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 25.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25. 25. 29.  0.  1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 25.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25. 25. 29.  0.  1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [25. 25. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[ 2.8638504]
 [ 9.357006 ]
 [ 9.357006 ]
 [10.951166 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  0.  1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.963109016418457



action possibilites: [-1. 25. 25. 29.] 
expected returns: [[10.342074]
 [16.806324]
 [16.806324]
 [18.361399]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.971513748168945



action possibilites: [-1. 25. 25.] 
expected returns: [[12.58155 ]
 [20.107292]
 [20.107292]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 28. 30.  8.  1.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.422189712524414



action possibilites: [-1] 
expected returns: [[-15.192124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  6.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 28. 30.  8.  0.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.107284545898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-17.888    ]
 [-10.7721195]
 [-16.168919 ]
 [-12.116364 ]
 [-15.557884 ]
 [-15.51692  ]
 [-15.292487 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25.  6.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 20. 30. 28. 30.  8.  0.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.192124366760254



buy possibilites: [-1] 
expected returns: [[-7.975663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25.  6.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -10.772103309631348






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [1. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  1. 29. 29. 15.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  6.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  1. 29. 29. 15.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  1. 29. 29. 15.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 0.  1. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[-6.995352 ]
 [ 1.316014 ]
 [ 1.316014 ]
 [-1.6837502]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29. 15.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [15. 11.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.975663185119629



action possibilites: [-1. 29.] 
expected returns: [[-7.3916464 ]
 [ 0.86498904]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [15. 11.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.7661256790161133



action possibilites: [-1.] 
expected returns: [[-11.316472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [15. 11.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.200730085372925





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-13.8997345]
 [ -7.5872717]
 [-12.452738 ]
 [-10.113913 ]
 [ -9.002232 ]
 [-12.120727 ]
 [-12.597482 ]
 [-11.917277 ]
 [ -6.6260233]
 [-11.381091 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  6.] 
adversary cards in hand: [15. 11.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -11.316472053527832



buy possibilites: [-1] 
expected returns: [[-13.324522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [15. 11.  0. 11.  6.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -6.626023292541504






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [15. 11.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 11.  6.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  5.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [25. 29. 25.  3. 29.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  6.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [25. 29. 25.  3. 29.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.  6.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [25. 29. 25.  3. 29.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [25. 29. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 29.] 
expected returns: [[20.9449  ]
 [26.972277]
 [28.519747]
 [26.972277]
 [28.519747]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  3. 29.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [6. 3. 6. 8. 8.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.324522018432617



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[1.4006708]
 [8.142054 ]
 [9.843274 ]
 [9.843274 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [6. 3. 6. 8. 8.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.777830123901367



action possibilites: [-1.] 
expected returns: [[2.8066638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [6. 3. 6. 8. 8.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.678474426269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[0.287992 ]
 [6.6004934]
 [1.735029 ]
 [5.1855307]
 [2.067035 ]
 [2.2704842]
 [2.8066747]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 19. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [6. 3. 6. 8. 8.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.806663751602173



buy possibilites: [-1] 
expected returns: [[-0.69772625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [6. 3. 6. 8. 8.] 
adversary cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.600482940673828






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 3. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 8. 8.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [1. 1. 3. 0. 1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 8. 8.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [1. 1. 3. 0. 1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 8. 8.] 
cards in discard: [ 6.  3.  0. 16. 11. 11. 16.  6.  6.  0. 16.  8.  3. 25.  6. 11.  1.  6.
  0.  0.  3. 11. 11. 15.  0. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [1. 1. 3. 0. 1.] 
adversary cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [1. 1. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-1.2198927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 0. 1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3.  6.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6977262496948242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -3.6390157 ]
 [  3.2238128 ]
 [-11.934055  ]
 [ -1.923467  ]
 [ -8.155031  ]
 [  0.32418275]
 [  1.9359357 ]
 [ -1.4045339 ]
 [  5.817156  ]
 [ -2.24051   ]
 [  2.9488437 ]
 [ -1.3890829 ]
 [ -8.658769  ]
 [  4.360036  ]
 [ -1.2198979 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  2.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3.  6.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.2198927402496338



buy possibilites: [-1] 
expected returns: [[-16.38396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 1.] 
cards in discard: [ 1. 15. 29. 25.  0.  0.  0. 29. 15.  1. 25.  1. 29. 29. 25.  0. 25. 25.
  6. 29. 15.  0.  3. 15. 29. 29.  1. 25.  3. 25. 29.  1. 29. 29.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3.  6.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0.  -60.
   0.    0.   62.5   0. ] 
sum of rewards: 177.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 5.81716251373291






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3. 25. 29. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  6.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3. 25. 29. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 11. 11.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  5.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 3. 25. 29. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 3. 25. 29. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 15.] 
expected returns: [[-6.174694 ]
 [ 1.0589635]
 [ 2.8483303]
 [ 1.0589635]
 [-0.4271555]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 25. 15.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  5.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  8. 15.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.383960723876953



action possibilites: [-1. 25. 25.] 
expected returns: [[-4.404789 ]
 [ 4.2599573]
 [ 4.2599573]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.] 
cards in discard: [15. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  5.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  8. 15.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -1.3596792221069336



action possibilites: [-1] 
expected returns: [[6.1297035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 29.] 
cards in discard: [15. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  5.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  8. 15.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.259937286376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[3.4813735]
 [5.367936 ]
 [6.3371534]
 [5.8964252]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 29.] 
cards in discard: [15. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  5.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  8. 15.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.129703521728516



buy possibilites: [-1] 
expected returns: [[14.647486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 29.] 
cards in discard: [15. 29.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6.  0.  0.  8. 15.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 161 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 6.3371477127075195






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  8. 15.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8  0 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6
  3  0  6  6  0  6 11 11  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0.  1. 25. 29. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 0.  1. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-4.822725 ]
 [ 1.53981  ]
 [ 3.0584552]
 [ 1.53981  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 29. 25.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6. 25.  0.  3.  8.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.647485733032227



action possibilites: [-1. 25. 25.] 
expected returns: [[ 8.595711]
 [15.373838]
 [15.373838]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6. 25.  0.  3.  8.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.8105921745300293



action possibilites: [-1] 
expected returns: [[-11.446998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6. 25.  0.  3.  8.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.373844146728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-15.105427 ]
 [ -8.263825 ]
 [-13.607333 ]
 [ -9.575201 ]
 [-12.8368435]
 [-12.725693 ]
 [-12.368278 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 18. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6. 25.  0.  3.  8.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.44699764251709



buy possibilites: [-1] 
expected returns: [[26.23449]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 6. 25.  0.  3.  8.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -8.263805389404297






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6. 25.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  0.  3.  8.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 1.  6.  0.  1. 29.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 3. 0.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 1.  6.  0.  1. 29.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 3. 0.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  4.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 1.  6.  0.  1. 29.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 3. 0.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 1.  6.  0.  1. 29.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 1.  6.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-14.087095 ]
 [ -6.5654964]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  1. 29.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0. 11. 11.  6. 16.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.23448944091797



action possibilites: [-1. 29.] 
expected returns: [[-11.733135]
 [ -2.553388]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0. 11. 11.  6. 16.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -10.150131225585938



action possibilites: [-1.] 
expected returns: [[-11.878072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0. 11. 11.  6. 16.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.058052062988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-14.873154 ]
 [ -7.5235777]
 [-13.094918 ]
 [-10.56131  ]
 [ -8.8541765]
 [-12.399963 ]
 [-13.399418 ]
 [-12.381789 ]
 [ -6.325675 ]
 [-12.198654 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0. 11. 11.  6. 16.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -11.878071784973145



buy possibilites: [-1] 
expected returns: [[-20.870518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  6. 16.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -90   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -6.32567024230957






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  6. 16.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10. 10. 10.  4.] 
adversary cards in hand: [15. 25.  3. 29.  1.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 16.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [15. 25.  3. 29.  1.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6. 16.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [15. 25.  3. 29.  1.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [15. 25.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29.] 
expected returns: [[-4.419502  ]
 [ 0.94748664]
 [ 2.322468  ]
 [ 4.0236883 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  3. 29.  1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [16.  6.  8.  0.  6.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.87051773071289



action possibilites: [-1. 25.] 
expected returns: [[-5.539337 ]
 [ 1.4957397]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [16.  6.  8.  0.  6.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 0.06442785263061523



action possibilites: [-1] 
expected returns: [[13.94976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 15.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [16.  6.  8.  0.  6.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.495736837387085





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.415384]
 [18.222937]
 [13.056307]
 [16.831182]
 [13.496416]
 [13.601486]
 [13.949768]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 15.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 17. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [16.  6.  8.  0.  6.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.949760437011719



buy possibilites: [-1] 
expected returns: [[11.7753315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 15.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [16.  6.  8.  0.  6.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 18.222929000854492






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [16.  6.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8.  0.  6.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  6  8  3  8  6  6  6  3
  0  6  6  0  6 11 11  0  8  8 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 28. 30.  8.  0.  6.  4.  3.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [25.  1. 29.  0. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [25.  1. 29.  0. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [25.  1. 29.  0. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [25.  1. 29.  0. 25.] 
adversary cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [25.  1. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-25.229855]
 [-18.314821]
 [-16.648338]
 [-18.314821]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  0. 25.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  6. 11.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0. 16.  8.  0.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.775331497192383



action possibilites: [-1. 25.] 
expected returns: [[-34.336163]
 [-29.127455]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15. 25.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  6. 11.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0. 16.  8.  0.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -20.527496337890625



action possibilites: [-1] 
expected returns: [[-18.404892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15. 25.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  6. 11.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0. 16.  8.  0.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -29.12745475769043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-20.790045]
 [-14.003494]
 [-28.778118]
 [-19.070639]
 [-25.058638]
 [-16.893877]
 [-15.360832]
 [-18.708399]
 [-11.457383]
 [-19.38374 ]
 [-14.255916]
 [-18.653559]
 [-25.607254]
 [-12.88104 ]
 [-18.40489 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15. 25.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  1.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  6. 11.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0. 16.  8.  0.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.404891967773438



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 10 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 1 
Witch: 9 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 5 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [15. 29.  8. 29. 25.  3. 25.  0. 29.  1.  1.  1. 29. 25.  0. 25. 15.  0.
  6.  0.  1. 25. 15. 29. 29.  1. 15. 29.  1. 29. 25.  3.  1.  3. 15. 25.
  1. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  1 29 29 29 29 29 29 29 29 25 25
  1  1 15 25  6 25 25 15  1  1 25 25 15  1 15  1 25  8  1 15  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 16. 30. 28. 30.  8.  0.  6.  4.  2.  0.  0. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  6. 11.] 
adversary cards in discard: [ 8.  3.  6.  1. 11. 11.  8.  6.  0. 15.  8. 25.  6.  0.  3.  8.  3.  0.
 10. 11.  0. 11.  6. 16.  8.  0. 16.  8.  0.  6.] 
adversary owned cards: [ 3  3 11 16 15 16 11  8 16 11  1 11  0 25  0  6  8  3  8  6  6  6  3  0
  6  6  0  6 11 11  0  8  8 10  8  0] -> size -> 36 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      40       0       0
       0       0    -110       0       0     125       0] 
sum of rewards: 3000200 

action type: buy - action 25.0
Learning step: 120008.4609375
desired expected reward: 119997.0



