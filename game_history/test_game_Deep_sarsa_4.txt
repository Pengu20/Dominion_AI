 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0        0        0
        0        0        0     -350        0        0       27        0] 
sum of rewards: -3000508 

action type: buy - action 1.0
Learning step: -300050.75
desired expected reward: -300051.15625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  0.  0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 22.  0.  0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 22.  0.  0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3. 22.  0.  3.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.  0.  3.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0. 3. 1.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 3. 1.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 3. 1.] 
cards in discard: [ 8.  0.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 22.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  3.] 
adversary cards in discard: [ 0.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  3.] 
adversary cards in discard: [ 0.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 5 
card supply: [20. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  3.] 
adversary cards in discard: [ 0.  8. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 25.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0.  3.] 
cards in discard: [ 0.  8. 22.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0. 3.] 
cards in discard: [ 0.  8. 22.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  3. 22. 25.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  3. 22. 25.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  3. 22. 25.  1.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3. 22. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 25.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22. 25.  1.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  0.  3.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  0.  3.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 29. 30. 30. 30.  8.  9. 10. 10.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  0.  3.  0.] 
cards in discard: [15.  0.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 1.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 22.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 22.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 22.  0.  0.] 
adversary cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  3. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 22.  0.  0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 22.  0.  0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 22.  0.  0.] 
cards in discard: [ 8.  1.  0.  0. 11.  8. 15. 15.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [11. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  0. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 15.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0. 11.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 1.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 15.  8.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9. 10. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8.] 
cards in discard: [ 0.  0.  3.  0.  0. 25.  0.  0. 15.  3.  0. 11. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  0. 15.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 22.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8. 22.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 7. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [29. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  3.  0.] 
cards in discard: [ 3. 15.  0.  8. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 29. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0] -> size -> 29 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [ 3. 15.  0.  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6] -> size -> 30 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [ 3. 15.  0.  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6] -> size -> 30 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -395 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  0.] 
adversary cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3.  0.] 
cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.] 
cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.] 
cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.] 
cards in discard: [ 3. 15.  0.  8. 22. 25. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 5. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -95.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  0.  8. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15 11  8 15  0  0  0 29  3 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 29. 30. 29. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10. 25.  8. 15.] 
adversary cards in discard: [3. 8. 0. 0. 1.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10. 25.  8. 15.] 
adversary cards in discard: [3. 8. 0. 0. 1.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10. 25.  8. 15.] 
adversary cards in discard: [3. 8. 0. 0. 1.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3. 10. 25.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  8. 15.] 
cards in discard: [3. 8. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 25.  8. 15.] 
cards in discard: [3. 8. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 25.  8. 15.] 
cards in discard: [3. 8. 0. 0. 1. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 22.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 22.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 3.
 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 2. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 22.  0. 29.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 22.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0. 29.  0.] 
cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0. 29.  0.] 
cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0. 29.  0.] 
cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 15.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.  0. 22.  0. 29.  0.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 15.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.  0. 22.  0. 29.  0.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 15.  3.] 
adversary cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.  0. 22.  0. 29.  0.] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -125.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  3.] 
cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.  0. 22.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 35 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  3.] 
cards in discard: [ 3.  8.  0.  0.  1.  0.  3. 10. 25.  8. 15.  0.  0. 22.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 35 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 29. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -10.     0.     0.    13.5    0. ] 
sum of rewards: -121.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  0.  8.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  1. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  0  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 15.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 28. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 15.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 15.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0 -20   0   0  16   0] 
sum of rewards: -99 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  8.] 
cards in discard: [ 8.  1. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3] -> size -> 37 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  8.] 
cards in discard: [ 8.  1. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3] -> size -> 37 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 27. 30. 27. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3.  0. 25. 15.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 27. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3.  0. 25. 15.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3.  0. 25. 15.] 
adversary cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -40.     0.     0.    13.5    0. ] 
sum of rewards: -151.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [22.  3.  0. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 25. 15.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0. 25. 15.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 15.  0. 10.  0.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 15.  0. 10.  0.] 
cards in discard: [ 8.  1. 15.  0.  3. 15.  3.  8.  3.  3.  0. 29.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 15.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 26. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 15.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 3. 0. 3. 6. 3. 0. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 15.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -50.     0.     0.    13.5    0. ] 
sum of rewards: -161.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 15.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  8.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 10.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -60.     0.     0.    13.5    0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  3. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3.  3.] 
cards in discard: [ 8.  0. 15.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [ 8.  0. 15.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [ 8.  0. 15.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.   -70.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [3. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 23. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.  8.  0.  0.] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.  -80.
   0.    0.   13.5   0. ] 
sum of rewards: -161.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [25.  1.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3. 29.  8.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3. 29.  8.] 
cards in discard: [ 8.  0. 15.  0.  0. 10. 15.  3. 15.  3.  3.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1] -> size -> 43 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15.  8.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 22.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  0. 22.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22  8  1 25  0 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 22.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 22.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 22.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [11. 15.  8.  8. 22.] 
adversary owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 21. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [11. 15.  8.  8. 22.] 
adversary owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 20. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  8.  3.  0.  0.] 
adversary cards in discard: [11. 15.  8.  8. 22.] 
adversary owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -90.     0.     0.     0.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [10.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  0.] 
cards in discard: [11. 15.  8.  8. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [11. 15.  8.  8. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [11. 15.  8.  8. 22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 20. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [11. 15.  8.  8. 22.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 25.  3.  3.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1] -> size -> 45 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 20. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 25.  3.  3.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 19. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 25.  3.  3.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -90.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    13.5    0. ] 
sum of rewards: -191.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [29.  3. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.  3.  3.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 19. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 19. 30. 24. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  1.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 19. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  1.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 15.  1.] 
adversary cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.  -120.     0.     0.    13.5    0. ] 
sum of rewards: -231.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3.  0.  0. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  1.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  1.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  9. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  1.] 
cards in discard: [11. 15.  8.  8. 22.  3.  8. 10.  0.  0. 25.  3. 29.  3.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 18. 30. 23. 30.  8.  8. 10.  8.  7.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0. 1. 1. 0. 6. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  7.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29.  3. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: -209 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [29.  3. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 10. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  7.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 15.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10. 15.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [3. 1. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 25.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 18. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 25.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0. 6.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8.  8.  3.  3. 25.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -90.     0.     0.     0.     0.     0.     0.
    0.  -140.     0.     0.    13.5    0. ] 
sum of rewards: -221.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8.  8.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  3. 25.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29  3 10  3  0  0  3  8  3 11  3  3 29
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  3. 15.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 17. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  3. 15.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  3. 15.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -150.     0.     0.    13.5    0. ] 
sum of rewards: -171.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3.  0.  1.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  3. 15.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  3. 15.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  8.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  3. 15.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 16. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -160.     0.     0.    13.5    0. ] 
sum of rewards: -181.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [22.  0.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 29.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  0. 29.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.  3. 15.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  0.  3. 15.] 
cards in discard: [ 8. 11. 29.  3. 10. 15.  8.  8. 25. 11.  3.  0.  1.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 15. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 8. 15.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -170.     0.     0.    13.5    0. ] 
sum of rewards: -191.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15 15  8 15  0  0  0 29 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1] -> size -> 52 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 14. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    13.5    0. ] 
sum of rewards: -201.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  6.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [8. 8. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 1.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25. 15. 29.  3.  1.] 
adversary cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1] -> size -> 53 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0. 13. 30. 22. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25. 15. 29.  3.  1.] 
adversary cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1] -> size -> 54 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 0. 12. 30. 22. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [25. 15. 29.  3.  1.] 
adversary cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.     0.     0.     0.     0.
    0.  -190.     0.     0.    13.5    0. ] 
sum of rewards: -211.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [25. 15. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 29.  3.  1.] 
cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  8. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1] -> size -> 54 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  1. 15. 10.] 
cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  7. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  3.  1. 15. 10.] 
cards in discard: [8. 8. 8. 0. 3. 8. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 12. 30. 22. 30.  8.  7. 10.  7.  5.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  3.  1. 15. 10.] 
cards in discard: [8. 8. 8. 0. 3. 8. 3. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 1. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6] -> size -> 55 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 12. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  3. 22.  8.  0.] 
adversary cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -200    0 -300
    0    0] 
sum of rewards: -565 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6] -> size -> 55 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0. 12. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  3. 22.  8.  0.] 
adversary cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  3. 22.  8.  0.] 
adversary cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -210.     0.     0.    13.5    0. ] 
sum of rewards: -261.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [11.  3. 22.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 22.  8.  0.] 
cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0. 11.  0.] 
cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0. 11.  0.] 
cards in discard: [ 8.  8.  8.  0.  3.  8.  3.  0.  8. 25. 15. 29.  3.  1. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 11. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8. 15. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -220.     0.     0.    13.5    0. ] 
sum of rewards: -271.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 3.  8. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25 15  8 15  0  0 10  0  0  3  8  3 11  3  3 29  8 11  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3. 29.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 10. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3. 29.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [1. 3. 1. 1. 0. 6. 1. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 3. 1. 0. 0. 0. 6. 0.
 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 6. 1. 1. 1. 1. 0. 0. 1. 3. 0. 0. 0.
 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  3. 29.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -230.     0.     0.    13.5    0. ] 
sum of rewards: -221.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [22.  3. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 29.  8. 11.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  3 29  8 11  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [ 8.  8. 22.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1] -> size -> 58 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  9. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [ 8.  8. 22.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [ 8.  8. 22.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -240.     0.     0.    13.5    0. ] 
sum of rewards: -201.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0.  3.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [ 8.  8. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [ 8.  8. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [ 8.  8. 22. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  8.  8. 15.  8.] 
adversary cards in discard: [ 8.  8. 22. 10.  0.  3.  1.  0. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  8. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  8.  8. 15.  8.] 
adversary cards in discard: [ 8.  8. 22. 10.  0.  3.  1.  0. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  7. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 8.  8.  8. 15.  8.] 
adversary cards in discard: [ 8.  8. 22. 10.  0.  3.  1.  0. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -250.     0.     0.    13.5    0. ] 
sum of rewards: -211.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8.  8.  8. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 15.  8.] 
cards in discard: [ 8.  8. 22. 10.  0.  3.  1.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 15.  8.] 
cards in discard: [ 8.  8. 22. 10.  0.  3.  1.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [1. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  7. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 1.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 60 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  7. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 1.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 61 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  6. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [ 1.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -260.     0.     0.    13.5    0. ] 
sum of rewards: -221.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 1.  8.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 22. 30.  8.  7. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 61 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6] -> size -> 62 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  6. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 0. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6] -> size -> 62 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  6. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0 -270    0 -300
    0    0] 
sum of rewards: -575 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6] -> size -> 62 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  6. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
adversary owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -280.     0.     0.    13.5    0. ] 
sum of rewards: -271.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 3. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 8.] 
cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  8  1 25  8 15  0  0 10  0  0  8  3  8  8  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [25.  1.  8.  0.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [15.  8.  0. 10. 22.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.  8.  0.  8.] 
adversary owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1] -> size -> 63 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  5. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [15.  8.  0. 10. 22.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.  8.  0.  8.] 
adversary owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  4. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [15.  8.  0. 10. 22.] 
adversary cards in discard: [25.  1.  8.  0.  0.  8. 10.  8.  0.  8.] 
adversary owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.     0.     0.     0.     0.
    0.  -290.     0.     0.    13.5    0. ] 
sum of rewards: -251.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  8.  0. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 10. 22.] 
cards in discard: [25.  1.  8.  0.  0.  8. 10.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 6.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1. 15.  8. 22.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  1 25  8 15  0  0 10  0  0  8  8  8  8 10] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 6.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 0.  4. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 6.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  4. 30. 22. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 6.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  4. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 0. 1. 3. 6.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 6.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  4. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  8.  8.  8.  8.] 
adversary cards in discard: [ 3. 10. 15.  8. 22.  0.] 
adversary owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 6.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1] -> size -> 64 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  4. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  8.  8.  8.  8.] 
adversary cards in discard: [ 3. 10. 15.  8. 22.  0.] 
adversary owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 6.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  8.  8.  8.  8.] 
adversary cards in discard: [ 3. 10. 15.  8. 22.  0.] 
adversary owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10  3] -> size -> 15 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -300.     0.     0.    13.5    0. ] 
sum of rewards: -291.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [10.  8.  8.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  8.  8.] 
cards in discard: [ 3. 10. 15.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25  8 15  0 10  0  0  8  8  8  8 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 10. 15.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 10. 15.  8. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1] -> size -> 65 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  3. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [10.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -310.     0.     0.    13.5    0. ] 
sum of rewards: -301.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [10.  0.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 6. 0. 1. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  7.] 
adversary cards in hand: [0. 6. 0. 1. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 25.  1.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 6. 0. 1. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 22.  8.  0.] 
adversary cards in discard: [15. 10.  0.  0. 25.  1.] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3 15] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1] -> size -> 66 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  2. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 22.  8.  0.] 
adversary cards in discard: [15. 10.  0.  0. 25.  1.] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3 15] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 22.  8.  0.] 
adversary cards in discard: [15. 10.  0.  0. 25.  1.] 
adversary owned cards: [22  1 25 15  0 10  0  0  8  8 10  3 15] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -320.     0.     0.    13.5    0. ] 
sum of rewards: -311.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15. 22.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 22.  8.  0.] 
cards in discard: [15. 10.  0.  0. 25.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25 15  0 10  0  0  8  8 10  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 22.  0.] 
cards in discard: [15. 10.  0.  0. 25.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 22.  0.] 
cards in discard: [15. 10.  0.  0. 25.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 25.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1] -> size -> 67 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  1. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 25.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 0.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 25.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.     0.     0.     0.     0.     0.     0.     0.     0.     0.
    0.  -330.     0.     0.    13.5    0. ] 
sum of rewards: -321.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15. 25.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 25 15  0 10  0  0  8 10  3 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  1.  0. 15.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1] -> size -> 68 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 30. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  1.  0. 15.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 0. 10.  1.  0. 15.] 
adversary cards in discard: [ 8. 15.] 
adversary owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0 1500    0 -340    0    0
  432    0] 
sum of rewards: 1617 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 0. 10.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0. 15.] 
cards in discard: [ 8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  0  8 10 15] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  1 15  0  0  8 10 15] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [ 8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  1 15  0  0  8 10 15] -> size -> 8 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 29. 21. 30.  8.  6. 10.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [ 8. 15. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 29. 21. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [1. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 21. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  0. 10.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2] -> size -> 69 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 29. 21. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  0. 10.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 3. 1. 0. 0. 6. 1. 1. 0. 1. 1.
 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 3. 6. 1. 1. 1. 0. 0. 1. 1. 0. 6. 0. 1.
 1. 1. 0. 1. 1. 1. 0. 2. 0. 3. 1. 0. 1. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  0. 10.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.   60.    0.    0.    0.    0.    0.    0.    0. -350.
    0.    0.    4.    0.] 
sum of rewards: -291.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [16.  0. 10.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0. 22.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0. 22.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  4.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0. 22.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [1. 1. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  8. 15. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3] -> size -> 70 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 29. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  8. 15. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 0. 0.] 
cards in discard: [2.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [16.  8. 15. 15.  1.] 
adversary cards in discard: [] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0 1500    0 -360    0    0
  432    0] 
sum of rewards: 1627 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [16.  8. 15. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 15. 15.  1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 15. 15.  1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  3.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 15. 15.  1.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8.  0. 10. 22.  0.] 
adversary cards in discard: [ 8. 16.  8. 15. 15.  1.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2] -> size -> 71 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 28. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8.  0. 10. 22.  0.] 
adversary cards in discard: [ 8. 16.  8. 15. 15.  1.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8.  0. 10. 22.  0.] 
adversary cards in discard: [ 8. 16.  8. 15. 15.  1.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0 1500    0 -370    0    0
  432    0] 
sum of rewards: 1617 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8.  0. 10. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 22.  0.] 
cards in discard: [ 8. 16.  8. 15. 15.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 22.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 22.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0.  0. 27. 20. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 22.  0.  8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 19. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [3. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 27. 19. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  1. 15. 16.  8.] 
adversary cards in discard: [ 3. 10.  8.  0. 22.  0.  8.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2] -> size -> 72 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 27. 19. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  1. 15. 16.  8.] 
adversary cards in discard: [ 3. 10.  8.  0. 22.  0.  8.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  1. 15. 16.  8.] 
adversary cards in discard: [ 3. 10.  8.  0. 22.  0.  8.] 
adversary owned cards: [22  1 15  0  0  8 10 15 16  8  8  3] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0. 1500.    0. -380.
    0.    0.  108.    0.] 
sum of rewards: 1253.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  1. 15. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 15. 16.  8.] 
cards in discard: [ 3. 10.  8.  0. 22.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  1 15  0  0  8 10 15 16  8  8  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  2.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 6. 1. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  8.] 
cards in discard: [ 3. 10.  8.  0. 22.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 6. 1. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  8.] 
cards in discard: [ 3. 10.  8.  0. 22.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 6. 1. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [1. 6. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 1. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 1. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2] -> size -> 73 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 26. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 1. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.    0.    0.    0. 1500.    0. -390.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [0. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22 15  0  0  8 10 15 16  8  8  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 15. 16. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2] -> size -> 74 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 25. 19. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 15. 16. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 15. 16. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0.    0.    0. -400.
    0.    0.    4.    0.] 
sum of rewards: -311.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15. 15. 16. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15. 16. 22.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 15. 16. 22.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 16. 22.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 16. 22.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 16.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3] -> size -> 75 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 25. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 16.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 16.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -410    0    0
  432    0] 
sum of rewards: 1607 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  8. 16.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 16.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22 15 10 15 16  8  8  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 0. 2. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 10 15 16  8  8  8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 0. 2. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 10 15 16  8  8  8] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 0. 2. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [6. 0. 2. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 2. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8.  8. 15. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 2. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2] -> size -> 76 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 24. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8.  8. 15. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 2. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8.  8. 15. 22.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -420.
    0.    0.  108.    0.] 
sum of rewards: 1273.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [10.  8.  8. 15. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 15. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8. 15. 22.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22 10 15 16  8  8  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 1. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 22.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 10 15 16  8  8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 1. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 22.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [22 10 15 16  8  8] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 1. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [22. 15.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8] -> size -> 6 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2] -> size -> 77 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 23. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [22. 15.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8] -> size -> 6 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [22. 15.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22 10 15 16  8  8] -> size -> 6 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -430.
    0.    0.  108.    0.] 
sum of rewards: 1263.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [22. 15.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [22 10 15 16  8  8] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2] -> size -> 78 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 22. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2] -> size -> 79 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0 1500    0 -440    0    0
  432    0] 
sum of rewards: 1577 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2] -> size -> 79 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 21. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 1. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2] -> size -> 79 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2] -> size -> 79 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 21. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2] -> size -> 79 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 21. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -450.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 15  8] -> size -> 3 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.  8.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 0. 0. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2] -> size -> 80 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0. 20. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.   90.    0.    0.    0.    0.    0. 1500.    0. -460.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 0. 6. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 0. 6. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 1. 0. 6. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2] -> size -> 81 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 19. 18. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [10.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.  120.    0.    0.    0.    0.    0.    0.    0. -470.
    0.    0.    4.    0.] 
sum of rewards: -351.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 1.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3] -> size -> 82 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0. 19. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 1.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [ 8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  120    0    0    0    0    0 1500    0 -480    0    0
  432    0] 
sum of rewards: 1567 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [ 8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [10 15  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2] -> size -> 83 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 18. 17. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [2. 1. 1. 6. 0. 0. 2. 0. 0. 0. 0. 1. 2. 3. 1. 1. 1. 0. 2. 1. 6. 1. 0. 1.
 3. 1. 0. 3. 0. 0. 2. 0. 0. 0. 1. 0. 2. 6. 0. 2. 1. 1. 2. 1. 1. 1. 1. 1.
 2. 1. 0. 3. 1. 0. 2. 0. 0. 1. 1. 0. 2. 0. 1. 0. 0. 1. 3. 3. 1. 0. 6. 1.
 2. 3. 0. 0. 1. 1. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [15. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 15  8] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0.    0.    0. -490.
    0.    0.    4.    0.] 
sum of rewards: -341.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 15  8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [1. 3. 1. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 79 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 79 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3] -> size -> 84 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 18. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1. 1.] 
cards in discard: [2.] 
cards in deck: 79 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2] -> size -> 85 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 17. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -500.
    0.    0.  108.    0.] 
sum of rewards: 1253.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 2. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2] -> size -> 85 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 17. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 2. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2] -> size -> 85 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [2. 0. 0. 2. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1.] 
cards in deck: 74 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2] -> size -> 85 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 17. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1.] 
cards in deck: 74 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2] -> size -> 85 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0. 17. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2.] 
cards in deck: 74 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2] -> size -> 86 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0. 16. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -510.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 2. 2. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2] -> size -> 86 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 16. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 2. 2. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2] -> size -> 86 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [0. 3. 2. 2. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 2. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1.] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2] -> size -> 86 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 16. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1.] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2] -> size -> 86 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 16. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 2. 2. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2.] 
cards in deck: 69 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.  150.    0.    0.    0.    0.    0. 1500.    0. -520.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2] -> size -> 87 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0. 15. 16. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3.] 
cards in deck: 64 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3] -> size -> 88 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 15. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0. -530.
    0.    0.    4.    0.] 
sum of rewards: -351.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 1. 0. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3] -> size -> 88 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 15. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 1. 0. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3] -> size -> 88 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3] -> size -> 88 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 15. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3] -> size -> 88 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 15. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2.] 
cards in deck: 59 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2] -> size -> 89 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 14. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0. 1500.    0. -540.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 2. 1. 2.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2] -> size -> 89 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 14. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 2. 1. 2.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2] -> size -> 89 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [1. 1. 2. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 2. 1. 2.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2] -> size -> 89 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 14. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 2. 1. 2.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2] -> size -> 89 
action values: 0 
buys: 1 
player value: 12 
card supply: [ 0.  0. 14. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 2. 1. 2.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2.] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2] -> size -> 90 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 0.  0. 13. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0. 1500.    0. -550.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 1. 0. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2] -> size -> 90 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 13. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 1. 0. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2] -> size -> 90 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [2. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2] -> size -> 90 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 13. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2] -> size -> 90 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 13. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 0. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2] -> size -> 91 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 12. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0. 1500.    0. -560.
    0.    0.  108.    0.] 
sum of rewards: 1223.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 1. 2. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2] -> size -> 91 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 1. 2. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2] -> size -> 91 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 2. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 2. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2] -> size -> 91 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 12. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 2. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2] -> size -> 91 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 12. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 2. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.  180.    0.    0.    0.    0.    0. 1500.    0. -570.
    0.    0.  108.    0.] 
sum of rewards: 1213.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2] -> size -> 92 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0. 11. 15. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0.    0.    0. -580.
    0.    0.    4.    0.] 
sum of rewards: -371.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [0. 1. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3] -> size -> 93 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 0.  0. 11. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2] -> size -> 94 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0. 10. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -590.
    0.    0.  108.    0.] 
sum of rewards: 1223.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 1. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2] -> size -> 94 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0. 10. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 1. 1.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2] -> size -> 94 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [2. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 1. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2] -> size -> 94 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0. 10. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2] -> size -> 94 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0. 10. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 1. 1.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2] -> size -> 95 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  9. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  210.    0.    0.    0.    0.    0. 1500.    0. -600.
    0.    0.  108.    0.] 
sum of rewards: 1213.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2] -> size -> 95 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  9. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2] -> size -> 95 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 0 
cards in hand: [6. 1. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2] -> size -> 95 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2] -> size -> 95 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0.  9. 14. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3] -> size -> 96 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  9. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0.    0.    0. -610.
    0.    0.    4.    0.] 
sum of rewards: -371.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3] -> size -> 96 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 0. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3] -> size -> 96 
adversary victory points: 8
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 83 -------------------- 
Player: 0 
cards in hand: [2. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3] -> size -> 96 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  9. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3] -> size -> 96 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0.  9. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -620.
    0.    0.  108.    0.] 
sum of rewards: 1223.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 2. 0. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 2. 0. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 2. 0. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 84 -------------------- 
Player: 0 
cards in hand: [6. 2. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 2. 0. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 0. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2] -> size -> 97 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0.  8. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 0. 1. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.    0.    0.    0. 1500.    0. -630.
    0.    0.  108.    0.] 
sum of rewards: 1213.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 85 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2] -> size -> 98 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0.  7. 13. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3] -> size -> 99 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  7. 12. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.  270.    0.    0.    0.    0.    0.    0.    0. -640.
    0.    0.    4.    0.] 
sum of rewards: -371.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 12. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 6. 1. 6.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3] -> size -> 99 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  7. 12. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 0. 6. 1. 6.] 
adversary cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3. 0. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3] -> size -> 99 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 86 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 6.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3. 0. 3. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3] -> size -> 99 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 12. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 6.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3. 0. 3. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3] -> size -> 99 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0.  0.  7. 12. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 6.] 
cards in discard: [2. 1. 3. 1. 1. 1. 2. 2. 0. 0. 2. 1. 2. 0. 3. 2. 2. 1. 3. 1. 0. 3. 3. 1.
 2. 1. 1. 1. 0. 1. 2. 1. 1. 2. 1. 2. 2. 2. 0. 1. 0. 1. 2. 1. 0. 1. 2. 0.
 3. 0. 3. 3. 1. 0. 2. 0. 1. 2. 0. 0. 2. 2. 0. 0. 1. 1. 3. 6. 1. 3. 1. 0.
 2. 2. 0. 0. 0. 0. 2. 6. 2. 0. 1. 0. 3. 0. 3. 1. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  300.    0.    0.    0.    0.    0.    0.    0. -650.
    0.    0.    4.    0.] 
sum of rewards: -351.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 87 -------------------- 
Player: 0 
cards in hand: [1. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 95 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 95 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3] -> size -> 100 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0.  7. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [2.] 
cards in deck: 95 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2] -> size -> 101 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0    0    0    0 1500    0 -660    0    0
  432    0] 
sum of rewards: 1567 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 1. 3. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2] -> size -> 101 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  6. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 0. 1. 3. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2] -> size -> 101 
adversary victory points: 10
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 88 -------------------- 
Player: 0 
cards in hand: [2. 0. 1. 3. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0.] 
cards in deck: 90 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2] -> size -> 101 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  6. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0.] 
cards in deck: 90 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2] -> size -> 101 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0.  6. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2.] 
cards in deck: 90 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.    0.    0.  300.    0.    0.    0.    0.    0. 1500.    0. -670.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 89 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.] 
cards in deck: 85 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2.] 
cards in deck: 85 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2] -> size -> 102 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0.  0.  5. 11. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3.] 
cards in deck: 85 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3] -> size -> 103 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  5. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.    0.    0.    0.    0.    0. -680.
    0.    0.    4.    0.] 
sum of rewards: -351.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 0. 1. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3] -> size -> 103 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  5. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 1. 0. 1. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3] -> size -> 103 
adversary victory points: 11
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 90 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 1. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3.] 
cards in deck: 80 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3] -> size -> 103 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  5. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3.] 
cards in deck: 80 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3] -> size -> 103 
action values: 0 
buys: 1 
player value: 10 
card supply: [ 0.  0.  5. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2.] 
cards in deck: 80 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2] -> size -> 104 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0.  0.  4. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.    0.    0.    0. 1500.    0. -690.
    0.    0.  108.    0.] 
sum of rewards: 1243.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  4. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 2. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2] -> size -> 104 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  4. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [2. 2. 3. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2] -> size -> 104 
adversary victory points: 11
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 91 -------------------- 
Player: 0 
cards in hand: [2. 2. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 2. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.] 
cards in deck: 75 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2] -> size -> 104 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  4. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.] 
cards in deck: 75 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2] -> size -> 104 
action values: 0 
buys: 1 
player value: 9 
card supply: [ 0.  0.  4. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 2. 3. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2.] 
cards in deck: 75 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.    0.    0.    0. 1500.    0. -700.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
adversary victory points: 11
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [3. 3. 2. 0. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
adversary victory points: 11
player victory points: 0 





         -------------------- Turn: 92 -------------------- 
Player: 0 
cards in hand: [3. 3. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0.] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0.] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2] -> size -> 105 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0.  0.  3. 10. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 2. 0. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3.] 
cards in deck: 70 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3] -> size -> 106 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0.  0.  3.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[  -5.    0.    0.  360.    0.    0.    0.    0.    0.    0.    0. -710.
    0.    0.    4.    0.] 
sum of rewards: -351.0 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 1. 3. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3] -> size -> 106 
adversary victory points: 12
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  3.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [1. 0. 1. 3. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3] -> size -> 106 
adversary victory points: 12
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 93 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3] -> size -> 106 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  3.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3] -> size -> 106 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0.  3.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2.] 
cards in deck: 65 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  360    0    0    0    0    0 1500    0 -720    0    0
  432    0] 
sum of rewards: 1567 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 1. 3. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
adversary victory points: 12
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 1. 3. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
adversary victory points: 12
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [6. 1. 1. 3. 2.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
adversary victory points: 12
player victory points: 0 





         -------------------- Turn: 94 -------------------- 
Player: 0 
cards in hand: [6. 1. 1. 3. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2] -> size -> 107 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0.  0.  2.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



buy possibilites: [-1] 
expected returns: [[-0.65123945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 3. 2.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2.] 
cards in deck: 60 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2] -> size -> 108 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0.  0.  1.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[  -5.    0.    0.  360.    0.    0.    0.    0.    0. 1500.    0. -730.
    0.    0.  108.    0.] 
sum of rewards: 1233.0 

action type: buy - action 2.0
Learning step: 0
desired expected reward: -0.6512394547462463






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  1.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2. 6. 1. 1. 3. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2] -> size -> 108 
adversary victory points: 12
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0.  0.  1.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [0. 3. 1. 1. 0.] 
adversary cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2. 6. 1. 1. 3. 2.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2] -> size -> 108 
adversary victory points: 12
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 95 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.65123945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2. 6. 1. 1. 3. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2] -> size -> 108 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0.  0.  1.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.6512394547462463





----------- BUY PHASE ----------- 
buy possibilites: [ 2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]
 [-0.65123945]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2. 6. 1. 1. 3. 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2] -> size -> 108 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0.  0.  1.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.6512394547462463



Player 0 won the game! 



Player 0 bought cards:
Copper: 23 
Silver: 29 
Gold: 30 
Estate: 13 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 3. 1. 1. 0.] 
cards in discard: [2. 1. 3. 1. 0. 0. 2. 2. 0. 1. 3. 2. 3. 3. 0. 3. 1. 3. 2. 1. 1. 0. 1. 2.
 2. 2. 2. 3. 1. 0. 3. 3. 3. 2. 0. 0. 2. 1. 0. 1. 3. 0. 2. 6. 1. 1. 3. 2.
 2.] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 1 3
 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 6 1 1 1 1 1 1 6 1 1 1 1 1 1 2 3 2 2 2 2
 3 2 2 2 2 2 2 3 2 3 2 2 2 3 2 2 2 2 3 2 2 3 2 2 3 3 2 2 3 2 2 3 2 2 2] -> size -> 109 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0.  0.  0.  9. 30.  8.  6.  9.  7.  1.  9.  8. 10. 10.  8.  9.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[     -5 3000000       0     360       0       0       0       0       0
    1500       0    -740       0       0     216       0] 
sum of rewards: 3001331 

action type: buy - action 2.0
Learning step: 300133.1875
desired expected reward: 300132.53125



