 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[45.09812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       20        0
        0        0        0      -80        0     -300        0        0] 
sum of rewards: -3000395 

action type: buy - action 6.0
Learning step: -300067.8125
desired expected reward: -299784.84375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.22438 ]
 [73.199425]
 [62.933952]
 [28.87069 ]
 [81.393234]
 [60.128498]
 [50.359344]
 [43.44191 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.502296447753906



buy possibilites: [-1] 
expected returns: [[31.484917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 81.39323425292969






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[47.626553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.48491668701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[46.674255]
 [72.832664]
 [64.47608 ]
 [31.06287 ]
 [62.2809  ]
 [80.63455 ]
 [62.03675 ]
 [98.62823 ]
 [44.61555 ]
 [53.789227]
 [70.66183 ]
 [48.126743]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.369876861572266



buy possibilites: [-1] 
expected returns: [[21.001467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.62822723388672






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[30.434998]
 [56.090954]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.001466751098633



action possibilites: [-1] 
expected returns: [[18.804352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.1300048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.023605]
 [36.13375 ]
 [30.375774]
 [ 7.567861]
 [41.45978 ]
 [28.594597]
 [23.081596]
 [19.808636]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.804351806640625



buy possibilites: [-1] 
expected returns: [[11.757376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.45977783203125






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 11.  3.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 11.  3.  3.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[40.44867]
 [69.53275]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.757375717163086



action possibilites: [-1.] 
expected returns: [[55.261765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.72371673583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 57.927753]
 [ 85.94509 ]
 [ 76.324814]
 [ 41.365547]
 [ 74.597984]
 [ 94.109116]
 [ 73.83631 ]
 [114.76274 ]
 [ 55.694366]
 [ 64.45991 ]
 [ 83.19476 ]
 [ 58.111416]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.26176452636719



buy possibilites: [-1] 
expected returns: [[40.43637]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.76274108886719






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.999346]
 [36.32103 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.436370849609375



action possibilites: [-1] 
expected returns: [[33.396645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.73146438598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.945217]
 [56.376503]
 [49.05852 ]
 [22.489641]
 [61.969727]
 [47.20186 ]
 [40.10063 ]
 [35.591106]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  5. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.396644592285156



buy possibilites: [-1] 
expected returns: [[22.76661]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0. 11.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 61.96971893310547






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[82.44263]
 [93.27561]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.76660919189453



action possibilites: [-1.] 
expected returns: [[75.89997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 83.18830108642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.45827 ]
 [114.05284 ]
 [104.375656]
 [ 66.21836 ]
 [103.14504 ]
 [120.95447 ]
 [102.02197 ]
 [137.8996  ]
 [ 82.61204 ]
 [ 92.35374 ]
 [111.15122 ]
 [ 84.166954]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.89997100830078



buy possibilites: [-1] 
expected returns: [[41.52935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 14.  3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 137.89962768554688






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.  3.] 
cards in discard: [11.  3.  0.  0.  0.  0. 11. 11.  3.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 29. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 29.] 
expected returns: [[ 9.548372]
 [10.71542 ]
 [29.602474]
 [23.786482]
 [29.602474]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.52935028076172



action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[15.566914]
 [17.173439]
 [38.193607]
 [46.872047]
 [17.173439]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  3. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.961830139160156



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[39.600014]
 [44.15953 ]
 [61.493134]
 [44.15953 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.872039794921875



action possibilites: [-1] 
expected returns: [[51.291027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.39131927490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.222214]
 [78.08043 ]
 [70.14186 ]
 [46.304558]
 [84.33032 ]
 [68.66801 ]
 [62.318344]
 [56.840595]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.2910270690918



buy possibilites: [-1] 
expected returns: [[48.2584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  2. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.33031463623047






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  2. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[13.811581]
 [34.07669 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.258399963378906



action possibilites: [-1] 
expected returns: [[-2.174391]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.29594421386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -3.1857502]
 [ 11.841885 ]
 [  7.5321584]
 [-10.255916 ]
 [ 16.34925  ]
 [  5.8071733]
 [  1.772809 ]
 [  0.6896577]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  2. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.174391031265259



buy possibilites: [-1] 
expected returns: [[23.053265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 16.349246978759766






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 9.763807]
 [20.235697]
 [25.49444 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 14.  3.  3.  0.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.053264617919922



action possibilites: [-1. 11.] 
expected returns: [[73.31875]
 [94.99926]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 14.  3.  3.  0.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.597637176513672



action possibilites: [-1] 
expected returns: [[30.161255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 14.  3.  3.  0.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.6868667602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.358267]
 [54.212574]
 [44.56402 ]
 [ 8.95116 ]
 [40.117344]
 [65.38877 ]
 [41.012516]
 [79.85013 ]
 [21.185032]
 [31.791851]
 [52.46226 ]
 [29.695251]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  7.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 14.  3.  3.  0.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.1612548828125



buy possibilites: [-1] 
expected returns: [[110.35108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  3. 10.  0. 10. 11. 11.  3.  0.  0.  0. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 14.  3.  3.  0.] 
adversary cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 79.85014343261719






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [11. 14.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  3.  0.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 11. 29. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 10.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 10.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.] 
cards in discard: [ 6. 10. 11.  0.  0.  3.  0.  3.  0.  0.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 10.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[49.0008  ]
 [68.873726]
 [52.827904]
 [52.827904]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [11. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 391   0] 
sum of rewards: 386 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 66.77393341064453



action possibilites: [-1] 
expected returns: [[38.06076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11. 29. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.3165054321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.145344]
 [36.30963 ]
 [46.17363 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 29. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.060760498046875



buy possibilites: [-1] 
expected returns: [[29.981804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 29. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 48.14533233642578






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[11.422928]
 [10.032257]
 [27.289871]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0.  3.] 
adversary cards in discard: [14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.98180389404297



action possibilites: [-1] 
expected returns: [[90.80549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0.  3.] 
adversary cards in discard: [14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.896949768066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.80805]
 [95.58685]
 [72.55342]
 [92.76542]
 [94.53896]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0.  3.] 
adversary cards in discard: [14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.80548858642578



buy possibilites: [-1] 
expected returns: [[48.82756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11.  0.  3.] 
adversary cards in discard: [14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 95.58686065673828






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.  3.] 
cards in discard: [14.  3.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9. 10.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 29. 29.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  3.] 
cards in discard: [14.  3.  3.  0. 11. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 29. 29.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  3.] 
cards in discard: [14.  3.  3.  0. 11. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 29. 29.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 29.] 
expected returns: [[65.13941 ]
 [61.351265]
 [79.48825 ]
 [79.48825 ]
 [79.48825 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 29. 29.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.82756042480469



action possibilites: [-1. 10. 29. 29. 10.] 
expected returns: [[61.22014 ]
 [56.100277]
 [81.03916 ]
 [81.03916 ]
 [56.100277]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 29. 10.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 79.48824310302734



action possibilites: [-1. 10. 29. 10. 11.] 
expected returns: [[48.666794]
 [43.46332 ]
 [73.533966]
 [43.46332 ]
 [65.431564]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 10. 11.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.03914642333984



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[46.597233]
 [40.200363]
 [40.200363]
 [61.935402]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.53394317626953



action possibilites: [-1] 
expected returns: [[39.63311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.26045989990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.355968]
 [54.337975]
 [47.999634]
 [21.069908]
 [15.437965]
 [40.78976 ]
 [65.73635 ]
 [44.047123]
 [82.39176 ]
 [74.12426 ]
 [28.65337 ]
 [51.490284]
 [37.772472]
 [26.223934]
 [54.737274]
 [40.450924]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10. 10.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.63311004638672



buy possibilites: [-1] 
expected returns: [[72.790855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 82.39173889160156






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  1. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25] -> size -> 30 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[141.10269]
 [168.16621]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.79085540771484



action possibilites: [-1] 
expected returns: [[91.319244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 174.9798126220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[86.25669 ]
 [95.21043 ]
 [78.86555 ]
 [93.35236 ]
 [94.258766]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.31924438476562



buy possibilites: [-1] 
expected returns: [[79.26676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [11. 29. 10.  0. 11. 10. 10. 10.  3. 11. 10.  0.  3.  0. 10. 25. 29. 29.
 29. 11.  0. 10. 10.  0. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 95.21044158935547






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0. 10.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [14.  3.  3.  0. 11. 16. 11. 10. 11.  0.  3. 11.  0.  0.  0.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[133.67593]
 [117.42782]
 [151.1161 ]
 [117.42782]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.26676177978516



action possibilites: [-1] 
expected returns: [[63.7134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 159.1012725830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.296356]
 [29.622398]
 [64.868645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.713401794433594






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [29. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10.] 
expected returns: [[122.43706 ]
 [136.38185 ]
 [113.330345]
 [113.330345]
 [113.330345]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 16. 11.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.86866760253906



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[81.69503]
 [75.44553]
 [75.44553]
 [75.44553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 16. 11.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 123.9737319946289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[67.825676]
 [80.64298 ]
 [57.94694 ]
 [77.84206 ]
 [82.978836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 16. 11.  0. 11.] 
adversary cards in discard: [3. 0. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.6950454711914






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  0. 11.] 
cards in discard: [3. 0. 0. 0. 6. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [25.  3. 29. 11. 15.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 11.] 
cards in discard: [3. 0. 0. 0. 6. 3. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [25.  3. 29. 11. 15.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 11.] 
cards in discard: [3. 0. 0. 0. 6. 3. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [25.  3. 29. 11. 15.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 11.] 
cards in discard: [3. 0. 0. 0. 6. 3. 1. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [25.  3. 29. 11. 15.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [25.  3. 29. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 15.] 
expected returns: [[111.66675 ]
 [112.93908 ]
 [106.99959 ]
 [111.86154 ]
 [106.043526]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 11. 15.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  9.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14. 11.  3.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3] -> size -> 26 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.97885131835938



action possibilites: [-1] 
expected returns: [[35.327763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 15. 10. 10.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14. 11.  3.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.9391098022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.097153]
 [23.175776]
 [35.934822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11. 15. 10. 10.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14. 11.  3.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.327762603759766






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  3.  0.  8.] 
cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  0.  3.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  3.  0.  8.] 
cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  0.  3.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[64.60755]
 [62.76866]
 [87.45414]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  0.  3.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.93482971191406



action possibilites: [-1. 10.] 
expected returns: [[44.89403]
 [45.71239]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.07139587402344



action possibilites: [-1. 11.] 
expected returns: [[59.414413]
 [75.03721 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 45.71240234375



action possibilites: [-1.] 
expected returns: [[97.20955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 78.8853759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.07538 ]
 [106.833755]
 [100.71581 ]
 [ 69.5125  ]
 [ 94.65014 ]
 [ 97.20511 ]
 [126.349495]
 [ 82.413536]
 [ 91.16235 ]
 [106.96362 ]
 [ 92.626114]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.20954895019531



buy possibilites: [-1] 
expected returns: [[106.88944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 126.34947967529297






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [ 3.  0.  0.  0.  6.  3.  1.  3. 11.  0. 16.  0. 11.  6. 14. 11.  3.  0.
  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29] -> size -> 35 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 96.78289 ]
 [113.368004]
 [113.368004]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.88944244384766



action possibilites: [-1] 
expected returns: [[33.856037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.5190200805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.275925]
 [32.857414]
 [27.604652]
 [31.836826]
 [33.817436]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [15. 11.  3. 10. 10.  0. 29. 29. 10. 10. 10.  0. 25.  3. 29. 11. 15. 10.
 10.  3. 15. 29. 29. 10. 11.  0.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.85603713989258






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0. 10. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[194.42159]
 [179.03506]
 [200.27696]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  8.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [11.  3.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.81743240356445



action possibilites: [-1] 
expected returns: [[123.308495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [11.  3.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 200.2770233154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[115.730446]
 [128.7051  ]
 [127.15865 ]
 [102.20335 ]
 [124.71862 ]
 [123.31531 ]
 [127.557396]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [11.  3.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.3084945678711



buy possibilites: [-1] 
expected returns: [[125.09463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 11.  0.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [11.  3.  6.  8.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6] -> size -> 30 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 128.7051239013672






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  3.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  8.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 15. 15. 29. 15.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  8.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 15. 15. 29. 15.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6.  8.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [10. 15. 15. 29. 15.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [10. 15. 15. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15. 29. 15.] 
expected returns: [[20.038822]
 [15.08984 ]
 [23.59198 ]
 [23.59198 ]
 [32.412983]
 [23.59198 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15. 29. 15.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.0946273803711



action possibilites: [-1. 15. 15. 15. 10.] 
expected returns: [[37.092373]
 [43.82284 ]
 [43.82284 ]
 [43.82284 ]
 [35.64694 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.348421096801758



action possibilites: [-1] 
expected returns: [[70.49988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 43.82283401489258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.372097]
 [49.377075]
 [70.17577 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.4998779296875






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 11. 15. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 11. 15. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 11. 15. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 11. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 10.] 
expected returns: [[ 82.40109]
 [ 83.12125]
 [102.79144]
 [ 94.91941]
 [ 83.12125]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  6.] 
adversary cards in hand: [16.  6. 14.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.1757583618164



action possibilites: [-1] 
expected returns: [[74.45951]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [16.  6. 14.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.39805603027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.10096 ]
 [54.324562]
 [75.45772 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [16.  6. 14.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.45951080322266






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [16.  6. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 14.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[104.84324 ]
 [ 97.780464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16] -> size -> 33 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0 -30   0   0 954   0] 
sum of rewards: 979 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 86.19329071044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.55224 ]
 [98.460754]
 [44.772022]
 [92.22262 ]
 [90.983536]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16] -> size -> 33 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.8432388305664



buy possibilites: [-1] 
expected returns: [[134.85774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16] -> size -> 33 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 98.46076965332031






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 0.  0.  3.  0. 11. 11.  6.  0. 11.  3.  6.  8.  0.  1.  3.  0.  0.  0.
  0. 16. 14. 16.  6.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [29.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [29.  3. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11.] 
expected returns: [[65.54014 ]
 [88.67058 ]
 [82.79559 ]
 [59.043068]
 [82.79559 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 10. 11.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 11.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.8577423095703



action possibilites: [-1. 11. 10. 11. 11.] 
expected returns: [[65.40206 ]
 [82.445946]
 [56.538654]
 [82.445946]
 [82.445946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  5.] 
adversary cards in hand: [ 0. 11.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.07814025878906



action possibilites: [-1] 
expected returns: [[40.813824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  4.] 
adversary cards in hand: [ 0. 11.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 88.24708557128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.032751]
 [ 9.440256]
 [40.813793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  4.] 
adversary cards in hand: [ 0. 11.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.81382369995117






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 29.  3.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  1. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 29.  3.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1. 11. 10.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0. 29. 29.  3.] 
adversary cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-30.645348]
 [-26.278675]
 [-26.278675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.  3.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.81382369995117



action possibilites: [-1. 10.] 
expected returns: [[34.758324]
 [22.95226 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -32.94831848144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  5.1474776]
 [-12.40819  ]
 [ 34.758324 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1. 25.  0. 10.  3.  0. 11.  0. 10. 29. 15. 15. 15. 10. 15. 11.  3. 10.
 15. 10. 29.  0.  3.  0.  0. 10.  3. 15. 29. 11. 10. 11. 11.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.75831604003906






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0. 11.  1. 11. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0. 11.  1. 11. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [10.  0. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.] 
expected returns: [[169.65343]
 [161.84889]
 [172.89323]
 [161.84889]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29
 10  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  8. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.75831604003906



action possibilites: [-1] 
expected returns: [[147.37636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  8. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 172.8932647705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[119.06866]
 [145.0212 ]
 [144.09666]
 [ 94.41279]
 [130.90329]
 [138.83513]
 [157.14015]
 [122.33772]
 [149.55891]
 [147.2221 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  5.  8. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.37635803222656



buy possibilites: [-1] 
expected returns: [[59.32067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [1. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 157.1401824951172






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 25.  3.] 
adversary cards in discard: [29. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  7.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 25.  3.] 
adversary cards in discard: [29. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 22. 30.  8.  7.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 25.  3.] 
adversary cards in discard: [29. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [11. 15.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25.] 
expected returns: [[136.98128]
 [148.08043]
 [139.80159]
 [165.60936]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 25.  3.] 
cards in discard: [29. 15. 10. 10.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  7.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3] -> size -> 37 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.32067108154297



action possibilites: [-1] 
expected returns: [[90.70458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  3.  0.  0.] 
cards in discard: [29. 15. 10. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.60940551757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[78.45672]
 [96.37059]
 [92.71325]
 [70.07369]
 [89.99733]
 [88.88776]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  3.  0.  0.] 
cards in discard: [29. 15. 10. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 22. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.70458221435547



buy possibilites: [-1] 
expected returns: [[55.24998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.  3.  0.  0.] 
cards in discard: [29. 15. 10. 10.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 96.37059783935547






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 11.  0.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 10. 10. 29.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 10. 10. 29.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 10. 10. 29.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [10. 29. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 10. 29.] 
expected returns: [[85.723885]
 [82.83839 ]
 [98.504814]
 [82.83839 ]
 [82.83839 ]
 [98.504814]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 10. 29.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.24998092651367



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[156.61899]
 [148.27013]
 [148.27013]
 [157.00029]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.95318603515625



action possibilites: [-1. 15.] 
expected returns: [[78.070915]
 [69.4519  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 150.44615173339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[50.807117]
 [68.44373 ]
 [40.811874]
 [63.980507]
 [78.82527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.07096862792969






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3. 29.  3. 15.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3. 29.  3. 15.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3. 29.  3. 15.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [10.  3. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[104.83233]
 [100.37856]
 [123.18546]
 [111.89791]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  3. 15.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.8252944946289



action possibilites: [-1. 15. 10.] 
expected returns: [[55.217552]
 [55.163696]
 [48.29518 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 110.77371978759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.230495]
 [35.236298]
 [55.110916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  6. 11.  3. 16.] 
adversary cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.21754455566406






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 11.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  3. 16.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 15.  0. 10.  1.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  3. 16.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 15.  0. 10.  1.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  3. 16.] 
cards in discard: [10.  0. 11.  1. 11. 10. 14.  0.  0.  3.  0.  0.  3.  1.  0.  3.  6.  3.
  6.  3. 11.  3.  8.  0.  0.  0. 11.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 15.  0. 10.  1.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [ 3. 15.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[81.422966]
 [97.88985 ]
 [75.16571 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 10.  1.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10
  0 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  6. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.11091232299805



action possibilites: [-1] 
expected returns: [[57.66535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  6. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 97.88982391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[44.55976 ]
 [55.81671 ]
 [55.122128]
 [40.50252 ]
 [39.484226]
 [48.704323]
 [52.558876]
 [70.20994 ]
 [63.998642]
 [46.633106]
 [54.035496]
 [42.77001 ]
 [57.89004 ]
 [58.54551 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  9.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  6. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.66535186767578



buy possibilites: [-1] 
expected returns: [[54.513412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0.  6. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -60   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 70.2099380493164






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  0.  6. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 14. 16.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3
  1  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25] -> size -> 41 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 14.] 
cards in discard: [3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 20. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25] -> size -> 41 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 14.] 
cards in discard: [3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 20. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25] -> size -> 41 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [11. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[58.898144]
 [82.86895 ]
 [82.86895 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 20. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.51341247558594



action possibilites: [-1] 
expected returns: [[-19.900108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 20. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 72.21829986572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-23.428331]
 [-19.650944]
 [-25.140509]
 [-20.975426]
 [-19.90009 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 20. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.900108337402344



buy possibilites: [-1] 
expected returns: [[-44.725533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 19. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  0.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -19.650959014892578






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 19. 30.  8.  6.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  3. 11. 15. 11.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3. 11. 11.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 19. 30.  8.  5.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  3. 11. 15. 11.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3. 11. 11.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 19. 30.  8.  5.  8.  0.  9.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  3. 11. 15. 11.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3. 11. 11.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [29.  3. 11. 15. 11.] 
adversary cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3. 11. 11.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
adversary victory points: 7
player victory points: 5 





Player: 0 
cards in hand: [29.  3. 11. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15. 11.] 
expected returns: [[ 61.253372]
 [104.24993 ]
 [ 91.65385 ]
 [ 76.55071 ]
 [ 91.65385 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 15. 11.] 
cards in discard: [29. 15. 10. 10.  0.  1. 25. 11. 15.  0.  3.  0.  0. 10. 29. 10. 10. 29.
 29. 15.  3. 10. 29.  3. 15. 10. 25. 15.  3. 10.  1.  1.  3. 11. 11.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -44.72553253173828



action possibilites: [-1. 11.] 
expected returns: [[43.53662 ]
 [59.419647]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.] 
cards in discard: [15. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 75.4053726196289



action possibilites: [-1] 
expected returns: [[108.84742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [15. 11.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 53.226104736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 97.0236  ]
 [121.71871 ]
 [116.17557 ]
 [ 83.146965]
 [112.55568 ]
 [109.8092  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [15. 11.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.84741973876953



buy possibilites: [-1] 
expected returns: [[177.061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [15. 11.  1.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  0. 10.  6.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[  -5    0    0   60    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 121.71868896484375






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 29.  3. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  8.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 29.  3. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  6.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10. 10. 29.  3. 29.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
adversary victory points: 7
player victory points: 5 





Player: 0 
cards in hand: [10. 10. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[64.61202 ]
 [62.378006]
 [62.378006]
 [82.15354 ]
 [82.15354 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  3. 29.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 177.06100463867188



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[41.49952 ]
 [39.973305]
 [39.973305]
 [66.46299 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 70.16442108154297



action possibilites: [-1. 10.] 
expected returns: [[80.96197]
 [80.00683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 50.461299896240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.47162 ]
 [89.80739 ]
 [66.154236]
 [87.58004 ]
 [84.90736 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1] -> size -> 45 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 19. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.96202850341797



buy possibilites: [-1] 
expected returns: [[165.39352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 14.  3. 11.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5    0    0   90    0    0   40    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 89.80741882324219






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3. 11.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 10. 15.  1.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
adversary victory points: 8
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 10. 15.  1.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 10. 15.  1.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 29. 10. 15.  1.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 10. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
expected returns: [[ 90.373726]
 [113.559166]
 [ 80.53838 ]
 [ 97.02197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 15.  1.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 165.39352416992188



action possibilites: [-1. 10. 15.] 
expected returns: [[128.51648 ]
 [117.835304]
 [130.20488 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0
 10  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 113.89047241210938



action possibilites: [-1] 
expected returns: [[210.65259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 130.2048797607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[180.82097]
 [199.71579]
 [200.33902]
 [168.85742]
 [187.68362]
 [195.67366]
 [208.76099]
 [184.6205 ]
 [204.49318]
 [208.19359]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  4.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 210.652587890625



buy possibilites: [-1] 
expected returns: [[164.2499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11.  0. 11.  3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5    0    0   90    0    0   40    0    0    0    0 -110    0    0
  128    0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 208.7610321044922






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 11.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 25. 11.  3.  3.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 11.  3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 25. 11.  3.  3.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
adversary victory points: 8
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[134.68565]
 [165.31114]
 [150.5446 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11.  3.  3.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  5.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 16.  0.  1.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0] -> size -> 46 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.24989318847656



action possibilites: [-1] 
expected returns: [[89.67954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.  1. 10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 16.  0.  1.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 47 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.31114196777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.03576 ]
 [79.010925]
 [64.40263 ]
 [76.04998 ]
 [89.67953 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.  1. 10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  0. 16.  0.  1.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 47 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.6795425415039






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  0.  1.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  1
  3  6  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [10.  0. 29. 15.  0.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [10.  0. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[110.47225]
 [ 98.14959]
 [132.3156 ]
 [114.78623]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 15.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.6795425415039



action possibilites: [-1. 10.] 
expected returns: [[58.89548 ]
 [44.839027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 111.42974090576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[25.107206 ]
 [60.6838   ]
 [56.30715  ]
 [ 3.9215255]
 [49.831303 ]
 [58.89548  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.8955078125



buy possibilites: [-1] 
expected returns: [[12.019392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11.  6.  0.  1.  0.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 60.683799743652344






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  1.  0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  4.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 10. 10.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  3.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 10. 10.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 22. 30. 18. 30.  8.  3.  8.  0.  7.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 10. 10.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 22. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15.  0. 10. 10.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [11. 15.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 10.] 
expected returns: [[71.83603]
 [88.948  ]
 [77.75395]
 [64.25519]
 [64.25519]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 10. 10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.019392013549805



action possibilites: [-1] 
expected returns: [[-22.78182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.6606674194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-28.387562]
 [-35.039837]
 [-22.781797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -22.78182029724121






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 29. 25. 15.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1. 11. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 18. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 29. 25. 15.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1. 11. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 3. 16. 10.  6. 14.  6.  8. 11.  6.  0.  0.  3.  8.  3.  0.  0. 10.  6.
  0.  0. 11.  0.  3. 14.  3.  3. 11.  0. 11.  3.  6.  8. 16.  0.  6.  8.
 11.  6.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 29. 25. 15.] 
adversary cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1. 11. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10. 29. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25. 15.] 
expected returns: [[49.56118 ]
 [42.485477]
 [66.07669 ]
 [79.05087 ]
 [54.25909 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 25. 15.] 
cards in discard: [15. 11.  1.  1. 29. 11.  3.  1.  3.  0. 10.  3.  3. 29. 29. 10.  1.  0.
 29. 29. 15. 10. 25.  3. 11.  3.  3.  1. 10. 15. 11.  1. 29. 10.  0.  0.
  1. 11. 15.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  3.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [8. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3] -> size -> 48 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -22.78182029724121



action possibilites: [-1] 
expected returns: [[64.981636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 15.  0. 15.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [8. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6] -> size -> 49 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.05086517333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.390587]
 [45.00714 ]
 [65.86471 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29. 15.  0. 15.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [8. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6] -> size -> 49 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.98163604736328






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 10.  3.  1.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  6.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 10.  3.  1.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 15. 10.  3.  1.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 0. 15. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[169.89162]
 [178.58061]
 [163.75322]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  3.  1.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10
  3 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  1. 11. 11. 11.] 
adversary cards in discard: [6. 8. 8. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.86471557617188



action possibilites: [-1] 
expected returns: [[92.58475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  1. 11. 11. 11.] 
adversary cards in discard: [6. 8. 8. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 178.58062744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 82.18119 ]
 [ 99.55271 ]
 [ 96.93939 ]
 [ 76.43007 ]
 [ 75.01816 ]
 [ 89.969246]
 [ 93.70891 ]
 [113.420746]
 [107.49405 ]
 [ 84.07953 ]
 [ 97.35063 ]
 [ 80.12913 ]
 [101.44198 ]
 [100.277084]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  8.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  1. 11. 11. 11.] 
adversary cards in discard: [6. 8. 8. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.58474731445312



buy possibilites: [-1] 
expected returns: [[142.37355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 8.  1. 11. 11. 11.] 
adversary cards in discard: [6. 8. 8. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0 -130    0    0
  250    0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 113.4207992553711






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11. 11. 11.] 
cards in discard: [6. 8. 8. 6. 0. 3. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  8. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 15. 10.  3.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11. 11.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 15. 10.  3.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 11. 11.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 15. 10.  3.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 11. 11.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 1. 29. 15. 10.  3.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 1. 29. 15. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.] 
expected returns: [[97.32667]
 [99.36425]
 [94.60459]
 [88.31895]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 15. 10.  3.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.37355041503906



action possibilites: [-1. 15. 10.] 
expected returns: [[108.83145]
 [104.44135]
 [ 95.50547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 92.2218017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 81.08622]
 [ 97.85162]
 [ 97.33236]
 [ 73.0109 ]
 [ 93.01307]
 [105.74186]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.83147430419922






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 30. 17. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 21. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [10.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 91.2097  ]
 [ 72.403145]
 [110.57308 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  3.  0. 14.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.74189758300781



action possibilites: [-1] 
expected returns: [[129.54971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  3.  0. 14.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 86.37821197509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[101.73687 ]
 [117.174614]
 [ 95.31069 ]
 [112.86318 ]
 [129.54973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [10.  3.  3.  0. 14.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.54971313476562






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 14.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11. 15.  3. 29.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14. 11.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11. 15.  3. 29.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 14. 11.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [11. 11. 15.  3. 29.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [11. 11. 15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 29.] 
expected returns: [[76.20537 ]
 [86.892746]
 [86.892746]
 [79.470024]
 [88.145615]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  3. 29.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.54971313476562



action possibilites: [-1. 11. 15. 29.] 
expected returns: [[75.174446]
 [86.831505]
 [76.58962 ]
 [87.64098 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.19864654541016



action possibilites: [-1. 11.] 
expected returns: [[59.925945]
 [61.579582]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 20. 30. 16. 30.  8.  2.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.55956268310547



action possibilites: [-1] 
expected returns: [[82.55]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 20. 30. 16. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5    0    0   90    0    0   60    0    0    0    0 -150    0 -300
    0    0] 
sum of rewards: -305 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 51.44525909423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.3466  ]
 [82.72681 ]
 [58.4193  ]
 [79.76829 ]
 [82.550026]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 30. 16. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.55000305175781



buy possibilites: [-1] 
expected returns: [[22.81864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  120    0    0   60    0    0    0    0 -160    0    0
   16    0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 82.72677612304688






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 11  0 14 11 11  6 10  0 16 11  8  3  3  6
  0  0  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3
  6  8 14  0  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3.  1. 10. 11.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-44.806507]
 [-41.25943 ]
 [-18.818886]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 10. 11.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.818639755249023



action possibilites: [-1] 
expected returns: [[-42.89745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -25.485628128051758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-49.256065]
 [-41.648277]
 [-54.017788]
 [-43.321487]
 [-42.89744 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 19. 30. 15. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.8974494934082



buy possibilites: [-1] 
expected returns: [[-51.693634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 14. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -180    0    0
   16    0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -41.64828109741211






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 14. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 25.  1. 10.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3. 11.
  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
adversary victory points: 9
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 19. 30. 14. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 25.  1. 10.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3. 11.
  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
adversary victory points: 9
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  6.] 
cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 19. 30. 14. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 25.  1. 10.] 
adversary cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3. 11.
  3.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
adversary victory points: 9
player victory points: 5 





Player: 0 
cards in hand: [ 3. 11. 25.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[ 62.739204]
 [ 91.84428 ]
 [112.57582 ]
 [ 59.12073 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  1. 10.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3. 11.
  3.  3.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 14. 30.  8.  1.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.  0.  3.  3. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0  0] -> size -> 53 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -51.693634033203125



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 4 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 3 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 11.  1. 10. 29.  1.] 
cards in discard: [25.  3. 10. 29. 15.  0. 15. 25. 15. 10.  3.  1.  3. 10. 29.  1. 15. 10.
  1. 11. 10.  3.  0.  0. 11.  3. 15.  1.  6.  3. 29. 29. 11.  1.  3. 11.
  3.  3.  1. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3 11 29 10 11 29 10 11 29 10 11 10 11 10 29 10  0 10  3
 10 25 15  3 15 15 29 15  1 15  3 15 29  1 25  1  3  1  1  3 29  1  1 25
  1  6  3  1  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 30. 14. 30.  8.  0.  8.  0.  5.  7.  3.  7. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  8.  8.  6.  0.  3.  0. 14.  0. 11.  8.  1. 11. 11.  3.  0.  0.  0.
  3.  3. 10.  3.  3.  0. 14. 11.  0.  8.  8.  6.  0.  3.  3. 16.  0.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 11  0 14 11 11 10  0 16 11  8  3  3  6  0  0
  6  0  1 16  3 10 14  3  6  3  0  0  3  6  8  8  0  0  6  6  8  3  6  8
 14  0  3  0  0  6] -> size -> 54 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000135 

action type: take_action - action 25.0
Learning step: 300002.25
desired expected reward: 300114.8125



