 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.589294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0       20        0
        0        0        0     -220        0        0        0        0] 
sum of rewards: -3000445 

action type: buy - action 0.0
Learning step: -120017.6953125
desired expected reward: -120020.265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[77.468475]
 [86.842926]
 [82.92705 ]
 [69.31254 ]
 [84.225136]
 [89.75453 ]
 [84.25208 ]
 [95.585396]
 [75.2059  ]
 [80.33621 ]
 [84.51706 ]
 [88.72326 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.39454650878906



buy possibilites: [-1] 
expected returns: [[95.358475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 95.58539581298828






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.27284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.35847473144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.09367 ]
 [102.45244 ]
 [ 97.66748 ]
 [ 81.222984]
 [105.98569 ]
 [ 99.2854  ]
 [ 94.50342 ]
 [104.78589 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.69398498535156



buy possibilites: [-1] 
expected returns: [[108.22855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 105.98568725585938






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[92.73054]
 [93.79628]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.22855377197266



action possibilites: [-1] 
expected returns: [[93.21846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 98.36286926269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.229836]
 [89.000435]
 [84.916466]
 [69.80813 ]
 [92.1178  ]
 [86.29201 ]
 [82.223145]
 [91.05205 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.21846008300781



buy possibilites: [-1] 
expected returns: [[102.30474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 92.1177978515625






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  3.  0.  0.  1. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 29.  0.  3.  0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[90.47139]
 [98.01137]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.30474090576172



action possibilites: [-1.] 
expected returns: [[108.76878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.2265853881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.44463 ]
 [109.21798 ]
 [105.09504 ]
 [ 90.30857 ]
 [106.44222 ]
 [112.26991 ]
 [106.478546]
 [118.091156]
 [ 97.070694]
 [102.39276 ]
 [106.76165 ]
 [111.23368 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.76878356933594



buy possibilites: [-1] 
expected returns: [[114.98457]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 118.09115600585938






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 96.21215]
 [102.48789]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  1.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.98457336425781



action possibilites: [-1.] 
expected returns: [[99.614456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  1.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.34817504882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 91.12822 ]
 [ 99.10418 ]
 [ 95.7774  ]
 [ 86.74925 ]
 [ 83.46192 ]
 [ 96.868286]
 [101.7025  ]
 [ 96.90146 ]
 [111.99967 ]
 [106.98055 ]
 [ 89.17164 ]
 [ 97.10227 ]
 [ 93.57756 ]
 [ 89.138954]
 [ 97.13545 ]
 [100.78429 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  1.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.61445617675781



buy possibilites: [-1] 
expected returns: [[121.46441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  1.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 111.99968719482422






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  1.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 8.  0.  3.  3.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[112.09035]
 [113.05406]
 [103.88823]
 [118.41251]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29.  0.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.46440887451172



action possibilites: [-1. 11. 10.] 
expected returns: [[148.70636]
 [149.83919]
 [138.93358]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.25096130371094



action possibilites: [-1] 
expected returns: [[145.79944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 154.49647521972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[140.17114]
 [148.87463]
 [145.24422]
 [131.73076]
 [146.43814]
 [151.54913]
 [146.4728 ]
 [156.79149]
 [138.02536]
 [142.84392]
 [146.727  ]
 [150.64987]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.7994384765625



buy possibilites: [-1] 
expected returns: [[158.14084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 156.79148864746094






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[104.726074]
 [110.8544  ]
 [105.63144 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.14083862304688



action possibilites: [-1. 11. 29.] 
expected returns: [[109.000885]
 [109.76116 ]
 [114.17612 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.33155822753906



action possibilites: [-1. 11.] 
expected returns: [[120.9505  ]
 [121.775406]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 114.17613220214844



action possibilites: [-1] 
expected returns: [[135.5047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.1982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[127.48917]
 [136.3487 ]
 [132.65292]
 [119.34069]
 [133.86623]
 [139.07205]
 [133.90292]
 [144.29561]
 [125.33568]
 [130.20718]
 [134.16219]
 [138.15913]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.50469970703125



buy possibilites: [-1] 
expected returns: [[158.30783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.29562377929688






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  3. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  3. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  3. 10.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[159.87277]
 [160.69885]
 [152.68929]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  1.  3. 15. 14.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.30783081054688



action possibilites: [-1] 
expected returns: [[163.18652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  1.  3. 15. 14.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.64625549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.2026 ]
 [167.72647]
 [164.07315]
 [151.17076]
 [170.46193]
 [165.28676]
 [161.76714]
 [169.53598]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  1.  3. 15. 14.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.1865234375



buy possibilites: [-1] 
expected returns: [[181.49017]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  1.  3. 15. 14.] 
adversary cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 170.4619140625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  3. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3. 15. 14.] 
cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3. 14.] 
cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3. 14.] 
cards in discard: [10.  3. 10.  0.  0.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[149.25325]
 [160.92769]
 [140.97006]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.49017333984375



action possibilites: [-1] 
expected returns: [[125.17755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.25746154785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.76674]
 [124.72717]
 [112.96248]
 [125.92735]
 [130.01195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.17755126953125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 15 10  8 14 10  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11. 29.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11. 29.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11. 29.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11. 29.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[139.57323]
 [131.68495]
 [140.49786]
 [140.49786]
 [145.65826]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [6. 0. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.01194763183594



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[158.6264 ]
 [150.05853]
 [159.63605]
 [159.63605]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [6. 0. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.81927490234375



action possibilites: [-1] 
expected returns: [[163.09915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [6. 0. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 163.76995849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[157.20822]
 [166.35316]
 [162.43636]
 [148.67589]
 [169.23523]
 [163.76195]
 [159.93896]
 [168.25723]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [6. 0. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.09915161132812



buy possibilites: [-1] 
expected returns: [[153.07541]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [6. 0. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 169.2352294921875






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 10.] 
cards in discard: [6. 0. 8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 10.] 
cards in discard: [6. 0. 8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 10.] 
cards in discard: [ 6.  0.  8.  0.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[124.16115 ]
 [125.26251 ]
 [114.856094]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 10.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 153.07540893554688



action possibilites: [-1] 
expected returns: [[90.21603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.99179077148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[79.77509 ]
 [84.49842 ]
 [72.38258 ]
 [85.70725 ]
 [89.843636]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 10.  0.  3.  0. 29. 29. 10. 11. 29. 11.  0. 10. 11.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.21602630615234






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [ 6.  0.  8.  0.  0.  3. 11.  1.  0.  3.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[ 96.84674]
 [ 91.01736]
 [ 91.01736]
 [102.23597]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.8436279296875



action possibilites: [-1. 10. 10.] 
expected returns: [[118.49785]
 [112.45822]
 [112.45822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.86271667480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[115.5606  ]
 [122.28005 ]
 [119.434044]
 [109.51958 ]
 [124.37694 ]
 [120.397766]
 [117.5555  ]
 [123.67207 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.49784851074219



buy possibilites: [-1] 
expected returns: [[144.91391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 124.37692260742188






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[118.70616 ]
 [119.46953 ]
 [112.187256]
 [119.46953 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  0.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 10.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.91390991210938



action possibilites: [-1] 
expected returns: [[119.10434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 10.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 120.21820068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.9481 ]
 [115.30017]
 [104.18641]
 [116.3628 ]
 [120.00538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 10.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.10433959960938






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0. 10.] 
cards in discard: [ 3.  0.  3.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.  0.] 
cards in discard: [ 3.  0.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[122.17082]
 [130.908  ]
 [111.8896 ]
 [123.44581]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  3.  0.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.00538635253906



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[139.04977]
 [130.08127]
 [140.09167]
 [130.08127]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.9080047607422



action possibilites: [-1] 
expected returns: [[127.0233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.48410034179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[113.83054]
 [120.65971]
 [102.82355]
 [122.3256 ]
 [128.12833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.02330017089844






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  0.  3. 11.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  0.  0. 10. 15.  3. 10. 11.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [29.  0.  3. 11.  0.] 
adversary cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[119.20801 ]
 [125.63475 ]
 [120.195145]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11.  0.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.12831115722656



action possibilites: [-1. 11. 10.] 
expected returns: [[124.5961 ]
 [125.56152]
 [116.22926]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 117.34896850585938



action possibilites: [-1] 
expected returns: [[131.75235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.45945739746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[120.860344]
 [130.88113 ]
 [126.68782 ]
 [111.43051 ]
 [133.96541 ]
 [128.10196 ]
 [132.89693 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  4.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 131.75234985351562



buy possibilites: [-1] 
expected returns: [[144.6657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11. 29. 10. 10.  3.  0.  0. 10. 11.  0. 10. 11.  0. 10. 29. 11. 10.  3.
  0. 10.  3. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 133.9654083251953






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  6. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 11. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  6.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[114.72372]
 [108.77924]
 [119.38661]
 [123.39868]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 25.] 
cards in discard: [ 0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  9. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 678   0] 
sum of rewards: 583 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 86.57003784179688



action possibilites: [-1] 
expected returns: [[134.95119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0.] 
cards in discard: [ 0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.9218978881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.13807]
 [113.00786]
 [129.06403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11.  0.] 
cards in discard: [ 0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.95118713378906






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  3. 10. 29.  0.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[105.16864]
 [110.67465]
 [ 98.45524]
 [110.67465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 29.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.06402587890625



action possibilites: [-1. 10. 10.] 
expected returns: [[109.164246]
 [101.36235 ]
 [101.36235 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 103.63180541992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.51094 ]
 [103.47342 ]
 [ 90.28879 ]
 [104.704544]
 [108.92164 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 10.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 10. 15.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 109.16423034667969






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10. 15.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  8.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 10  8 14 10  0  6  0 11  0  3 15  3  3
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0. 29. 11. 10.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  0. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10.] 
expected returns: [[81.30964 ]
 [82.34504 ]
 [88.264694]
 [82.34504 ]
 [73.81789 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11. 10.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.921630859375



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[131.27408]
 [132.2226 ]
 [132.2226 ]
 [123.42376]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.5121841430664



action possibilites: [-1] 
expected returns: [[120.223206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 136.00173950195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.21579 ]
 [115.26787 ]
 [102.39941 ]
 [116.49369 ]
 [120.765114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.22320556640625






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10. 10. 10.  0.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3. 14. 11.  3.  0.  6.  6. 10.  3.  3.  3.  0.  3. 10.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 10. 10. 10.  0.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 10.] 
expected returns: [[84.93666]
 [81.0877 ]
 [77.9726 ]
 [77.9726 ]
 [77.9726 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 10.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.76510620117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.13837 ]
 [69.947205]
 [85.40197 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10. 10.  0.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  6. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.9366683959961



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  6. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 14.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  3.  0. 10.  3.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  3.  3.] 
adversary cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[82.158554]
 [82.78618 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 806   0] 
sum of rewards: 771 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 104.92771911621094



action possibilites: [-1] 
expected returns: [[63.913284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.28458404541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[55.633316]
 [49.245743]
 [63.613594]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 11. 25. 10. 29. 11.  0. 29. 29.  3. 10.  0. 10.  0. 15. 29. 11. 11.
 10.  0. 15. 10. 10. 10.  0.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.91328430175781






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [14.  8.  0.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10. 25.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [14.  8.  0.  6.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10. 25.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 25.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[144.0877 ]
 [137.93729]
 [152.7498 ]
 [144.80676]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  8. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.61358642578125



action possibilites: [-1] 
expected returns: [[159.10129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.19979858398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.14594]
 [138.6904 ]
 [153.92566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  6.  0. 11.  3.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.10128784179688






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  3.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  3.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.  3.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[140.03654]
 [131.82935]
 [135.91692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.9256591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[130.51337]
 [139.6792 ]
 [135.85568]
 [121.61259]
 [142.49942]
 [137.15028]
 [141.53734]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  3.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 140.0365447998047



buy possibilites: [-1] 
expected returns: [[121.98689]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.4994354248047






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11. 10. 10. 29. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  9.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11. 10. 10. 29. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14.  8.  0.  6.  1.  3.  0. 10.  3.  3.  6.  3.  0.  6.  0. 11.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11. 10. 10. 29. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29. 10.] 
expected returns: [[129.93307 ]
 [131.21161 ]
 [118.905136]
 [118.905136]
 [138.40686 ]
 [118.905136]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 29. 10.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.98689270019531



action possibilites: [-1. 11. 10. 10. 11.] 
expected returns: [[110.87111 ]
 [111.98459 ]
 [101.260445]
 [101.260445]
 [111.98459 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 11.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 127.43223571777344



action possibilites: [-1] 
expected returns: [[167.53378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.51445007324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[152.4931 ]
 [140.58731]
 [167.47626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 8. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.53378295898438






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  3 10  8 14 10  0  6  0 11  0  3  3  3  6  6  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[142.10849]
 [132.90448]
 [132.90448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.4762420654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[129.42441]
 [135.4095 ]
 [119.46471]
 [136.85783]
 [141.7743 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 142.10848999023438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15. 29. 11.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15. 29. 11.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [11. 15. 29. 11.  0.] 
adversary cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11. 15. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29. 11.] 
expected returns: [[75.76074 ]
 [76.682014]
 [72.37571 ]
 [81.84941 ]
 [76.682014]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 29. 11.  0.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 141.7742919921875



action possibilites: [-1. 11. 15. 11. 15.] 
expected returns: [[54.143494]
 [54.997303]
 [50.536728]
 [54.997303]
 [50.536728]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 15.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  4.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.24193572998047



action possibilites: [-1] 
expected returns: [[65.62761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 58.39314270019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.280743]
 [51.445824]
 [64.97104 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 15.] 
cards in discard: [25. 10.  3.  3. 11.  0. 29. 11.  0. 10.  0. 15.  0. 10. 15. 29. 11. 10.
 10. 11.  0.  3. 10.  0. 10.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.62760925292969






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 24. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29. 29. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29. 29. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 10. 29.] 
expected returns: [[149.94548]
 [154.8153 ]
 [154.8153 ]
 [150.65807]
 [143.6983 ]
 [154.8153 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.97105407714844



action possibilites: [-1. 11. 10. 29. 10.] 
expected returns: [[160.09   ]
 [160.81195]
 [153.84268]
 [164.9725 ]
 [153.84268]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29. 10.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 148.50033569335938



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[178.33676]
 [179.07431]
 [172.03392]
 [172.03392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [29. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.67156982421875



action possibilites: [-1] 
expected returns: [[167.36647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [29. 15. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 182.0176544189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[158.11934]
 [162.83167]
 [150.75815]
 [163.98004]
 [167.88904]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [29. 15. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.36647033691406






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [11.  0.  0. 29.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [11.  0.  0. 29.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [0. 8. 3. 3. 0. 6. 3. 6. 0. 3. 0. 3. 0. 3. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [11.  0.  0. 29.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[160.5669 ]
 [161.72116]
 [168.3386 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [14.  3. 10.  3.  1.] 
adversary cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.8890380859375



action possibilites: [-1. 11.] 
expected returns: [[180.9231]
 [181.8701]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  2.] 
adversary cards in hand: [14.  3. 10.  3.  1.] 
adversary cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.25494384765625



action possibilites: [-1] 
expected returns: [[154.7669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3. 10.  3.  1.] 
adversary cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 185.71693420410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[144.28229]
 [153.08482]
 [149.17232]
 [137.23283]
 [155.96762]
 [150.49672]
 [154.9982 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  2.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3. 10.  3.  1.] 
adversary cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.76690673828125



buy possibilites: [-1] 
expected returns: [[164.26498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3. 10.  3.  1.] 
adversary cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -30    0    0
   54    0] 
sum of rewards: -61 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 155.9676055908203






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14.  3. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10.  3.  1.] 
cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 10. 15. 11. 25.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10.  3.  1.] 
cards in discard: [ 0.  8.  3.  3.  0.  6.  3.  6.  0.  3.  0.  3.  0.  3.  6.  3.  0.  3.
  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 10. 15. 11. 25.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 15. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 11. 25.] 
expected returns: [[163.2515 ]
 [164.24434]
 [154.5451 ]
 [158.86761]
 [164.24434]
 [175.28471]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 11. 25.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  7. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.26498413085938



action possibilites: [-1] 
expected returns: [[152.0928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15. 11. 15.  3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 175.2847137451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.37283]
 [131.92145]
 [150.92686]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 15. 11. 15.  3.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6] -> size -> 27 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.09280395507812






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15.  0. 15.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  1.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15.  0. 15.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15.  0. 15.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [10. 11. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 15.] 
expected returns: [[108.525856]
 [102.14853 ]
 [109.282265]
 [105.32195 ]
 [105.32195 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  0. 15.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  6.  3. 11.  8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.9268798828125



action possibilites: [-1] 
expected returns: [[97.05369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 15.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  6.  3. 11.  8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: -88 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 107.08778381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[85.69559 ]
 [78.33802 ]
 [95.180145]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0. 15.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  6.  3. 11.  8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.0536880493164






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 11.  8.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 11. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [10. 11. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[57.382904]
 [53.177666]
 [57.89457 ]
 [57.89457 ]
 [53.177666]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.18014526367188



action possibilites: [-1] 
expected returns: [[40.038605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: -98 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 56.43061828613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.7588  ]
 [32.505787]
 [40.038605]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.038604736328125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 22. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [ 0.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[55.485153]
 [51.596138]
 [51.596138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1. 11. 10. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.038604736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[50.26016 ]
 [52.80153 ]
 [46.01743 ]
 [53.421787]
 [55.48515 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 10.  0.] 
cards in discard: [29. 15. 15. 29. 29. 11. 10. 10.  0. 15. 11. 29. 11.  0.  0.  3. 25. 11.
 10. 15. 11. 15.  3.  1. 11. 10. 15.  0. 15.  1. 11. 10. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.48515701293945



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  8.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [11.  0. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 11.] 
expected returns: [[155.37105]
 [156.10095]
 [149.39294]
 [152.2976 ]
 [156.10095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 15. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3  8] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.48515701293945



action possibilites: [-1] 
expected returns: [[165.61308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15. 11.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3  8] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0  -60    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 153.92811584472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.32336]
 [150.60133]
 [165.89903]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15. 11.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3  8] -> size -> 31 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.6130828857422






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  8. 14.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3
  3  3  6 11  0  3  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  3.  0. 11.  0.  6.  3.  8.  3.  0.  3.  3.  3.
  1.  8. 10.  0.  3.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 11. 15.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [15. 15. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10. 11. 15.] 
expected returns: [[184.68427]
 [180.52124]
 [180.52124]
 [176.4022 ]
 [185.63354]
 [180.52124]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 11. 15.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  0.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 165.8990478515625



action possibilites: [-1] 
expected returns: [[183.08856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 15.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  0.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -88 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 182.7976837158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.59018]
 [162.38193]
 [183.04256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10. 15.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6.  0.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 183.08856201171875






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  6.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  8. 14.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 10. 15.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 21. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[143.93802]
 [134.19745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 3. 3. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0  -70    0    0
 1261    0] 
sum of rewards: 1096 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 11.643942832946777





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.20787]
 [136.53581]
 [120.87912]
 [138.08453]
 [143.85605]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 3. 3. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 143.93801879882812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11. 29.  0. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[139.96689]
 [141.10635]
 [147.50754]
 [130.19496]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0. 10.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.85604858398438



action possibilites: [-1. 11. 10.] 
expected returns: [[106.38447]
 [107.46031]
 [ 98.2829 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 137.758056640625



action possibilites: [-1] 
expected returns: [[156.23143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -108 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 104.30557250976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.97502]
 [147.29767]
 [130.7111 ]
 [148.83365]
 [154.12233]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 3. 8. 1.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.23143005371094






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 1.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3
  6 11  0  3  8  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 25. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 25. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 15. 25. 10.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11.  0. 15. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25. 10.] 
expected returns: [[ 95.0926  ]
 [ 95.910065]
 [ 91.684296]
 [105.17431 ]
 [ 88.46356 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 25. 10.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  6. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0] -> size -> 30 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.12234497070312



action possibilites: [-1] 
expected returns: [[77.514565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15. 10. 10. 15.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.1742935180664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.68102]
 [62.21135]
 [77.51457]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15. 10. 10. 15.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 20. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.51456451416016






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [11.  6.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  8.  0.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 20. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1.  3. 29.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1.  3. 29.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 11.  1.  3. 29.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 11.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[43.01995]
 [43.54094]
 [46.43687]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  3. 29.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.51456451416016



action possibilites: [-1. 11. 29.] 
expected returns: [[26.227196]
 [26.56993 ]
 [28.351727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.021751403808594



action possibilites: [-1.] 
expected returns: [[43.275482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.64544677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[38.380493]
 [42.463886]
 [40.75084 ]
 [34.636147]
 [41.326706]
 [41.332993]
 [46.12987 ]
 [37.38943 ]
 [41.44717 ]
 [43.27548 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.275482177734375



buy possibilites: [-1] 
expected returns: [[50.316353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -90   0   0 128   0] 
sum of rewards: 13 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 46.12987518310547






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 11.  3. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29] -> size -> 44 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 19. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 11.  3. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29] -> size -> 44 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 10. 11.  3. 11.] 
adversary cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29] -> size -> 44 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[87.86478 ]
 [81.43164 ]
 [88.669014]
 [88.669014]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 11.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.  3.  0.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.31635284423828



action possibilites: [-1] 
expected returns: [[80.23856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.  3.  0.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -148 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 86.31153869628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.26955 ]
 [66.15813 ]
 [80.238556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.] 
cards in discard: [ 1. 11.  0. 10. 15. 11.  1. 11. 15. 15. 10. 15. 29. 15.  0. 10.  0.  0.
 10.  1. 29. 11.  0. 10. 25. 11.  0. 15. 10. 10. 15.  3.  1. 11.  3. 29.
 29. 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.  3.  0.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.23856353759766






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 3. 14.  6.  0.  6.  8.  0.  3.  3.  3.  3.  3.  8.  0.  1.  6.  3. 11.
  6.  3.  8.  0.  3.  0.  3.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 18. 30.  8.  4. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 18. 30.  8.  4. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [6. 1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  0. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[137.99777]
 [131.49292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3.  6.  3.  6.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.23856353759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[131.21931 ]
 [139.18619 ]
 [128.16566 ]
 [135.74013 ]
 [127.187164]
 [124.225914]
 [136.87479 ]
 [136.90695 ]
 [151.34541 ]
 [146.63832 ]
 [129.4014  ]
 [137.11478 ]
 [129.37186 ]
 [137.14694 ]
 [140.8677  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  9.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3.  6.  3.  6.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.99778747558594



buy possibilites: [-1] 
expected returns: [[182.1868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  0.] 
cards in discard: [25.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [14.  3.  6.  3.  6.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -110.     0.     0.    62.5    0. ] 
sum of rewards: -112.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 151.34542846679688






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [14.  3.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  3.  6.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  1.  0. 29. 15.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 15.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 15.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[160.58533]
 [168.00851]
 [155.8359 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -110    0    0
 1477    0] 
sum of rewards: 1302 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -9.618392944335938



action possibilites: [-1. 10.] 
expected returns: [[189.64352]
 [180.693  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.42654418945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[177.34074]
 [167.81747]
 [189.31969]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 3. 8. 8.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 189.64353942871094






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 8.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 14 10  0  6  0 11  0  3  3  3  6  6  3  8  0  3  3  3  6 11
  0  3  8  0  3  0  6  3  3  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15.] 
expected returns: [[144.36835]
 [145.79536]
 [132.25111]
 [132.25111]
 [138.25793]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 15.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 189.3197021484375



action possibilites: [-1] 
expected returns: [[118.46834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -108 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 141.62286376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.4721 ]
 [ 94.5044 ]
 [117.29559]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 21. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.46833801269531






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 10. 11.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 18. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 10. 11.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 10. 10. 11.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [15. 10. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11.] 
expected returns: [[139.29674]
 [134.74466]
 [130.31252]
 [130.31252]
 [140.32893]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10. 11.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.29559326171875



action possibilites: [-1] 
expected returns: [[112.83776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -148 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 137.23031616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.37262]
 [ 92.02192]
 [112.83777]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 10.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 20. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.83776092529297






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 1.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 29.  3. 29.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 1.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 20. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 29.  3. 29.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 1.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 19. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 29.  3. 29.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29. 15. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 29.] 
expected returns: [[70.14507]
 [75.35686]
 [66.74819]
 [75.35686]
 [75.35686]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 29.  3. 29.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 19. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 112.83776092529297



action possibilites: [-1. 15. 11.] 
expected returns: [[75.18546 ]
 [71.785065]
 [76.05051 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 19. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.61742401123047



action possibilites: [-1] 
expected returns: [[82.74556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   40    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -138 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 73.55225372314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.27583 ]
 [65.714966]
 [82.74556 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.74555969238281






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 11.  3. 15. 11.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 11.  3. 15. 11.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [ 6.  1. 10. 11.  0.  0.  0. 11. 14.  3.  6.  3.  6.  8.  3.  3.  6.  0.
  3.  3.  0.  1.  6.  0.  0.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 11.  3. 15. 11.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1. 11.  3. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[50.224243]
 [50.75005 ]
 [47.946228]
 [50.75005 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3. 15. 11.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 18. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.74555969238281



action possibilites: [-1] 
expected returns: [[34.26014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15. 11.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: -168 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 49.19495391845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.375275]
 [32.2327  ]
 [27.487322]
 [32.701572]
 [34.260128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 15. 11.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3. 10.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.26013946533203






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14 10  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8
  0  3  0  6  3  3  6  1  3  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 29.  1.  3.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 29.  1.  3.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 29.  1.  3.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11. 29.  1.  3.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11. 11. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[75.62092]
 [76.2657 ]
 [76.2657 ]
 [80.02698]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.  1.  3.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.26013946533203



action possibilites: [-1. 11. 11.] 
expected returns: [[53.480713]
 [54.09915 ]
 [54.09915 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 17. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.4074935913086



action possibilites: [-1] 
expected returns: [[29.99905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 16. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   40    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 52.29383087158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[23.49593 ]
 [28.901932]
 [26.640522]
 [18.603386]
 [27.406683]
 [29.99905 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 16. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.99905014038086






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11. 11.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 17. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 10.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [0. 8. 3. 0. 3. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 10.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [0. 8. 3. 0. 3. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  7.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 10.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [0. 8. 3. 0. 3. 3. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 15. 10. 10.  0.] 
adversary cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [15. 15. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10. 10.] 
expected returns: [[76.43201 ]
 [73.690506]
 [73.690506]
 [70.967125]
 [70.967125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 10.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.99905014038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.09709 ]
 [63.315506]
 [76.43201 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10. 10.  0.] 
cards in discard: [25.  1.  0. 10.  1.  0.  0.  1.  0. 15. 29. 10.  1. 11. 10. 10. 15.  0.
  1. 11. 15. 10. 10.  0. 29. 29.  1. 29. 11. 15.  3.  1. 11.  1.  3. 15.
 11.  3.  1.  1. 29. 11. 11.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.43201446533203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.  6.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11.  0. 29. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 16. 30. 16. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 16. 30. 15. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [ 0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[116.801956]
 [121.99791 ]
 [126.176605]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.] 
cards in discard: [11. 11.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  4. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3] -> size -> 38 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0 -160    0    0
 1612    0] 
sum of rewards: 1327 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 23.021282196044922



action possibilites: [-1] 
expected returns: [[128.24371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 15.] 
cards in discard: [11. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.17660522460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[118.33891 ]
 [125.192154]
 [122.30528 ]
 [112.089645]
 [123.28351 ]
 [126.635605]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 15.] 
cards in discard: [11. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.24371337890625






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 10.  0. 11. 25.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  6.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 10.  0. 11. 25.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  5.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 10.  0. 11. 25.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 1. 10.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[111.35307]
 [104.07255]
 [112.23906]
 [121.87302]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 11. 25.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  3. 10.  0.  5.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.63560485839844



action possibilites: [-1] 
expected returns: [[117.72516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 11.  1. 29.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 121.87301635742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[108.23121 ]
 [115.27966 ]
 [112.29753 ]
 [104.38266 ]
 [101.50806 ]
 [113.28936 ]
 [113.30867 ]
 [125.61319 ]
 [121.65014 ]
 [106.51283 ]
 [113.49275 ]
 [106.49527 ]
 [113.512085]
 [116.71433 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 11.  1. 29.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  8.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.72515869140625



buy possibilites: [-1] 
expected returns: [[95.48244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 11.  1. 29.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  7.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 6. 8. 3. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -170    0    0
  250    0] 
sum of rewards: 5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 125.61318969726562






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 3.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  7.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1.  1. 10.  3.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25] -> size -> 52 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 3.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  7.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1.  1. 10.  3.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25] -> size -> 52 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  1.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[79.04176 ]
 [73.121414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 10.  3.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  7.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 1. 3. 6. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.48243713378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[71.269745]
 [77.88275 ]
 [68.51503 ]
 [75.119804]
 [67.61257 ]
 [64.95665 ]
 [76.03552 ]
 [76.055595]
 [87.88014 ]
 [83.95267 ]
 [69.63709 ]
 [76.225174]
 [69.61715 ]
 [76.245255]
 [79.21709 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 10.  3.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25] -> size -> 52 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  7.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 1. 3. 6. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.04177856445312



buy possibilites: [-1] 
expected returns: [[67.97311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 10.  3.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 1. 3. 6. 3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -60.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    62.5    0. ] 
sum of rewards: -182.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 87.88015747070312






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 1. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 6. 3.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  0. 10.  0.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 6. 3.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  0. 10.  0.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 6. 3.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0. 15.  0. 10.  0.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 15.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[28.486557]
 [26.442154]
 [24.49065 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 10.  0.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.  3.  1.  3.  6.
  3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.97310638427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[23.148157]
 [27.570011]
 [25.700151]
 [18.901833]
 [26.325048]
 [28.486557]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 10.  0.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.  3.  1.  3.  6.
  3.] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.486553192138672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.  3.  1.  3.  6.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.  3.  1.  3.  6.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  5.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  8.  3.  0.  3.  3.  8. 11.  3.  3.  1. 11.  3. 14.  0.  0.  6.  6.
  6.  8.  3.  0.  6.  3.  0.  6.  6.  6.  8.  3.  3.  0.  3.  1.  3.  6.
  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [15. 29. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15. 10. 11.] 
expected returns: [[25.930542]
 [24.211073]
 [28.651028]
 [24.211073]
 [22.517542]
 [26.366959]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 15. 10. 11.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.486553192138672



action possibilites: [-1. 15. 10.] 
expected returns: [[21.95479 ]
 [20.523695]
 [19.134619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.177183151245117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[18.194216]
 [21.323397]
 [19.988197]
 [15.242518]
 [20.438738]
 [21.954788]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 6. 11.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.954788208007812






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  6  0 11  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0
  3  0  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 10. 15.  0. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29. 10. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15. 10.] 
expected returns: [[26.934986]
 [28.939514]
 [24.671978]
 [25.78937 ]
 [24.671978]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 15.  0. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.954788208007812



action possibilites: [-1. 10. 10.] 
expected returns: [[14.26238 ]
 [12.037852]
 [12.037852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.429258346557617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.438883]
 [12.593656]
 [ 9.611108]
 [12.922284]
 [14.262376]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.262381553649902






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [8. 3. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15.  3. 10.  0.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [8. 3. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15.  3. 10.  0.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 15.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.] 
expected returns: [[36.742905]
 [39.611366]
 [34.9886  ]
 [33.244637]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3. 10.  0.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 1. 8. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.262381553649902



action possibilites: [-1. 10.] 
expected returns: [[36.81037 ]
 [32.749027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 1. 8. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 38.90129470825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[31.36396 ]
 [35.904625]
 [34.002907]
 [27.04221 ]
 [34.64018 ]
 [34.648006]
 [40.065132]
 [30.245667]
 [34.77645 ]
 [36.810375]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  5.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 1. 8. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.81037902832031



buy possibilites: [-1] 
expected returns: [[44.01358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 1. 8. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -190    0    0
  128    0] 
sum of rewards: -137 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.06512451171875






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 14  0  0  0  3  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0
  6  3  3  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11.  3. 15. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11.  3. 15. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11.  3. 15. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [11. 11.  3. 15. 10.] 
adversary cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11. 11.  3. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 10.] 
expected returns: [[50.720863]
 [51.154884]
 [51.154884]
 [49.00532 ]
 [47.307255]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 15. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 16. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
adversary owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.013580322265625



action possibilites: [-1] 
expected returns: [[62.332726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
adversary owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: -218 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 49.968292236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.298916]
 [53.460026]
 [62.332726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 15. 10.] 
cards in discard: [11. 11. 25.  0. 29.  1. 15. 25. 25.  1. 10.  0. 11.  1. 29. 25.  1.  1.
  1. 10.  3.  0. 15.  0. 10.  0. 15. 11. 29. 15. 10.  1. 15. 11. 29. 10.
  0. 10. 15.  3. 29. 29. 10.  0.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [0. 8. 3. 3. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
adversary owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.332725524902344






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 3.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  0  3  6  6  3  8  0  3  3  3  6 11  0  3  8  0  3  0  6  3  3
  6  1  3  1  0  0  3  8  3  6  8  6  0  8  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  1.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  1.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  1.  1.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  1.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[124.2781 ]
 [128.92953]
 [124.93057]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  1. 11.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 8. 8. 6.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.332725524902344



action possibilites: [-1. 11.] 
expected returns: [[120.804115]
 [121.44388 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.] 
cards in discard: [1. 1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 15. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 8. 8. 6.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 122.96833038330078



action possibilites: [-1] 
expected returns: [[118.62662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [1. 1. 1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 8. 8. 6.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 119.58235168457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[108.21218 ]
 [113.72071 ]
 [111.39941 ]
 [105.22867 ]
 [102.99367 ]
 [112.172485]
 [112.18695 ]
 [122.51517 ]
 [119.00268 ]
 [106.87924 ]
 [112.33028 ]
 [106.866066]
 [112.344734]
 [114.83547 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [1. 1. 1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  6.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 8. 8. 6.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.62661743164062



buy possibilites: [-1] 
expected returns: [[119.79937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 1.  1.  1. 25.] 
cards in deck: 49 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 0. 8. 8. 6.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -220    0    0
  250    0] 
sum of rewards: 95 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 122.51517486572266






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 6.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  6  6  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1
  0  0  3  8  3  6  8  6  0  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1. 11.  1.  0.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1. 11.  1.  0.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1. 11.  1.  0.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1.  1. 11.  1.  0.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 1.  1. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[86.70946]
 [87.73778]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.  1.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 14. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.79936981201172



action possibilites: [-1] 
expected returns: [[84.064896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 13. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -230    0    0
   27    0] 
sum of rewards: -218 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 84.68680572509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[75.23442 ]
 [82.572624]
 [72.61962 ]
 [79.50831 ]
 [71.77667 ]
 [69.20911 ]
 [80.51952 ]
 [80.545876]
 [93.53271 ]
 [89.18955 ]
 [73.671906]
 [80.73292 ]
 [73.65434 ]
 [80.75928 ]
 [84.0649  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1] -> size -> 58 
action values: 0 
buys: 1 
player value: 7 
card supply: [18. 13. 30. 15. 30.  8.  2. 10.  0.  4.  5.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.06489562988281



buy possibilites: [-1] 
expected returns: [[71.4386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 13. 30. 15. 30.  8.  2. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.    20.     0.     0.     0.
    0.  -240.     0.     0.    62.5    0. ] 
sum of rewards: -192.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 93.53269958496094






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [3. 3. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 13. 30. 15. 30.  8.  2. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 25. 15. 25. 15.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 13. 30. 15. 30.  8.  2. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 25. 15. 25. 15.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 12. 30. 15. 30.  8.  2. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 1. 25. 15. 25. 15.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 1. 25. 15. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 25. 15.] 
expected returns: [[65.587074]
 [74.63252 ]
 [62.866615]
 [74.63252 ]
 [62.866615]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15. 25. 15.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 12. 30. 15. 30.  8.  2. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  0.  6. 11.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.4385986328125



action possibilites: [-1] 
expected returns: [[79.31831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 25. 15.  1.  1.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 12. 30. 15. 30.  8.  1. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  0.  6. 11.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.63253021240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[71.709526]
 [78.02568 ]
 [69.10078 ]
 [75.37994 ]
 [68.252464]
 [65.80132 ]
 [76.263176]
 [76.27263 ]
 [87.75406 ]
 [83.8512  ]
 [70.148735]
 [76.43711 ]
 [70.14059 ]
 [76.44657 ]
 [79.31831 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 25. 15.  1.  1.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 12. 30. 15. 30.  8.  1. 10.  0.  4.  4.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  0.  6. 11.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.31831359863281



buy possibilites: [-1] 
expected returns: [[98.332214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 25. 15.  1.  1.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 12. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 3.  3.  0.  6. 11.] 
adversary cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.   -30.     0.     0.    20.     0.     0.     0.
    0.  -250.     0.     0.    62.5    0. ] 
sum of rewards: -202.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 87.75405883789062






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 11.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 12. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 11.  3. 10.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 11.  3. 10.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 11.  3. 10.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6.] 
cards in discard: [8. 3. 0. 0. 3. 6. 3. 6. 0. 8. 0. 8. 0. 8. 0. 8. 1. 3. 3. 1. 6. 0. 6. 1.
 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29.  0. 11.  3. 10.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[51.947517]
 [54.95365 ]
 [52.409603]
 [48.071556]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 10.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.33221435546875



action possibilites: [-1. 10.] 
expected returns: [[37.1432 ]
 [34.27091]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 54.22102355957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.450706]
 [35.051235]
 [30.896263]
 [35.500946]
 [37.1432  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 3. 3. 0. 1.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.14320373535156






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15. 10. 11.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15. 10. 11.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 1.] 
cards in discard: [ 8.  3.  0.  0.  3.  6.  3.  6.  0.  8.  0.  8.  0.  8.  0.  8.  1.  3.
  3.  1.  6.  0.  6.  1.  0. 11.  3.  3.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 11. 15. 10. 11.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 10. 11.] 
expected returns: [[10.745199 ]
 [ 9.206114 ]
 [10.975225 ]
 [ 9.9883175]
 [ 9.206114 ]
 [10.975225 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 10. 11.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 11. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.14320373535156



action possibilites: [-1] 
expected returns: [[12.886178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 11.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 10. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -260    0    0
   27    0] 
sum of rewards: -218 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 10.43346118927002





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.393287]
 [ 8.709765]
 [12.886178]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10. 11.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 10. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.886178016662598






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 10. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 11.  1. 29.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 10. 30. 15. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 11.  1. 29.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 10. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [29. 15. 11.  1. 29.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 15. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11. 29.] 
expected returns: [[26.283033]
 [29.147137]
 [24.620598]
 [26.730396]
 [29.147137]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 11.  1. 29.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 10. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.886178016662598



action possibilites: [-1. 15. 11.] 
expected returns: [[32.807205]
 [30.983036]
 [33.260727]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 10. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 28.445249557495117



action possibilites: [-1] 
expected returns: [[28.715736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 1 
card supply: [16.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -270    0    0
   27    0] 
sum of rewards: -238 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 32.001949310302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.841682]
 [26.635086]
 [22.033728]
 [27.115826]
 [28.71574 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [1. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.] 
adversary owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.715736389160156






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [1. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  0  8  0  3  3  6 11  0  3  8  0  3  0  6  3  3  6  1  3  1  0  0
  3  8  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0. 10. 25.  3.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  6 11  0  3  8  0  3  0  6  3  3  6  3  1  0  0  3  8
  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0. 10. 25.  3.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  6 11  0  3  8  0  3  0  6  3  3  6  3  1  0  0  3  8
  3  6  8  6  0  8  0  0  1  6  1  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [16.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0. 10. 25.  3.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 14.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  0  8  0  3  6 11  0  3  8  0  3  0  6  3  3  6  3  1  0  0  3  8
  3  6  8  6  0  8  0  0  1  6  1  0  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0. 10. 25.  3.] 
adversary cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [15.  0. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 25.] 
expected returns: [[31.731308]
 [29.981995]
 [28.292948]
 [37.328377]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 25.  3.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  9. 30. 14. 30.  8.  1. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.  0.  8.  3.  0.] 
adversary owned cards: [14  0  0  8  0  3  6 11  0  3  8  0  3  0  6  3  3  6  3  1  0  0  3  8
  3  6  8  6  0  8  0  0  1  6  1  0  0  3  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.715736389160156



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 7 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  0. 10.  3. 15.  1.] 
cards in discard: [ 1.  1.  1. 25. 29. 11.  1.  1.  1. 25. 11.  1.  1.  1.  0. 25. 25.  1.
 15. 25. 15.  1.  1.  0. 11. 29.  3. 10.  0.  1. 11. 10. 15. 10. 11.  1.
 29.  1. 29. 11. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 29 25 10 29 10 29 10 11 10 11
 10 11 10 10 15 11 15 15 11 15 15 15 15 11  1  1  1  1  1 29  1 25  1  1
  1  1  1 25 25 29  1  1 25  1 25 25  1  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [15.  9. 30. 14. 30.  8.  0. 10.  0.  4.  3.  4.  9. 10.  0. 10.  1.] 
adversary cards in hand: [6. 3. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.  0.  8.  3.  0.  6.] 
adversary owned cards: [14  0  0  8  0  3  6 11  0  3  8  0  3  0  6  3  3  6  3  1  0  0  3  8
  3  6  8  6  0  8  0  0  1  6  1  0  0  3  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0       0       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000015 

action type: take_action - action 25.0
Learning step: 119999.109375
desired expected reward: 120036.4375



