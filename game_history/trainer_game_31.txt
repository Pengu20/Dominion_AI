 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.637314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -469 

action type: gain_card_n - action 8
Learning step: -14.56567096710205
desired expected reward: 1.9566926956176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.790882]
 [19.975485]
 [18.692581]
 [14.745734]
 [18.45254 ]
 [21.602335]
 [20.688908]
 [21.769762]
 [17.625057]
 [19.396883]
 [19.807503]
 [19.905281]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5434662699699402
desired expected reward: 19.473196029663086



buy possibilites: [-1] 
expected returns: [[21.928791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.3871593475341797
desired expected reward: 22.156923294067383






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.367922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.560223400592804
desired expected reward: 21.368568420410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.86607 ]
 [24.109539]
 [22.795235]
 [18.736137]
 [25.764404]
 [24.83524 ]
 [23.520935]
 [24.038074]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6084896326065063
desired expected reward: 22.976303100585938



buy possibilites: [-1] 
expected returns: [[24.493114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.1257544308900833
desired expected reward: 25.638648986816406






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.967964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6196505427360535
desired expected reward: 23.873464584350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.211695]
 [25.388807]
 [24.113392]
 [20.166546]
 [23.87335 ]
 [26.994783]
 [26.093082]
 [27.1608  ]
 [23.045868]
 [24.81767 ]
 [25.22298 ]
 [25.319527]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6437276005744934
desired expected reward: 24.60797882080078



buy possibilites: [-1] 
expected returns: [[24.02004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.52445387840271
desired expected reward: 24.864355087280273






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.30278 ]
 [23.160206]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6344437003135681
desired expected reward: 23.385597229003906



action possibilites: [-1. 11.] 
expected returns: [[26.565374]
 [28.299473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.042703285813331604
desired expected reward: 23.281301498413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.534685]
 [26.778154]
 [25.463852]
 [21.396759]
 [28.441528]
 [27.503853]
 [26.189547]
 [26.70669 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.06986812502145767
desired expected reward: 26.49550437927246



buy possibilites: [-1] 
expected returns: [[25.371618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.4530574083328247
desired expected reward: 27.231210708618164






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.961872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6467805504798889
desired expected reward: 24.724838256835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.300665]
 [25.4967  ]
 [22.02525 ]
 [24.204676]
 [21.528866]
 [20.255514]
 [23.962317]
 [27.123545]
 [26.210127]
 [29.08581 ]
 [27.290977]
 [23.134834]
 [23.092216]
 [24.918095]
 [20.915106]
 [25.328718]
 [25.426493]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6400380730628967
desired expected reward: 24.537864685058594



buy possibilites: [-1] 
expected returns: [[25.803043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 16.0
Learning step: -0.3579375445842743
desired expected reward: 23.604379653930664






Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [16.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.134836]
 [24.861164]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [16.  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6694865822792053
desired expected reward: 25.133556365966797



action possibilites: [-1] 
expected returns: [[25.839622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  1.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.6380704641342163
desired expected reward: 19.41292381286621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.027351]
 [24.953215]
 [20.903795]
 [26.981878]
 [26.188871]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  1.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06179414689540863
desired expected reward: 25.777828216552734



buy possibilites: [-1] 
expected returns: [[28.435474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  1.  0. 16.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.1791161149740219
desired expected reward: 27.160993576049805






Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [10.  0. 11.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [10.  0. 11.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.556822]
 [28.4768  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7111631035804749
desired expected reward: 27.72431182861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.16365 ]
 [27.438768]
 [26.102879]
 [22.078318]
 [25.853148]
 [29.136265]
 [28.18106 ]
 [29.315605]
 [24.991451]
 [26.832743]
 [27.26367 ]
 [27.362972]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6640765070915222
desired expected reward: 25.984045028686523



buy possibilites: [-1] 
expected returns: [[27.488758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  3.  0.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.3488883376121521
desired expected reward: 25.34033966064453






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0. 16.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0. 16.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  0. 16.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[25.839352]
 [27.528542]
 [24.384155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0. 16.] 
cards in discard: [14.  0.  1. 29.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6990385055541992
desired expected reward: 26.789718627929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.655928]
 [20.610424]
 [25.778538]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0. 16.] 
cards in discard: [14.  0.  1. 29.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6751358509063721
desired expected reward: 25.17141342163086



buy possibilites: [-1] 
expected returns: [[26.237978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0. 16.] 
cards in discard: [14.  0.  1. 29.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5841791033744812
desired expected reward: 23.07175064086914






Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [3. 0. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  1.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [3. 0. 0. 1. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  1.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 3.  0.  0.  1.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  1.] 
adversary cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[23.890282]
 [22.478678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  1.] 
cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0. 10.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6917235851287842
desired expected reward: 25.546255111694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.464554]
 [24.500658]
 [23.296879]
 [20.874102]
 [19.736425]
 [23.075447]
 [26.091845]
 [25.196238]
 [28.01572 ]
 [26.259893]
 [22.31468 ]
 [22.279613]
 [23.94427 ]
 [20.326868]
 [24.33996 ]
 [24.430834]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  1.] 
cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0. 10.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6111282706260681
desired expected reward: 23.32100486755371



buy possibilites: [-1] 
expected returns: [[31.668278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  1.] 
cards in discard: [14.  0.  1. 29.  3.  0.  0.  3. 11.  3.  0. 16. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  0. 10.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 25.0
Learning step: 0.842045247554779
desired expected reward: 28.857765197753906






Player: 1 
cards in hand: [ 0.  3. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  3.] 
cards in discard: [ 3.  0.  0.  1.  0.  0. 10.  0.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  3.] 
cards in discard: [ 3.  0.  0.  1.  0.  0. 10.  0.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 20 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.982012]
 [29.810287]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7898656725883484
desired expected reward: 30.8784122467041



action possibilites: [-1] 
expected returns: [[27.03745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: -0.09165990352630615
desired expected reward: 27.524402618408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.419178]
 [26.346931]
 [22.323164]
 [28.39828 ]
 [27.561838]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0830041691660881
desired expected reward: 26.95444679260254



buy possibilites: [-1] 
expected returns: [[25.634012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.04341825470328331
desired expected reward: 25.375761032104492






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[22.3822  ]
 [25.908854]
 [24.19736 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6616844534873962
desired expected reward: 24.972328186035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.534088]
 [21.373266]
 [17.703539]
 [23.289331]
 [22.508112]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0. 29.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5953112244606018
desired expected reward: 21.781517028808594



buy possibilites: [-1] 
expected returns: [[22.460531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0. 29.  0.] 
cards in discard: [0. 8. 0. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.37284421920776367
desired expected reward: 22.91648292541504






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 1. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 11.  1.  0. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 1. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 11.  1.  0. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 1. 3. 0. 0. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16. 11.  1.  0. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [16. 11.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 14.] 
expected returns: [[26.268509]
 [24.869322]
 [28.00238 ]
 [24.0455  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  1.  0. 14.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5476738214492798
desired expected reward: 21.912857055664062



action possibilites: [-1] 
expected returns: [[24.848524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0. 14.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.14056719839572906
desired expected reward: 23.1519775390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.132967]
 [25.27676 ]
 [24.012049]
 [20.179604]
 [26.850422]
 [25.96647 ]
 [24.701757]
 [25.16954 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0. 14.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03401578962802887
desired expected reward: 24.81450843811035



buy possibilites: [-1] 
expected returns: [[26.15695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0. 14.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.5235951542854309
desired expected reward: 25.225353240966797






Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [0. 1. 3. 0. 0. 3. 8. 3. 0. 0. 0. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[25.373623]
 [23.96131 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.674217164516449
desired expected reward: 25.48273277282715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.38881 ]
 [25.548775]
 [24.27532 ]
 [20.416565]
 [24.042372]
 [27.147917]
 [26.249634]
 [27.321331]
 [23.216162]
 [24.967001]
 [25.373833]
 [25.439745]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6456626057624817
desired expected reward: 24.72795867919922



buy possibilites: [-1] 
expected returns: [[30.82337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  8. 25.  3.  0. 29.  0.  3. 10. 11. 16.  1.  0. 14. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.3140054941177368
desired expected reward: 27.63533592224121






Player: 1 
cards in hand: [ 1.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  8.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  1.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3. 11.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [16.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[22.631361]
 [21.176462]
 [24.400118]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11.  1.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8320488333702087
desired expected reward: 29.991321563720703



action possibilites: [-1] 
expected returns: [[25.20097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 3
Learning step: 0.039879683405160904
desired expected reward: 26.530895233154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.724356]
 [24.641193]
 [20.573057]
 [26.698029]
 [25.80548 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.045940473675727844
desired expected reward: 25.155029296875



buy possibilites: [-1] 
expected returns: [[24.19785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.] 
cards in discard: [8. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.14313645660877228
desired expected reward: 26.841167449951172






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  7.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 16. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8  8] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 1. 16. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
expected returns: [[29.633188]
 [28.206459]
 [29.183464]
 [30.550068]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 10.  0.  8.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16 16  8 14  0 25  0  8  3 10 29  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5645155310630798
desired expected reward: 23.633333206176758



action possibilites: [-1] 
expected returns: [[29.457687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.004833640996366739
desired expected reward: 25.153902053833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.24314 ]
 [30.428167]
 [29.130392]
 [25.191767]
 [32.060844]
 [31.148571]
 [29.831018]
 [30.260532]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11829368025064468
desired expected reward: 29.339393615722656



buy possibilites: [-1] 
expected returns: [[29.766567]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.05136285722255707
desired expected reward: 29.079030990600586






Player: 1 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [11. 10.  1.  0.  0. 10.  1. 11.  0.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[25.450954]
 [27.364208]
 [23.276297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14.  0.  0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7723185420036316
desired expected reward: 28.99424934387207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.70876 ]
 [25.875376]
 [24.59175 ]
 [20.769495]
 [27.455631]
 [26.572641]
 [25.289015]
 [25.713085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 14.  0.  0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6463527679443359
desired expected reward: 24.819787979125977



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[26.372425]
 [29.909458]
 [28.182793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  3.  0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6220815777778625
desired expected reward: 25.09100341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.676151]
 [25.497997]
 [21.849669]
 [27.341705]
 [26.541624]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  3.  0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  5.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.672231137752533
desired expected reward: 25.700193405151367



buy possibilites: [-1] 
expected returns: [[32.9177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  3.  0.] 
cards in discard: [ 8.  8. 16.  3. 11.  1.  3.  8.  1.  0. 29.  0. 14.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 10.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.38461530208587646
desired expected reward: 26.957090377807617






Player: 1 
cards in hand: [ 3.  0.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  6.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  1.] 
cards in discard: [ 8.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.121742]
 [27.996716]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 11.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8470369577407837
desired expected reward: 32.07066345214844



action possibilites: [-1] 
expected returns: [[21.87926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 11.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.032071150839328766
desired expected reward: 23.70673179626465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.312395]
 [17.46219 ]
 [22.135319]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 11.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.007854137569665909
desired expected reward: 21.887113571166992



buy possibilites: [-1] 
expected returns: [[21.106222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11. 11. 11.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.062243442982435226
desired expected reward: 20.374637603759766






Player: 1 
cards in hand: [ 0.  3. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 11.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  5.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  4.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  4.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.934889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  4.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4995601177215576
desired expected reward: 20.60666275024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.144575]
 [27.352207]
 [26.037483]
 [22.043242]
 [28.956615]
 [28.063707]
 [26.748985]
 [27.12806 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  4.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6775039434432983
desired expected reward: 26.334545135498047



buy possibilites: [-1] 
expected returns: [[28.482922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.17962771654129028
desired expected reward: 28.77698516845703






Player: 1 
cards in hand: [ 1. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0.  0.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 29.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0.  0.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 29.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  0.  0.] 
cards in discard: [ 8.  0.  3. 11.  3.  0.  3. 10.  1. 11. 11.  0.  3. 11. 11. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [11. 29.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 29.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.  8.] 
expected returns: [[29.3205  ]
 [31.149055]
 [31.316753]
 [30.256147]
 [30.256147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8.  0.  8.] 
cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6828863024711609
desired expected reward: 27.80003547668457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.452528]
 [24.402897]
 [29.413973]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  8.  0.  8.] 
cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.740218460559845
desired expected reward: 28.577852249145508



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  1. 16. 14.  1.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  1. 16. 14.  1.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  1. 16. 14.  1.] 
adversary cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8.  1. 16. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
expected returns: [[28.799385]
 [29.708689]
 [27.51281 ]
 [26.675337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 16. 14.  1.] 
cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  7.  9. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7333688735961914
desired expected reward: 28.68060302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.931658]
 [29.077072]
 [27.79935 ]
 [23.9599  ]
 [27.572554]
 [30.636122]
 [29.768433]
 [30.799114]
 [26.735079]
 [28.490707]
 [28.880495]
 [28.859125]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 16. 14.  1.] 
cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  7.  9. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7116467356681824
desired expected reward: 28.087739944458008



buy possibilites: [-1] 
expected returns: [[28.365389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 16. 14.  1.] 
cards in discard: [ 0.  8.  3.  3. 11.  0.  3.  0.  0.  3. 11. 29.  8.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.5718846321105957
desired expected reward: 27.918825149536133






Player: 1 
cards in hand: [ 1. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 26. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[25.84931 ]
 [26.724836]
 [27.71729 ]
 [29.429598]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0 25  0  8  3 29  8  8  3  8  0 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  0.  8.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7084920406341553
desired expected reward: 27.656896591186523



action possibilites: [-1] 
expected returns: [[17.705126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  0.  8.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.04054366797208786
desired expected reward: 22.507705688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.46382  ]
 [17.23328  ]
 [13.9667845]
 [18.99157  ]
 [18.176243 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  0.  8.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10124576091766357
desired expected reward: 17.806371688842773



buy possibilites: [-1] 
expected returns: [[20.758574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  0.  8.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.3909665644168854
desired expected reward: 17.624248504638672






Player: 1 
cards in hand: [11. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.  8.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10.  8.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 11. 14.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 11. 14.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 11. 14.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  8.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 8. 11. 14.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14. 29.] 
expected returns: [[21.314896]
 [22.179775]
 [23.005106]
 [19.307669]
 [23.160124]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 14.  0. 29.] 
cards in discard: [ 3.  8.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  1.  3. 22.  0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5410339832305908
desired expected reward: 20.217538833618164



action possibilites: [-1.  8. 11. 14.  8.] 
expected returns: [[23.264841]
 [24.120783]
 [24.89139 ]
 [21.4584  ]
 [24.120783]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 14.  0.  8.] 
cards in discard: [ 3.  8.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  1.  3. 22.  0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.012187900021672249
desired expected reward: 22.94826889038086



action possibilites: [-1] 
expected returns: [[27.589169]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  8.] 
cards in discard: [ 3.  8.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.6959341168403625
desired expected reward: 22.154338836669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.976582]
 [28.114182]
 [26.83645 ]
 [23.010033]
 [26.608635]
 [29.661804]
 [28.801937]
 [29.814152]
 [25.766773]
 [27.524208]
 [27.904371]
 [27.839401]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  8.] 
cards in discard: [ 3.  8.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5144355893135071
desired expected reward: 28.10360336303711



buy possibilites: [-1] 
expected returns: [[33.609535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  8.] 
cards in discard: [ 3.  8.  0.  0. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3. 22.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.6236026287078857
desired expected reward: 26.600183486938477






Player: 1 
cards in hand: [10.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 22.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 22.] 
cards in discard: [14.  0.  3.  0.  0.  0.  3.  1. 10.  3.  0.  0. 16.  0. 11. 11. 11.  0.
  8.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.820177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9501742124557495
desired expected reward: 32.65936279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.299463 ]
 [20.28354  ]
 [19.0976   ]
 [15.5597315]
 [18.88612  ]
 [21.720036 ]
 [20.921898 ]
 [21.861345 ]
 [18.10467  ]
 [19.735958 ]
 [20.088749 ]
 [20.028454 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 24. 30.  8. 10.  7.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5344852209091187
desired expected reward: 19.28569221496582



buy possibilites: [-1] 
expected returns: [[23.688398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.4921445846557617
desired expected reward: 19.378265380859375






Player: 1 
cards in hand: [11.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  3.  8. 16.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  8. 16.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16] -> size -> 27 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 11.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  8. 16.] 
adversary cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16] -> size -> 27 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[19.250664]
 [20.870934]
 [20.106422]
 [18.156424]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8. 16.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 14.  1. 22. 11.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6522156596183777
desired expected reward: 23.036182403564453



action possibilites: [-1] 
expected returns: [[27.387466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 16.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 14.  1. 22. 11.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.20944844186306
desired expected reward: 17.813446044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.86935 ]
 [23.284538]
 [27.47044 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 16.] 
cards in discard: [ 3.  8.  0.  0. 29.  0. 29. 14.  8. 11.  0.  8. 16.  3.  1.  3.  0.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 14.  1. 22. 11.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09938792884349823
desired expected reward: 27.28807830810547






Player: 1 
cards in hand: [ 0. 14.  1. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 22. 11.] 
cards in discard: [15. 11.  0.  3. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22. 11.] 
cards in discard: [15. 11.  0.  3. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22. 11.] 
cards in discard: [15. 11.  0.  3. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  3.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22. 11.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [10.  8.  1.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[23.918095]
 [23.59713 ]
 [24.904633]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.] 
cards in discard: [3. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11 10
  3  0 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 6
Learning step: -0.4761674404144287
desired expected reward: 18.898820877075195



action possibilites: [-1] 
expected returns: [[24.302528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.08542007207870483
desired expected reward: 20.74397087097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.788355]
 [20.246002]
 [24.475441]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8. 10.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.038650017231702805
desired expected reward: 24.263877868652344



buy possibilites: [-1] 
expected returns: [[17.744425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.970968246459961
desired expected reward: 11.27186393737793






Player: 1 
cards in hand: [ 1.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [3. 3. 6. 8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 24. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [3. 3. 6. 8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 0. 11.  8.  0.  0.] 
adversary cards in discard: [3. 3. 6. 8.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[24.57066 ]
 [26.468891]
 [25.598171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [3. 3. 6. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0. 11. 10.  8.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4121624529361725
desired expected reward: 17.33226203918457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.004442]
 [25.179022]
 [23.875156]
 [20.024363]
 [26.748333]
 [25.877615]
 [24.57375 ]
 [24.850105]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0.  0.] 
cards in discard: [3. 3. 6. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0. 11. 10.  8.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6271088719367981
desired expected reward: 23.94355010986328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11. 10.  8.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  8.  0. 16. 14.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11. 10.  8.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  8.  0. 16. 14.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11. 10.  8.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 1.  8.  0. 16. 14.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  0. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
expected returns: [[23.942013]
 [24.93525 ]
 [22.774502]
 [21.939476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 16. 14.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6465974450111389
desired expected reward: 24.203508377075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.371027]
 [24.47315 ]
 [23.212673]
 [19.40902 ]
 [25.99004 ]
 [25.148397]
 [23.887918]
 [24.15516 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 16. 14.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  4.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6156015992164612
desired expected reward: 23.326412200927734



buy possibilites: [-1] 
expected returns: [[25.303185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  0. 16. 14.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5787685513496399
desired expected reward: 24.569631576538086






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  2.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15. 11.  0.  3. 11. 11. 11. 14.  0.  1. 22. 11.  3.  1.  0.  0.  0. 10.
  0. 16.  0. 11. 10.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.992565]
 [25.997036]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6445454359054565
desired expected reward: 24.658639907836914



action possibilites: [-1. 29.] 
expected returns: [[27.977322]
 [30.079575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.022905005142092705
desired expected reward: 25.974130630493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.244547]
 [28.36864 ]
 [27.086647]
 [23.27755 ]
 [29.967945]
 [29.072798]
 [27.771175]
 [28.043999]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  6.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.09556199610233307
desired expected reward: 27.881759643554688



buy possibilites: [-1] 
expected returns: [[28.503727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [11. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.4561538100242615
desired expected reward: 28.22732925415039






Player: 1 
cards in hand: [11. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8 10] -> size -> 29 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8 10] -> size -> 29 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8 10] -> size -> 29 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[27.115774]
 [28.112162]
 [28.112162]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 11  1 16  8 14  0  0  8  3 29  8  8  3  8  0 11  3  0
 16  0  6  8 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11  0] -> size -> 34 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.712723970413208
desired expected reward: 27.79100227355957



action possibilites: [-1] 
expected returns: [[27.914955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11  0] -> size -> 34 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.10191169381141663
desired expected reward: 28.065378189086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.078644]
 [23.125048]
 [27.859081]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  3.  6.  8.  0. 11.  8.  0.  0.  8.  1.  8.  0. 16. 14. 10. 29.  3.
  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 15.  3.  3.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11  0] -> size -> 34 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11316879093647003
desired expected reward: 27.801786422729492






Player: 1 
cards in hand: [ 1. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3.  3.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22
 14  3 16  0 15 11  3  0 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 11.  3. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 11.  3. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 23. 30.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 11.  3. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 11.  3. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 11.] 
expected returns: [[15.191906]
 [16.711212]
 [14.242932]
 [16.711212]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 16. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6
  8 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [22.  0.  3. 11. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.818678617477417
desired expected reward: 27.040403366088867



action possibilites: [-1] 
expected returns: [[17.391022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [22.  0.  3. 11. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.12144120782613754
desired expected reward: 21.16025733947754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.330536]
 [13.988353]
 [17.716072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [22.  0.  3. 11. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09997100383043289
desired expected reward: 17.49099349975586






Player: 1 
cards in hand: [22.  0.  3. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3. 11. 16.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  3. 29.  1.  8.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.] 
adversary owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  3. 11. 16.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  3. 29.  1.  8.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.] 
adversary owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 29.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[16.13914 ]
 [16.980389]
 [17.778728]
 [16.980389]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  1.  8.] 
cards in discard: [ 3. 16. 11.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 11.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5016016364097595
desired expected reward: 17.21446990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.898549]
 [15.578468]
 [12.536592]
 [17.15862 ]
 [16.316887]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  1.  8.] 
cards in discard: [ 3. 16. 11.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 22. 29.  8.  9.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 11.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4696393609046936
desired expected reward: 15.669499397277832



buy possibilites: [-1] 
expected returns: [[14.231392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.  1.  8.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 1. 11.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.376667976379395
desired expected reward: 3.1599225997924805






Player: 1 
cards in hand: [ 1. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  0.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
adversary owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
adversary owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
adversary owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[18.889704]
 [18.675488]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3794995844364166
desired expected reward: 13.851892471313477



action possibilites: [-1.  8.] 
expected returns: [[17.624256]
 [18.573975]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29 11  1 16 14  0  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8
 10  3  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.08077336847782135
desired expected reward: 18.75625991821289



action possibilites: [-1.] 
expected returns: [[22.785326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.85202956199646
desired expected reward: 15.425908088684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.338577]
 [18.668732]
 [22.985613]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 22. 29.  8.  8.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5910901427268982
desired expected reward: 23.376415252685547



buy possibilites: [-1] 
expected returns: [[28.002647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 22. 29.  8.  7.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.216033935546875
desired expected reward: 10.45269775390625






Player: 1 
cards in hand: [ 0.  0.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 14.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 29.  8.  7.  6.  1.  3.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 6. 29. 14.  8. 16.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 6. 29. 14.  8. 16.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 6. 29. 14.  8. 16.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [ 6. 29. 14.  8. 16.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6. 29. 14.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.  8. 16.] 
expected returns: [[14.036278]
 [15.627892]
 [12.475365]
 [14.854621]
 [13.137021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 14.  8. 16.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8394404649734497
desired expected reward: 27.163206100463867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.692508]
 [10.470739]
 [14.076328]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 14.  8. 16.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43725723028182983
desired expected reward: 13.599020957946777



buy possibilites: [-1] 
expected returns: [[15.920778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 14.  8. 16.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.36360710859298706
desired expected reward: 12.328902244567871






Player: 1 
cards in hand: [10. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.  8.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  8.  8. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0. 11. 10.  0.  3.  3.  4. 15.  1.  3.  3. 22.  0.  3. 11. 16.  1.  1.
 11.  3.  0.  0.  8.  1. 11.  0.  0.  0. 14. 29. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
adversary owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.194118]
 [28.172684]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 11  1 16 14  0  8  3 29  8  8  3  8  0 11  3  0 16  0  6  8 10  3
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10. 11. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0] -> size -> 40 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.335920125246048
desired expected reward: 15.584857940673828



action possibilites: [-1] 
expected returns: [[25.088142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10. 11. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.04634679853916168
desired expected reward: 22.282302856445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.589413]
 [20.892872]
 [25.149084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16. 11.  3. 11.  6.  8.  3. 29.  1.  8.  6. 10.  8.  0.  3.  0.  6.
 29. 14.  8. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [10. 11. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05486331880092621
desired expected reward: 25.033279418945312






Player: 1 
cards in hand: [10. 11. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 11.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 21. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 11.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 21. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 11.] 
cards in discard: [3. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 21. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [16.  0.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[10.238529]
 [ 9.525972]
 [11.549658]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 21. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16. 14.  0.  4.  0.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7925386428833008
desired expected reward: 24.356548309326172



action possibilites: [-1. 16. 16.] 
expected returns: [[14.511595]
 [13.696541]
 [13.696541]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  1 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 21. 29.  8.  7.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16. 14.  0.  4.  0.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.25131767988204956
desired expected reward: 11.800975799560547



action possibilites: [-1] 
expected returns: [[16.562023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 21. 29.  8.  6.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16. 14.  0.  4.  0.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -265 

action type: gain_card_n - action 4
Learning step: -8.146544456481934
desired expected reward: 4.201647758483887





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.375156]
 [16.056662]
 [13.216215]
 [17.69032 ]
 [16.800907]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 21. 29.  8.  6.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16. 14.  0.  4.  0.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7232428789138794
desired expected reward: 17.285266876220703



buy possibilites: [-1] 
expected returns: [[16.442862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [16. 14.  0.  4.  0.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 3.0
Learning step: 0.9809502363204956
desired expected reward: 17.03761100769043






Player: 1 
cards in hand: [16. 14.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  0.  4.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  4  1  8  1 29 10  0  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8. 10.  4.  9.  9.] 
adversary cards in hand: [11.  8.  3.  8. 11.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
adversary owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  8.  3.  8. 11.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
adversary owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  8.  3.  8. 11.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
adversary owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  8.  3.  8. 11.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
adversary owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11.  8.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 11.] 
expected returns: [[14.7211895]
 [16.175335 ]
 [15.49784  ]
 [15.49784  ]
 [16.175335 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  8. 11.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 16 14  8  3 29  8  8  3  8 11  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0] -> size -> 43 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4781641960144043
desired expected reward: 15.964696884155273



action possibilites: [-1] 
expected returns: [[12.183227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0] -> size -> 43 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.054240185767412186
desired expected reward: 17.51036262512207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.32139 ]
 [ 9.675913]
 [12.297214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0] -> size -> 43 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20355196297168732
desired expected reward: 12.386778831481934






Player: 1 
cards in hand: [ 3.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 29.  8.  6.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
adversary owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 20. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
adversary owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 20. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
adversary owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  8.  3.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
adversary owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
expected returns: [[17.18111 ]
 [18.124916]
 [17.000898]
 [18.124916]
 [18.124916]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8.  3.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14  3 29  8  8  3  8  3 16  0  6  8 10  3  6  6  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3320786952972412
desired expected reward: 11.965133666992188



action possibilites: [-1] 
expected returns: [[11.814473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.015306243672966957
desired expected reward: 19.629968643188477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.911453]
 [ 9.175593]
 [11.956843]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  5.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.21039804816246033
desired expected reward: 12.024870872497559



buy possibilites: [-1] 
expected returns: [[11.291568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.706706047058105
desired expected reward: 0.4688873291015625






Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  6.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  6.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  6.] 
adversary cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.021595]
 [18.58596 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3.  6.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 11.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3001647889614105
desired expected reward: 10.991402626037598



action possibilites: [-1.] 
expected returns: [[18.819658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 11.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.09002751857042313
desired expected reward: 18.675989151000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.67144  ]
 [18.268244 ]
 [15.5762615]
 [19.690006 ]
 [18.900154 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  2.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 11.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.07813750952482224
desired expected reward: 18.897796630859375



buy possibilites: [-1] 
expected returns: [[20.545218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [ 6.  3. 29. 16.  0.  3. 16.  8.  3.  6.  8.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  1. 11.  0. 11.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.31502455472946167
desired expected reward: 20.005033493041992






Player: 1 
cards in hand: [ 0.  1. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0. 11.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  1.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  6. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[7.783427 ]
 [8.873334 ]
 [6.8089433]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 29. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.682018518447876
desired expected reward: 19.86319923400879



action possibilites: [-1. 14.] 
expected returns: [[11.194581]
 [ 9.946727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.3546931743621826
desired expected reward: 7.274991989135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.151658]
 [ 8.303163]
 [11.260051]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8] -> size -> 20 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  4.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.22101032733917236
desired expected reward: 11.4155912399292



buy possibilites: [-1] 
expected returns: [[11.897503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.] 
cards in discard: [0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 10. 15.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.67417049407959
desired expected reward: -0.37100887298583984






Player: 1 
cards in hand: [ 8.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10. 15.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0 11 10  3 10  0  8  1 11 11  0 11 11 22 14
  3 16  0 15 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  8. 16. 29.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  8. 16. 29.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  8. 16. 29.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.] 
adversary owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  8. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16. 29.] 
expected returns: [[ 9.660646]
 [10.278777]
 [10.278777]
 [ 9.024895]
 [10.857177]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  8. 16. 29.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11. 10. 11.  1. 22.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3999565541744232
desired expected reward: 11.497546195983887



action possibilites: [-1.  8. 16.] 
expected returns: [[ 9.4720745]
 [10.220098 ]
 [ 8.740617 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 16.  3.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 16 14 29  8  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11. 10. 11.  1. 22.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.2544586658477783
desired expected reward: 10.14163589477539



action possibilites: [-1] 
expected returns: [[11.306445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 10. 11.  1. 22.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 9
Learning step: 1.3364415168762207
desired expected reward: 11.745647430419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.33002 ]
 [ 8.398676]
 [11.488532]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 10. 11.  1. 22.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.819540798664093
desired expected reward: 12.125986099243164



buy possibilites: [-1] 
expected returns: [[10.705283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 10. 11.  1. 22.] 
adversary cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.8525048494338989
desired expected reward: 11.182524681091309






Player: 1 
cards in hand: [11. 10. 11.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1. 22.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 6. 6. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0. 29. 16.  6.  3.] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1.  3.  0.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 6. 6. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0. 29. 16.  6.  3.] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  1.  3.  0.  0.] 
cards in discard: [ 3.  0. 11. 10. 29.  0. 11. 23.  0. 16. 14.  0.  0.  6.  3. 11.  3.  0.
  0.  3.  0.  0.  3.  0.  3.  8. 11. 11.  0.  1.  0. 11.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 6. 6. 6. 8.] 
adversary cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0. 29. 16.  6.  3.] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[12.945117]
 [13.759208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 8.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0. 29. 16.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 6. 0. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3301059901714325
desired expected reward: 10.375177383422852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.737687]
 [ 9.592378]
 [12.996381]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 8.] 
cards in discard: [ 0.  6. 29.  3.  6. 14.  3.  8. 15.  0. 29. 16.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 6. 0. 1. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4149470627307892
desired expected reward: 12.530169486999512



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 6. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  1.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 1.] 
cards in discard: [8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [16.  0.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
expected returns: [[ 9.95605 ]
 [ 9.333445]
 [10.589761]
 [ 9.333445]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 14 29  3  8  3 16  0  6  8  3  6  6  0  6  3  6  8  6 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  3. 11.  0. 23.] 
adversary cards in discard: [8. 0. 6. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.43530622124671936
desired expected reward: 12.561074256896973



action possibilites: [-1] 
expected returns: [[11.018039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 14 29  3  8  3 16  6  8  3  6  6  6  3  6  8  6 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  3. 11.  0. 23.] 
adversary cards in discard: [8. 0. 6. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.2518521547317505
desired expected reward: 10.713093757629395





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.182698]
 [ 8.480306]
 [11.198041]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 14 29  3  8  3 16  6  8  3  6  6  6  3  6  8  6 15  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  3. 11.  0. 23.] 
adversary cards in discard: [8. 0. 6. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22658565640449524
desired expected reward: 11.244624137878418






Player: 1 
cards in hand: [11.  3. 11.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0. 23.] 
cards in discard: [8. 0. 6. 0. 1. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3.  8. 15. 29.] 
adversary cards in discard: [ 8. 16.] 
adversary owned cards: [29 14 29  3  8  3 16  6  8  3  6  6  6  3  6  8  6 15  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  0. 23.] 
cards in discard: [8. 0. 6. 0. 1. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3.  8. 15. 29.] 
adversary cards in discard: [ 8. 16.] 
adversary owned cards: [29 14 29  3  8  3 16  6  8  3  6  6  6  3  6  8  6 15  0] -> size -> 19 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
expected returns: [[7.0495434]
 [7.604614 ]
 [7.1390247]
 [8.106137 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 15. 29.] 
cards in discard: [ 8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29 14 29  3  8  3 16  6  8  3  6  6  6  3  6  8  6 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.40612977743148804
desired expected reward: 10.791912078857422



action possibilites: [-1] 
expected returns: [[8.836246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.3136613965034485
desired expected reward: 7.950966835021973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.017338]
 [6.545151]
 [8.922694]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  3.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26940882205963135
desired expected reward: 9.1056547164917



buy possibilites: [-1] 
expected returns: [[9.358544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.648089408874512
desired expected reward: -2.102938652038574






Player: 1 
cards in hand: [ 0.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 11.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0 11  3 10  0  8  1 11 11  0 11 11 22 14  3 16
  0 11  3  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  3.  6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 29.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[10.771091]
 [11.402101]
 [11.975223]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3.  6.] 
cards in discard: [ 8. 16.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0] -> size -> 43 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.30999279022216797
desired expected reward: 9.048551559448242



action possibilites: [-1.] 
expected returns: [[12.527771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 8. 16.  6.  8.  3.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0] -> size -> 43 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.30660316348075867
desired expected reward: 9.471217155456543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.494909]
 [12.002044]
 [ 9.830921]
 [12.515263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 8. 16.  6.  8.  3.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 11. 10.  1.  3.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0] -> size -> 43 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.19671952724456787
desired expected reward: 12.72449016571045






Player: 1 
cards in hand: [22. 11. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 11. 10.  1.  3.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  8.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.  8.  3. 29.  0.  6.  6.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  1.  3.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.  8.  3. 29.  0.  6.  6.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  1.  3.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [6. 6. 6. 3. 6.] 
adversary cards in discard: [ 8. 16.  6.  8.  3.  8.  3. 29.  0.  6.  6.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.455048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 6.] 
cards in discard: [ 8. 16.  6.  8.  3.  8.  3. 29.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.41567981243133545
desired expected reward: 12.099580764770508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.48506  ]
 [ 7.8303947]
 [10.505793 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 6.] 
cards in discard: [ 8. 16.  6.  8.  3.  8.  3. 29.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.36368975043296814
desired expected reward: 10.091358184814453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 29.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 29.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 29.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 6. 29.  0.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[6.330494 ]
 [7.3183765]
 [5.4114375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  6. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15] -> size -> 45 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39643633365631104
desired expected reward: 10.109355926513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.604696]
 [4.197466]
 [6.414785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  6. 14.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15] -> size -> 45 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2810363173484802
desired expected reward: 6.049457550048828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  3.  6.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6. 14.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 19. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  3.  6.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6. 14.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3.  3.  6.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6. 14.] 
adversary owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[7.3585596]
 [7.9395037]
 [6.822402 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  8. 16.] 
cards in discard: [ 6. 29.  0.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  8  3 16  6  8  3  6  6  6  3  6  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  8.  9.  4.  9.  6.] 
adversary cards in hand: [11. 11. 11. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3] -> size -> 46 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.26383325457572937
desired expected reward: 6.150951385498047



action possibilites: [-1] 
expected returns: [[8.828779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6. 29.  0.  6. 14. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  6.] 
adversary cards in hand: [11. 11. 11. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3] -> size -> 46 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 6
Learning step: 0.9366012215614319
desired expected reward: 3.8066325187683105





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.142502 ]
 [6.6828976]
 [9.016595 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [ 6. 29.  0.  6. 14. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  6.] 
adversary cards in hand: [11. 11. 11. 14.  1.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3] -> size -> 46 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.27082905173301697
desired expected reward: 9.099608421325684






Player: 1 
cards in hand: [11. 11. 11. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  6.] 
adversary cards in hand: [3. 6. 8. 8. 6.] 
adversary cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
adversary owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [3. 6. 8. 8. 6.] 
adversary cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
adversary owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 18. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [3. 6. 8. 8. 6.] 
adversary cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
adversary owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.  1.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [3. 6. 8. 8. 6.] 
adversary cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
adversary owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [3. 6. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[8.313899]
 [8.980732]
 [8.980732]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 8. 6.] 
cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  3 16  6  8  3  6  6  6  3  6  8  6  0  6 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.32806727290153503
desired expected reward: 8.688528060913086



action possibilites: [-1] 
expected returns: [[9.346489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.34749507904052734
desired expected reward: 7.035595417022705





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.595575]
 [7.125316]
 [9.566961]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 6. 29.  0.  6. 14. 14. 16.  3.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2605019211769104
desired expected reward: 9.606990814208984






Player: 1 
cards in hand: [10.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [0. 3. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 17. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [0. 3. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [ 8.  0.  6.  0.  1.  1. 11.  3. 11.  0. 23.  0.  8.  0. 15. 11. 22. 10.
  1.  3.  0.  0. 15. 29.  0.  0.  0.  3.  8.  3.  0.  3.  0. 15.  3. 11.
 11. 11. 14.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [0. 3. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[9.023908]
 [9.700769]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14 29  3 16  8  3  6  6  3  6  8  6  0  6 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [11.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.33242207765579224
desired expected reward: 9.048822402954102



action possibilites: [-1] 
expected returns: [[8.511661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [11.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.21042165160179138
desired expected reward: 11.175446510314941





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.6226177]
 [6.1026917]
 [8.621361 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [11.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2753257155418396
desired expected reward: 8.786986351013184



buy possibilites: [-1] 
expected returns: [[7.9815416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [11.  1.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.3051276206970215
desired expected reward: 7.927745342254639






Player: 1 
cards in hand: [11.  1.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11 11  0 11 11 22 14  3 16  0 11  3
  0 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  9.  4.  9.  5.] 
adversary cards in hand: [ 3. 16.  6.  8. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [23.] 
cards in deck: 44 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 3. 16.  6.  8. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [23.] 
cards in deck: 44 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 3. 16.  6.  8. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  6.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 29.] 
expected returns: [[6.9949627]
 [6.3839235]
 [7.644747 ]
 [8.210796 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  8. 29.] 
cards in discard: [0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.31081125140190125
desired expected reward: 7.6707305908203125



action possibilites: [-1. 16.] 
expected returns: [[9.694145 ]
 [8.9044895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.33083999156951904
desired expected reward: 7.585238456726074





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.540583]
 [6.51112 ]
 [9.781343]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.] 
cards in discard: [0. 8. 0. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.24924899637699127
desired expected reward: 9.943394660949707






Player: 1 
cards in hand: [ 3. 11.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  0.] 
cards in discard: [23. 16.  1.  3.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [16. 14.  6.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  0.  0.] 
cards in discard: [23. 16.  1.  3.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 24. 30. 16. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [16. 14.  6.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  0.  0.] 
cards in discard: [23. 16.  1.  3.  0.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 15. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [16. 14.  6.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [16. 14.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 14.] 
expected returns: [[8.886449 ]
 [8.36516  ]
 [7.9610624]
 [7.9610624]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  6.  3. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 16  8  3  3  6  8  6  0  6 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 29.  8.  2.  6.  0.  0.  9.  7.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3551138937473297
desired expected reward: 9.426229476928711



action possibilites: [-1] 
expected returns: [[9.548625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 29.  8.  2.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.7262709736824036
desired expected reward: 10.859253883361816





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.880787]
 [7.475065]
 [9.674251]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 15. 29.  8.  2.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.256741464138031
desired expected reward: 9.805366516113281



buy possibilites: [-1] 
expected returns: [[9.189096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.] 
cards in discard: [29.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.677765846252441
desired expected reward: -1.2027010917663574






Player: 1 
cards in hand: [ 8.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  1.  0.] 
cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 6. 29.  0.  8.  8.] 
adversary cards in discard: [29.  6. 16.  6.  3. 14.] 
adversary owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 14 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  1.  0.] 
cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 24. 30. 15. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 6. 29.  0.  8.  8.] 
adversary cards in discard: [29.  6. 16.  6.  3. 14.] 
adversary owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 14 
adversary victory points: -2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  1.  0.] 
cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 14. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [ 6. 29.  0.  8.  8.] 
adversary cards in discard: [29.  6. 16.  6.  3. 14.] 
adversary owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 14 
adversary victory points: -2
player victory points: 10 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[ 9.198867]
 [10.523788]
 [ 9.909119]
 [ 9.909119]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  8.  8.] 
cards in discard: [29.  6. 16.  6.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 14. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [23. 14. 15.  0. 11.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.  3.  8.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3  3] -> size -> 51 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3205370306968689
desired expected reward: 8.868559837341309



action possibilites: [-1] 
expected returns: [[8.595799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [29.  6. 16.  6.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 14. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [23. 14. 15.  0. 11.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.  3.  8.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3  3] -> size -> 51 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.25130563974380493
desired expected reward: 9.882980346679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.973368]
 [6.489363]
 [8.826972]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8.] 
cards in discard: [29.  6. 16.  6.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  3  6  8  6  0  6 14  0 29  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 24. 30. 14. 29.  8.  1.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [23. 14. 15.  0. 11.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.  3.  8.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3  3] -> size -> 51 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2758738100528717
desired expected reward: 8.871673583984375



Player 1 won the game! 



Player 0 bought cards:
Copper: 7 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 2 
Workshop: 2 
Chapel: 6 
Witch: 1 
Poacher: 2 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 8.] 
cards in discard: [29.  6. 16.  6.  3. 14.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  3  6  8  6  0  6 14  0 29  6  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 14. 29.  8.  0.  6.  0.  0.  9.  6.  7.  8.  4.  9.  5.] 
adversary cards in hand: [23. 14. 15.  0. 11.] 
adversary cards in discard: [23. 16.  1.  3.  0.  3.  3. 11.  1.  0.  0.  3.  8.  0. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3 10  0  8  1 11  0 11 11 22 14  3 16  0 11  3  0
 11  0  1  8  1 29 10  0  3  0 23  0  6  3  0 11  8  0 15 15  3 15  3  3
 23  3  3] -> size -> 51 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -785 

action type: buy - action 6.0
Learning step: -23.744680404663086
desired expected reward: -17.25531768798828



