 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[324.5254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -652 

action type: buy - action -1.0
Learning step: -43.80289840698242
desired expected reward: 180.2550048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.53796]
 [309.5266 ]
 [308.55383]
 [294.21887]
 [317.51788]
 [310.70294]
 [309.7301 ]
 [324.98038]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.367554664611816
desired expected reward: 316.5717468261719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[351.81433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.857024192810059
desired expected reward: 316.123291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[323.28738]
 [331.20377]
 [330.21667]
 [316.17865]
 [328.82605]
 [340.45337]
 [332.45975]
 [341.6137 ]
 [325.39188]
 [331.47263]
 [334.05286]
 [349.49945]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.81674861907959
desired expected reward: 344.3829040527344



buy possibilites: [-1] 
expected returns: [[337.1701]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 1.0
Learning step: -9.348859786987305
desired expected reward: 321.8548889160156






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.16632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.369197845458984
desired expected reward: 326.8009033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[297.7749 ]
 [305.55096]
 [304.58984]
 [292.6734 ]
 [290.64227]
 [303.34955]
 [313.8705 ]
 [306.68988]
 [320.772  ]
 [314.96622]
 [299.92297]
 [304.7244 ]
 [305.72876]
 [296.58264]
 [308.06476]
 [322.00302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.41225814819336
desired expected reward: 305.6680603027344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.01953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.081949234008789
desired expected reward: 312.9211120605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[315.6943 ]
 [323.3405 ]
 [308.03854]
 [325.4769 ]
 [343.26193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.175227165222168
desired expected reward: 328.41162109375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.79327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -11.387406349182129
desired expected reward: 331.8745422363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[285.8594 ]
 [293.8417 ]
 [292.88455]
 [280.62897]
 [278.55432]
 [291.58734]
 [302.421  ]
 [295.0085 ]
 [309.4933 ]
 [303.53265]
 [288.09073]
 [293.03912]
 [294.0514 ]
 [284.66953]
 [296.46033]
 [310.82077]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.69839859008789
desired expected reward: 295.887939453125



buy possibilites: [-1] 
expected returns: [[298.37762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -17.5 

action type: buy - action 11.0
Learning step: -9.282553672790527
desired expected reward: 293.138427734375






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.02094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.266374588012695
desired expected reward: 289.1112365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[277.11517]
 [285.76987]
 [284.74805]
 [269.20175]
 [295.0931 ]
 [287.02737]
 [286.00555]
 [304.31937]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.59201717376709
desired expected reward: 290.5194091796875



buy possibilites: [-1] 
expected returns: [[304.34827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -4 

action type: buy - action 11.0
Learning step: -8.106820106506348
desired expected reward: 286.9862976074219






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[275.82373]
 [267.61584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.630179405212402
desired expected reward: 293.71807861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[246.98305]
 [253.44414]
 [252.54758]
 [242.72556]
 [241.00652]
 [251.59746]
 [260.65323]
 [254.39937]
 [266.9741 ]
 [261.68515]
 [248.68213]
 [252.6007 ]
 [253.50282]
 [245.88028]
 [255.40254]
 [267.94678]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -9.75355052947998
desired expected reward: 268.58575439453125



buy possibilites: [-1] 
expected returns: [[262.1475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -30.0 

action type: buy - action 8.0
Learning step: -7.328591346740723
desired expected reward: 227.2095947265625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[252.37762]
 [248.1322 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [ 8. 11.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.058863639831543
desired expected reward: 253.088623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[242.28831]
 [245.94385]
 [238.03882]
 [247.42949]
 [255.84877]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [ 8. 11.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -8.670344352722168
desired expected reward: 244.2164306640625



buy possibilites: [-1] 
expected returns: [[284.55557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [ 8. 11.  0.  0.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -8.811915397644043
desired expected reward: 233.47637939453125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  7.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  8.  0. 14.  0.  3.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  6.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.47586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  6.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.478854179382324
desired expected reward: 274.07672119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[216.0045 ]
 [222.80246]
 [221.92134]
 [209.71451]
 [220.87155]
 [230.57185]
 [223.79234]
 [231.62407]
 [217.81795]
 [222.91122]
 [225.02307]
 [238.31003]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  6.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -8.39759349822998
desired expected reward: 229.3323974609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  6.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  6.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  3.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 8. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[238.53447]
 [226.2391 ]
 [232.02055]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3.  3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 11  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11 11] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -8.228387832641602
desired expected reward: 230.0815887451172



action possibilites: [-1] 
expected returns: [[274.30264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11 11] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 9
Learning step: -8.644428253173828
desired expected reward: 253.68031311035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[252.59294]
 [246.6521 ]
 [273.4687 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11 11] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -9.554162979125977
desired expected reward: 264.74847412109375






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3 11  1  3 14  3  8 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  3.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[294.46826]
 [285.50223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  3.  1.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -8.855076789855957
desired expected reward: 264.61358642578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[276.48276]
 [284.19766]
 [283.255  ]
 [271.4198 ]
 [269.36755]
 [282.0117 ]
 [292.48364]
 [285.31372]
 [299.54843]
 [293.57816]
 [278.59622]
 [283.40674]
 [284.37106]
 [275.2942 ]
 [286.70883]
 [300.9259 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [ 0.  0.  0.  3.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  5.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  3.  1.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.902667045593262
desired expected reward: 283.4158935546875



buy possibilites: [-1] 
expected returns: [[231.20256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [ 0.  0.  0.  3.  0.  8. 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  4.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  3.  1.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -29.5 

action type: buy - action 11.0
Learning step: -10.897126197814941
desired expected reward: 281.5865478515625






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  1.] 
cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  4.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  4.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  4.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [11.  0.  3.  0.  0.  3.  0.  8.  3.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[223.91666]
 [217.08595]
 [217.08595]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.272865295410156
desired expected reward: 222.9296875



action possibilites: [-1] 
expected returns: [[246.65187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -5 

action type: gain_card_n - action 9
Learning step: -5.385951995849609
desired expected reward: 213.91253662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[231.09023]
 [236.43706]
 [235.61606]
 [226.07619]
 [234.9012 ]
 [241.94681]
 [237.22797]
 [242.77171]
 [232.40694]
 [236.40697]
 [237.94678]
 [247.27505]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -7.6636505126953125
desired expected reward: 238.98822021484375



buy possibilites: [-1] 
expected returns: [[241.78763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.] 
cards in discard: [10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -12.0 

action type: buy - action 8.0
Learning step: -7.021176815032959
desired expected reward: 230.206787109375






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8] -> size -> 15 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[243.35226]
 [234.05946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0.  0.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.469766616821289
desired expected reward: 233.31785583496094



action possibilites: [-1] 
expected returns: [[205.9976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  0.  1. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -5 

action type: gain_card_n - action 1
Learning step: -6.712889194488525
desired expected reward: 215.2438201904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[182.80446]
 [189.86932]
 [189.12263]
 [176.36612]
 [187.90312]
 [197.58891]
 [190.86815]
 [198.54785]
 [184.8324 ]
 [190.12143]
 [192.29988]
 [205.2585 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  0.  1. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -6.653353214263916
desired expected reward: 199.34425354003906



buy possibilites: [-1] 
expected returns: [[137.11728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.  0.  1. 11.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 18 

action type: buy - action 29.0
Learning step: -5.942253112792969
desired expected reward: 192.6055908203125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [14.  0.  0. 14.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [14.  0.  0. 14.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29] -> size -> 17 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.20068]
 [205.23933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3.  1. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.8242719173431396
desired expected reward: 133.2930145263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[203.75337]
 [208.2661 ]
 [207.66977]
 [199.56854]
 [206.98222]
 [213.33391]
 [208.91733]
 [214.04234]
 [204.94977]
 [208.321  ]
 [209.73033]
 [218.40276]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  3.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3.  1. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.70697021484375
desired expected reward: 207.13424682617188



buy possibilites: [-1] 
expected returns: [[190.46439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  2.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  3.  1. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -29.5 

action type: buy - action 11.0
Learning step: -7.856246471405029
desired expected reward: 205.47764587402344






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  1. 11.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  2.  6. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 1.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  0. 29. 10.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [11.  0.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[195.91754]
 [189.77733]
 [190.49985]
 [183.99435]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 10.] 
cards in discard: [11.  1.  0.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -7.465485572814941
desired expected reward: 182.9989013671875



action possibilites: [-1] 
expected returns: [[152.47679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -8 

action type: gain_card_n - action 10
Learning step: -6.086742877960205
desired expected reward: 176.26266479492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.90811]
 [142.23914]
 [133.96121]
 [143.42442]
 [153.61356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 10.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 11.] 
adversary cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -5.5766921043396
desired expected reward: 146.9001007080078






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 11.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 11.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 25. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 11.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [14.  0.  0. 14.  0.  0.  3.  8. 11.  0.  0.  8.  3. 11.  8.  3.  3.  1.
  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 11.] 
adversary cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  8.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[160.3935 ]
 [151.20879]
 [155.4952 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  0. 11.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1 11 11  8  0 11 10  8  1 29 11 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -7.402388095855713
desired expected reward: 146.21115112304688



action possibilites: [-1] 
expected returns: [[105.723495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 7
Learning step: -6.761170864105225
desired expected reward: 132.03782653808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 88.75709 ]
 [ 93.218445]
 [ 92.78962 ]
 [ 84.70713 ]
 [ 98.15292 ]
 [ 93.84321 ]
 [ 93.4144  ]
 [103.44881 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -5.340599060058594
desired expected reward: 100.38289642333984



buy possibilites: [-1] 
expected returns: [[142.63632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  1.  0.  8.  0.  3. 15. 11.  0.  0. 29. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  8.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -4.928536891937256
desired expected reward: 83.82854461669922






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0] -> size -> 18 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0] -> size -> 18 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0] -> size -> 18 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[159.67293]
 [154.70033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 11.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: discard_down_to_3_cards - action 4
Learning step: -8.23743724822998
desired expected reward: 162.2271728515625



action possibilites: [-1] 
expected returns: [[117.56021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 11.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -35 

action type: gain_card_n - action 9
Learning step: -6.753087043762207
desired expected reward: 146.2107391357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[104.554405]
 [108.778885]
 [108.14796 ]
 [100.99722 ]
 [113.16555 ]
 [109.3923  ]
 [108.76138 ]
 [117.4692  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 11.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -5.592237949371338
desired expected reward: 111.96797180175781



buy possibilites: [-1] 
expected returns: [[162.03407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 11.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -26 

action type: buy - action 10.0
Learning step: -3.0923030376434326
desired expected reward: 105.6690902709961






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0. 11.  3.] 
cards in discard: [14.  8.  8.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  2.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 15.  0.  3. 10.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [11. 15.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[111.96467]
 [107.32808]
 [104.16758]
 [102.86523]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  3. 10.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -8.920533180236816
desired expected reward: 153.11354064941406



action possibilites: [-1] 
expected returns: [[139.28267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -28 

action type: gain_card_n - action 10
Learning step: -3.322557210922241
desired expected reward: 97.8057861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.55619 ]
 [119.252686]
 [139.1765  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -6.250340461730957
desired expected reward: 133.03233337402344



buy possibilites: [-1] 
expected returns: [[133.30421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -6.878464698791504
desired expected reward: 116.6777114868164






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0. 11. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 24. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0. 11. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  8.] 
adversary cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0. 11. 15.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [29.  1.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[152.19687]
 [148.47136]
 [143.92732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  8.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0. 11. 15.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -7.0142412185668945
desired expected reward: 126.28997039794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[141.73087]
 [145.76813]
 [145.12257]
 [137.93678]
 [144.60524]
 [149.89644]
 [146.35966]
 [150.55133]
 [142.69612]
 [145.71411]
 [146.87845]
 [154.27933]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  8.] 
cards in discard: [ 8.  0. 10. 10. 11.  1.  0. 15.  0. 11. 15.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3] -> size -> 28 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -7.991377353668213
desired expected reward: 144.20550537109375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  1.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[114.85902]
 [109.5738 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  3. 14.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -8.308406829833984
desired expected reward: 133.51797485351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 99.60229 ]
 [104.23575 ]
 [103.72933 ]
 [ 95.357025]
 [104.88732 ]
 [104.38091 ]
 [114.53148 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11.  3. 14.  3.] 
adversary cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -6.946293830871582
desired expected reward: 105.58197021484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 14.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0. 10.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.] 
cards in discard: [14.  8.  8.  3.  3.  1. 11. 11.  1.  0. 11.  3.  3. 11.  0.  0.  0.  0.
 11.  3.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[137.81555]
 [129.0108 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: discard_down_to_3_cards - action 6
Learning step: -4.683421611785889
desired expected reward: 74.59156799316406



action possibilites: [-1] 
expected returns: [[71.50962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action 15.0
Learning step: -7.4571709632873535
desired expected reward: 119.8655776977539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.81544 ]
 [62.612133]
 [62.203537]
 [55.34362 ]
 [61.561497]
 [63.148964]
 [67.27118 ]
 [59.88791 ]
 [62.740353]
 [63.899643]
 [71.33605 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  5. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -4.830554962158203
desired expected reward: 66.67906188964844



buy possibilites: [-1] 
expected returns: [[102.63165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -52.0 

action type: buy - action 8.0
Learning step: -3.4482357501983643
desired expected reward: 59.700721740722656






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 15.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 15.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 15.  8.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [29. 15.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8. 10.] 
expected returns: [[69.16288]
 [67.71589]
 [66.15184]
 [65.93249]
 [65.66036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  8.  0. 10.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  1. 11.] 
adversary cards in discard: [3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -7.816539287567139
desired expected reward: 94.81511688232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.25329]
 [62.62897]
 [69.46342]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  8.  0. 10.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  1. 11.] 
adversary cards in discard: [3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -6.168980121612549
desired expected reward: 62.993900299072266



buy possibilites: [-1] 
expected returns: [[72.0178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  8.  0. 10.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  3.  1. 11.] 
adversary cards in discard: [3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -114.0 

action type: buy - action 0.0
Learning step: -7.292263984680176
desired expected reward: 56.96102523803711






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  1. 11.] 
cards in discard: [3. 3. 8. 0. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10. 11.  1. 11.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1. 11.] 
cards in discard: [3. 3. 8. 0. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10. 11.  1. 11.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1. 11.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11.  1. 11.  8.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [10. 11.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.] 
expected returns: [[69.98425]
 [63.76879]
 [66.81841]
 [66.81841]
 [64.06012]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 11.  8.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -6.294116973876953
desired expected reward: 65.72367858886719



action possibilites: [-1. 11. 11.  8.] 
expected returns: [[100.005486]
 [ 96.1777  ]
 [ 96.1777  ]
 [ 92.84301 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  8.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -63 

action type: take_action - action 10.0
Learning step: -4.156378269195557
desired expected reward: 59.61241912841797



action possibilites: [-1. 11.  8.] 
expected returns: [[126.59457]
 [122.9665 ]
 [119.87682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  40   0   0   0   0   0   0   0   4   0] 
sum of rewards: -29 

action type: gain_card_n - action 2
Learning step: -3.079090118408203
desired expected reward: 85.20307922363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[117.52307 ]
 [120.85653 ]
 [120.4846  ]
 [114.460335]
 [121.32308 ]
 [120.95116 ]
 [128.1076  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.  1. 10.  8. 15.  0.  0. 29. 15.  8.  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 21. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.236535549163818
desired expected reward: 121.35802459716797






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  3.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8. 10. 10.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [11.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[39.581062]
 [36.25448 ]
 [33.137287]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16  0] -> size -> 34 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -9.236366271972656
desired expected reward: 118.8712387084961



action possibilites: [-1. 11.] 
expected returns: [[53.29014]
 [50.11049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16  0] -> size -> 34 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 10.0
Learning step: -2.8586173057556152
desired expected reward: 24.710107803344727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.594933]
 [47.16702 ]
 [46.91639 ]
 [42.41157 ]
 [46.460575]
 [47.525448]
 [50.53909 ]
 [45.338867]
 [47.27482 ]
 [48.077076]
 [53.337658]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16  0] -> size -> 34 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -4.226433277130127
desired expected reward: 49.0637092590332






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3
  3  1 11  3 11  0  3 10 16  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0. 15.  0.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0. 15.  0.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0. 15.  0.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [10. 29.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 15.] 
expected returns: [[74.68669 ]
 [70.129555]
 [72.836494]
 [70.76358 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 15.  0.] 
cards in discard: [10. 11.  0.  1.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14.  1.  0. 11. 14.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -4.1838812828063965
desired expected reward: 49.153778076171875



action possibilites: [-1] 
expected returns: [[74.384834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.] 
cards in discard: [10. 11.  0.  1.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14.  1.  0. 11. 14.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 15.0
Learning step: -4.014520168304443
desired expected reward: 66.74905395507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[68.09192 ]
 [70.49033 ]
 [70.10926 ]
 [65.82294 ]
 [69.80425 ]
 [70.83747 ]
 [73.324165]
 [68.65549 ]
 [70.45642 ]
 [71.14233 ]
 [75.33937 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.] 
cards in discard: [10. 11.  0.  1.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14.  1.  0. 11. 14.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -4.26539945602417
desired expected reward: 70.11943817138672






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14.  1.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0. 11. 14.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  1.  8.  3. 10.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 14.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 14.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 14.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[32.366657]
 [28.210266]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: discard_down_to_3_cards - action 3
Learning step: -4.339294910430908
desired expected reward: 33.247962951660156



action possibilites: [-1.  8.] 
expected returns: [[42.771133]
 [36.644436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 10.0
Learning step: -2.6544439792633057
desired expected reward: 25.555818557739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.246696]
 [32.71128 ]
 [43.210434]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -3.4355156421661377
desired expected reward: 39.33561706542969






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 3.  3.  8.  0.  3.  0. 10. 11.  0.  3.  1. 11. 16.  0. 11.  0.  0. 11.
  3.  8.  8.  0.  8. 14.  1.  0. 11. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  0.  0. 15.] 
adversary cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 8.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[67.42014 ]
 [62.110588]
 [62.62226 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 15.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11 15  0 10 10 15  0  8  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -3.8554680347442627
desired expected reward: 39.3549690246582



action possibilites: [-1] 
expected returns: [[90.19145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.2487237453460693
desired expected reward: 59.31190490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[80.501724]
 [83.580574]
 [83.08774 ]
 [77.66991 ]
 [84.07538 ]
 [83.582535]
 [90.65637 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  3. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -4.754817008972168
desired expected reward: 85.43663787841797



buy possibilites: [-1] 
expected returns: [[77.87421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11.  0.  1.  0.  3. 15. 10. 29.  0.  1.  8. 10.  0.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -41.0 

action type: buy - action 8.0
Learning step: -4.501599311828613
desired expected reward: 79.57377624511719






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1
 11  3 11  0  3 10 16  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  1. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 8.  0.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[30.655231]
 [25.22903 ]
 [27.773754]
 [27.773754]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 11  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -5.912367820739746
desired expected reward: 71.96183776855469



action possibilites: [-1] 
expected returns: [[49.33082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.572311282157898
desired expected reward: 19.072782516479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.916622]
 [43.55144 ]
 [49.89248 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -3.0632667541503906
desired expected reward: 46.26755142211914



buy possibilites: [-1] 
expected returns: [[31.789808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  8. 11.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action 0.0
Learning step: -4.68056058883667
desired expected reward: 40.23606491088867






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  8. 11.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  8. 11.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  8. 29.  0.] 
adversary cards in discard: [ 0.  8. 11.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[28.822393]
 [24.22526 ]
 [24.475313]
 [26.495811]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 29.  0.] 
cards in discard: [ 0.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -3.661987781524658
desired expected reward: 28.12782096862793



action possibilites: [-1. 10.] 
expected returns: [[18.827034]
 [11.170212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0.  8. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: discard_n_cards - action 1
Learning step: -2.468384265899658
desired expected reward: 20.964719772338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.2106905]
 [12.056583 ]
 [11.807434 ]
 [ 9.241996 ]
 [11.446335 ]
 [12.3684025]
 [16.01286  ]
 [10.561904 ]
 [12.119252 ]
 [12.790301 ]
 [20.128317 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0.  8. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -2.276538133621216
desired expected reward: 16.550500869750977



buy possibilites: [-1] 
expected returns: [[61.388893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0.  8. 11.  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -28.5 

action type: buy - action 1.0
Learning step: -0.6465792655944824
desired expected reward: 11.41000747680664






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  8. 15.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  8. 15.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  8. 15.  3.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [10.  0.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[48.442017]
 [44.236874]
 [44.53738 ]
 [44.820415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 15.  3.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -4.683383464813232
desired expected reward: 56.705509185791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.358562]
 [40.937588]
 [47.912052]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 15.  3.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -4.070803165435791
desired expected reward: 44.3712158203125



buy possibilites: [-1] 
expected returns: [[40.7665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 15.  3.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -5.350682258605957
desired expected reward: 37.00788879394531






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  2. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[94.54724]
 [90.56563]
 [87.10115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  1.  3. 11.  8.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -2.6309974193573
desired expected reward: 38.135501861572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.55984]
 [88.77349]
 [82.39067]
 [89.53245]
 [96.97854]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8. 10.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  1.  3. 11.  8.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -5.348416328430176
desired expected reward: 89.19882202148438



buy possibilites: [-1] 
expected returns: [[65.08618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [ 0.  8. 11.  8.  1. 29. 10.  0.  0.  0.  0. 10.  0.  8. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 21. 30.  8. 10.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [10.  1.  3. 11.  8.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -6.963552951812744
desired expected reward: 78.59627532958984






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  1.  3. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3. 11.  8.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8. 10.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  8.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  8.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 21. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  8.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 3.  0.  8.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[18.35972 ]
 [14.236057]
 [14.076321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  1. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  8. 14. 11.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6  3] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -5.542701721191406
desired expected reward: 59.543479919433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 8.908965 ]
 [10.272831 ]
 [10.14576  ]
 [ 7.9231343]
 [10.482033 ]
 [10.354837 ]
 [14.389935 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  1. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  0.  8. 14. 11.] 
adversary cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6  3] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -3.318363666534424
desired expected reward: 15.041349411010742



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [11.  0.  8. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 14. 11.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  3 14  3  8 11 11  0  8 11 14  8  3  3  3  1 11  3 11
  0  3 10 16  0  8  0  0  0  8  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  0.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  0.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  0.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 0.  8. 16.  0.  3. 14.  8. 11.  0.  3.  0.  0.  0.  3.  8.  0.  3. 11.
  0.  3.  6.  3. 11. 10.  1.  3.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 11. 15.] 
adversary cards in discard: [ 3.  0.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[40.7563  ]
 [37.988823]
 [36.72742 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11. 15.] 
cards in discard: [ 3.  0.  8.  1. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -2.2831482887268066
desired expected reward: 7.8877129554748535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.475407]
 [36.01133 ]
 [35.835453]
 [33.181625]
 [35.552486]
 [36.243988]
 [38.576984]
 [34.851994]
 [36.068115]
 [36.598396]
 [40.80742 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11. 15.] 
cards in discard: [ 3.  0.  8.  1. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -3.85429310798645
desired expected reward: 36.90201187133789



buy possibilites: [-1] 
expected returns: [[38.34488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11. 15.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -21 

action type: buy - action 14.0
Learning step: -1.9298397302627563
desired expected reward: 32.922149658203125






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  9.  9.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [16.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  8.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 10.] 
expected returns: [[43.324497]
 [39.784115]
 [39.784115]
 [39.545082]
 [39.545082]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 10. 10.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -3.646235704421997
desired expected reward: 34.69864273071289



action possibilites: [-1] 
expected returns: [[43.751778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.5284061431884766
desired expected reward: 34.72801208496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.83445 ]
 [33.784523]
 [43.54902 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -2.964780569076538
desired expected reward: 40.7869987487793



buy possibilites: [-1] 
expected returns: [[31.532595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action 0.0
Learning step: -4.23223876953125
desired expected reward: 31.60220718383789






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  1. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0] -> size -> 25 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[45.34884 ]
 [42.659325]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -3.230987548828125
desired expected reward: 28.301607131958008



action possibilites: [-1] 
expected returns: [[49.66887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -24 

action type: gain_card_n - action 7
Learning step: -1.9923971891403198
desired expected reward: 36.20653533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[44.281387]
 [46.06198 ]
 [45.823475]
 [42.764435]
 [45.498566]
 [48.57008 ]
 [44.70403 ]
 [46.11079 ]
 [46.71868 ]
 [51.282307]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 25. 30. 20. 30.  8.  9.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -3.0733048915863037
desired expected reward: 46.59556579589844



buy possibilites: [-1] 
expected returns: [[50.960426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  8.  1. 10. 14.  0.  0.  1. 11. 15.  0.  8.  8. 10. 10. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -18.191612243652344
desired expected reward: 24.572834014892578






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [10.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-1.8839074]
 [-1.8839074]
 [-1.8839074]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [16.  0.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -5.790409088134766
desired expected reward: 45.17001724243164



action possibilites: [-1.] 
expected returns: [[-1.8852088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [16.  0.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: discard_n_cards - action 2
Learning step: -2.1456501483917236
desired expected reward: -4.029557704925537





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[-1.8852088]
 [-1.8852088]
 [-1.8852088]
 [-1.8852088]
 [-1.8852088]
 [-1.8852088]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 20. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [16.  0.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -2.1481568813323975
desired expected reward: -4.033365726470947



buy possibilites: [-1] 
expected returns: [[10.032871]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [16.  0.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 3.0
Learning step: -1.2300000190734863
desired expected reward: -3.115208864212036






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [16.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0. 14. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0. 14. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3] -> size -> 28 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
expected returns: [[ 0.4744742]
 [-1.4330527]
 [-1.8852088]
 [-1.500379 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 8. 3. 8. 8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -3.1696383953094482
desired expected reward: 6.863232612609863





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-1.8852088 ]
 [-1.4048204 ]
 [-1.8852088 ]
 [ 0.76977444]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 8. 3. 8. 8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -2.690781354904175
desired expected reward: -2.216310501098633



buy possibilites: [-1] 
expected returns: [[57.90439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 8. 3. 8. 8.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -2.7528908252716064
desired expected reward: -4.638099670410156






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 8. 8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  3 14  3  8 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10
 16  0  8  0  0  0  8  6  3  0 16  0  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  3. 10.  0.  1.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  3. 10.  0.  1.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  3. 10.  0.  1.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  3. 10.  0.  1.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [11.  3. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[7.8399324]
 [7.1376104]
 [6.415659 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  1.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 14.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.381844520568848
desired expected reward: 53.522544860839844



action possibilites: [-1. 11.  8.] 
expected returns: [[38.25393]
 [35.33541]
 [32.77279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1.  8.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 14.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -0.16151051223278046
desired expected reward: 6.254149436950684





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[27.87874 ]
 [30.228907]
 [30.024576]
 [25.738861]
 [30.35802 ]
 [35.760826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  1.  8.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 14.  3.] 
adversary cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.8639494180679321
desired expected reward: 36.38998031616211






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 14.  3.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 14 11  0  8 11 14  8  3  3  3  1 11  3 11  0  3 10 16  0  8
  0  0  0  8  6  3  0 16  0  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [16.  0. 11.  3.  0.  3.  1.  8. 14.  0.  3.  0.  3. 10.  0. 11.  0.  3.
 16.  0.  6.  0.  8.  0.  8.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.40696 ]
 [16.603943]
 [14.963554]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.5457637310028076
desired expected reward: 33.21507263183594



action possibilites: [-1] 
expected returns: [[87.51952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 8
Learning step: 1.8645269870758057
desired expected reward: 16.9577693939209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[77.88866 ]
 [80.43144 ]
 [80.17685 ]
 [75.56013 ]
 [79.73762 ]
 [83.70901 ]
 [78.58561 ]
 [80.53372 ]
 [81.296906]
 [86.438934]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -2.6913912296295166
desired expected reward: 84.82813262939453



buy possibilites: [-1] 
expected returns: [[55.690876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 10.0
Learning step: -2.698641538619995
desired expected reward: 77.8350830078125






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15.  6.  8. 10.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15.  6.  8. 10.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15.  6.  8. 10.] 
adversary cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
adversary owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 15.  6.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[61.817764]
 [58.272648]
 [58.225296]
 [57.767494]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  8. 10.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14
  0 10  6  3  0 15 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -2.595031499862671
desired expected reward: 53.09584426879883



action possibilites: [-1] 
expected returns: [[30.633894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 15.0
Learning step: -2.3743696212768555
desired expected reward: 55.89827346801758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[24.325142]
 [26.279877]
 [26.087196]
 [22.539156]
 [26.359676]
 [30.509388]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -1.0777746438980103
desired expected reward: 29.556119918823242



buy possibilites: [-1] 
expected returns: [[15.680882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.] 
cards in discard: [ 8.  0.  3. 29.  0.  3.  0.  0.  8.  0. 14. 10.  0. 10. 11.  3.  0.  1.
  8. 15. 10. 11.  1.  0. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 15 

action type: buy - action 10.0
Learning step: -0.07266874611377716
desired expected reward: 23.437103271484375






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  1.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0
  8  6  3  0 16  0  8  0  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10 10] -> size -> 31 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 1. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[6.865265]
 [5.52539 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0 11 10  8  1 29 11  0 10 10 15  0  8  0  3  8  0  1  0  0 14  0
 10  6  3  0 15 10 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 11.  3.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -1.7918840646743774
desired expected reward: 13.888998031616211



action possibilites: [-1] 
expected returns: [[14.29131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 11.  3.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 11
Learning step: -0.6891694068908691
desired expected reward: 5.525307655334473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 8.612771 ]
 [10.0989485]
 [ 7.0871153]
 [13.921663 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 24. 30. 19. 30.  8.  8.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 11.  3.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -1.1746625900268555
desired expected reward: 13.116647720336914



buy possibilites: [-1] 
expected returns: [[19.429338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 24. 30. 19. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 11.  3.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -16.16719627380371
desired expected reward: -9.080083847045898






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  3.  3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  3. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [6. 8. 1.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 19. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [6. 8. 1.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 24. 30. 19. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [6. 8. 1.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [6. 8. 1.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-1.8875756]
 [-1.8875756]
 [-1.8875756]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [6. 8. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 16.  6.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -3.763937473297119
desired expected reward: 15.665401458740234



action possibilites: [-1. 10. 10.] 
expected returns: [[ 1.9536866]
 [-0.9143731]
 [-0.9143731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [6. 8. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 16.  6.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -1.6467920541763306
desired expected reward: -3.534367561340332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[-1.8239121 ]
 [-0.70744103]
 [-0.8473575 ]
 [-1.8875756 ]
 [-0.6706167 ]
 [ 2.0248642 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [6. 8. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 16.  6.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -1.8513058423995972
desired expected reward: 0.10238337516784668



buy possibilites: [-1] 
expected returns: [[-1.8875756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [ 6.  8.  1. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  8.  8. 16.  6.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -17 

action type: buy - action 10.0
Learning step: -0.8589396476745605
desired expected reward: -1.529556393623352






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 16.  6.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  6  3  0 16  0  8  0  0  1 10  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  7.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 15. 10. 14.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 15. 10. 14.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 15. 10. 14.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 15. 10. 14.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 15. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14.] 
expected returns: [[-1.7034706]
 [-1.8875756]
 [-1.8875756]
 [-1.8875756]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10. 14.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  8.  0. 11.  8.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.696486234664917
desired expected reward: -4.584061622619629



action possibilites: [-1] 
expected returns: [[5.7961016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 14.0
Learning step: -1.5252089500427246
desired expected reward: -3.4127845764160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[2.209474 ]
 [3.190113 ]
 [3.0862346]
 [1.3543679]
 [2.9025164]
 [4.8598466]
 [2.4746113]
 [3.2433658]
 [3.5896292]
 [6.3821015]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  8.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -1.9522966146469116
desired expected reward: 3.8438048362731934



buy possibilites: [-1] 
expected returns: [[-1.8875756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -3 

action type: buy - action 16.0
Learning step: -0.3375963568687439
desired expected reward: 2.5649213790893555






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 11. 10.  0.  3.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10 16] -> size -> 31 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 8. 11. 10.  0.  3.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10 16] -> size -> 31 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[5.8968916]
 [4.7122536]
 [5.276432 ]
 [4.5751963]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.  3.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.5373027324676514
desired expected reward: -4.424878120422363



action possibilites: [-1.  8. 11. 15.] 
expected returns: [[-1.7742224]
 [-1.8923831]
 [-1.8923831]
 [-1.8923831]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3. 15.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11 10  8  1 29 11 10 10 15  0  8  0  3  8  0  1  0  0 14  0 10  6  3
  0 15 10 10  6 10 16] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: -2.0146663188934326
desired expected reward: 2.5605242252349854



action possibilites: [-1. 11.] 
expected returns: [[3.298442]
 [2.566105]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.1378933191299438
desired expected reward: -3.030276298522949



action possibilites: [-1] 
expected returns: [[7.736822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 10 

action type: gain_card_n - action 8
Learning step: 0.5783734917640686
desired expected reward: 2.4924728870391846





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.1555405]
 [4.3931565]
 [7.9199142]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  6.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -0.5471709370613098
desired expected reward: 7.189651012420654



buy possibilites: [-1] 
expected returns: [[0.84099877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0   60    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -317 

action type: buy - action 6.0
Learning step: -16.050735473632812
desired expected reward: -11.657569885253906






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [10.  1.  8. 29.  6.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [10.  1.  8. 29.  6.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [10.  1.  8. 29.  6.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 11. 11.  8.  0. 14.  1. 10.  3. 11.  1.  3.  3.  3.  6.
  0. 16.  0.  8.  8.  8.  8.  0.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [10.  1.  8. 29.  6.] 
adversary cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
adversary owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [10.  1.  8. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[-1.8923831]
 [-1.8923831]
 [-1.8923831]
 [-1.8923831]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8. 29.  6.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11 10  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10
 10  6 10 16 15  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -3.9346282482147217
desired expected reward: -3.0936293601989746



action possibilites: [-1] 
expected returns: [[12.597828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: trash_cards_n_from_hand - action 3
Learning step: -2.4719297885894775
desired expected reward: -4.364313125610352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[12.197308]
 [12.311901]
 [12.027727]
 [12.615053]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -3.202061414718628
desired expected reward: 9.395766258239746



buy possibilites: [-1] 
expected returns: [[-0.8599521]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6.] 
cards in discard: [ 6.  8.  1. 10. 10.  0. 10.  0.  0. 10. 16. 14.  0.  0. 15. 10. 15.  6.
 10.  8. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -4.979214668273926
desired expected reward: 7.218094825744629






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8
  3  0 16  0  8  0  0  1 10  3  6  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  7. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  0.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [ 8.  0.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[-1.8923831]
 [-1.8923831]
 [-1.8923831]
 [-1.8923831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3.  0.  8. 11.] 
adversary cards in discard: [14. 16.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -3.349580764770508
desired expected reward: -4.209532737731934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-1.8923831]
 [-1.8923831]
 [-1.789004 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30. 18. 30.  8.  5.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3.  0.  8. 11.] 
adversary cards in discard: [14. 16.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -3.2968997955322266
desired expected reward: -5.1892828941345215



buy possibilites: [-1] 
expected returns: [[-1.8923831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  8. 11.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30. 18. 30.  8.  4.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [ 8.  3.  0.  8. 11.] 
adversary cards in discard: [14. 16.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -18.847959518432617
desired expected reward: -20.74034309387207






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  8. 11.] 
cards in discard: [14. 16.  3.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 30.  8.  4.  7.  0.  0. 10.  9.  6. 10.  1. 10.  6.] 
adversary cards in hand: [10. 10.  6. 10. 15.] 
adversary cards in discard: [ 6.  8.  0.  3.  8. 11.] 
adversary owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0  6] -> size -> 31 
adversary victory points: -3
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 4 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 10.  6. 10. 15.] 
cards in discard: [ 6.  8.  0.  3.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  8  1 29 11 10 10  8  0  8  0  1  0  0 14  0 10  6  3  0 15 10 10
  6 10 16 15  6  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 30.  8.  4.  7.  0.  0. 10.  9.  6. 10.  0. 10.  6.] 
adversary cards in hand: [8. 3. 0. 8.] 
adversary cards in discard: [14. 16.  3.  0.  0. 10.] 
adversary owned cards: [ 0  1 11  0  8 11 14  8  3  1 11  3 11  0  3 10 16  0  8  0  0  0  8  3
  0 16  0  8  0  0  1 10  3  6  0  0 14 10] -> size -> 38 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5 -500   -3  -70    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -578 

action type: buy - action -1
Learning step: -28.80537986755371
desired expected reward: -30.697763442993164



