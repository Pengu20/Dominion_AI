 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.33889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       20        0
        0        0        0     -190        0        0        0        0] 
sum of rewards: -3000235 

action type: gain_card_n - action 0
Learning step: -120009.3984375
desired expected reward: -120009.515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[86.443886]
 [86.443886]
 [86.446205]
 [86.446655]
 [86.454704]
 [86.446075]
 [86.44985 ]
 [86.45536 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.76809692382812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.518524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.45536041259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[88.46278]
 [88.46278]
 [88.4651 ]
 [88.46555]
 [88.46278]
 [88.47359]
 [88.46498]
 [88.47309]
 [88.47493]
 [88.46875]
 [88.47929]
 [88.47425]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.3968276977539



buy possibilites: [-1] 
expected returns: [[93.152054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [4. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 33 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 88.47927856445312






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [4. 0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.26819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.15205383300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[92.4028 ]
 [92.40281]
 [92.40511]
 [92.40557]
 [92.4028 ]
 [92.41361]
 [92.40499]
 [92.41311]
 [92.41494]
 [92.40877]
 [92.41931]
 [92.41428]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.8814468383789



buy possibilites: [-1] 
expected returns: [[92.45056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 4. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 3 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 92.41930389404297






Player: 1 
cards in hand: [0. 4. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[91.721725]
 [91.726746]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 4. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.4505615234375



action possibilites: [-1] 
expected returns: [[92.59223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 4. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 89.07754516601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[95.27651]
 [95.27652]
 [95.27882]
 [95.27928]
 [95.27651]
 [95.28733]
 [95.2787 ]
 [95.28682]
 [95.28866]
 [95.28247]
 [95.29301]
 [95.28799]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 4. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.59223175048828



buy possibilites: [-1] 
expected returns: [[106.16562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [15.  0.  3.  0.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [0. 0. 4. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 23 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 95.29301452636719






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 0. 4. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [0. 0. 4. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[97.11516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.16561889648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[98.32697]
 [98.32697]
 [98.32929]
 [98.32975]
 [98.33778]
 [98.32917]
 [98.33295]
 [98.33845]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.2464599609375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 15. 15.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 15. 15.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[101.134735]
 [101.139755]
 [101.139755]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15. 15.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.33845520019531



action possibilites: [-1] 
expected returns: [[94.25422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 98.6016616821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[97.0809  ]
 [97.0809  ]
 [97.08323 ]
 [97.08148 ]
 [97.08367 ]
 [97.0809  ]
 [97.091736]
 [97.0831  ]
 [97.08555 ]
 [97.091225]
 [97.093056]
 [97.08675 ]
 [97.086876]
 [97.08364 ]
 [97.09742 ]
 [97.09239 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.25421905517578



buy possibilites: [-1] 
expected returns: [[95.59169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0.  0.  3.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -73.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 97.097412109375






Player: 1 
cards in hand: [3. 0. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [3. 0. 3. 0. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[99.363785]
 [99.368805]
 [99.368805]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.59169006347656



action possibilites: [-1] 
expected returns: [[95.60855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 15 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 97.24710083007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[97.305336]
 [97.30534 ]
 [97.307655]
 [97.30811 ]
 [97.305336]
 [97.316154]
 [97.30754 ]
 [97.31567 ]
 [97.3175  ]
 [97.31131 ]
 [97.32184 ]
 [97.31681 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 15 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.60855102539062



buy possibilites: [-1] 
expected returns: [[109.898056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 15 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 23 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 97.32183837890625






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [15. 15.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 4 3 0 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [15. 15.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [15. 15.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[93.316956]
 [93.321976]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [15. 15.  0. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 15 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.89805603027344



action possibilites: [-1] 
expected returns: [[86.612335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [15. 15.  0. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 90.75408935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[89.69275 ]
 [89.692764]
 [89.69507 ]
 [89.69332 ]
 [89.695526]
 [89.69275 ]
 [89.703575]
 [89.69495 ]
 [89.69739 ]
 [89.70307 ]
 [89.704895]
 [89.69859 ]
 [89.69872 ]
 [89.69548 ]
 [89.70926 ]
 [89.70424 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15. 15.  0. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  5.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.61233520507812



buy possibilites: [-1] 
expected returns: [[94.374565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15. 15.  0. 15.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 15 15 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  4.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -73.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 89.70925903320312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  4.] 
adversary cards in hand: [ 0.  0.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[92.27942]
 [92.28444]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 15 15 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  4.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.37456512451172



action possibilites: [-1] 
expected returns: [[91.747314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  4.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 89.82096099853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[93.61824]
 [93.61825]
 [93.62056]
 [93.621  ]
 [93.61824]
 [93.62905]
 [93.62042]
 [93.62854]
 [93.63039]
 [93.62421]
 [93.63473]
 [93.62971]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  4.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.747314453125



buy possibilites: [-1] 
expected returns: [[104.323746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  3.] 
adversary cards in hand: [0. 1. 0. 3. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 23 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 93.63473510742188






Player: 1 
cards in hand: [0. 1. 0. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 4.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [15.  3. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[96.72884]
 [96.73387]
 [96.73387]
 [96.73387]
 [96.73387]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 15. 15.] 
cards in discard: [15. 15.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.32374572753906



action possibilites: [-1] 
expected returns: [[90.02713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [15. 15.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 94.31226348876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[92.04304]
 [92.04581]
 [92.05452]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [15. 15.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.02713012695312






Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  0.  1.  0.  3.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  3. 15. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  0.  1.  0.  3.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  3. 15. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  0.  1.  0.  3.  4. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  3. 15. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[82.452095]
 [82.45712 ]
 [82.45712 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 15.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 15 15 15 15 15 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.05451965332031



action possibilites: [-1] 
expected returns: [[86.74872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 79.91902160644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[88.948975]
 [88.94898 ]
 [88.951294]
 [88.951744]
 [88.95979 ]
 [88.95117 ]
 [88.95493 ]
 [88.96046 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.74871826171875






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  0.  3.] 
adversary cards in discard: [15.  3.  3. 15.] 
adversary owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  0.  3.] 
adversary cards in discard: [15.  3.  3. 15.] 
adversary owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  1.  0.  3.  4. 11.  3.  0. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  0.  3.] 
adversary cards in discard: [15.  3.  3. 15.] 
adversary owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[83.997406]
 [84.002426]
 [84.002426]
 [84.002426]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  0.  3.] 
cards in discard: [15.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 15 15 15 15 15 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [10.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.96044921875



action possibilites: [-1] 
expected returns: [[82.465805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.] 
cards in discard: [15.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [10.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 81.580810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[84.85578 ]
 [84.85578 ]
 [84.858086]
 [84.85855 ]
 [84.86659 ]
 [84.85797 ]
 [84.861755]
 [84.867256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3.] 
cards in discard: [15.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [10.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.46580505371094






Player: 1 
cards in hand: [10.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3. 10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15. 15.] 
expected returns: [[94.69589]
 [94.70091]
 [94.70091]
 [94.70091]
 [94.70091]
 [94.70091]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 0. 4. 1. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.86724853515625



action possibilites: [-1] 
expected returns: [[94.36835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 0. 4. 1. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 92.16281127929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[96.82233]
 [96.8251 ]
 [96.83381]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [0. 0. 4. 1. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.36834716796875






Player: 1 
cards in hand: [0. 0. 4. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 1. 0.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15.  3. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[85.789154]
 [85.79418 ]
 [85.79418 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.83380889892578



action possibilites: [-1] 
expected returns: [[74.518196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 83.35370635986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.50667 ]
 [76.509445]
 [76.51815 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.51819610595703






Player: 1 
cards in hand: [ 3.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 0. 10.  0.  3.  3. 10.  4.  0.  0.  4.  1.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[87.05393 ]
 [87.058975]
 [87.058975]
 [87.058975]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.51814270019531



action possibilites: [-1] 
expected returns: [[88.17964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 84.49107360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[90.50131]
 [90.50409]
 [90.5128 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8] -> size -> 22 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.17964172363281






Player: 1 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [15. 15. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [15. 15. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [15. 15. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [15. 15. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[82.04605]
 [82.05109]
 [82.05109]
 [82.05109]
 [82.05109]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.  3.] 
cards in discard: [15. 15. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.5127944946289



action possibilites: [-1] 
expected returns: [[65.23523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3.] 
cards in discard: [15. 15. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 79.71382904052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.17712]
 [67.1799 ]
 [67.1886 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.  3.] 
cards in discard: [15. 15. 15.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.2352294921875






Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  7. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [15. 15.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[80.065   ]
 [80.070015]
 [80.070015]
 [80.070015]
 [80.070015]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 0. 10.  4. 10.  4.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.1885986328125



action possibilites: [-1] 
expected returns: [[76.22354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 0. 10.  4. 10.  4.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 77.69635009765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.20924]
 [78.21203]
 [78.22073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 0. 10.  4. 10.  4.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.22354125976562






Player: 1 
cards in hand: [ 0. 10.  4. 10.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  4. 10.  4.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 10.  4. 10.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 10.  4. 10.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 10.  4. 10.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[73.1831 ]
 [73.18811]
 [73.18811]
 [73.18811]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.2207260131836



action possibilites: [-1] 
expected returns: [[62.07461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 70.76687622070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.48775 ]
 [64.490524]
 [64.49922 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.07461166381836






Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10. 10. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 1.  3. 11.  0.  0.  0.  3. 10.  3.  0.  0.  0.  8.  0. 10.  0.  4. 10.
  4. 10. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [15.  3.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[67.998505]
 [68.003525]
 [68.003525]
 [68.003525]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [10.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.49922943115234



action possibilites: [-1] 
expected returns: [[67.20557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [10.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 65.6583251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.9821 ]
 [68.98488]
 [68.99358]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [10.  0. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.20556640625






Player: 1 
cards in hand: [10.  0. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 10. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  9. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8] -> size -> 28 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  9.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15. 15. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [15.  3. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[61.082428]
 [61.08745 ]
 [61.08745 ]
 [61.08745 ]
 [61.08745 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 15. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8 11] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.99358367919922



action possibilites: [-1] 
expected returns: [[51.584637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8 11] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 57.94240951538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.630447]
 [54.63322 ]
 [54.641926]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [ 3. 10.  0.  0.  8.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8 11] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.58463668823242






Player: 1 
cards in hand: [ 3. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3
 10  0 14  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15.  3. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [15. 15.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[55.2644 ]
 [55.26942]
 [55.26942]
 [55.26942]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.64192581176758



action possibilites: [-1] 
expected returns: [[50.771206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 52.932167053222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.642323]
 [52.645092]
 [52.653797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.77120590209961






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15. 15.  3. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[54.42187]
 [54.4269 ]
 [54.4269 ]
 [54.4269 ]
 [54.4269 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [4. 1. 0. 3. 1.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.6537971496582



action possibilites: [-1] 
expected returns: [[46.348392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [4. 1. 0. 3. 1.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 51.20174026489258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.38242 ]
 [49.38519 ]
 [49.393894]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3. 15.] 
cards in discard: [15. 15.  3. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [4. 1. 0. 3. 1.] 
adversary cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.348392486572266






Player: 1 
cards in hand: [4. 1. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1. 0. 3. 1.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 3. 1.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9. 10.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 3. 1.] 
cards in discard: [ 8. 11. 10. 11. 10. 10.  0.  3.  0.  0.  3.  8. 10.  0.  0.  1.  3.  3.
  0.  0.  0. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15.  3.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15.  3.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[40.172626]
 [40.17765 ]
 [40.17765 ]
 [40.17765 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [11. 14.  0.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.393898010253906



action possibilites: [-1] 
expected returns: [[39.303654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [11. 14.  0.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 37.75640869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.646008]
 [41.648785]
 [41.65749 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [11. 14.  0.  4.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.303653717041016






Player: 1 
cards in hand: [11. 14.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  4.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  4.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  4.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  8. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  4.  0.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[42.550568]
 [42.55559 ]
 [42.55559 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23  8] -> size -> 32 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: discard_down_to_3_cards - action 2
Learning step: 0
desired expected reward: 26.391742706298828



action possibilites: [-1] 
expected returns: [[38.363724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23  8] -> size -> 32 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 39.38108825683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.22926 ]
 [41.232037]
 [41.24074 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [15.  3.  3. 15. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  8.  0. 10.  3.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23  8] -> size -> 32 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.36372375488281






Player: 1 
cards in hand: [ 0.  8.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  3.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  4  3  0  1 10 10 10 11  0  0  4  8  1  3 10
  0 14  8 11  3  1 23  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 3. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 3. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 3. 15.  3. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[46.58253]
 [46.58755]
 [46.58755]
 [46.58755]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  0.  1.  0. 10.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.24074172973633



action possibilites: [-1] 
expected returns: [[42.7775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  0.  1.  0. 10.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 44.250301361083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.648613]
 [44.651386]
 [44.660095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [ 0.  0.  1.  0. 10.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.77750015258789






Player: 1 
cards in hand: [ 0.  0.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  9.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [15.  3.  3. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[44.463005]
 [44.46803 ]
 [44.46803 ]
 [44.46803 ]
 [44.46803 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [ 1.  3.  3. 10.  0.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.660091400146484



action possibilites: [-1] 
expected returns: [[34.03626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [ 1.  3.  3. 10.  0.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 41.24287414550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.07028 ]
 [37.073055]
 [37.08176 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3. 15.] 
cards in discard: [15.  3.  3. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [ 1.  3.  3. 10.  0.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.036258697509766






Player: 1 
cards in hand: [ 1.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 10.  0.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  3.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[15.725461]
 [15.730435]
 [15.730435]
 [15.730435]
 [15.730435]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.08176040649414



action possibilites: [-1] 
expected returns: [[14.831574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 13.341300010681152





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.144518]
 [17.14726 ]
 [17.155924]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.831574440002441






Player: 1 
cards in hand: [ 3.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15.  3.  3.] 
adversary cards in discard: [15. 15. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[36.402424]
 [36.407444]
 [36.407444]
 [36.407444]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 4.  3. 10.  0. 23.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.15592384338379



action possibilites: [-1] 
expected returns: [[25.216307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 4.  3. 10.  0. 23.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 33.232940673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.081846]
 [28.08462 ]
 [28.093325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3.  3.] 
cards in discard: [15. 15. 15. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [ 4.  3. 10.  0. 23.] 
adversary cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.216306686401367






Player: 1 
cards in hand: [ 4.  3. 10.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3. 10.  0. 23.] 
cards in discard: [ 8. 14. 11.  0.  4.  0.  8.  0. 23.  0.  0.  1.  0. 10. 15. 10.  1.  3.
  3.  0.  1.  0.  3.  0.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3.  0. 23.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  0. 23.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [15. 15.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[14.45918 ]
 [14.464154]
 [14.464154]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [11.  0. 11.  8. 10.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.093324661254883



action possibilites: [-1] 
expected returns: [[11.941447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [11.  0. 11.  8. 10.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 11.917908668518066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.5063505]
 [14.509093 ]
 [14.517757 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [11.  0. 11.  8. 10.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.941447257995605






Player: 1 
cards in hand: [11.  0. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  8. 10.] 
cards in discard: [10.  4.  3.  0. 23.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  9.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [15. 15.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 10.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [15. 15.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 10.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [15. 15.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 10.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15. 15. 15. 15.] 
adversary cards in discard: [15. 15.  3.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 15. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15. 15.] 
expected returns: [[32.246708]
 [32.251728]
 [32.251728]
 [32.251728]
 [32.251728]
 [32.251728]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15. 15.] 
cards in discard: [15. 15.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [14.  0.  0.  0. 15.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.517757415771484



action possibilites: [-1] 
expected returns: [[17.757696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [15. 15.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [14.  0.  0.  0. 15.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 29.073007583618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.422396]
 [20.425169]
 [20.433874]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15. 15.] 
cards in discard: [15. 15.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [14.  0.  0.  0. 15.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.7576961517334






Player: 1 
cards in hand: [14.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 15.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 15.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  7. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 15.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[4.9188523]
 [4.922918 ]
 [4.922918 ]
 [4.922918 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  3. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  1. 23.  4.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.433874130249023



action possibilites: [-1] 
expected returns: [[5.8556786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  1. 23.  4.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 2.65398907661438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.576453]
 [8.579092]
 [8.587533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3.  1. 23.  4.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.855678558349609






Player: 1 
cards in hand: [ 3.  1. 23.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 23.  4.  3.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [15.  3. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 23.  4.  3.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [15.  3. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 23.  4.  3.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [15. 15.  3. 15. 15.] 
adversary cards in discard: [15.  3. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 15.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[28.794718]
 [28.799744]
 [28.799744]
 [28.799744]
 [28.799744]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 15. 15.] 
cards in discard: [15.  3. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.587532043457031



action possibilites: [-1] 
expected returns: [[6.972508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 15.] 
cards in discard: [15.  3. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 26.114084243774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.484984]
 [8.487326]
 [8.49514 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15. 15.] 
cards in discard: [15.  3. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.972507953643799






Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  6. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [ 3. 15. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[0.81467474]
 [0.8167456 ]
 [0.8167456 ]
 [0.8167456 ]
 [0.8167456 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.495140075683594



action possibilites: [-1] 
expected returns: [[0.5292789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 0.10975701361894608





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.5790224]
 [1.5802531]
 [1.5849038]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.5292788743972778






Player: 1 
cards in hand: [ 0.  0. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15.  3. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15.  3. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  8.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15.  3. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  4.  3.  0. 23.  1. 14.  0. 11.  0. 11.  8. 10.  8. 14.  0.  0.  0.
 15.  3.  3.  1. 23.  4.  3. 10.  0.  0.  8.  8.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15.  3. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[2.2953455]
 [2.2978666]
 [2.2978666]
 [2.2978666]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3. 15.] 
cards in discard: [15.  3. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.5849043130874634



action possibilites: [-1] 
expected returns: [[0.05587976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [15.  3. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 1.6141184568405151





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[0.1860025 ]
 [0.18675649]
 [0.18930876]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3. 15.] 
cards in discard: [15.  3. 15. 15. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.05587976425886154






Player: 1 
cards in hand: [15.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14. 10.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 15. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14.  3. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15. 15. 15.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  6. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 11.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.] 
adversary cards in discard: [15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 10.  0. 23.  0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: discard_down_to_3_cards - action 2
Learning step: 0
desired expected reward: 30.469228744506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.] 
cards in discard: [15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 10.  0. 23.  0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[0.08923348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.] 
cards in discard: [15. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 10.  0. 23.  0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0. 10.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 23.  0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15. 15.  0. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 23.  0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  8.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15. 15.  0. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 23.  0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  3. 15.  3. 15.] 
adversary cards in discard: [15. 15.  0. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [15.  3. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  3. 15.] 
cards in discard: [15. 15.  0. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 1. 10.  0. 10.  1.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.08923348039388657





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.  3. 15.] 
cards in discard: [15. 15.  0. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 1. 10.  0. 10.  1.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.  3. 15.] 
cards in discard: [15. 15.  0. 15.  3. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 1. 10.  0. 10.  1.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 1. 10.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 10.  1.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  1.  1.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  1.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 27. 30. 26. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1.  1.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  3. 15. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14. 23.  8.  0.  4.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 15.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14. 23.  8.  0.  4.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 15.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14. 23.  8.  0.  4.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [14. 23.  8.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 23.  8.  0.  4.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0 14  8
 11  3  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15. 15.  0.  3. 15.] 
adversary cards in discard: [ 0.  0.  3. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  4.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15. 15.  0.  3. 15.] 
adversary cards in discard: [ 0.  0.  3. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  4.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15. 15.  0.  3. 15.] 
adversary cards in discard: [ 0.  0.  3. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 15.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  3. 15.] 
cards in discard: [ 0.  0.  3. 15. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 8.  0.  0. 14. 11.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  3. 15.] 
cards in discard: [ 0.  0.  3. 15. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 8.  0.  0. 14. 11.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  3. 15.] 
cards in discard: [ 0.  0.  3. 15. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 8.  0.  0. 14. 11.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 8.  0.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14. 11.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10. 10.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [15.  0. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15. 15. 15.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  7.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0. 15.  0. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 15.  3.] 
cards in discard: [ 0. 15.  0. 15. 15. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 0. 4. 3.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 15.  3.] 
cards in discard: [ 0. 15.  0. 15. 15. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 0. 4. 3.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 15.  3.] 
cards in discard: [ 0. 15.  0. 15. 15. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 0. 4. 3.] 
adversary cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [3. 8. 0. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 4. 3.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 4. 3.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 4. 3.] 
cards in discard: [ 8. 10. 14. 15.  0.  3. 11. 11.  0. 10.  0. 23.  0.  3. 10.  1.  0. 10.
  1.  1.  8. 23.  4. 29.  0. 11.  8.  0.  0. 14. 11.  3.  0.  8.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14.  8. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14.  8. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3.  3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [14.  8. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [14.  8. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 12 


action possibilites: [-1. 14.  8. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 11.  3. 10.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  4  3  0  1 10 10 11  0  0  4  8  1  3 10  0  8 11  3
  1 23  8 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [ 0.  0. 15. 15.  3.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 15.  3.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 1. 0. 8.] 
adversary cards in discard: [29.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 15.  3.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 1. 0. 8.] 
adversary cards in discard: [29.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 15.  3.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [3. 8. 1. 0. 8.] 
adversary cards in discard: [29.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [3. 8. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0. 8.] 
cards in discard: [29.  8. 14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 8.] 
cards in discard: [29.  8. 14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  5. 10.  2.] 
adversary cards in hand: [15.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 8.] 
cards in discard: [29.  8. 14. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [15.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15. 15.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [0. 0. 4. 0. 1.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15. 15.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [0. 0. 4. 0. 1.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15. 15.] 
cards in discard: [ 0. 15.  0. 15.  3.  3.  0.  0.  0. 15. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [0. 0. 4. 0. 1.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [0. 0. 4. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 0. 1.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [15. 15. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 1.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  2.] 
adversary cards in hand: [15. 15. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 0. 1.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15. 15. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [15. 15. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  1.] 
adversary cards in hand: [10.  0.  3. 11.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15] -> size -> 42 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  1.] 
adversary cards in hand: [10.  0.  3. 11.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15] -> size -> 42 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  1.] 
adversary cards in hand: [10.  0.  3. 11.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15] -> size -> 42 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [10.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  9.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 3
player victory points: 11 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [10. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 25. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[3.1164236]
 [3.1197731]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  3.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15. 11.  4.  0. 23.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563



action possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15. 11.  4.  0. 23.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 3.1197733879089355





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15. 11.  4.  0. 23.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 9. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15. 11.  4.  0. 23.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -255.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [15. 11.  4.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  4.  0. 23.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 28.  8. 10. 10.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  4.  0. 23.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  4.  0. 23.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  0. 15. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 12 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [14. 11.  8.  1.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 15. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [14. 11.  8.  1.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 15. 15.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [14. 11.  8.  1.  3.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
adversary victory points: 12
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -275.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [14. 11.  8.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  8.  1.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
adversary victory points: 3
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  8.  1.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 24. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
adversary victory points: 3
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  8.  1.  3.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
adversary victory points: 3
player victory points: 13 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -300.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 13 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  9.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.  8. 14. 10.  3.  8.  1.  0.  8. 15.  0.  0.  4.  0.  1. 29.  0. 11.
 10.  0.  3.  3.  3.  0.  0.  8. 10.  0. 16. 11. 15.  4.  0. 23.  3. 14.
 11.  8.  1.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 13 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  4.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 48 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  4.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 48 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[4.347909]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 0.  4.  8.  0. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 48 
adversary victory points: 13
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -300.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  4.  8.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  8.  0. 23.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  4  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8
 23 15  0 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
adversary victory points: 3
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[29.3075  ]
 [29.312525]
 [29.312525]
 [29.312525]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0. 15.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [ 0.  8. 23.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.347908973693848



action possibilites: [-1] 
expected returns: [[1.3772066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [ 0.  8. 23.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 29.312524795532227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[0.9885256 ]
 [0.9885285 ]
 [0.9894711 ]
 [0.98966086]
 [0.9885256 ]
 [0.99323785]
 [0.98954606]
 [0.99317956]
 [0.99382937]
 [0.9910476 ]
 [0.9958285 ]
 [0.9936025 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  1.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [ 0.  8. 23.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.377206563949585



buy possibilites: [-1] 
expected returns: [[17.058601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.] 
cards in discard: [ 0.  3.  0. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  0.  0.  0.
 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [ 0.  8. 23.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: -67 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 0.9958287477493286






Player: 1 
cards in hand: [ 3.  3.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11.  0.] 
cards in discard: [ 0.  8. 23.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11.  0.] 
cards in discard: [ 0.  8. 23.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 11.  0.] 
cards in discard: [ 0.  8. 23.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.05860137939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 15.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -210.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  8.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  1.  3. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  1.  3. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  1.  3. 10.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -210.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  1.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15. 15.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  5. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15. 15.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.  0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15. 15.  3.  0.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.  3.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.  3.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[0.63786614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.  3.  0.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -210.    0.    0.    0.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -215.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  4. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[62.245365]
 [62.250393]
 [62.250393]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 15.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0  0 15
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [11. 10. 16. 15.  3.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.6378661394119263



action possibilites: [-1] 
expected returns: [[0.04667871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [11. 10. 16. 15.  3.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 62.250389099121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[-0.07559413]
 [-0.07559322]
 [-0.07518807]
 [-0.07545277]
 [-0.07504849]
 [-0.07559413]
 [-0.07369092]
 [-0.0752144 ]
 [-0.07479808]
 [-0.07366563]
 [-0.07338664]
 [-0.07449187]
 [-0.07458349]
 [-0.0750706 ]
 [-0.07347368]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  7.  8.  4. 10.  0.] 
adversary cards in hand: [11. 10. 16. 15.  3.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.04667871445417404



buy possibilites: [-1] 
expected returns: [[19.183105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 0.  0.  0. 15.  0. 15.  0.  3.  0.  0. 15.  0.  0.  0. 15. 15.  3.  0.
 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  6.  8.  4. 10.  0.] 
adversary cards in hand: [11. 10. 16. 15.  3.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -210.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -163.0 

action type: buy - action 14.0
Learning step: 0
desired expected reward: -0.07338660955429077






Player: 1 
cards in hand: [11. 10. 16. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 16. 15.  3.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1. 11. 16. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 15.  3. 10.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1. 11. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  3. 10.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8 11  3  1 23  8 23 15  0
 14  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16
  8  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  8.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 23.  1. 29. 16.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.18310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 27. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 23.  1. 29. 16.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 23.  1. 29. 16.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -161 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0. 23.  1. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1. 29. 16.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1] -> size -> 28 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1. 29. 16.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1] -> size -> 28 
adversary victory points: 3
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 8. 15.  4.  8.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 26. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 8. 15.  4.  8.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 8. 15.  4.  8.  0.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
adversary owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -161 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 8. 15.  4.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  4.  8.  0.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  1 10  0  0  4  8  1  3 10  0  8  3  1 23  8 23 15  0 14
  0  8  3 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8
  8 29  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0. 15.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [10. 14.  3. 29. 11.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0. 15.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 25. 30. 23. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [10. 14.  3. 29. 11.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[1.6353208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0. 15.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [10. 14.  3. 29. 11.] 
adversary cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -79 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [10. 14.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  3. 29. 11.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15.  0. 15. 14.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 14. 29. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 29. 11.  1.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0. 15.  0. 15. 14.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  1.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  1.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  4. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  1.] 
cards in discard: [ 0.  8. 23.  0.  3.  3.  8. 11.  0. 16.  8.  0.  0.  0.  0.  8.  0.  1.
  3. 10.  0.  8.  0.  3.  3.  0. 14. 29.  0. 10. 15. 16.  3. 10.  0. 23.
  1. 29. 16.  8.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0. 15.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[54.838757]
 [54.843777]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0  0 15  0
  0  0 14  1  1  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -0.17649227380752563



action possibilites: [-1] 
expected returns: [[30.10819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 54.84377670288086





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
expected returns: [[28.428644]
 [28.430954]
 [28.431414]
 [28.428638]
 [28.439453]
 [28.430832]
 [28.438953]
 [28.440784]
 [28.434608]
 [28.440117]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  6.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.108190536499023



buy possibilites: [-1] 
expected returns: [[33.141396]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 53 

action type: buy - action 14.0
Learning step: 0
desired expected reward: 28.440786361694336






Player: 1 
cards in hand: [10.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3
 10 14  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0
 10] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [10.  8. 10.] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[43.75858]
 [43.7636 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0  0 15  0  0
  0 14  1  1  3 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  8. 10.  3. 29.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.141395568847656



action possibilites: [-1] 
expected returns: [[39.889645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  8. 10.  3. 29.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 43.763607025146484





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[38.83542 ]
 [38.837734]
 [38.835983]
 [38.83819 ]
 [38.83541 ]
 [38.846237]
 [38.83761 ]
 [38.840046]
 [38.845734]
 [38.847553]
 [38.841248]
 [38.841385]
 [38.838135]
 [38.84689 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  5.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  8. 10.  3. 29.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.889644622802734



buy possibilites: [-1] 
expected returns: [[46.172718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.  1.  0. 15.  3.  0.  0.  3. 15.  0. 15.  0. 15.
 15. 14. 14. 15.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [10.  8. 10.  3. 29.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -43.0 

action type: buy - action 14.0
Learning step: 0
desired expected reward: 38.847564697265625






Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  8. 10.  3. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  8. 10.  3. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  6.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [10.  8. 10.  3. 29. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8. 16.  3. 10. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10 11] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.1727180480957





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 25. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8. 16.  3. 10. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10 11] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.  0.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8. 16.  3. 10. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10 11] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -41 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 8. 16.  3. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 10. 16.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14
  8 11  3 29  0 11  0 10 15 29  0  3 16  3 16  0  0 16  8  8 29  0 10 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  1. 15.  0.  3.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0. 10. 14.  8.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0. 10. 14.  8.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.  0.  3.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0. 10. 14.  8.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -51.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  0. 10. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 14.  8.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1. 14.  8. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8. 23.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 23.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  7.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 3.  1. 23. 10. 11.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 30. 22. 28.  8. 10.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 3.  1. 23. 10. 11.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.08003049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 22. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 3.  1. 23. 10. 11.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -395.0 

action type: buy - action 6.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 3.  1. 23. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 23. 10. 11.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 22. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15. 15.  0.  0. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1  6] -> size -> 33 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 23. 10. 11.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 30. 22. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15. 15.  0.  0. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1  6] -> size -> 33 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 23. 10. 11.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15. 15.  0.  0. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1  6] -> size -> 33 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [15. 15.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 14.] 
expected returns: [[7.428085 ]
 [7.4330096]
 [7.4330096]
 [7.428739 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  0. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0  0 15  0  0  0
 14  1  1  3 14 14  1  1  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.08003048598766327



action possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 23. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 7.433010578155518





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.15748754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.     0.     0.     0.    13.5    0. ] 
sum of rewards: -91.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 14. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 30. 21. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 14. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  3.  3. 14. 14.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[30.638859]
 [30.639528]
 [30.639528]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.15748754143714905



action possibilites: [-1] 
expected returns: [[23.18488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 8. 3.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 14.0
Learning step: 0
desired expected reward: 30.639528274536133





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.512346]
 [22.51466 ]
 [22.515116]
 [22.52316 ]
 [22.514534]
 [22.51831 ]
 [22.52382 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 14.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [0. 8. 3.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.184879302978516






Player: 1 
cards in hand: [0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1.  0. 15.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1.  0. 15.  0.] 
adversary cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [15.  1.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[30.535608]
 [30.540636]
 [30.540636]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0. 15.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0  0 15  0  0  0 14
  1  1  3 14 14  1  1  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 29. 11. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.523820877075195



action possibilites: [-1] 
expected returns: [[6.8750076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 29. 11. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 30.54063606262207





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[3.7552104]
 [3.755354 ]
 [3.7566442]
 [3.7556152]
 [3.7569232]
 [3.7552066]
 [3.7623389]
 [3.756759 ]
 [3.7582762]
 [3.7620738]
 [3.7632008]
 [3.7587783]
 [3.7591102]
 [3.7567875]
 [3.7627885]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  4.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 29. 11. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.875007629394531



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 1. 15.  0. 15.  0.  0.  1.  0.  1. 15.  0.  3.  0.  0.  6. 15.  3.  0.
  1. 15. 15.  0. 14. 14.  0.  3.  3. 14. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 29. 11. 16.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -150.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -103.0 

action type: buy - action 14.0
Learning step: 0
desired expected reward: 3.7632012367248535






Player: 1 
cards in hand: [ 8.  0. 29. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 11. 16.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14] -> size -> 33 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29. 11. 16.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14] -> size -> 33 
adversary victory points: 3
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [15.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [29.  0.  1. 15. 14.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 30. 20. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [29.  0.  1. 15. 14.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 15.  3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [29.  0.  1. 15. 14.] 
adversary cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -109 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [29.  0.  1. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1. 15. 14.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15. 15.  1.  0. 14.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15. 15.  1.  0. 14.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1.  0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  3. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1.  0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10.  8. 10.  3. 29. 11.  0.  0.  3.  0.  1.  8. 10. 29. 10. 14.  0.  0.
  8. 23.  3.  3.  1. 23. 10. 11.  3.  0.  0.  8.  0.  0.  8.  3.  0.  8.
  3.  8.  0. 29. 11. 16.  1. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1.  0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3
  8] -> size -> 49 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3
  8] -> size -> 49 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8. 23.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3
  8] -> size -> 49 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -71 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 1.  8. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 23.  0.  3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 10  0  0  8  1  3 10  0  8  3  1 23  8 23  0 14  0  8  3 10 14  8
 11  3 29  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1. 15.  0. 15.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1. 15.  0. 15.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [15.  1. 15.  0. 15.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [15.  1. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 15.  0. 15.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [10.  3.  3. 29.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 15.  0. 15.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [10.  3.  3. 29.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[0.93173087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 15.  0. 15.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [10.  3.  3. 29.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0  -10    0    0
   54    0] 
sum of rewards: -81 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [10.  3.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 29.  3.] 
cards in discard: [8. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 3.  1.  0.  0. 14.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3. 29.  3.] 
cards in discard: [8. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 3.  1.  0.  0. 14.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
adversary victory points: 4
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-0.13299023]
 [-0.13282067]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 14.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8.  3. 29.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.9317308664321899



action possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1. 29.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 14.0
Learning step: 0
desired expected reward: -0.13282053172588348





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 20. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1. 29.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [ 1. 29.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
adversary owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.   -20.     0.     0.    13.5    0. ] 
sum of rewards: -111.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 1. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  1  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3 29
  0 11  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.348148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[3.409058 ]
 [3.4092658]
 [3.4106262]
 [3.4094722]
 [3.4109938]
 [3.4090543]
 [3.4164205]
 [3.4105694]
 [3.412154 ]
 [3.4160979]
 [3.4174545]
 [3.4130363]
 [3.4131343]
 [3.4109318]
 [3.4169328]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  3.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.348147869110107



buy possibilites: [-1] 
expected returns: [[14.830825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [10.  8.  0. 11. 10.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.    0.    0.    0.    0.    0.  -30.
    0.    0.   32.    0.] 
sum of rewards: -123.0 

action type: buy - action 14.0
Learning step: 0
desired expected reward: 3.4174554347991943






Player: 1 
cards in hand: [10.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11. 10.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  6. 15. 14.  0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14] -> size -> 38 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11. 10.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  6. 15. 14.  0.] 
adversary cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14] -> size -> 38 
adversary victory points: 4
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15. 14.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.  0.  1.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.830824851989746





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15. 14.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.  0.  1.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 19. 30. 19. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15. 14.  0.] 
cards in discard: [ 3. 15.  0.  0. 15.  3. 15. 14.  1. 15.  1.  0.  1. 15.  1. 15.  0. 15.
  1. 14.  3.  1.  0.  0. 14.  0.  1.  3.  1.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0 -40   0   0  16   0] 
sum of rewards: -119 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  1.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3] -> size -> 39 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 19. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  1.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3] -> size -> 39 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 19. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 23. 10.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 19. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 23. 10.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 14.  0.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 18. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 8.  0. 23. 10.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.    0.    0.    0.    0.    0.  -50.
   0.    0.   13.5   0. ] 
sum of rewards: -131.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 8.  0. 23. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 23. 10.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [14. 15. 15.  1.  6.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1] -> size -> 40 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 23. 10.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 18. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [14. 15. 15.  1.  6.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1] -> size -> 40 
adversary victory points: 5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [14. 15. 15.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 15.  1.  6.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 16.  3.  3. 11.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15. 15.  1.  6.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 18. 30. 18. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 16.  3.  3. 11.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15. 15.  1.  6.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 17. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0. 16.  3.  3. 11.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
adversary victory points: 8
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0 -60   0   0  16   0] 
sum of rewards: -109 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [ 0. 16.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3. 11.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 17. 28.  8.  9.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  0. 15.  3. 15.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
adversary victory points: 6
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  0. 15.  3. 15.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 18. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  0. 15.  3. 15.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 15.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  3. 15.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 18. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]
 [-0.17649227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3. 15.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 18. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.17649227380752563



buy possibilites: [-1] 
expected returns: [[-0.17649227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3. 15.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0.  8.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0 -70   0   0  54   0] 
sum of rewards: -51 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -0.17649227380752563






Player: 1 
cards in hand: [10. 14. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 15.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 15.  0.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [14. 14.  3.  0.  3.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  8.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 7 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.1682997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8. 11.  3. 29.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -0.17649227380752563





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[3.2300818]
 [3.2369502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  8. 11.  3. 29.] 
adversary cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
adversary victory points: 7
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.168299674987793



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  8. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.  3. 29.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 17. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 29.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 16. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3. 29.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 17. 30. 16. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3. 29.] 
cards in discard: [ 8.  3. 10.  3.  3. 29.  3.  8.  3.  8. 10.  8.  0. 11. 10.  0.  0.  0.
 29.  0.  8.  0. 23. 10.  8.  6. 11.  0. 16.  3.  3. 14. 10. 15.  0.  8.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
adversary victory points: 6
player victory points: 9 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[31.243902]
 [31.248926]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0  0 15  0  0  0 14  1
  1  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.236949920654297



action possibilites: [-1] 
expected returns: [[22.827646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 31.248929977416992





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[21.013649]
 [21.013924]
 [21.015963]
 [21.014214]
 [21.016418]
 [21.013643]
 [21.024462]
 [21.015837]
 [21.018278]
 [21.023964]
 [21.025793]
 [21.019478]
 [21.019613]
 [21.016365]
 [21.025124]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  2.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.827646255493164



buy possibilites: [-1] 
expected returns: [[18.985615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.  20.   0.   0.   0.   0. -70.   0.   0.
  32.   0.] 
sum of rewards: -113.0 

action type: buy - action 14.0
Learning step: 0
desired expected reward: 21.025793075561523






Player: 1 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  1. 14.  3.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
adversary victory points: 6
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 17. 30. 15. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  1. 14.  3.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
adversary victory points: 6
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 17. 30. 14. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [ 1.  1. 14.  3.  0.] 
adversary cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
adversary victory points: 6
player victory points: 10 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[1.6987427]
 [1.6990126]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 14.  3.  0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 17. 30. 14. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [ 0.  3. 23. 11.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3  3] -> size -> 48 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.985614776611328



action possibilites: [-1] 
expected returns: [[18.05659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 17. 30. 14. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [23. 11.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.  0.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3  3] -> size -> 48 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 14.0
Learning step: 0
desired expected reward: 1.699013352394104





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. -1.] 
expected returns: [[18.045115]
 [18.045391]
 [18.04743 ]
 [18.045681]
 [18.047884]
 [18.04511 ]
 [18.055927]
 [18.047302]
 [18.049742]
 [18.055428]
 [18.057257]
 [18.050941]
 [18.051077]
 [18.04783 ]
 [18.05659 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14] -> size -> 42 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 17. 30. 14. 28.  8.  8.  7.  5.  2. 10.  6.  1.  8.  3. 10.  0.] 
adversary cards in hand: [23. 11.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.  0.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3  3] -> size -> 48 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.056589126586914



Player 1 won the game! 



Player 0 bought cards:
Copper: 18 
Silver: 10 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 7 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 8 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 1. 3. 0.] 
cards in discard: [ 1.  1.  1.  3. 14.  0.  3. 14. 15. 15.  1.  6.  1.  1.  0. 15.  3. 15.
 14. 14.  3.  0.  3. 14. 15.  0.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 15 15 15 15 15 15 15  0  0  0  0  0  0  0 15  0  0  0 14  1  1
  3 14 14  1  1  6  1 14  3  1  1  1 14  3  1  3  1 14 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 17. 30. 14. 28.  8.  8.  7.  5.  2. 10.  6.  0.  8.  3. 10.  0.] 
adversary cards in hand: [23. 11.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 14.  0.  3.] 
adversary owned cards: [10  0  0  8  3 10  0  8  3  1  8 23  0 14  0  8  3 10 14  8 11  3  0 11
  0 10 15 29  0  3  3  0  0 16  8  8 29  0 10 11 29  3  3  8  6  3  3  3] -> size -> 48 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0      -80        0        0       64        0] 
sum of rewards: -3000121 

action type: buy - action 14.0
Learning step: -120005.5546875
desired expected reward: -119987.5



