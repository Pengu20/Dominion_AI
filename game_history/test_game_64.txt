 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.600883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0     -130        0        0        8        0] 
sum of rewards: -3000367 

action type: buy - action 8.0
Learning step: -120008.1796875
desired expected reward: -120170.703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.718032]
 [ 26.051666]
 [ 15.686945]
 [-57.244713]
 [ 20.835323]
 [ 13.512741]
 [ 18.078463]
 [  9.628418]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.373483657836914



buy possibilites: [-1] 
expected returns: [[10.549345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.051666259765625






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.530544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.549345016479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 19.439423]
 [ 35.13024 ]
 [ 24.657026]
 [-49.494774]
 [ 28.303406]
 [ 29.893337]
 [ 22.142813]
 [ 42.420845]
 [ 27.560907]
 [ 27.007551]
 [ 33.936714]
 [ 18.195139]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.147823333740234



buy possibilites: [-1] 
expected returns: [[8.136887]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.42082977294922






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.8120413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.136886596679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  5.228204 ]
 [ 20.583138 ]
 [ 10.430129 ]
 [-22.919924 ]
 [-62.806152 ]
 [ 14.13163  ]
 [ 15.511227 ]
 [  7.7547207]
 [ 22.03078  ]
 [ 27.4543   ]
 [ 13.392105 ]
 [ 19.859865 ]
 [ 12.887226 ]
 [  3.4243906]
 [ 19.344088 ]
 [  4.8444567]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.489687919616699



buy possibilites: [-1] 
expected returns: [[32.77122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.45431137084961






Player: 1 
cards in hand: [10. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-8.687666]
 [13.384872]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [29.  0.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.77122116088867



action possibilites: [-1.] 
expected returns: [[7.6979675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.28349494934082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 10.621903 ]
 [ 26.16188  ]
 [ 16.010805 ]
 [-74.15557  ]
 [ 19.792082 ]
 [ 21.300346 ]
 [ 13.46855  ]
 [ 32.994865 ]
 [ 19.107986 ]
 [ 18.585663 ]
 [ 25.070028 ]
 [ 10.2648945]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.697967529296875



buy possibilites: [-1] 
expected returns: [[1.1163075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.9948616027832






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10. 16.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10. 16.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10. 16.  3.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.093826]
 [48.08844 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.1163074970245361



action possibilites: [-1. 29.] 
expected returns: [[ 4.6340094]
 [27.356401 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.42019271850586



action possibilites: [-1.] 
expected returns: [[8.43681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.356414794921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.204926 ]
 [ 26.484222 ]
 [-22.980938 ]
 [ 16.88058  ]
 [-19.593145 ]
 [-61.05216  ]
 [ 20.684057 ]
 [ 22.06495  ]
 [ 13.948395 ]
 [ 28.135015 ]
 [ 33.106274 ]
 [ 20.082964 ]
 [ 25.966034 ]
 [ 19.61077  ]
 [  9.501649 ]
 [ 25.534721 ]
 [ 12.0884695]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.436809539794922



buy possibilites: [-1] 
expected returns: [[2.6672618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.10626983642578






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.046411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0. 10.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.667261838912964





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.208493]
 [ 25.397263]
 [ 15.430904]
 [-56.710495]
 [ 20.313408]
 [ 12.452484]
 [ 17.902733]
 [ 10.513776]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0. 10.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.150385856628418



buy possibilites: [-1] 
expected returns: [[22.247341]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29. 29. 29.  3.  0.  1.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0. 10.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 25.397266387939453






Player: 1 
cards in hand: [16.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0. 10.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 16  0  8 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.  4.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[29.877151]
 [48.462364]
 [48.462364]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.24734115600586



action possibilites: [-1. 29.] 
expected returns: [[-8.388108]
 [11.950104]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.81709671020508



action possibilites: [-1.] 
expected returns: [[6.365247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 11.950109481811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  5.5631924]
 [ 21.201656 ]
 [-28.73581  ]
 [ 11.339058 ]
 [-25.19265  ]
 [-67.27951  ]
 [ 15.196505 ]
 [ 16.728739 ]
 [  8.4295845]
 [ 22.837416 ]
 [ 27.746546 ]
 [ 14.5863495]
 [ 20.695312 ]
 [ 14.07593  ]
 [  3.8533962]
 [ 20.271578 ]
 [  5.94903  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.365246772766113



buy possibilites: [-1] 
expected returns: [[24.196587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.   32.    0.] 
sum of rewards: -53.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.746543884277344






Player: 1 
cards in hand: [14.  3.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  8 14  4  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.479404]
 [35.3182  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  1.  0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  4.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.19658660888672



action possibilites: [-1.] 
expected returns: [[17.998417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  4.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.082763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 20.727058]
 [ 35.706593]
 [ 25.815342]
 [ -9.606795]
 [-49.43181 ]
 [ 29.616093]
 [ 30.983955]
 [ 23.699213]
 [ 37.149303]
 [ 42.160007]
 [ 28.93858 ]
 [ 35.06784 ]
 [ 28.45128 ]
 [ 18.547735]
 [ 34.595795]
 [ 20.688374]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  4.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.998416900634766



buy possibilites: [-1] 
expected returns: [[23.591108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [29. 29. 29.  0.  3.  0.  0.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  4.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -43.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.16002655029297






Player: 1 
cards in hand: [ 0.  0.  3. 16.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  4.] 
cards in discard: [8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  0  8  4  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  9. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4.] 
cards in discard: [8. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4.] 
cards in discard: [8. 3. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-1.2390125]
 [17.294277 ]
 [17.294277 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.591108322143555



action possibilites: [-1. 29. 29.] 
expected returns: [[11.303083]
 [33.369164]
 [33.369164]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.393604278564453



action possibilites: [-1. 29.] 
expected returns: [[28.601742]
 [50.43048 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.36916732788086



action possibilites: [-1.] 
expected returns: [[24.059414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.430484771728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.93846  ]
 [ 40.284546 ]
 [ -8.195079 ]
 [ 30.417759 ]
 [ -4.3497634]
 [ 38.990917 ]
 [-44.909588 ]
 [ 34.13862  ]
 [ 35.575996 ]
 [ 27.525484 ]
 [ 41.806705 ]
 [ 46.85057  ]
 [ 33.472935 ]
 [ 39.67837  ]
 [ 32.971886 ]
 [ 23.243895 ]
 [ 39.214993 ]
 [ 24.990015 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  4.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.05941390991211



buy possibilites: [-1] 
expected returns: [[29.278465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 46.85057830810547






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  3.  8. 16.  0.  0.  4. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[51.747128]
 [71.81466 ]
 [71.81466 ]
 [71.81466 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 29.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.278465270996094



action possibilites: [-1. 29. 29.] 
expected returns: [[51.831406]
 [72.211525]
 [72.211525]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.7890625



action possibilites: [-1. 29.] 
expected returns: [[43.071133]
 [63.308647]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.21154022216797



action possibilites: [-1.] 
expected returns: [[81.613106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.30867004394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 85.76421 ]
 [100.31172 ]
 [ 52.582508]
 [ 90.84466 ]
 [ 56.017994]
 [ 15.900837]
 [ 94.570786]
 [ 95.811485]
 [ 88.469925]
 [101.61509 ]
 [106.348816]
 [ 93.91684 ]
 [ 99.67689 ]
 [ 93.46542 ]
 [ 83.77002 ]
 [ 99.220894]
 [ 86.27453 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  3.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.61310577392578



buy possibilites: [-1] 
expected returns: [[86.93286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29.  3.  0.  0.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 106.34881591796875






Player: 1 
cards in hand: [ 8. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  8  4  3  8 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-12.662061]
 [  6.696705]
 [  6.696705]
 [  6.696705]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  1.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.932861328125



action possibilites: [-1. 29. 29.] 
expected returns: [[-3.9760928]
 [16.768501 ]
 [16.768501 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.47675895690918



action possibilites: [-1. 29.] 
expected returns: [[-5.7819777]
 [14.435003 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.76849365234375



action possibilites: [-1. 29.] 
expected returns: [[28.294178]
 [48.625435]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.435001373291016



action possibilites: [-1.] 
expected returns: [[48.526436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 48.62544250488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 50.30653 ]
 [ 65.485985]
 [ 17.493279]
 [ 55.98526 ]
 [ 20.469612]
 [ 63.67383 ]
 [-18.843693]
 [ 59.711525]
 [ 61.223953]
 [ 53.07081 ]
 [ 67.10428 ]
 [ 71.80797 ]
 [ 59.137123]
 [ 65.02535 ]
 [ 58.639935]
 [ 48.636707]
 [ 64.62677 ]
 [ 50.802002]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  2.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.52643585205078



buy possibilites: [-1] 
expected returns: [[46.03746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  8.  4.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -90.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 71.80797576904297






Player: 1 
cards in hand: [ 0.  3. 15.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  8.  4.] 
cards in discard: [ 1.  3. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  4  3  8 15  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [ 1.  3. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 1.  3. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 1.  3. 16.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 29.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[67.825  ]
 [88.45463]
 [88.45463]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0. 29.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.03746032714844



action possibilites: [-1. 29.] 
expected returns: [[ 99.6099 ]
 [117.70838]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 29.  3.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.84490966796875



action possibilites: [-1. 29.] 
expected returns: [[111.225876]
 [131.60881 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 29.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 117.7083740234375



action possibilites: [-1. 29.] 
expected returns: [[120.53784]
 [139.73941]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 29.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.6088104248047



action possibilites: [-1.] 
expected returns: [[126.454834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 139.73939514160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[127.13573 ]
 [141.67781 ]
 [ 92.70814 ]
 [132.3442  ]
 [ 96.32322 ]
 [140.1557  ]
 [ 55.884354]
 [136.11273 ]
 [137.45494 ]
 [130.16965 ]
 [143.0788  ]
 [148.0147  ]
 [135.5397  ]
 [141.0871  ]
 [135.0834  ]
 [125.02063 ]
 [140.6887  ]
 [127.81444 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 9 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.454833984375



buy possibilites: [-1] 
expected returns: [[204.1762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [29. 29. 29. 29. 29.  1.  3.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [4. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 148.0146942138672






Player: 1 
cards in hand: [4. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 29.  8. 10.  9. 10.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 9.724328]
 [30.615105]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  3.  8.] 
adversary cards in discard: [11.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 204.1761932373047



action possibilites: [-1.] 
expected returns: [[25.537857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  3.  8.] 
adversary cards in discard: [11.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.077272415161133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 27.344175]
 [ 42.695854]
 [ 32.75316 ]
 [-42.073345]
 [ 36.530396]
 [ 37.947304]
 [ 30.050137]
 [ 35.854694]
 [ 35.356144]
 [ 41.60036 ]
 [ 27.413986]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  3.  8.] 
adversary cards in discard: [11.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.537857055664062



buy possibilites: [-1] 
expected returns: [[39.68109]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  3.  8.] 
adversary cards in discard: [11.  4.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -31.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 42.69585037231445






Player: 1 
cards in hand: [ 0. 16.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  8.] 
cards in discard: [11.  4.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 16  0  4  3  8  1  3  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  8. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  0.  3.  1.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [11.  4.  0.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  0.  3.  1.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [11.  4.  0.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  0.  3.  1.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [11.  4.  0.  3.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  0.  3.  1.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[42.657097]
 [63.68004 ]
 [63.68004 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3.  1.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.68109130859375



action possibilites: [-1.] 
expected returns: [[82.15789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.448184967041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.073746]
 [103.08332 ]
 [ 54.060196]
 [ 93.553696]
 [ 57.293858]
 [ 17.153286]
 [ 97.41521 ]
 [ 98.84186 ]
 [ 91.139595]
 [104.6045  ]
 [ 96.83311 ]
 [102.59219 ]
 [ 96.35454 ]
 [ 86.01042 ]
 [102.187805]
 [ 88.815475]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7. 10.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.15789031982422



buy possibilites: [-1] 
expected returns: [[102.20653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 17.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 104.60448455810547






Player: 1 
cards in hand: [11.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 29.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  1.] 
cards in discard: [4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[169.09073]
 [184.58089]
 [184.58089]
 [184.58089]
 [184.58089]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29. 29.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.20652770996094



action possibilites: [-1. 29. 29.] 
expected returns: [[164.14348]
 [178.4468 ]
 [178.4468 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 178.28704833984375



action possibilites: [-1.] 
expected returns: [[198.06975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 173.9999542236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[193.90271 ]
 [207.51724 ]
 [199.53111 ]
 [162.87271 ]
 [124.340256]
 [203.15347 ]
 [204.39145 ]
 [196.54909 ]
 [208.8506  ]
 [202.74934 ]
 [207.23305 ]
 [202.35811 ]
 [192.33662 ]
 [206.95341 ]
 [196.12584 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  9.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 198.0697479248047



buy possibilites: [-1] 
expected returns: [[130.06627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  1. 29.  0.  3.  0.  0. 29. 25. 29.  0.  3.  1.  1. 29. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 8.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
  250    0] 
sum of rewards: 135 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 208.85060119628906






Player: 1 
cards in hand: [3. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 8.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 8.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 8.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[-0.13720965]
 [18.888617  ]
 [18.888617  ]
 [18.888617  ]
 [18.888617  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.06626892089844



action possibilites: [-1. 29. 29.] 
expected returns: [[23.676384]
 [42.945023]
 [42.945023]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.227944374084473



action possibilites: [-1. 29.] 
expected returns: [[63.96602]
 [81.97089]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.27122116088867



action possibilites: [-1.] 
expected returns: [[44.934658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 74.16915893554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 46.77548 ]
 [ 61.466805]
 [ 52.17409 ]
 [-24.277807]
 [ 55.902878]
 [ 57.23558 ]
 [ 49.488865]
 [ 55.310135]
 [ 54.85141 ]
 [ 60.526825]
 [ 47.56834 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.93465805053711



buy possibilites: [-1] 
expected returns: [[62.05594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 29.  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  4.] 
adversary cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -150.     0.     0.    60.     0.     0.     0.
    0.     0.     0.     0.    13.5    0. ] 
sum of rewards: -81.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 61.46680450439453






Player: 1 
cards in hand: [ 0. 16.  0.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  4.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  4  3  8  1  3  0 11  8  0  4  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 28.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 4. 11.  0.  0.  0.  1.  0.  3.  8.  3.  0.  8.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  1.  3.  3.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[72.22772]
 [92.58706]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  3.  3.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.055938720703125



action possibilites: [-1.] 
expected returns: [[111.375595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 84.78543090820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[110.928055]
 [124.59091 ]
 [115.912155]
 [ 46.4115  ]
 [120.47597 ]
 [113.13466 ]
 [118.36551 ]
 [111.89674 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.37559509277344



buy possibilites: [-1] 
expected returns: [[98.63489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -81 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 124.59089660644531






Player: 1 
cards in hand: [ 0.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  0.  1.  0.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  7.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  0.  1.  0.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  0.  1.  0.] 
adversary cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[60.952972]
 [73.58977 ]
 [77.80535 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  1.  0.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 4.  8. 16.  0.  4.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.6348876953125



action possibilites: [-1. 25. 25.] 
expected returns: [[ 90.49115]
 [106.31804]
 [106.31804]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 25.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 27.  8. 10.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 4.  8. 16.  0.  4.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 72.43655395507812



action possibilites: [-1] 
expected returns: [[38.440586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 4.  8. 16.  0.  4.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8  6] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.31803894042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 31.821198]
 [ 44.98524 ]
 [ 37.517906]
 [-35.225018]
 [ 41.92243 ]
 [ 33.583298]
 [ 40.285583]
 [ 35.268513]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 4.  8. 16.  0.  4.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8  6] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.44058609008789



buy possibilites: [-1] 
expected returns: [[4.2329397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 29. 29.] 
cards in discard: [29. 29.  1.  1. 29. 29. 29.  3.  0.  1.  1. 29.  0.  3.  3.  0.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 4.  8. 16.  0.  4.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8  6] -> size -> 19 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -61 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.9852294921875






Player: 1 
cards in hand: [ 4.  8. 16.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8. 16.  0.  4.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  0  3  8  1  3  0 11  8  0  4  0  4  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[17.808174]
 [31.409111]
 [35.729565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.232939720153809



action possibilites: [-1. 25.] 
expected returns: [[ 4.0640306]
 [19.315643 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 27.  8.  9.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.668128967285156



action possibilites: [-1] 
expected returns: [[31.662365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 28. 27.  8.  8.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.315650939941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 35.676414]
 [ 50.05695 ]
 [ 40.860275]
 [-29.34882 ]
 [ 44.412468]
 [ 45.597656]
 [ 37.86273 ]
 [ 43.758553]
 [ 43.320404]
 [ 48.95326 ]
 [ 36.34042 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 23. 30. 28. 27.  8.  8.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.662364959716797



buy possibilites: [-1] 
expected returns: [[42.025597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 28. 27.  8.  8.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 108.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 50.056941986083984






Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 27.  8.  8.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  1.  3. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 22. 30. 28. 27.  8.  8.  9.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  1.  3. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  0. 11.  8.  6.  8. 16.  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  1.  3. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[107.79629]
 [125.8799 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 29.  1.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.025596618652344



action possibilites: [-1.] 
expected returns: [[102.287735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 120.23802185058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 92.21752 ]
 [106.29819 ]
 [ 59.30514 ]
 [ 97.1888  ]
 [ 62.412613]
 [104.49293 ]
 [ 23.788498]
 [100.85524 ]
 [102.06532 ]
 [ 94.965904]
 [107.584045]
 [100.246414]
 [105.72302 ]
 [ 99.81545 ]
 [ 90.19622 ]
 [105.2993  ]
 [ 92.949974]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 9 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  8.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.28773498535156



buy possibilites: [-1] 
expected returns: [[52.42799]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 167.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 107.58401489257812






Player: 1 
cards in hand: [ 0. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0. 29.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[79.45558]
 [93.9547 ]
 [93.9547 ]
 [93.9547 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0. 29.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.4279899597168



action possibilites: [-1. 29. 29.] 
expected returns: [[60.485016]
 [76.58067 ]
 [76.58067 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.60161590576172



action possibilites: [-1. 29.] 
expected returns: [[-0.11016178]
 [17.85919   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.75138092041016



action possibilites: [-1.] 
expected returns: [[46.3773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.343603134155273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 42.72426 ]
 [ 56.570236]
 [ 48.321945]
 [-25.167995]
 [ 51.94451 ]
 [ 52.90225 ]
 [ 44.623913]
 [ 51.404366]
 [ 51.047504]
 [ 55.65357 ]
 [ 45.362534]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 22. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 46.37730026245117



buy possibilites: [-1] 
expected returns: [[37.74659]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 158.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 56.570228576660156






Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  6.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  1.] 
adversary cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[34.36615]
 [50.82146]
 [50.82146]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  1.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  8.  1. 16.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.74658966064453



action possibilites: [-1.] 
expected returns: [[7.882948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  8.  1. 16.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.852264404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  6.0051527]
 [ 19.190111 ]
 [-20.618952 ]
 [ 10.967003 ]
 [-17.465668 ]
 [-50.940567 ]
 [ 14.1684265]
 [ 15.030033 ]
 [  7.2582626]
 [ 20.07029  ]
 [ 13.5259   ]
 [ 18.484362 ]
 [ 13.167543 ]
 [  5.1210985]
 [ 18.034689 ]
 [  7.458847 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  7.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  8.  1. 16.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.88294792175293



buy possibilites: [-1] 
expected returns: [[8.561266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29.  1. 29. 25.  3.  0.  0. 25.  0.  3. 25. 29.  1.  1.  1.  1. 29. 29.
  1.  1. 29. 29. 29.  3.  0. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  8.  1. 16.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 167.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 20.070297241210938






Player: 1 
cards in hand: [ 6.  8.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  1. 16.  0.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6  6 16  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 21. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  0.  8.  0.  8.  0.  8.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  3. 29.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25.  3. 29.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 1.0256274]
 [15.076847 ]
 [19.65943  ]
 [19.65943  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  1. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.56126594543457



action possibilites: [-1. 25. 29. 25.] 
expected returns: [[24.224766]
 [37.638714]
 [41.81887 ]
 [37.638714]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 25.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.629854202270508



action possibilites: [-1. 25. 25.] 
expected returns: [[21.250473]
 [34.97103 ]
 [34.97103 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.] 
cards in discard: [3. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 27. 27.  8.  8.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.49730682373047



action possibilites: [-1] 
expected returns: [[89.28686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [3. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 27. 27.  8.  7.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.971031188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[82.49683 ]
 [96.5611  ]
 [87.854866]
 [52.96299 ]
 [13.825211]
 [91.3981  ]
 [92.74169 ]
 [85.101776]
 [97.99795 ]
 [90.88177 ]
 [96.1434  ]
 [90.43866 ]
 [80.88877 ]
 [95.785065]
 [83.37968 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [3. 1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 20. 30. 27. 27.  8.  7.  8.  9.  5.  6.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.28685760498047



buy possibilites: [-1] 
expected returns: [[48.242393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [ 3.  1. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 335 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 97.99795532226562






Player: 1 
cards in hand: [ 0.  3.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 27. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 20. 30. 27. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[51.524628]
 [69.118935]
 [69.118935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 29.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.242393493652344



action possibilites: [-1. 29.] 
expected returns: [[50.84568]
 [69.39534]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.83563232421875



action possibilites: [-1. 29.] 
expected returns: [[53.880302]
 [72.14436 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.82649230957031



action possibilites: [-1.] 
expected returns: [[97.21403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 66.65939331054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 96.77135 ]
 [110.80361 ]
 [102.10634 ]
 [ 67.57075 ]
 [ 28.965664]
 [105.64142 ]
 [106.934   ]
 [ 99.26375 ]
 [112.18121 ]
 [105.10917 ]
 [110.35183 ]
 [104.67439 ]
 [ 95.2085  ]
 [109.98198 ]
 [ 97.748474]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  5.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.21402740478516



buy possibilites: [-1] 
expected returns: [[74.594315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  1. 16.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
adversary owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 335 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 112.18120574951172






Player: 1 
cards in hand: [16.  0.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  1. 16.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 26. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  1.  3. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  1.  3. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 20. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  1.  3. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25. 29.  1.  3. 29.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25. 29.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 6.3123226]
 [18.688618 ]
 [22.846138 ]
 [22.846138 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  3. 29.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.59431457519531



action possibilites: [-1. 25. 29.] 
expected returns: [[23.22148 ]
 [35.58262 ]
 [39.541237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  1.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.8544979095459



action possibilites: [-1. 29.] 
expected returns: [[31.994534]
 [50.160114]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.62504577636719



action possibilites: [-1.] 
expected returns: [[19.95692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 30.387470245361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 17.39683  ]
 [ 31.546074 ]
 [-11.82481  ]
 [ 22.615366 ]
 [ -8.4046545]
 [-45.007202 ]
 [ 26.089283 ]
 [ 27.053473 ]
 [ 18.97478  ]
 [ 32.53499  ]
 [ 25.399897 ]
 [ 30.79797  ]
 [ 25.005938 ]
 [ 16.243343 ]
 [ 30.315674 ]
 [ 18.730007 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  4.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.956920623779297



buy possibilites: [-1] 
expected returns: [[43.12474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 32.53494644165039






Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  1. 25.  0.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  1. 25.  0.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  1. 25.  0.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  1. 25.  0.] 
adversary cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29. 29.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-10.171069 ]
 [  6.5446043]
 [  6.5446043]
 [  2.36984  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1. 25.  0.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.12474060058594



action possibilites: [-1. 25.] 
expected returns: [[ 3.3772376]
 [17.030521 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  0.] 
cards in discard: [ 3.  1. 25. 29. 29. 25. 25.  0.  0.  0.  1.  1.  1. 25. 29. 29. 29.  0.
  0.  3. 25.  1. 25. 29. 29. 29.  1.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 25. 27.  8.  7.  8.  9.  5.  3.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.50020432472229



action possibilites: [-1] 
expected returns: [[58.24108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  3.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.03050422668457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[57.513412]
 [71.69926 ]
 [62.903595]
 [29.18312 ]
 [-8.816131]
 [66.481705]
 [67.714676]
 [59.874012]
 [73.00625 ]
 [65.92057 ]
 [71.19319 ]
 [65.49314 ]
 [56.025085]
 [70.802704]
 [58.777435]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  3.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.24108123779297



buy possibilites: [-1] 
expected returns: [[59.00125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.  3.] 
cards in discard: [25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 73.00625610351562






Player: 1 
cards in hand: [8. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 3.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  3  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 6.  3.  0.  3.  0.  6. 11.  3.  1. 16.  0.  0.  1. 10.  8.  0.  0.  0.
  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  1.  1.  0.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 25.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[14.794882]
 [31.828976]
 [27.728855]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  1.  0.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.001251220703125



action possibilites: [-1. 25.] 
expected returns: [[35.442184]
 [48.793564]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  0.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 25. 27.  8.  6.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.699970245361328



action possibilites: [-1] 
expected returns: [[55.33722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29. 29.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 19. 30. 25. 27.  8.  5.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.79356384277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 54.733643]
 [ 69.262764]
 [ 60.180374]
 [ 25.046282]
 [-14.649445]
 [ 63.83541 ]
 [ 65.12441 ]
 [ 57.221874]
 [ 70.62983 ]
 [ 63.25376 ]
 [ 68.740685]
 [ 62.808075]
 [ 53.11859 ]
 [ 68.33597 ]
 [ 55.708286]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29. 29.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 19. 30. 25. 27.  8.  5.  8.  9.  5.  2.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.33721923828125



buy possibilites: [-1] 
expected returns: [[63.0793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29. 29.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -20   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 70.62982177734375






Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 19. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 25. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 19. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 25. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [6. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 25. 29.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[36.806747]
 [53.178886]
 [49.17112 ]
 [53.178886]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25. 29.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.07929992675781



action possibilites: [-1. 29.] 
expected returns: [[17.976921]
 [35.03038 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  3.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.20957946777344



action possibilites: [-1. 29.] 
expected returns: [[-2.2238216]
 [14.990112 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.886425018310547



action possibilites: [-1.] 
expected returns: [[12.469928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.799297332763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  9.674671]
 [ 22.93163 ]
 [ 14.740271]
 [-52.46815 ]
 [ 18.109606]
 [ 19.079704]
 [ 11.507534]
 [ 17.537613]
 [ 17.17031 ]
 [ 21.9506  ]
 [ 11.326154]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 18. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.469927787780762



buy possibilites: [-1] 
expected returns: [[-11.177541]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8. 11.  0.] 
adversary cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  120.    0.    0.   60.    0.    0.    0.    0.  -30.
   0.    0.   13.5   0. ] 
sum of rewards: 158.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.931598663330078






Player: 1 
cards in hand: [ 0.  6.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8. 11.  0.] 
cards in discard: [6. 1. 3. 0. 0. 0. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 25. 27.  8.  5.  8.  9.  5.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [6. 1. 3. 0. 0. 0. 1. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 25. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [6. 1. 3. 0. 0. 0. 1. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 17. 30. 25. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [6. 1. 3. 0. 0. 0. 1. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 24. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[ 0.43098187]
 [17.123116  ]
 [17.123116  ]
 [12.868109  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 24. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.17754077911377



action possibilites: [-1. 29. 25.] 
expected returns: [[-15.004586 ]
 [  1.8282769]
 [ -2.3566248]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 17. 30. 24. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.992449760437012



action possibilites: [-1. 25.] 
expected returns: [[-44.401443]
 [-31.753485]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 24. 27.  8.  5.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.2500619888305664



action possibilites: [-1] 
expected returns: [[-25.5632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 24. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -31.753482818603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-27.018347]
 [-13.808658]
 [-22.032633]
 [-78.69921 ]
 [-17.955038]
 [-25.753649]
 [-19.82662 ]
 [-25.563187]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 17. 30. 24. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.563199996948242



buy possibilites: [-1] 
expected returns: [[-11.954028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 25.] 
cards in discard: [25. 29. 25.  1.  0.  0. 25.  3.  1. 25. 29. 25.  1.  0.  0. 29. 29. 25.
  1.  1.  1. 29. 29. 29.  0.  3.  1.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 24. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  3.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3  6] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -13.808662414550781






Player: 1 
cards in hand: [ 8.  6. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16.  0.  3.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0
  6  1  8  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 24. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 23. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 16. 30. 23. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  1. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  3.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[34.373768]
 [51.9367  ]
 [47.683113]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 23. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  1. 10.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -11.954028129577637



action possibilites: [-1. 25. 25.] 
expected returns: [[38.86076 ]
 [53.430733]
 [53.430733]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 25.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 23. 27.  8.  4.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  1. 10.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.602142333984375



action possibilites: [-1] 
expected returns: [[61.507164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 29. 25.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 23. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  1. 10.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.43072509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.439102]
 [65.86846 ]
 [-6.975314]
 [62.700188]
 [61.840515]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 29. 25.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 16. 30. 23. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  1. 10.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.507164001464844



buy possibilites: [-1] 
expected returns: [[39.710964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 29. 25.] 
cards in discard: [1. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  1. 10.] 
adversary cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 65.86846160888672






Player: 1 
cards in hand: [ 3.  8.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  1. 10.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25. 25.  1.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1. 1.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25. 25.  1.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1. 1.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 16. 30. 22. 27.  8.  3.  8.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25. 25.  1.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1. 1.] 
cards in discard: [ 6.  1.  3.  0.  0.  0.  1.  8.  3. 11.  0.  6.  8.  0.  6.  3.  0. 16.
  8.  6.  3.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 22. 27.  8.  3.  7.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25. 25.  1.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[19.503601]
 [32.580135]
 [32.580135]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25. 25.  1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  3.  7.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.71096420288086



action possibilites: [-1] 
expected returns: [[5.1095695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  1. 25. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16  6] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.58013916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  3.288359 ]
 [ 16.865852 ]
 [  8.305365 ]
 [-24.133808 ]
 [-60.840233 ]
 [ 11.795915 ]
 [ 12.787777 ]
 [  5.3355722]
 [ 17.896244 ]
 [ 11.185659 ]
 [ 16.235376 ]
 [ 10.803957 ]
 [  1.7827094]
 [ 15.809093 ]
 [  4.7392797]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  1. 25. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  1.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16  6] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.109569549560547



buy possibilites: [-1] 
expected returns: [[22.072266]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.  1. 25. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16  6] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -60   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.8962459564209






Player: 1 
cards in hand: [6. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6
  1  8  3  6  3  0  6 16  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0. 25.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0. 25.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0. 25.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0. 25.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 29.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-14.331659 ]
 [  1.5728657]
 [  1.5728657]
 [ -2.3279905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  0. 25.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.072265625



action possibilites: [-1. 25. 29.] 
expected returns: [[-16.685848  ]
 [ -4.1962385 ]
 [ -0.05224729]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.2214694023132324



action possibilites: [-1. 29.] 
expected returns: [[-24.495037]
 [ -8.414731]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.07374382019043



action possibilites: [-1.] 
expected returns: [[-15.475917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -26.42043685913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-17.75661  ]
 [ -4.683977 ]
 [-12.7282295]
 [-75.69378  ]
 [ -8.561154 ]
 [-16.226942 ]
 [-10.367728 ]
 [-15.905061 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25] -> size -> 41 
action values: 1 
buys: 1 
player value: 3 
card supply: [22. 16. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -15.475916862487793



buy possibilites: [-1] 
expected returns: [[-3.5283647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  6.  0. 10.  8.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -4.684003829956055






Player: 1 
cards in hand: [ 8.  6.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10.  8.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0 11  8  0  0  8  6 16  0  8  3  1  6  3  3  1 10  6  0  6  1  8
  3  6  3  0  6 16  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6. 0. 8. 6. 6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 25.  0. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-18.360521 ]
 [ -5.712558 ]
 [ -1.5276594]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  0. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  3.] 
adversary cards in discard: [6. 0. 8. 6. 6. 0. 8. 6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.528364658355713



action possibilites: [-1. 25.] 
expected returns: [[ 9.912096]
 [23.035702]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 22. 27.  8.  2.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  3.] 
adversary cards in discard: [6. 0. 8. 6. 6. 0. 8. 6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -6.605999946594238



action possibilites: [-1] 
expected returns: [[-25.36345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 15. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  3.] 
adversary cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.035703659057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-26.65425 ]
 [-13.146145]
 [-21.634392]
 [-50.477566]
 [-78.74766 ]
 [-18.37734 ]
 [-17.439215]
 [-25.292349]
 [-19.033894]
 [-13.854034]
 [-19.41382 ]
 [-27.580997]
 [-14.313253]
 [-25.363447]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 15. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  3.] 
adversary cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.363449096679688



buy possibilites: [-1] 
expected returns: [[-22.632969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  3.] 
adversary cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.  -80.
   0.    0.   13.5   0. ] 
sum of rewards: 148.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -13.146146774291992






Player: 1 
cards in hand: [16.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  3.] 
cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  1.  1. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.  3.] 
cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  1.  1. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.  3.] 
cards in discard: [6. 0. 8. 6. 6. 0. 8. 6. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  1.  1. 29.] 
adversary cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-19.944803 ]
 [ -1.6857796]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  1. 29.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.63296890258789



action possibilites: [-1.] 
expected returns: [[-9.027271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.  1.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.18913459777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.865134 ]
 [  3.8749416]
 [-37.904472 ]
 [ -4.89911  ]
 [-34.396755 ]
 [-69.08774  ]
 [ -1.5856179]
 [ -0.5594981]
 [ -8.224855 ]
 [ -2.256177 ]
 [  3.1675327]
 [ -2.6604137]
 [-11.027496 ]
 [  2.6988237]
 [ -9.027267 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.  1.
  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 14. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.027271270751953



buy possibilites: [-1] 
expected returns: [[-16.446955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1.  3. 29. 25.  3.  0. 25. 29. 25. 25. 25.  0.  1. 25.  1. 25. 29. 29.
  1.  0. 25. 29.  1. 29. 29. 29.  1.  3.  1. 29. 25.  0.  0. 25.  1.  1.
  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1.  6.  0. 16.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: 148.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 3.8749501705169678






Player: 1 
cards in hand: [ 3.  1.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6.  0. 16.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6.  0. 16.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 8.617026]
 [26.480038]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.44695472717285



action possibilites: [-1.] 
expected returns: [[19.063503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [0. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.110145568847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 17.428722]
 [ 31.314468]
 [ 22.454561]
 [-43.741173]
 [ 25.949636]
 [ 27.072893]
 [ 19.504013]
 [ 25.364365]
 [ 24.957323]
 [ 30.225574]
 [ 18.513435]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [0. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 13. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.06350326538086



buy possibilites: [-1] 
expected returns: [[24.03571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [0. 0. 1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[  -5.     0.     0.   210.     0.     0.    20.     0.     0.     0.
    0.  -100.     0.     0.    13.5    0. ] 
sum of rewards: 138.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 31.314472198486328






Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 25. 25.  0.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 25. 25.  0.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 25. 25.  0.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-60.361607]
 [-63.10725 ]
 [-63.10725 ]
 [-63.10725 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 25.  0.] 
cards in discard: [ 0.  0.  1. 29.  3.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  6. 11.  3.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.035709381103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -76.6445  ]
 [ -70.78669 ]
 [-145.78856 ]
 [ -77.440575]
 [ -61.58287 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 25.  0.] 
cards in discard: [ 0.  0.  1. 29.  3.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  6. 11.  3.] 
adversary cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -60.361595153808594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  1.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  6. 11.  3.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.  1.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25.  1. 29. 25.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  6. 11.  3.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.  1.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25.  1. 29. 25.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  6. 11.  3.] 
cards in discard: [ 6.  0.  8.  6.  6.  0.  8.  6.  6.  0. 16.  3.  0.  3.  3.  3.  1.  6.
  0. 16. 14.  1.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25.  1. 29. 25.] 
adversary cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[64.96904 ]
 [77.801025]
 [81.72934 ]
 [77.801025]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1. 29. 25.] 
cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  1.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -61.582862854003906



action possibilites: [-1. 25.] 
expected returns: [[25.541222]
 [37.506042]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.] 
cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0. 25.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 12. 30. 22. 27.  8.  1.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  1.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.690673828125



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 14 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  1.  1. 29.] 
cards in discard: [ 0.  0.  1. 29.  3.  0.  1.  0. 25. 25. 25.  0. 25.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29 29 29  1 29 29 29 29 29 29  1 25
 25  1  1  1  1 25  1 25 25 25 25 25 25  1  1  3 25  1  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 12. 30. 22. 27.  8.  0.  7.  9.  4.  0.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  1.  6.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 1  0 11  0  0  8  6 16  0  8  3  1  6  3  3  1  6  0  6  1  8  3  6  3
  0  6 16  6  0  0  6  0 14  0  6] -> size -> 35 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     210       0       0      40       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000245 

action type: take_action - action 25.0
Learning step: 120008.296875
desired expected reward: 120045.8046875



