 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.974508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: 544 

action type: buy - action 11.0
Learning step: 15.463543891906738
desired expected reward: 44.01203918457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.840052]
 [20.938066]
 [19.757978]
 [16.016008]
 [19.365913]
 [22.717888]
 [21.799961]
 [22.779877]
 [18.975914]
 [20.619873]
 [21.073927]
 [21.338152]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5728132128715515
desired expected reward: 20.814104080200195



buy possibilites: [-1] 
expected returns: [[22.03754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.4091762900352478
desired expected reward: 21.483104705810547






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.754166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5590664744377136
desired expected reward: 21.478473663330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.925388]
 [24.053343]
 [22.856419]
 [19.091198]
 [25.858559]
 [24.927528]
 [23.730606]
 [24.459095]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6196203231811523
desired expected reward: 23.386066436767578



buy possibilites: [-1] 
expected returns: [[23.441965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.08545950055122375
desired expected reward: 23.967880249023438






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.494587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5718525648117065
desired expected reward: 22.870113372802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.420052]
 [26.566214]
 [25.353111]
 [22.753542]
 [21.557274]
 [24.95314 ]
 [28.395868]
 [27.452238]
 [30.149534]
 [28.459574]
 [24.5578  ]
 [24.217154]
 [26.23914 ]
 [22.090364]
 [26.70591 ]
 [26.977476]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6750087141990662
desired expected reward: 26.12559700012207



buy possibilites: [-1] 
expected returns: [[26.366882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6057493090629578
desired expected reward: 23.81430435180664






Player: 1 
cards in hand: [ 3.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 1. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 1. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 1. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 1. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.084837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 1. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6866583228111267
desired expected reward: 25.68022346496582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.884918]
 [24.01287 ]
 [22.815948]
 [19.058844]
 [22.418255]
 [25.835484]
 [24.891855]
 [25.899189]
 [22.022728]
 [23.690136]
 [24.150682]
 [24.418625]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 1. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6255511045455933
desired expected reward: 23.598085403442383



buy possibilites: [-1] 
expected returns: [[24.782284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  1.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5298504829406738
desired expected reward: 25.305633544921875






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[24.87872 ]
 [24.607658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6304304003715515
desired expected reward: 24.151853561401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.662428]
 [24.789219]
 [23.59295 ]
 [19.851685]
 [26.617405]
 [25.673775]
 [24.466688]
 [25.199013]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6464038491249084
desired expected reward: 24.513469696044922



buy possibilites: [-1] 
expected returns: [[22.894855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.11328060179948807
desired expected reward: 24.67593765258789






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.005358]
 [22.385094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 15.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6064273118972778
desired expected reward: 22.288427352905273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.485273]
 [21.534937]
 [20.377798]
 [17.89771 ]
 [16.773577]
 [19.996538]
 [23.329641]
 [22.39861 ]
 [25.059898]
 [23.392492]
 [19.61732 ]
 [19.29056 ]
 [21.221035]
 [17.270603]
 [21.66893 ]
 [21.930183]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 15.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5569732785224915
desired expected reward: 20.559785842895508



buy possibilites: [-1] 
expected returns: [[21.253614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0. 15.  3. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  3. 15.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 22.0
Learning step: 1.067760705947876
desired expected reward: 17.91450309753418






Player: 1 
cards in hand: [ 3. 10.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 15.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.526175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4854506850242615
desired expected reward: 20.768163681030273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.678911]
 [28.793655]
 [27.597046]
 [23.852152]
 [30.578495]
 [29.660366]
 [28.463757]
 [29.139292]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7130910158157349
desired expected reward: 28.063833236694336



buy possibilites: [-1] 
expected returns: [[24.973438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.20169146358966827
desired expected reward: 28.262062072753906






Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.753376]
 [27.173248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 15.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6190144419670105
desired expected reward: 24.35442352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.713398]
 [25.779154]
 [24.606413]
 [20.957031]
 [24.221998]
 [27.540003]
 [26.634207]
 [27.595158]
 [23.831305]
 [25.453655]
 [25.898758]
 [26.12013 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 15.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6553856134414673
desired expected reward: 25.177324295043945



buy possibilites: [-1] 
expected returns: [[29.46651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 15.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.29154372215270996
desired expected reward: 27.88669776916504






Player: 1 
cards in hand: [ 3.  3.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 15.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [15.  0. 22.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [15.  0. 22.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [15.  0. 22.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [15.  0. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22.] 
expected returns: [[26.636017]
 [26.428905]
 [22.207773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 22.  0.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.766817569732666
desired expected reward: 28.69969367980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.698448]
 [26.65034 ]
 [25.545895]
 [22.06597 ]
 [28.314758]
 [27.45498 ]
 [26.345837]
 [26.96928 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 22.  0.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6725389361381531
desired expected reward: 26.009052276611328



buy possibilites: [-1] 
expected returns: [[31.173235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 22.  0.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.  3.  0.  1.  0. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.13212375342845917
desired expected reward: 28.182634353637695






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [22.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[29.693604]
 [24.895916]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0. 15.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7923738956451416
desired expected reward: 30.380861282348633



action possibilites: [-1] 
expected returns: [[31.588158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 15. 11. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0. 15.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: LIBRARY: skip_action_card - action 1
Learning step: -0.14445853233337402
desired expected reward: 30.726680755615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.74559 ]
 [31.831175]
 [30.649788]
 [26.971823]
 [33.61601 ]
 [32.697884]
 [31.503353]
 [32.176804]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15. 11. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0. 15.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16539904475212097
desired expected reward: 31.422758102416992



buy possibilites: [-1] 
expected returns: [[33.14034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15. 11. 11.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0. 15.] 
adversary cards in discard: [8. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.09407981485128403
desired expected reward: 29.64103126525879






Player: 1 
cards in hand: [10.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 15.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [8. 8. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.43804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8866714239120483
desired expected reward: 32.253665924072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.20876 ]
 [25.245632]
 [22.064768]
 [24.085659]
 [21.624485]
 [20.51134 ]
 [23.703146]
 [26.95858 ]
 [26.07858 ]
 [28.616032]
 [27.006271]
 [23.310503]
 [22.979656]
 [24.918612]
 [20.978775]
 [25.348816]
 [25.520636]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6220754384994507
desired expected reward: 23.905418395996094



buy possibilites: [-1] 
expected returns: [[24.230185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.  2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  0.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1767 

action type: buy - action 2.0
Learning step: 52.60247039794922
desired expected reward: 74.667236328125






Player: 1 
cards in hand: [10.  0.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.  2.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.  2.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.564032]
 [23.009466]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.  2.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [10.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6309324502944946
desired expected reward: 23.599252700805664



action possibilites: [-1. 29.] 
expected returns: [[23.380808]
 [24.845953]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [ 0. 22.  3.  3.  0.  1. 15. 11. 11.  2.  0.  0.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [10.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.011930751614272594
desired expected reward: 23.105201721191406



action possibilites: [-1.] 
expected returns: [[31.35312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [10.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.6338290572166443
desired expected reward: 25.47978401184082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[29.109226]
 [31.172585]
 [29.989218]
 [27.50401 ]
 [26.375132]
 [29.606703]
 [32.933014]
 [32.028637]
 [34.63648 ]
 [32.982147]
 [29.212408]
 [28.87694 ]
 [30.83648 ]
 [26.849192]
 [31.278683]
 [31.45526 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 29. 29. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [10.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.4366871416568756
desired expected reward: 31.78980827331543



buy possibilites: [-1] 
expected returns: [[37.092613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [10.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 43.0 

action type: buy - action 16.0
Learning step: 0.7912712097167969
desired expected reward: 30.397977828979492






Player: 1 
cards in hand: [0. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [10.  0.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 10  8  8  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  2.  0.  1.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  0.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  2.  0.  1.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  0.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  7. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  2.  0.  1.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  0.  8.  3.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  2.  0.  1.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  2.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[30.66319 ]
 [32.140945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  2.  0.  1.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9304215908050537
desired expected reward: 36.162193298339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.986607]
 [31.083138]
 [27.807785]
 [29.890978]
 [27.35182 ]
 [26.193808]
 [29.497908]
 [32.843563]
 [31.939184]
 [34.547028]
 [32.8927  ]
 [29.0927  ]
 [28.748505]
 [30.747028]
 [26.680082]
 [31.189236]
 [31.36581 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  2.  0.  1.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 28. 29. 29. 30.  8. 10.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7480184435844421
desired expected reward: 30.018352508544922



buy possibilites: [-1] 
expected returns: [[27.42158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  2.  0.  1.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 7 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.647887229919434
desired expected reward: 16.54592514038086






Player: 1 
cards in hand: [ 0.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.  1.  0.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.  1.  0.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6. 10.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.  1.  0.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 11.  0.  1.  0.] 
adversary cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[28.13991 ]
 [29.569384]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  1.  0.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9. 10. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  8.  3.  0. 10.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6675270795822144
desired expected reward: 26.754053115844727



action possibilites: [-1] 
expected returns: [[32.613556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  8.  3.  0. 10.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.4098525047302246
desired expected reward: 29.1628475189209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.414728]
 [32.511265]
 [31.319103]
 [27.586655]
 [30.926035]
 [34.27169 ]
 [33.36731 ]
 [34.320827]
 [30.520824]
 [32.175156]
 [32.617363]
 [32.793938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16. 10. 29.  3.  0.  0.  0.  0.  6.  0. 11.  2.  0.  1. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  8.  3.  0. 10.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.18835550546646118
desired expected reward: 32.425201416015625






Player: 1 
cards in hand: [ 8.  8.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  0. 10.] 
cards in discard: [25. 15.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0. 22. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3.  0. 10.] 
cards in discard: [25. 15.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0. 22. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3.  0. 10.] 
cards in discard: [25. 15.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0. 22. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 22. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.] 
expected returns: [[30.39305 ]
 [25.947662]
 [30.278473]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22. 15.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.821745753288269
desired expected reward: 31.80262565612793



action possibilites: [-1] 
expected returns: [[34.870644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: LIBRARY: skip_action_card - action 0
Learning step: 0.5673660039901733
desired expected reward: 28.859891891479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.062916]
 [35.061302]
 [33.916027]
 [30.36045 ]
 [36.730488]
 [35.877377]
 [34.7321  ]
 [35.25887 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 29. 29. 30.  8.  9.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.36976420879364014
desired expected reward: 35.24040603637695



buy possibilites: [-1] 
expected returns: [[30.712093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  3.  0.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.538335800170898
desired expected reward: 21.822118759155273






Player: 1 
cards in hand: [ 3. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3 10  8  8  0  8 25  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  2.  6.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  3  8  8  0  8 25  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  2.  6.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  3  8  8  0  8 25  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  2.  6.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16. 11.  2.  6.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 16. 11.  2.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[26.869074]
 [25.181114]
 [28.321613]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  2.  6.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  9.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0. 15.  8.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7862350344657898
desired expected reward: 29.925857543945312



action possibilites: [-1] 
expected returns: [[28.2516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  2.  6.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0. 15.  8.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.5037270784378052
desired expected reward: 24.60088539123535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.474373]
 [28.420332]
 [27.305101]
 [23.842789]
 [26.943766]
 [30.059418]
 [29.21887 ]
 [30.099928]
 [26.55516 ]
 [28.09976 ]
 [28.501118]
 [28.612724]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  2.  6.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  0. 15.  8.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10044479370117188
desired expected reward: 28.151155471801758



buy possibilites: [-1] 
expected returns: [[26.625372]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  2.  6.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  0. 15.  8.  0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.021573714911937714
desired expected reward: 28.1213321685791






Player: 1 
cards in hand: [ 8.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  8.  0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  3  8  8  0  8 25  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  0.  1.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15  3  8  8  0  8 25  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  0.  1.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15  3  8  8  0  8 25  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 14. 10.  0.  1.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0. 14. 10.  0.  1.] 
adversary cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 14. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[27.666504]
 [25.61854 ]
 [27.150085]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  0.  1.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6653461456298828
desired expected reward: 25.960025787353516



action possibilites: [-1. 14.] 
expected returns: [[30.129047]
 [28.050392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  1.  0.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.057113226503133774
desired expected reward: 27.100814819335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.056698]
 [30.113745]
 [28.925331]
 [26.51785 ]
 [25.4645  ]
 [28.543888]
 [31.848955]
 [30.962105]
 [33.54072 ]
 [31.891829]
 [28.138021]
 [27.812075]
 [29.771465]
 [25.890959]
 [30.200068]
 [30.319153]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  1.  0.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.13773736357688904
desired expected reward: 29.99131202697754



buy possibilites: [-1] 
expected returns: [[35.525463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  1.  0.] 
cards in discard: [ 6. 22. 11.  0.  0. 15.  3.  3.  0.  3. 29. 10. 11.  0. 16.  2.  6. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 23.0
Learning step: 1.4886553287506104
desired expected reward: 29.300724029541016






Player: 1 
cards in hand: [ 8.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  3  8  8  0  8 25  0  0 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  8  8  8 25  0  0 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  8  8  8 25  0  0 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  3  8  8  8 25  0  0 15  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 29.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[30.650639]
 [32.180447]
 [32.223316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 15.  8.  0.  8.] 
adversary cards in discard: [ 0.  8. 25.  3.] 
adversary owned cards: [ 3 15  3  8  8  8 25  0  0 15  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8815786838531494
desired expected reward: 34.643882751464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.795856]
 [30.873352]
 [29.68271 ]
 [25.992037]
 [29.296976]
 [32.60857 ]
 [31.721718]
 [32.651436]
 [28.882183]
 [30.53107 ]
 [30.959682]
 [31.078762]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 15.  8.  0.  8.] 
adversary cards in discard: [ 0.  8. 25.  3.] 
adversary owned cards: [ 3 15  3  8  8  8 25  0  0 15  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7478387951850891
desired expected reward: 29.937456130981445



buy possibilites: [-1] 
expected returns: [[33.015102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  1.  0.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15. 15.  8.  0.  8.] 
adversary cards in discard: [ 0.  8. 25.  3.] 
adversary owned cards: [ 3 15  3  8  8  8 25  0  0 15  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.18297968804836273
desired expected reward: 32.63894271850586






Player: 1 
cards in hand: [15. 15.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  8.  0.  8.] 
cards in discard: [ 0.  8. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  8  8  8 25  0  0 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 3. 15.  0.  2.  0.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.] 
cards in discard: [ 0.  8. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  8  8  8 25  0 15  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 3. 15.  0.  2.  0.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.] 
cards in discard: [ 0.  8. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  8  8  8 25  0 15  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 29. 29. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 3. 15.  0.  2.  0.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.] 
cards in discard: [ 0.  8. 25.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15  3  8  8  8 25  0 15  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 3. 15.  0.  2.  0.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0.  2.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[35.60272 ]
 [35.540485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  2.  0.] 
cards in discard: [29. 11. 29.  0.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [25. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  8  8  8 25  0 15  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7664170265197754
desired expected reward: 32.24868392944336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.771317]
 [35.752182]
 [34.609673]
 [32.19143 ]
 [31.090763]
 [34.24457 ]
 [37.398743]
 [36.56039 ]
 [39.01451 ]
 [37.434628]
 [33.837997]
 [33.503044]
 [35.41788 ]
 [31.522177]
 [35.81886 ]
 [35.881096]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  2.  0.] 
cards in discard: [29. 11. 29.  0.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  8.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [25. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  8  8  8 25  0 15  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.844514787197113
desired expected reward: 34.802860260009766



buy possibilites: [-1] 
expected returns: [[32.166958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  2.  0.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [25. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15  3  8  8  8 25  0 15  0  3] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.7992093563079834
desired expected reward: 36.59953689575195






Player: 1 
cards in hand: [25. 15.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  3  8  8  8 25  0 15  0  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8  8 25 15  0  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8  8 25 15  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 15.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.315838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15.  3.  3.  8.] 
adversary cards in discard: [ 0.  8. 25. 15.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8278778791427612
desired expected reward: 31.339080810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.808361]
 [27.455154]
 [26.491518]
 [23.630562]
 [28.88735 ]
 [28.155624]
 [27.165298]
 [27.566902]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  7.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15.  3.  3.  8.] 
adversary cards in discard: [ 0.  8. 25. 15.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6837915778160095
desired expected reward: 26.662002563476562



buy possibilites: [-1] 
expected returns: [[27.951473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15.  3.  3.  8.] 
adversary cards in discard: [ 0.  8. 25. 15.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.18313007056713104
desired expected reward: 28.704221725463867






Player: 1 
cards in hand: [ 8. 15.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  3.  8.] 
cards in discard: [ 0.  8. 25. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 14.  3.  6. 23.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8.] 
cards in discard: [ 0.  8. 25. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 14.  3.  6. 23.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8.] 
cards in discard: [ 0.  8. 25. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11. 14.  3.  6. 23.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 14.  3.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 23.] 
expected returns: [[25.066006]
 [26.387745]
 [23.309904]
 [23.02285 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  6. 23.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7277782559394836
desired expected reward: 27.223695755004883



action possibilites: [-1. 11. 14. 22.] 
expected returns: [[24.648544]
 [26.04422 ]
 [22.838078]
 [20.860764]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  6. 22.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [ 8. 15.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.012229728512465954
desired expected reward: 23.035079956054688



action possibilites: [-1] 
expected returns: [[23.373484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6. 22.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.6102792024612427
desired expected reward: 23.44835662841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.482847]
 [23.11401 ]
 [22.168793]
 [19.325447]
 [24.536104]
 [23.812017]
 [22.83496 ]
 [23.22526 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6. 22.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11] -> size -> 31 
action values: 0 
buys: 2 
player value: 3 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  7.  9.  7.] 
adversary cards in hand: [15.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5898457169532776
desired expected reward: 23.963329315185547



buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.979282]
 [17.819717]
 [21.74599 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6. 22.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: buy - action 10.0
Learning step: 0.8473436832427979
desired expected reward: 23.68230438232422



buy possibilites: [-1] 
expected returns: [[21.566265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6. 22.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: buy - action 0.0
Learning step: 0.677067220211029
desired expected reward: 20.656349182128906






Player: 1 
cards in hand: [15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.] 
cards in discard: [8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  0. 10. 10. 16.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  0. 10. 10. 16.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [8. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  0. 10. 10. 16.] 
adversary cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 16.] 
expected returns: [[21.86677 ]
 [23.112213]
 [21.495365]
 [21.495365]
 [20.557642]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 10. 16.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5661263465881348
desired expected reward: 21.000139236450195



action possibilites: [-1. 29. 10. 16.] 
expected returns: [[21.822334]
 [23.151262]
 [21.429203]
 [20.440453]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 16.  0.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.036127567291259766
desired expected reward: 21.531490325927734



action possibilites: [-1. 10. 16.] 
expected returns: [[23.379576]
 [23.050138]
 [22.084637]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0.  1.] 
cards in discard: [29. 11. 29.  0.  1.  0. 11.  3. 15.  0.  2.  0. 11.  0.  6.  0.  0.  3.
 10.  0. 23. 14. 11.  3.  6. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.5945402383804321
desired expected reward: 23.745803833007812



action possibilites: [-1. 16.] 
expected returns: [[36.24954]
 [34.6983 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  1  0 11  1 22 10 29 11  0  2 16  6 14
  6 29 10 23 29 11 11 10  0] -> size -> 33 
action values: 3 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 28. 30.  8.  8.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.3326008319854736
desired expected reward: 24.382740020751953



action possibilites: [-1.] 
expected returns: [[35.94268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 28. 30.  8.  7.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   80    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -225 

action type: gain_card_n - action 4
Learning step: -7.421661376953125
desired expected reward: 27.547000885009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.109615]
 [36.064045]
 [34.928978]
 [31.453436]
 [34.57122 ]
 [37.682304]
 [36.862934]
 [37.71264 ]
 [34.161526]
 [35.727867]
 [36.115963]
 [36.12246 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 29. 28. 30.  8.  7.  9.  6.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 1.5487751960754395
desired expected reward: 37.491455078125



buy possibilites: [-1] 
expected returns: [[30.99317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 29. 28. 30.  8.  7.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8.  3. 25.  0.] 
adversary cards in discard: [ 8.  3.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 79.5 

action type: buy - action 11.0
Learning step: 1.5799592733383179
desired expected reward: 39.26226043701172






Player: 1 
cards in hand: [15.  8.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3. 25.  0.] 
cards in discard: [ 8.  3.  0. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 28. 30.  8.  7.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [14. 22. 29.  0.  0.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11] -> size -> 34 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 28. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [14. 22. 29.  0.  0.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 29. 28. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [14. 22. 29.  0.  0.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  3.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 27. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [14. 22. 29.  0.  0.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [14. 22. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 29.] 
expected returns: [[24.577082]
 [22.767569]
 [20.76415 ]
 [26.073168]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 22. 29.  0.  0.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 27. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.827115058898926
desired expected reward: 21.166053771972656



action possibilites: [-1] 
expected returns: [[25.60183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  0.  0.  6. 11.  6.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 27. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: LIBRARY: skip_action_card - action 1
Learning step: 0.5229668021202087
desired expected reward: 27.051380157470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.757185]
 [24.477724]
 [21.461586]
 [26.274305]
 [25.581806]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  0.  0.  6. 11.  6.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 29. 27. 30.  8.  6.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.541329562664032
desired expected reward: 26.143159866333008



buy possibilites: [-1] 
expected returns: [[23.406374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  0.  0.  6. 11.  6.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -266.0 

action type: buy - action 6.0
Learning step: -8.378080368041992
desired expected reward: 13.083503723144531






Player: 1 
cards in hand: [ 3.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 2.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 2.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 15.  8.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 2.  0.  3.  0. 11.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 2.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.621391]
 [26.00695 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0.  3.  0. 11.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 15.  8.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.584937572479248
desired expected reward: 22.821435928344727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.028242]
 [24.712513]
 [23.73285 ]
 [21.69613 ]
 [20.789099]
 [23.42507 ]
 [26.134607]
 [25.412075]
 [27.585464]
 [26.162218]
 [23.072893]
 [22.78275 ]
 [24.419819]
 [21.137915]
 [24.75796 ]
 [24.763577]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  3.  0. 11.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 15.  8.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6293153166770935
desired expected reward: 23.992076873779297



buy possibilites: [-1] 
expected returns: [[23.782843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  3.  0. 11.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0. 15.  8.] 
adversary owned cards: [15  3  8  8  8 25 15  0  3  0  0  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.6511273980140686
desired expected reward: 22.377113342285156






Player: 1 
cards in hand: [0. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8  8 25 15  0  3  0  0  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  3.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  3.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  3.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3.  0. 15.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [29.  1.  0. 11.  3.] 
adversary cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  1.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[17.722471]
 [18.962198]
 [18.938116]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 11.  3.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  8. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6679208278656006
desired expected reward: 23.11492156982422



action possibilites: [-1. 11. 23.] 
expected returns: [[18.69552 ]
 [19.905642]
 [17.03977 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3. 23.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  8. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.08163024485111237
desired expected reward: 18.94717025756836



action possibilites: [-1. 11.] 
expected returns: [[18.94592 ]
 [20.291328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3.  0.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 2 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  8. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 23.0
Learning step: 0.7462151646614075
desired expected reward: 17.785985946655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.52946 ]
 [19.05774 ]
 [16.659725]
 [18.16527 ]
 [16.33714 ]
 [15.558413]
 [17.88438 ]
 [20.332449]
 [19.689686]
 [21.649792]
 [20.346584]
 [17.557062]
 [17.289251]
 [18.79038 ]
 [15.842122]
 [19.085644]
 [19.04554 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.  0.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0] -> size -> 37 
action values: 0 
buys: 2 
player value: 6 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  9.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  8. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6806688904762268
desired expected reward: 19.626590728759766



buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.17679 ]
 [17.957592]
 [21.794352]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.  0.] 
cards in discard: [ 6. 11. 10. 29. 10. 16.  0.  0.  0.  6.  6. 22. 10. 14. 29.  0.  0.  6.
 11.  6.  0.  2.  0.  3.  0. 11. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  8. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0 25  0] 
sum of rewards: 57 

action type: buy - action 25.0
Learning step: 1.2740745544433594
desired expected reward: 22.92386817932129






Player: 1 
cards in hand: [ 0. 15.  8. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 15. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  5.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25] -> size -> 38 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6] -> size -> 39 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 15.  3.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6] -> size -> 39 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[29.474089]
 [31.036966]
 [29.522795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25.  0. 15.  8. 15.  3.  3.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -4    0 -300
    0    0] 
sum of rewards: -309 

action type: buy - action -1.0
Learning step: -9.60622501373291
desired expected reward: 12.188126564025879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.658588]
 [28.439192]
 [25.177969]
 [30.30221 ]
 [29.51993 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  6.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25.  0. 15.  8. 15.  3.  3.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7344932556152344
desired expected reward: 28.771249771118164



buy possibilites: [-1] 
expected returns: [[27.200346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [6. 8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  5.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [25.  0. 15.  8. 15.  3.  3.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0  8  0] 
sum of rewards: -2 

action type: buy - action 8.0
Learning step: -0.6834625601768494
desired expected reward: 29.618743896484375






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.  0. 15.  8. 15.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  5.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  2.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.  0. 15.  8. 15.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  5.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  2.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.  0. 15.  8. 15.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  4.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  2.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.684282]
 [31.223925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  2.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  4.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  8.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6446256637573242
desired expected reward: 26.555721282958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.779299]
 [29.627537]
 [28.548298]
 [26.287617]
 [25.25708 ]
 [28.208572]
 [31.152622]
 [30.383623]
 [32.661133]
 [31.169443]
 [27.812704]
 [27.48589 ]
 [29.30439 ]
 [25.637655]
 [29.660938]
 [29.612982]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  2.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  4.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  8.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7301304340362549
desired expected reward: 28.954151153564453



buy possibilites: [-1] 
expected returns: [[26.899033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  2.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  8.  3. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -6.  0.  0.  2.  0.] 
sum of rewards: -9.0 

action type: buy - action 8.0
Learning step: -0.8990688323974609
desired expected reward: 29.484554290771484






Player: 1 
cards in hand: [ 0.  8.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 15.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [11. 29.  1. 29.  0.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 15.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [11. 29.  1. 29.  0.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 29.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[19.154001]
 [20.456587]
 [20.470947]
 [20.470947]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1. 29.  0.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 15.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.  8.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7448217868804932
desired expected reward: 26.154211044311523



action possibilites: [-1. 11. 29.] 
expected returns: [[22.95743 ]
 [24.27639 ]
 [24.290747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  0.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 15.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.  8.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.0871509313583374
desired expected reward: 20.55809783935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.35984 ]
 [22.89963 ]
 [21.995636]
 [19.312101]
 [21.714756]
 [24.1944  ]
 [23.538057]
 [24.208755]
 [21.38741 ]
 [22.626781]
 [22.9278  ]
 [22.88729 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  0.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  9.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 15.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.  8.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.0004521560622379184
desired expected reward: 22.957883834838867



buy possibilites: [-1] 
expected returns: [[25.337784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  0.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 15.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 15.  8.] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 32  0] 
sum of rewards: 40 

action type: buy - action 14.0
Learning step: 0.8244243860244751
desired expected reward: 22.211835861206055






Player: 1 
cards in hand: [ 0. 25. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.  3.  3.] 
cards in discard: [ 0.  8.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  4.  9.  5.  3.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23. 16. 10. 11. 29.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14] -> size -> 42 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  0.  0.] 
cards in discard: [ 0.  8.  3. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  3.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23. 16. 10. 11. 29.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6] -> size -> 43 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  0.  0.] 
cards in discard: [ 0.  8.  3. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  3.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23. 16. 10. 11. 29.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6] -> size -> 43 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  0.  0.] 
cards in discard: [ 0.  8.  3. 15.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23. 16. 10. 11. 29.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6] -> size -> 43 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [23. 16. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16. 10. 11. 29.] 
expected returns: [[21.311966]
 [19.443552]
 [20.072569]
 [21.038578]
 [22.707594]
 [22.722958]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16. 10. 11. 29.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -8    0 -300
    0    0] 
sum of rewards: -313 

action type: buy - action -1
Learning step: -9.924199104309082
desired expected reward: 15.41358470916748



action possibilites: [-1. 23. 16. 10. 11. 11.] 
expected returns: [[21.831726]
 [19.97468 ]
 [20.622742]
 [21.604393]
 [23.312592]
 [23.312592]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16. 10. 11. 11.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  7.  8.  9.  6.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -6.809234764659777e-05
desired expected reward: 22.722888946533203



action possibilites: [-1] 
expected returns: [[21.66802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16. 10. 11.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -9  0  0 16  0] 
sum of rewards: 42 

action type: gain_card_n - action 7
Learning step: 0.8995000123977661
desired expected reward: 20.499975204467773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.116016]
 [17.957752]
 [21.668018]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 16. 10. 11.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6127392649650574
desired expected reward: 22.280759811401367






Player: 1 
cards in hand: [0. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  0  3  0  0  3  0  0  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 25.  0.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.49893 ]
 [30.455103]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  0.  6.  0.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  3.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8. 25.  3.  0.] 
adversary cards in discard: [8. 3. 8. 0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4926779866218567
desired expected reward: 21.175342559814453



action possibilites: [-1] 
expected returns: [[31.452963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8. 25.  3.  0.] 
adversary cards in discard: [8. 3. 8. 0. 6.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.1333969682455063
desired expected reward: 30.321706771850586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.741375]
 [31.52977 ]
 [30.481668]
 [27.310007]
 [33.000217]
 [32.25993 ]
 [31.211832]
 [31.452963]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8. 25.  3.  0.] 
adversary cards in discard: [8. 3. 8. 0. 6.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16495129466056824
desired expected reward: 31.28801155090332



buy possibilites: [-1] 
expected returns: [[28.817884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0. 3.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  8. 25.  3.  0.] 
adversary cards in discard: [8. 3. 8. 0. 6.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0  18   0] 
sum of rewards: 23 

action type: buy - action 1.0
Learning step: 0.04669469594955444
desired expected reward: 31.576461791992188






Player: 1 
cards in hand: [15.  8. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 25.  3.  0.] 
cards in discard: [8. 3. 8. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1. 25.  6.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1] -> size -> 45 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 25.  3.  0.] 
cards in discard: [8. 3. 8. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1. 25.  6.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1] -> size -> 45 
adversary victory points: -4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.828804]
 [22.594917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1. 25.  6.  0.  6.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7758164405822754
desired expected reward: 28.042068481445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.16995 ]
 [22.903337]
 [21.88647 ]
 [18.815857]
 [24.33005 ]
 [23.611786]
 [22.594915]
 [22.828804]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1. 25.  6.  0.  6.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 29. 27. 30.  8.  2.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5967227220535278
desired expected reward: 22.232080459594727



buy possibilites: [-1] 
expected returns: [[22.427866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [ 6.  8.  0.  0. 11. 15.  3.  8.  0. 11.  3.  0.  2. 14. 29. 11.  1. 29.
  0.  6.  6. 29. 29. 11. 23. 16. 10. 11.  1. 25.  6.  0.  6.  0.  0.  3.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  8.  0.] 
adversary cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -11.
    0. -300.    0.    0.] 
sum of rewards: -316.0 

action type: buy - action 6.0
Learning step: -9.808982849121094
desired expected reward: 9.006874084472656






Player: 1 
cards in hand: [ 0. 15.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  8.  0.] 
cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  0  3  0  0  8  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  6. 14. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  6. 14. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  5.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  6. 14. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 8.  3.  8.  0.  6. 15.  8. 25.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  4.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  6. 14. 10. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  6. 14. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10. 22.] 
expected returns: [[26.95569 ]
 [28.588472]
 [25.179995]
 [26.701168]
 [22.987999]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 14. 10. 22.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  4.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5437058210372925
desired expected reward: 21.8841609954834



action possibilites: [-1] 
expected returns: [[25.388819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 10. 22.] 
cards in discard: [11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -12   0   0   9   0] 
sum of rewards: 12 

action type: gain_card_n - action 5
Learning step: -0.13873443007469177
desired expected reward: 25.37183380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.612581]
 [21.141155]
 [25.344442]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10. 22.] 
cards in discard: [11.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.062166307121515274
desired expected reward: 25.32665252685547



buy possibilites: [-1] 
expected returns: [[27.14633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10. 22.] 
cards in discard: [11.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [15.  6.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0   0   0] 
sum of rewards: 2 

action type: buy - action 0.0
Learning step: -0.36334097385406494
desired expected reward: 23.24924087524414






Player: 1 
cards in hand: [15.  6.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [29.  0.  2. 16. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0] -> size -> 48 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [29.  0.  2. 16. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0] -> size -> 48 
adversary victory points: -5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  0.  2. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11.] 
expected returns: [[21.422443]
 [22.830564]
 [20.251251]
 [22.823458]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  2. 16. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 29 11  0  2 16  6 14  6
 29 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  6.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [15.  6.  3.  8. 11.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.73305743932724
desired expected reward: 26.413272857666016



action possibilites: [-1] 
expected returns: [[21.159912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [15.  6.  3.  8. 11.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 18 

action type: gain_card_n - action 10
Learning step: 0.14424510300159454
desired expected reward: 20.74204444885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.894983]
 [21.224112]
 [20.443617]
 [18.078512]
 [20.197363]
 [22.324215]
 [21.765306]
 [22.327559]
 [19.90417 ]
 [20.983747]
 [21.233297]
 [21.131145]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  3.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [15.  6.  3.  8. 11.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03674611821770668
desired expected reward: 21.196659088134766



buy possibilites: [-1] 
expected returns: [[22.416502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  2.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 15.  8.  0.] 
adversary cards in discard: [15.  6.  3.  8. 11.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -14.
   0.    0.    4.5   0. ] 
sum of rewards: 5.5 

action type: buy - action 11.0
Learning step: -0.26935312151908875
desired expected reward: 22.054859161376953






Player: 1 
cards in hand: [ 0.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  0.] 
cards in discard: [15.  6.  3.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  2.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23.  0.  6.  6.  3.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  0.] 
cards in discard: [15.  6.  3.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  2.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23.  0.  6.  6.  3.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  8.  0.] 
cards in discard: [15.  6.  3.  8. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [23.  0.  6.  6.  3.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [23.  0.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[15.645982]
 [14.146394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  6.  3.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  8.] 
adversary cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 16 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6645104885101318
desired expected reward: 21.751991271972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.384501]
 [12.584386]
 [15.670472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  6.  3.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3. 25.  8.  8.] 
adversary cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.] 
adversary owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 16 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4670812487602234
desired expected reward: 15.178900718688965



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 25.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  8.  8.] 
cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  6. 25.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.] 
cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  6. 25.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.] 
cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  6. 25.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.] 
cards in discard: [15.  6.  3.  8. 11. 11.  0.  0. 15.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  6. 25.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 25.] 
expected returns: [[15.403827]
 [16.58174 ]
 [16.026978]
 [17.69756 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  6. 25.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  1.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.44495800137519836
desired expected reward: 15.225513458251953



action possibilites: [-1] 
expected returns: [[19.068108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  6. 10. 10.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 16 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.11928834766149521
desired expected reward: 17.81684684753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.79033 ]
 [19.068108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  6. 10. 10.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 15.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 16 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0728052482008934
desired expected reward: 19.140913009643555






Player: 1 
cards in hand: [ 3.  0.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 15.  6.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  0.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  0.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  0. 29.  6.  0.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
adversary victory points: -5
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.996695]
 [20.212233]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6.  0.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6.] 
adversary owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5149200558662415
desired expected reward: 18.55318832397461



action possibilites: [-1.] 
expected returns: [[17.659609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6.] 
adversary owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.06268879026174545
desired expected reward: 19.1539249420166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.337553]
 [17.759136]
 [16.924377]
 [16.660933]
 [18.937054]
 [18.336855]
 [18.940596]
 [16.34743 ]
 [17.502096]
 [17.769014]
 [17.659609]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  5.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6.] 
adversary owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.10750219225883484
desired expected reward: 17.76711082458496



buy possibilites: [-1] 
expected returns: [[15.33999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 8. 11.  8.  3.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6.] 
adversary owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0  32   0] 
sum of rewards: 32 

action type: buy - action 29.0
Learning step: 0.5528519749641418
desired expected reward: 19.49344825744629






Player: 1 
cards in hand: [ 8. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  3.  0.] 
cards in discard: [6. 8. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 25 15  3  0  3  0  0  8  8  6 11 11  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  0.  6. 14. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 8. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  0.  6. 14. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 8. 3. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  0.  6. 14. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
adversary victory points: -5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 8. 3. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11.  0.  6. 14. 11.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
adversary victory points: -5
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11.  0.  6. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
expected returns: [[15.957841]
 [17.248148]
 [14.719106]
 [17.248148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 14. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 8. 0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.43711477518081665
desired expected reward: 14.902874946594238





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[14.41949 ]
 [15.643691]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 14. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 8. 0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.46019360423088074
desired expected reward: 15.183497428894043



buy possibilites: [-1] 
expected returns: [[15.904707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 14. 11.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0. 25. 11. 15.  0.] 
adversary cards in discard: [6. 8. 3. 0. 6. 0. 8. 0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -0.8955852389335632
desired expected reward: 13.523904800415039






Player: 1 
cards in hand: [ 0. 25. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11. 15.  0.] 
cards in discard: [6. 8. 3. 0. 6. 0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  4.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 15.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
adversary victory points: -5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  8.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 15.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  8.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  2.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 15.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
adversary victory points: -5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 15.  0.] 
cards in discard: [ 6.  8.  3.  0.  6.  0.  8.  0. 29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  6.  8.  3. 15.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
adversary victory points: -5
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[16.654898]
 [17.440567]
 [16.807737]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  3. 15.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 11  1 22 10 11  0  2 16  6 14  6 29
 10 23 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29
 11 29  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [25.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44798702001571655
desired expected reward: 15.456720352172852



action possibilites: [-1] 
expected returns: [[18.932663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [25.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.07832267880439758
desired expected reward: 19.0939998626709





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.660604]
 [18.932665]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [25.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0754704624414444
desired expected reward: 19.008132934570312






Player: 1 
cards in hand: [25.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
adversary victory points: -6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
adversary victory points: -6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
adversary victory points: -6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11. 15.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 29.  0.  6.] 
adversary cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
adversary victory points: -6
player victory points: -1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.245582]
 [16.643707]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  6.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  8. 29.  8.] 
adversary cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5490930676460266
desired expected reward: 18.383569717407227



action possibilites: [-1.] 
expected returns: [[11.353745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  8. 29.  8.] 
adversary cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.10749981552362442
desired expected reward: 15.4979829788208





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.140614]
 [11.481954]
 [10.687065]
 [ 9.066507]
 [10.439291]
 [12.612897]
 [12.038794]
 [13.773445]
 [12.613395]
 [10.144105]
 [ 9.905943]
 [11.231862]
 [ 8.589822]
 [11.485524]
 [11.353745]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  3.  8. 29.  8.] 
adversary cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2310282588005066
desired expected reward: 11.584774017333984



buy possibilites: [-1] 
expected returns: [[13.776704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [11.  0. 11.  6. 14. 10. 22. 29. 11. 16.  0.  2. 11. 23.  0.  6.  6.  3.
 25.  3. 11.  8.  6. 10. 10. 29. 29. 29.  0.  0.  6.  0.  0. 11.  0.  6.
 14. 11.  8.  0.  6.  1. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 6.  3.  8. 29.  8.] 
adversary cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.] 
adversary owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
adversary victory points: -1
player victory points: -6 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0  50   0] 
sum of rewards: 50 

action type: buy - action 22.0
Learning step: 1.386960744857788
desired expected reward: 9.97678279876709






Player: 1 
cards in hand: [ 6.  3.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 29.  8.] 
cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [11. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
adversary victory points: -6
player victory points: -1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0.] 
cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [25 15  0  3  0  0  8  8  6 11  0  6  0 29  8 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [11. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
adversary victory points: -6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [11. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
adversary victory points: -6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 25.  8.  0.  0. 11. 15.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [11. 29.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
adversary victory points: -6
player victory points: -2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 29.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[23.428114]
 [25.039347]
 [25.039986]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3048962950706482
desired expected reward: 13.471807479858398



action possibilites: [-1. 14.] 
expected returns: [[21.039011]
 [19.572388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 14.] 
cards in discard: [11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.009089584462344646
desired expected reward: 21.864431381225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[19.644024]
 [21.271425]
 [20.310589]
 [22.625475]
 [21.940859]
 [20.968042]
 [21.11594 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 14.] 
cards in discard: [11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  1.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.04379476606845856
desired expected reward: 21.082807540893555



buy possibilites: [-1] 
expected returns: [[23.37523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 14.] 
cards in discard: [11. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -16   0   0  18   0] 
sum of rewards: 17 

action type: buy - action 11.0
Learning step: 0.07695155590772629
desired expected reward: 22.70242691040039






Player: 1 
cards in hand: [ 0.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 1. 22. 10. 10.  6.] 
adversary cards in discard: [11. 11. 29.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
adversary victory points: -6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  5.  8.  7.] 
adversary cards in hand: [ 1. 22. 10. 10.  6.] 
adversary cards in discard: [11. 11. 29.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
adversary victory points: -6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  6.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [ 1. 22. 10. 10.  6.] 
adversary cards in discard: [11. 11. 29.  6.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
adversary victory points: -6
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 22. 10. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10. 10.] 
expected returns: [[18.737297]
 [15.975418]
 [18.634275]
 [18.634275]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22. 10. 10.  6.] 
cards in discard: [11. 11. 29.  6.  0.  0. 14.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [25.  8. 29.  0.  6.] 
adversary cards in discard: [10.  0.  0. 11.  0.  6.] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6607478857040405
desired expected reward: 22.7144832611084



action possibilites: [-1. 22. 10. 29.] 
expected returns: [[18.331022]
 [15.603667]
 [18.230137]
 [19.586208]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22. 10.  6. 29.] 
cards in discard: [11. 11. 29.  6.  0.  0. 14.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [25.  8. 29.  0.  6.] 
adversary cards in discard: [10.  0.  0. 11.  0.  6.] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.08277986198663712
desired expected reward: 18.717056274414062



action possibilites: [-1. 22.] 
expected returns: [[17.750591]
 [14.79819 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  6.] 
cards in discard: [11. 11. 29.  6.  0.  0. 14. 10.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
action values: 2 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [25.  8. 29.  0.  6.] 
adversary cards in discard: [10.  0.  0. 11.  0.  6.] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0.669486403465271
desired expected reward: 19.15264320373535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[16.589617]
 [18.043652]
 [17.179285]
 [18.635712]
 [17.770397]
 [17.879297]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22.  6.] 
cards in discard: [11. 11. 29.  6.  0.  0. 14. 10.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  1.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [25.  8. 29.  0.  6.] 
adversary cards in discard: [10.  0.  0. 11.  0.  6.] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.705154299736023
desired expected reward: 18.455747604370117



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 3 
Gold: 1 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 7 
Chapel: 3 
Witch: 1 
Poacher: 3 
Militia: 1 
Market: 1 
Village: 3 
Library: 2 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 22.  6.] 
cards in discard: [11. 11. 29.  6.  0.  0. 14. 10.  6.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0 11  1 22 10 11  0  2 16  6 14  6 29 10 23
 29 11 11 10  0  6 11  6  6  0 25  6  8  8 14  6 29  1  6 11  0 29 11 29
  0 22 11  8] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 27. 30.  8.  0.  9.  0.  0.  8.  3.  8.  9.  4.  8.  7.] 
adversary cards in hand: [25.  8. 29.  0.  6.] 
adversary cards in discard: [10.  0.  0. 11.  0.  6.] 
adversary owned cards: [25 15  0  0  8  6 11  0  6  0 29  8 10 10] -> size -> 14 
adversary victory points: -2
player victory points: -6 

Reward from previous game state: 
[  -5 -500    0    0    0    0   40    0    0    0    0  -17    0    0
    4    0] 
sum of rewards: -478 

action type: buy - action 8.0
Learning step: -14.899070739746094
desired expected reward: 3.736642837524414



