 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[59.272335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 9.316545486450195
desired expected reward: -228.5970916748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 44.216396]
 [ 86.06366 ]
 [ 59.44903 ]
 [-20.408077]
 [ 86.00825 ]
 [ 70.86551 ]
 [ 44.122425]
 [ 58.02316 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.890071868896484



buy possibilites: [-1] 
expected returns: [[63.00984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 86.06364440917969






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[65.596695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.00983810424805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 52.492516 ]
 [ 93.16031  ]
 [ 67.19587  ]
 [-14.4938345]
 [ 81.54031  ]
 [ 93.09683  ]
 [ 78.28676  ]
 [108.312805 ]
 [ 12.082079 ]
 [ 52.451786 ]
 [ 52.928303 ]
 [ 66.033714 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.09042358398438



buy possibilites: [-1] 
expected returns: [[56.86008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 108.31278228759766






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[76.39737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.86008071899414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 65.37762 ]
 [105.51227 ]
 [ 79.435394]
 [ 27.251406]
 [  3.100675]
 [ 93.78521 ]
 [105.3253  ]
 [ 90.54388 ]
 [161.53333 ]
 [120.35499 ]
 [ 27.085348]
 [ 68.59671 ]
 [ 65.21158 ]
 [ 30.122015]
 [ 65.560036]
 [ 77.36294 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.59912109375



buy possibilites: [-1] 
expected returns: [[77.92995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 161.53330993652344






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.03338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.92994689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 72.14104 ]
 [112.4864  ]
 [ 86.51449 ]
 [  8.255497]
 [100.81495 ]
 [112.44667 ]
 [ 97.49751 ]
 [127.51643 ]
 [ 33.65412 ]
 [ 72.1192  ]
 [ 72.59124 ]
 [ 85.457695]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 83.7324447631836



buy possibilites: [-1] 
expected returns: [[61.392727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25.  0.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 127.51641845703125






Player: 1 
cards in hand: [ 3.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 64.32449 ]
 [102.021996]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.39272689819336



action possibilites: [-1.] 
expected returns: [[78.76055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.32363891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 68.54534 ]
 [106.870804]
 [ 82.487724]
 [ 31.694742]
 [  8.661158]
 [ 95.9911  ]
 [106.85837 ]
 [ 92.88852 ]
 [161.57526 ]
 [121.45813 ]
 [ 31.79157 ]
 [ 72.2173  ]
 [ 68.595436]
 [ 34.807014]
 [ 69.11476 ]
 [ 81.90956 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.76055145263672



buy possibilites: [-1] 
expected returns: [[78.61227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 161.5752410888672






Player: 1 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[67.19423]
 [98.15365]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.61226654052734



action possibilites: [-1.] 
expected returns: [[83.79149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.57430267333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.86128 ]
 [103.20174 ]
 [ 84.22916 ]
 [ 47.232853]
 [ 31.359774]
 [ 93.87469 ]
 [103.506386]
 [ 91.483765]
 [149.45476 ]
 [116.1136  ]
 [ 47.55222 ]
 [ 77.29894 ]
 [ 74.25512 ]
 [ 49.803234]
 [ 74.90803 ]
 [ 85.87173 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 83.79148864746094



buy possibilites: [-1] 
expected returns: [[128.30086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  1.  3.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 149.4547576904297






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 29.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  8. 10. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [16. 29.  3.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [25.  1.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 68.27538]
 [140.87218]
 [140.87218]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.3008575439453



action possibilites: [-1] 
expected returns: [[40.813465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 16.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.82894897460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 32.7383   ]
 [ 66.868866 ]
 [ 44.389782 ]
 [  1.4587274]
 [-17.104902 ]
 [ 56.922844 ]
 [ 67.10958  ]
 [ 53.948486 ]
 [115.519165 ]
 [ 80.277794 ]
 [  1.7225137]
 [ 36.178764 ]
 [ 33.068214 ]
 [  4.5880466]
 [ 33.693893 ]
 [ 44.965473 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 16.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.8134651184082



buy possibilites: [-1] 
expected returns: [[57.28426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  0.  0. 25.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0. 16.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 115.51914978027344






Player: 1 
cards in hand: [ 3. 11.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 16.  0.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3.  0.] 
adversary cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[118.466835]
 [142.62709 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  0.] 
cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.28425979614258



action possibilites: [-1.] 
expected returns: [[138.42201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.11631774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[131.95305]
 [159.77875]
 [142.36678]
 [ 88.05801]
 [152.10585]
 [160.13002]
 [149.71631]
 [170.49272]
 [105.10225]
 [132.3043 ]
 [132.92798]
 [143.75946]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1.  0. 25.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 138.42201232910156



buy possibilites: [-1] 
expected returns: [[181.07495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [25. 25.  1.  0. 25.  0.  0. 25. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 170.4927520751953






Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 6.  0.  3. 11.  0. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [25.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 57.104256]
 [116.899025]
 [ 86.10722 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.074951171875



action possibilites: [-1] 
expected returns: [[110.57178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.45065307617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[103.098625]
 [134.33437 ]
 [115.54345 ]
 [ 49.76321 ]
 [134.83888 ]
 [123.43158 ]
 [103.631226]
 [117.774124]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  9. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.57177734375



buy possibilites: [-1] 
expected returns: [[123.78137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3. 11.  0. 16.  0.  3.  0.  0. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 134.83888244628906






Player: 1 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [ 6.  0.  3. 11.  0. 16.  0.  3.  0.  0. 16.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[150.03593]
 [204.71936]
 [204.71936]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  0.] 
cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  8.  8. 10.  6.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.7813720703125



action possibilites: [-1] 
expected returns: [[154.23955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 29.  1.] 
cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 201.0908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[150.03447]
 [178.12038]
 [160.49315]
 [107.50154]
 [170.34427]
 [178.4179 ]
 [167.9487 ]
 [189.09608]
 [124.32138]
 [150.3335 ]
 [150.91675]
 [161.55527]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.  1.] 
cards in discard: [11. 25.  3. 29.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.2395477294922



buy possibilites: [-1] 
expected returns: [[135.2596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0. 29.  1.] 
cards in discard: [11. 25.  3. 29.  3.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 189.0960235595703






Player: 1 
cards in hand: [ 3.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 89.58237]
 [137.01457]
 [111.58189]
 [137.01457]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.2595977783203



action possibilites: [-1] 
expected returns: [[121.94713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.6385955810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[114.20237 ]
 [123.86093 ]
 [ 73.44277 ]
 [131.10269 ]
 [125.246826]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  6.  8.  8. 10.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.94712829589844



buy possibilites: [-1] 
expected returns: [[139.09592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  0. 29.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 131.10267639160156






Player: 1 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  1.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  6.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  1.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [10. 29.  0.  0.  0.  3. 16.  6.  3.  0.  3.  3. 11.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  6.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  1.  0.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[136.67577]
 [157.92468]
 [179.58415]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  0.  0.] 
cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  6.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.09591674804688



action possibilites: [-1] 
expected returns: [[167.75989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.  0.] 
cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  6. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 176.452880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[158.84659 ]
 [185.80264 ]
 [169.0482  ]
 [132.19151 ]
 [114.640205]
 [178.59258 ]
 [186.06126 ]
 [176.38356 ]
 [221.21098 ]
 [195.72037 ]
 [132.53307 ]
 [161.90303 ]
 [159.06807 ]
 [134.82713 ]
 [159.58633 ]
 [169.6811  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.  0.] 
cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8.  5.  8.  8.  9.  6.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  6. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 167.7598876953125



buy possibilites: [-1] 
expected returns: [[190.46353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.  0.] 
cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  6. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 221.21095275878906






Player: 1 
cards in hand: [ 3.  3.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6. 16.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3. 25. 25. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6. 16.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  5.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3. 25. 25. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6. 16.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  5.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3. 25. 25. 29.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[161.6898 ]
 [210.10759]
 [177.846  ]
 [186.41173]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 29.  0.] 
cards in discard: [ 8. 25. 29. 25.  0.  0. 29.  3. 25. 25. 29.  1.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 190.46353149414062



action possibilites: [-1] 
expected returns: [[120.33905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 210.10755920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[116.53218 ]
 [125.794556]
 [ 79.603615]
 [132.24283 ]
 [127.47801 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  8.  9.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.33905029296875



buy possibilites: [-1] 
expected returns: [[122.16652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0.  3.  3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  8.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 132.24282836914062






Player: 1 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  8.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  8.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  7.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[100.56168]
 [150.44768]
 [125.37303]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  4.  8.  7.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  6.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11] -> size -> 26 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.16651916503906



action possibilites: [-1] 
expected returns: [[82.94417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 29. 29.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  6.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 149.73475646972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.44809 ]
 [91.13626 ]
 [77.53077 ]
 [43.927376]
 [91.433334]
 [83.23153 ]
 [70.616714]
 [78.24553 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0. 29. 29.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  7.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  6.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.94416809082031



buy possibilites: [-1] 
expected returns: [[92.938644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0. 29. 29.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  6.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 91.43328857421875






Player: 1 
cards in hand: [11. 29.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  6.  0.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  1.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  6.  0.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 25.  1.] 
adversary cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 79.155624]
 [123.72824 ]
 [123.72824 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25.  1.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  3.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  6.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.93864440917969



action possibilites: [-1] 
expected returns: [[86.252655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  8.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  6.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.72828674316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 78.61886 ]
 [104.89345 ]
 [ 87.92289 ]
 [ 37.198605]
 [ 97.340996]
 [104.846214]
 [ 95.21782 ]
 [114.578285]
 [ 52.937546]
 [ 78.50881 ]
 [ 78.7485  ]
 [ 87.04638 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  8.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  6.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.25265502929688



buy possibilites: [-1] 
expected returns: [[59.48206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  8.  0.] 
cards in discard: [ 8. 25. 11.  0. 29.  0.  3.  3. 11. 25.  0.  0. 29.  0. 29. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  6.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.57829284667969






Player: 1 
cards in hand: [ 3.  3.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  6.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 3.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 3.] 
cards in discard: [ 6.  0.  3.  3.  0.  6. 16.  6. 11.  0.  0.  0. 16.  0.  6. 11. 29.  0.
  6.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 98.234406]
 [120.96328 ]
 [145.82687 ]
 [145.82687 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.482059478759766



action possibilites: [-1] 
expected returns: [[124.018555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 25.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  3.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.48806762695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[112.82961]
 [133.56238]
 [120.70116]
 [ 80.98254]
 [133.95631]
 [126.08476]
 [113.22358]
 [122.49222]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  6.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  3.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.0185546875



buy possibilites: [-1] 
expected returns: [[113.480125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  0.  8.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  3.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6  6] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 133.956298828125






Player: 1 
cards in hand: [16.  6.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  0.  6.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0
  6 11  6  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[ 81.10329 ]
 [101.32969 ]
 [101.32969 ]
 [ 93.542206]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29. 11.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.4801254272461



action possibilites: [-1. 29. 11.  8.] 
expected returns: [[62.00578 ]
 [83.761734]
 [75.53592 ]
 [67.30381 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11.  8.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.3297119140625



action possibilites: [-1. 11.  8.] 
expected returns: [[ 92.365616]
 [106.40654 ]
 [ 98.022446]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  8.  3.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.76173400878906



action possibilites: [-1] 
expected returns: [[77.466736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 322 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 120.67034912109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.23474 ]
 [89.61227 ]
 [77.400955]
 [39.237865]
 [89.75982 ]
 [82.588455]
 [70.384155]
 [77.80701 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  5.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.46673583984375



buy possibilites: [-1] 
expected returns: [[90.14532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 349 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.75981140136719






Player: 1 
cards in hand: [0. 3. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29. 11. 29.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29. 11. 29.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[57.99245 ]
 [81.352776]
 [72.87712 ]
 [81.352776]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11. 29.  0.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.14531707763672



action possibilites: [-1. 11. 29.] 
expected returns: [[57.66496]
 [73.40759]
 [82.13351]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  0.  0.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.35279846191406



action possibilites: [-1. 11. 25.] 
expected returns: [[ 60.44704 ]
 [ 73.78862 ]
 [102.307014]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0. 25.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  1.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.13352966308594



action possibilites: [-1] 
expected returns: [[42.743633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0. 25. 25.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  0.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.3070068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.204895]
 [54.98225 ]
 [24.785517]
 [42.187145]
 [19.104607]
 [49.07629 ]
 [54.938087]
 [47.514893]
 [81.91872 ]
 [62.25526 ]
 [19.10231 ]
 [36.960564]
 [35.188084]
 [20.406538]
 [35.418007]
 [41.657314]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0. 25. 25.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 28. 30.  8.  0.  8.  4.  8.  5.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.74363327026367



buy possibilites: [-1] 
expected returns: [[44.93999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0. 25. 25.] 
cards in discard: [11. 25. 29.  0.  0. 25.  0.  8. 10. 11. 29. 29. 11.  0.  3.  8.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 357.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.91873168945312






Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 25. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[ 65.37404 ]
 [ 76.983826]
 [106.629745]
 [106.629745]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.93999099731445



action possibilites: [-1] 
expected returns: [[70.22232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.62973022460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[62.878696]
 [71.19014 ]
 [77.343994]
 [72.58522 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  8.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.22232055664062



buy possibilites: [-1] 
expected returns: [[93.13742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  3.  0. 25.  0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 77.34397888183594






Player: 1 
cards in hand: [ 3. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3. 25.  0. 29.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3. 25.  0. 29.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
adversary victory points: 3
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  3. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[50.873108]
 [64.11241 ]
 [91.894684]
 [71.65965 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.  0. 29.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.13742065429688



action possibilites: [-1] 
expected returns: [[86.66356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.  8. 10.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.89470672607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[77.06949]
 [86.84566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 29.  8. 10.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [16.  6.  3. 10.  0.] 
adversary cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.66355895996094






Player: 1 
cards in hand: [16.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3. 10.  0.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1. 29.  3. 25.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3. 10.  0.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1. 29.  3. 25.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3. 10.  0.] 
cards in discard: [ 6. 15. 16.  6.  0.  6.  0.  3.  3.  6.  6.  6.  0.  0.  0.  6.  0.  6.
  3. 11.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  1. 29.  3. 25.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  1. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[55.327984]
 [67.35469 ]
 [74.44612 ]
 [94.13792 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  3. 25.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.84564971923828



action possibilites: [-1] 
expected returns: [[65.337616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  3. 29.  0.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.1379165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[59.567783]
 [78.30078 ]
 [66.3849  ]
 [78.3102  ]
 [71.49305 ]
 [59.577168]
 [66.02134 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  3. 29.  0.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  4.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.33761596679688



buy possibilites: [-1] 
expected returns: [[62.61066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  3. 29.  0.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 78.3101577758789






Player: 1 
cards in hand: [ 6.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  8.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  0.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 29.] 
cards in discard: [16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  0.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 29.] 
cards in discard: [16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  8.  0.] 
adversary cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[44.66054 ]
 [56.961163]
 [63.716953]
 [50.26184 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  8.  0.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.610660552978516



action possibilites: [-1. 11. 25.] 
expected returns: [[25.744413]
 [38.63254 ]
 [65.99929 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.979312896728516



action possibilites: [-1] 
expected returns: [[25.02028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.9992904663086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.243708 ]
 [36.900585 ]
 [25.126614 ]
 [31.490427 ]
 [36.889294 ]
 [29.950804 ]
 [44.65209  ]
 [ 3.2417016]
 [19.239267 ]
 [19.436497 ]
 [24.710882 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  4. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.020280838012695



buy possibilites: [-1] 
expected returns: [[43.426853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 25. 11. 25.  3.  0. 25.  0. 25. 11.  3.  0. 29.  8. 10. 11. 25. 11.
  1. 29.  3. 29.  0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 433 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 44.65207290649414






Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [16. 11.  6.  3.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [16. 11.  6.  3.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  7.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29.  8. 29.] 
expected returns: [[ 77.93705]
 [ 82.6805 ]
 [123.01575]
 [100.19012]
 [ 82.6805 ]
 [100.19012]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 29.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  6.  6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.42685317993164



action possibilites: [-1] 
expected returns: [[106.59956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  6.  6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.01576232910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 98.93024]
 [107.77589]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  8. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 16.  6.  6.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.59956359863281






Player: 1 
cards in hand: [ 6.  0. 16.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  6.  6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 11. 29.  3.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  6.  6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 11. 29.  3.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[ 72.001884]
 [108.15503 ]
 [ 82.221054]
 [ 89.30173 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11. 29.  3.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 107.7758560180664



action possibilites: [-1] 
expected returns: [[86.951996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3. 11.  8.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.15498352050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[80.187775]
 [87.290695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  3. 11.  8.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.95199584960938






Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  3.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25.  3.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 25.  3.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 25.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 82.018814]
 [102.45945 ]
 [122.55994 ]
 [122.55994 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  0. 25.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  0. 15.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.29074096679688



action possibilites: [-1] 
expected returns: [[76.20851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 11.  0.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  0. 15.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.55986022949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.479935]
 [76.37033 ]
 [81.83896 ]
 [76.394035]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25. 11.  0.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  6.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  0. 15.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.20851135253906



buy possibilites: [-1] 
expected returns: [[96.51253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25. 11.  0.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  6.  0. 15.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 81.8389892578125






Player: 1 
cards in hand: [11.  6.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  0. 15.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6
 11  6  6  6 15  6  0  0 16  8 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 29.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 29.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 29.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  6.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11. 29.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 29.] 
expected returns: [[57.05605]
 [68.35558]
 [74.81772]
 [68.35558]
 [74.81772]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11. 29.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10. 16.  6.  0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.51252746582031



action possibilites: [-1. 11. 11.] 
expected returns: [[67.15036 ]
 [78.380615]
 [78.380615]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10. 16.  6.  0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.30532836914062



action possibilites: [-1] 
expected returns: [[89.01239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 16.  6.  0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 369 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.47506713867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[82.0009 ]
 [89.29225]
 [95.76814]
 [88.76636]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  5.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 16.  6.  0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.01239013671875



buy possibilites: [-1] 
expected returns: [[83.85206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 16.  6.  0.] 
adversary cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 95.76811981201172






Player: 1 
cards in hand: [ 6. 10. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 16.  6.  0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8. 29. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6.  0.  0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  6  0  6 10  6  6  3  6  0  6 11
  6  6  6 15  6  0  0 16  8 10  1] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8. 29. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8. 29. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [16. 11.  6.  3.  0. 29.  8.  0.  3.  3.  0.  6.  6.  0. 16.  6.  6. 10.
  0.  6.  0.  3.  0.  1. 15. 11.  6.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  0. 25.] 
adversary cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8. 29. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[25.440275]
 [64.8997  ]
 [64.8997  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  0. 25.] 
cards in discard: [25.  8. 29.  8. 29.  0. 10. 25.  0. 11. 29.  3. 11.  8.  8. 25. 29.  3.
  0. 25. 11.  0. 29. 15.  8. 29. 11.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.85205841064453



action possibilites: [-1] 
expected returns: [[132.26991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 25. 29.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.8996810913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.94255]
 [146.19344]
 [131.02295]
 [139.50305]
 [146.50575]
 [137.42537]
 [155.53902]
 [102.23253]
 [122.25482]
 [122.808  ]
 [132.30086]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25. 29.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  3. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.26991271972656



buy possibilites: [-1] 
expected returns: [[173.678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 25. 29.  8.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 155.53903198242188






Player: 1 
cards in hand: [ 6.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [1. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 11. 29.] 
expected returns: [[78.34625]
 [82.71514]
 [89.43106]
 [96.33792]
 [89.43106]
 [96.33792]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29. 11. 29.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 16.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.67799377441406



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[73.29404]
 [78.2107 ]
 [85.29712]
 [85.29712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 16.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.28297424316406



action possibilites: [-1] 
expected returns: [[94.743515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.43302154541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[88.16916 ]
 [94.67407 ]
 [99.41951 ]
 [94.901505]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  4.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.74351501464844



buy possibilites: [-1] 
expected returns: [[89.30728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0.  6. 16.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 99.41954040527344






Player: 1 
cards in hand: [ 6.  0.  6. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 16.  6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [11. 29.  3. 29. 11.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16.  6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [11. 29.  3. 29. 11.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16.  6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [11. 29.  3. 29. 11.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 29.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[ 85.677986]
 [100.31835 ]
 [108.87281 ]
 [108.87281 ]
 [100.31835 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 29. 11.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.30728149414062



action possibilites: [-1. 11. 11.] 
expected returns: [[ 99.81229]
 [114.24506]
 [114.24506]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 100.34727478027344



action possibilites: [-1] 
expected returns: [[101.686615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 269 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 127.91432189941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 95.74763]
 [103.02537]
 [108.42389]
 [102.86775]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  3.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.68661499023438



buy possibilites: [-1] 
expected returns: [[136.40678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6.  0. 29.  0. 10.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 108.42388916015625






Player: 1 
cards in hand: [ 6.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  0. 10.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 16.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0  6 10  6  6  3  6  0  6 11  6
  6  6 15  6  0  0 16  8 10  1  3  1  0  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  3.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 25. 25. 10.  0.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29. 25. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 10.] 
expected returns: [[ 74.26483 ]
 [ 97.06433 ]
 [115.101425]
 [115.101425]
 [ 67.493195]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25. 10.  0.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3 11] -> size -> 39 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.4067840576172



action possibilites: [-1] 
expected returns: [[51.0003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 10.  0.  8.  8.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3 11] -> size -> 39 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.1014404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.008514]
 [50.99554 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 10.  0.  8.  8.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3 11] -> size -> 39 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.000301361083984






Player: 1 
cards in hand: [16.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1.  0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6
  6 15  6  0  0 16  8 10  1  3  1  0  0  3 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  2.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 11. 25.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 11. 25.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  2.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 11. 25.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  8. 11. 25.] 
adversary cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[ 85.451004]
 [ 88.957184]
 [ 94.98316 ]
 [118.42622 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11. 25.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.99554443359375



action possibilites: [-1] 
expected returns: [[76.10127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.  0. 25.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.42622375488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[68.76816 ]
 [75.17908 ]
 [79.8075  ]
 [76.101265]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 11.  0. 25.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  1.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.10127258300781



buy possibilites: [-1] 
expected returns: [[53.068462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 11.  0. 25.] 
cards in discard: [29. 25.  0.  1.  0. 25. 29.  8. 29. 15.  8. 29. 11.  8. 11.  0. 29. 15.
  8. 29. 11.  3. 11.  0. 25. 29. 25. 10.  0.  8.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  3.  3.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 79.80750274658203






Player: 1 
cards in hand: [ 3. 15.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  3.  3.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 8. 25. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  3.  3.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 8. 25. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  3.  3.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 8. 25. 10. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10. 15.] 
expected returns: [[103.338264]
 [107.2125  ]
 [144.02193 ]
 [ 94.76006 ]
 [ 95.2556  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10. 15.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.06846237182617



action possibilites: [-1] 
expected returns: [[100.6184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 15.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.0218963623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 93.36255]
 [101.90756]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 15.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 11.  0.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.61840057373047






Player: 1 
cards in hand: [ 6. 11.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  8.  6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16 11  0 10  6  6  3  6  0  6 11  6  6  6
 15  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 11.  0. 11. 25.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 11.  0. 11. 25.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 11.  0. 11. 25.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  0. 11.  6.  0.  6.  0.  0.  6.  0.  6. 16.  6.  6.  3. 11. 29. 10.
 16.  0.  0.  8. 11. 16.  3.  1.  0.  0.  3. 15.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 11.  0. 11. 25.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [25. 11.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 25.] 
expected returns: [[ 98.44914]
 [134.91052]
 [109.26524]
 [109.26524]
 [134.91052]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 11. 25.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.9075698852539



action possibilites: [-1] 
expected returns: [[87.99393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 25.  0.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.9104766845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[79.48527 ]
 [87.833244]
 [88.18973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 25.  0.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.99392700195312






Player: 1 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 29. 11. 25. 29.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 29. 11. 25. 29.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [29. 29. 11. 25. 29.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 25. 29.] 
expected returns: [[ 91.868454]
 [113.16889 ]
 [113.16889 ]
 [105.5473  ]
 [134.26546 ]
 [113.16889 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 25. 29.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 16.  0.  0. 16.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.18975830078125



action possibilites: [-1] 
expected returns: [[92.08844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 29. 11. 29.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 16.  0.  0. 16.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.2654571533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[84.07175]
 [92.37012]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11. 29. 11. 29.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 3. 16.  0.  0. 16.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.08843994140625






Player: 1 
cards in hand: [ 3. 16.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  3. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15
  6  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  7.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [11.  3.  0. 15.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[78.183945]
 [92.1408  ]
 [70.18836 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 15.  0.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 16. 11.  1.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.37013244628906



action possibilites: [-1] 
expected returns: [[50.79887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 16. 11.  1.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 92.02547454833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[44.725494]
 [52.351368]
 [51.734158]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 16. 11.  1.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.79887008666992



buy possibilites: [-1] 
expected returns: [[63.513958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  0. 16. 11.  1.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 161 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 52.35136032104492






Player: 1 
cards in hand: [ 0.  0. 16. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 11.  1.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6
  0  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 29.  8.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 29.  8.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [15.  8.  0. 29.  8.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [15.  8.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29.  8.] 
expected returns: [[24.323912]
 [17.1519  ]
 [31.121408]
 [47.357834]
 [31.121408]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 29.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 11.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.51395797729492



action possibilites: [-1.  8. 25.] 
expected returns: [[-8.5305805]
 [-4.043298 ]
 [24.581125 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 11.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.23422622680664



action possibilites: [-1] 
expected returns: [[43.63467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 11.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.581125259399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[34.992527]
 [43.16378 ]
 [43.63467 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 11.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.63467025756836






Player: 1 
cards in hand: [ 0.  3.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11.  3.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 29.  8. 29.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.  3.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 29.  8. 29.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.  3.] 
cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [25. 29.  8. 29.  0.] 
adversary cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 29.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8. 29.] 
expected returns: [[ 6.1684585]
 [46.05238  ]
 [26.370836 ]
 [11.672873 ]
 [26.370836 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  8. 29.  0.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.  0.
  0.  3.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.63467025756836



action possibilites: [-1] 
expected returns: [[34.26264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  0.  1.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.  0.
  0.  3.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.0523567199707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[26.8411  ]
 [44.791   ]
 [33.53308 ]
 [44.989067]
 [27.039164]
 [34.262638]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 29.  0.  1.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 24. 30.  8.  0.  6.  1.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.  0.
  0.  3.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.26264190673828



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 8 
Witch: 6 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  8. 29.  0.  1.  8.] 
cards in discard: [25.  8. 10. 15.  3.  0.  8. 25. 11.  0. 11. 25.  0.  8. 25. 29. 29. 11.
 29. 11. 29.  1.  3. 11.  3.  0. 15.  0. 15.  8. 29. 25.  0.  8.  3.  8.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29 25 25 25 29 11 29  8 25  8 11
 29 11 10 11 25  8 11 29  8 15  8 29 15  8 15  8  8  1  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  0.  6.  0.  0.  4.  2. 10. 10.  7. 10.  6.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3. 11. 16.  0. 16.  0.  0. 16.  3. 16.  0. 11.  1.  0.
  0.  3.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  3 29 16  0 10  6  6  3  6  0  6 11  6  6  6 15  6  0
  0 16  8 10  1  3  1  0  0  3 11  8 11  0  0 16  0  3  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0     -90       0       0      27       0] 
sum of rewards: 3000132 

action type: buy - action 11.0
Learning step: 120003.4765625
desired expected reward: 120048.46875



