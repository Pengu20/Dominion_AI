 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[56.909332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000245 

action type: buy - action 0.0
Learning step: -119996.09375
desired expected reward: -120338.6328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 44.600086]
 [ 88.68741 ]
 [ 62.25866 ]
 [-28.881361]
 [ 86.95981 ]
 [ 69.215256]
 [ 42.786526]
 [ 55.031666]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 57.750831604003906



buy possibilites: [-1] 
expected returns: [[62.772827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.68740844726562






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.72393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.7728271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 65.047966]
 [110.768936]
 [ 83.366   ]
 [ -9.189317]
 [103.17837 ]
 [109.02059 ]
 [ 90.56212 ]
 [127.28372 ]
 [ 16.704443]
 [ 63.327072]
 [ 61.685005]
 [ 76.098465]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.1240234375



buy possibilites: [-1] 
expected returns: [[43.80581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 127.28372192382812






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.15579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.805809020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 58.53099  ]
 [ 98.60508  ]
 [ 34.59556  ]
 [ 74.60425  ]
 [ 17.036198 ]
 [ -6.508784 ]
 [ 91.98398  ]
 [ 97.12659  ]
 [ 80.93201  ]
 [159.37999  ]
 [113.05204  ]
 [ 15.4734955]
 [ 66.528946 ]
 [ 56.968307 ]
 [ 26.519676 ]
 [ 55.480854 ]
 [ 68.330284 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.03160095214844



buy possibilites: [-1] 
expected returns: [[70.546844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 57.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 159.37998962402344






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 56.99832 ]
 [101.333954]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  3.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.54684448242188



action possibilites: [-1.] 
expected returns: [[85.90596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.32423400878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 77.03437 ]
 [117.093765]
 [ 92.85004 ]
 [ 13.319344]
 [115.33135 ]
 [ 99.011   ]
 [ 75.635345]
 [ 87.00691 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.90596008300781



buy possibilites: [-1] 
expected returns: [[84.15562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [25.  0.  0.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 117.0937271118164






Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.98026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.1556167602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 38.65398  ]
 [ 78.68435  ]
 [ 14.934357 ]
 [ 54.674725 ]
 [ -2.1001368]
 [-25.067663 ]
 [ 72.093605 ]
 [ 77.00165  ]
 [ 60.98088  ]
 [134.46014  ]
 [ 92.878624 ]
 [ -3.5573516]
 [ 46.54212  ]
 [ 36.97126  ]
 [  7.0789075]
 [ 35.429375 ]
 [ 47.73556  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.6775016784668



buy possibilites: [-1] 
expected returns: [[53.53694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 134.46011352539062






Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 8 8 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 8 8 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  7.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  6.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 64.15779]
 [151.69193]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  3.] 
cards in discard: [25.  0.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  6.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.53694152832031



action possibilites: [-1] 
expected returns: [[36.801388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.06863403320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 30.534542]
 [ 67.05395 ]
 [ 45.22357 ]
 [-27.860786]
 [ 61.02604 ]
 [ 65.680916]
 [ 50.953995]
 [ 81.087105]
 [ -8.1119  ]
 [ 29.166893]
 [ 27.832607]
 [ 39.406105]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.801387786865234



buy possibilites: [-1] 
expected returns: [[61.257538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0. 1.] 
cards in discard: [25.  0.  0.  1.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 81.08709716796875






Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [8. 8. 0. 0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [8. 8. 0. 0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [8. 8. 0. 0. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 8 8 8 0 8 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [8. 8. 0. 0. 8. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.333897]
 [61.165718]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.257537841796875



action possibilites: [-1. 25.] 
expected returns: [[ 43.595013]
 [123.11005 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 25.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.06248474121094



action possibilites: [-1] 
expected returns: [[45.405487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.11001586914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 36.61223  ]
 [ 73.263695 ]
 [ 18.121675 ]
 [ 50.860504 ]
 [  4.205463 ]
 [-14.177782 ]
 [ 67.019196 ]
 [ 72.257904 ]
 [ 56.806744 ]
 [126.62105  ]
 [ 87.215225 ]
 [  3.7488065]
 [ 43.64252  ]
 [ 36.155567 ]
 [ 12.070148 ]
 [ 35.32117  ]
 [ 47.063705 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  8.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.405487060546875



buy possibilites: [-1] 
expected returns: [[77.68948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 126.62104797363281






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[41.51494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 8.] 
adversary cards in discard: [6. 3. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.68948364257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 34.734444 ]
 [ 64.58941  ]
 [ 47.025906 ]
 [-13.343561 ]
 [ 59.660576 ]
 [ 64.00285  ]
 [ 51.71137  ]
 [ 76.299095 ]
 [  3.4398446]
 [ 34.147858 ]
 [ 33.291256 ]
 [ 44.029606 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 8.] 
adversary cards in discard: [6. 3. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.86571502685547



buy possibilites: [-1] 
expected returns: [[46.235825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [25. 29. 25.  0.  3.  1.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 8.] 
adversary cards in discard: [6. 3. 8. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6 3] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.29908752441406






Player: 1 
cards in hand: [6. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 8.] 
cards in discard: [6. 3. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 8 8 8 0 8 6 0 6 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6. 3. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 8 6 0 6 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6. 3. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 8 6 0 6 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[10.94268 ]
 [43.35506 ]
 [43.35506 ]
 [82.160675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 8 6 0 6 3] -> size -> 11 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.23582458496094



action possibilites: [-1] 
expected returns: [[35.425087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 0 8 6 0 6 3 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 81.93091583251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 23.039835]
 [ 53.639664]
 [ 35.881516]
 [-25.505493]
 [ 48.4651  ]
 [ 53.66397 ]
 [ 40.652084]
 [ 66.10773 ]
 [ -8.047799]
 [ 23.025639]
 [ 22.409258]
 [ 34.74547 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 0 8 6 0 6 3 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.425086975097656



buy possibilites: [-1] 
expected returns: [[61.36042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0.  0.  1.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 0 8 6 0 6 3 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 66.10774230957031






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 8 6 0 6 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 8 6 0 6 3 6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 8 6 0 6 3 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 8 0 8 6 0 6 3 6 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 47.947006]
 [102.75085 ]
 [102.75085 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  0.] 
cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 8. 6. 0.] 
adversary cards in discard: [6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 8 0 8 6 0 6 3 6 0] -> size -> 11 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.36042022705078



action possibilites: [-1] 
expected returns: [[55.82911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0.  3.  1.] 
cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 8. 6. 0.] 
adversary cards in discard: [6. 0. 8. 0. 0. 6.] 
adversary owned cards: [0 0 8 0 8 6 0 6 3 6 0 6] -> size -> 12 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.68663024902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.14814  ]
 [73.404785 ]
 [55.89521  ]
 [ 1.2224069]
 [68.42779  ]
 [73.20991  ]
 [60.605476 ]
 [85.053955 ]
 [16.678991 ]
 [44.061256 ]
 [43.486485 ]
 [54.50602  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  3.  1.] 
cards in discard: [29. 25.  3. 29. 29.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 8. 6. 0.] 
adversary cards in discard: [6. 0. 8. 0. 0. 6.] 
adversary owned cards: [0 0 8 0 8 6 0 6 3 6 0 6] -> size -> 12 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.82910919189453



buy possibilites: [-1] 
expected returns: [[98.327805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  3.  1.] 
cards in discard: [29. 25.  3. 29. 29.  0.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 8. 6. 0.] 
adversary cards in discard: [6. 0. 8. 0. 0. 6.] 
adversary owned cards: [0 0 8 0 8 6 0 6 3 6 0 6] -> size -> 12 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.0539779663086






Player: 1 
cards in hand: [3. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 6. 0.] 
cards in discard: [6. 0. 8. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 8 0 8 6 0 6 3 6 0 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [6. 0. 8. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [6. 0. 8. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[45.67727]
 [74.10191]
 [74.10191]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.32780456542969



action possibilites: [-1. 29.] 
expected returns: [[65.25874]
 [94.10873]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.48497009277344



action possibilites: [-1. 29.] 
expected returns: [[121.62662]
 [152.00139]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.10874938964844



action possibilites: [-1. 25.] 
expected returns: [[128.33716]
 [186.6407 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  6. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6] -> size -> 11 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 152.00137329101562



action possibilites: [-1] 
expected returns: [[138.96689]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6 6] -> size -> 12 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 186.64068603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[132.40965]
 [165.37212]
 [114.42018]
 [146.10504]
 [100.7661 ]
 [131.7109 ]
 [ 82.77665]
 [159.86876]
 [165.30464]
 [151.31212]
 [212.32797]
 [178.37245]
 [100.58473]
 [139.90579]
 [132.22829]
 [108.60328]
 [131.52959]
 [144.68977]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 9 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6 6] -> size -> 12 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.96688842773438



buy possibilites: [-1] 
expected returns: [[191.13884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29.  1.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 8 0 8 6 0 6 3 6 0 6 6] -> size -> 12 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 212.3280029296875






Player: 1 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0 8 6 0 6 3 6 0 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 3 6 0 6 6] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 3 6 0 6 6] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 3 6 0 6 6 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 74.21738]
 [132.76332]
 [103.20203]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0.  0.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  5. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 8.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0] -> size -> 9 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 191.1388397216797



action possibilites: [-1] 
expected returns: [[81.999985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.5693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 71.99928 ]
 [102.14676 ]
 [ 84.5407  ]
 [ 23.801657]
 [101.807045]
 [ 89.26564 ]
 [ 71.65956 ]
 [ 82.34078 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  3.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.99998474121094



buy possibilites: [-1] 
expected returns: [[79.184494]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  3.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  0. 29.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6] -> size -> 10 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 102.14677429199219






Player: 1 
cards in hand: [3. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [6. 0. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [6. 0. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [6. 0. 8. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  1. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  1.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[32.037422]
 [60.88742 ]
 [89.803696]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 25.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  4. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0] -> size -> 11 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.18449401855469



action possibilites: [-1] 
expected returns: [[58.214798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  3. 29.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  3. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6] -> size -> 12 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.3281021118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 50.70896 ]
 [ 80.72967 ]
 [ 34.43623 ]
 [ 63.13198 ]
 [ 21.977085]
 [  6.411221]
 [ 75.705666]
 [ 80.65445 ]
 [ 67.89147 ]
 [123.58888 ]
 [ 92.58829 ]
 [ 22.046604]
 [ 57.468094]
 [ 50.778492]
 [ 29.234032]
 [ 50.245102]
 [ 61.861633]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  3. 29.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 27. 30. 29. 30.  8.  3. 10. 10.  6.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6] -> size -> 12 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.21479797363281



buy possibilites: [-1] 
expected returns: [[74.56375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  3. 29.  1.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8.  3. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6] -> size -> 12 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 123.58888244628906






Player: 1 
cards in hand: [0. 6. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  3. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  3.  3.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 29. 30.  8.  3. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  3.  3.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 8.] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  3. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  3.  3.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [25. 29. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[26.080276]
 [81.429016]
 [53.082756]
 [53.082756]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  3.  3.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  3. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [6. 0. 0. 6. 6. 6. 8.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0] -> size -> 13 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.56375122070312



action possibilites: [-1] 
expected returns: [[63.471878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  3.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  2. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [6. 0. 0. 6. 6. 6. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6] -> size -> 14 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.81442260742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[60.2453  ]
 [72.04937 ]
 [14.863054]
 [76.47252 ]
 [70.27275 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  3.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 29. 30.  8.  2. 10. 10.  6.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [6. 0. 0. 6. 6. 6. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6] -> size -> 14 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.47187805175781



buy possibilites: [-1] 
expected returns: [[75.283844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  3.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  2. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 3.] 
adversary cards in discard: [6. 0. 0. 6. 6. 6. 8. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6] -> size -> 14 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 76.47254180908203






Player: 1 
cards in hand: [8. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [6. 0. 0. 6. 6. 6. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  2. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  0.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [6. 0. 0. 6. 6. 6. 8. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  2. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  0.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 3.] 
cards in discard: [6. 0. 0. 6. 6. 6. 8. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  2. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  0.  0.] 
adversary cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 88.92115]
 [118.52771]
 [147.28436]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  2. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0] -> size -> 15 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.28384399414062



action possibilites: [-1] 
expected returns: [[58.27694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  1. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6] -> size -> 16 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.2237548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 57.219025]
 [ 80.34481 ]
 [ 66.80966 ]
 [ 33.491405]
 [ 19.956312]
 [ 76.52564 ]
 [ 80.027145]
 [ 70.4365  ]
 [114.64637 ]
 [ 89.204926]
 [ 33.173782]
 [ 62.388687]
 [ 56.901356]
 [ 39.26291 ]
 [ 56.299553]
 [ 64.93936 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 29. 30.  8.  1. 10. 10.  5.  5.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6] -> size -> 16 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.276939392089844



buy possibilites: [-1] 
expected returns: [[42.707794]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.  0.] 
cards in discard: [25. 25. 29.  1.  1.  3. 29.  1.  8. 25. 29. 29.  3.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  1. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6] -> size -> 16 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 535 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 114.64637756347656






Player: 1 
cards in hand: [6. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  1. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  1. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 0.] 
cards in discard: [6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  1. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  1.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
adversary victory points: 3
player victory points: -7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 29.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[41.19535 ]
 [98.961624]
 [70.04536 ]
 [98.961624]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  0. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  1. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0] -> size -> 17 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.707794189453125



action possibilites: [-1] 
expected returns: [[51.15378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 25.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  0. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6] -> size -> 18 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 97.9801025390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[53.69372 ]
 [80.08314 ]
 [64.839645]
 [80.11299 ]
 [68.96711 ]
 [53.723583]
 [63.978493]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0. 25.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  0. 10. 10.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6] -> size -> 18 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.15378189086914



buy possibilites: [-1] 
expected returns: [[73.80121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0. 25.  3. 29.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6] -> size -> 18 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.11300659179688






Player: 1 
cards in hand: [0. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 6.] 
cards in discard: [6. 0. 6. 6. 6. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0. 29.  3.] 
adversary cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 6.] 
cards in discard: [6. 0. 6. 6. 6. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0. 29.  3.] 
adversary cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 6.] 
cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0. 29.  3.] 
adversary cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[29.819069]
 [87.74316 ]
 [58.243996]
 [58.243996]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 29.  3.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.80120849609375



action possibilites: [-1] 
expected returns: [[51.161636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  0. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.2706069946289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[42.566032]
 [53.02545 ]
 [56.94288 ]
 [51.37532 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  3.  0. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  5.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.16163635253906



buy possibilites: [-1] 
expected returns: [[69.5596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  3.  0. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 361 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 56.942867279052734






Player: 1 
cards in hand: [6. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0. 25.  0.  0.] 
adversary cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [6. 0. 6. 6. 6. 6. 0. 6. 0. 0. 8. 8. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0. 25.  0.  0.] 
adversary cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
adversary victory points: 3
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[42.499313]
 [96.89886 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  0.  0.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.55960083007812



action possibilites: [-1] 
expected returns: [[79.3997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0.  8. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.89886474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.68047 ]
 [ 98.47408 ]
 [ 83.81246 ]
 [ 48.123474]
 [ 94.37773 ]
 [ 97.89872 ]
 [ 87.712074]
 [133.8586  ]
 [107.7121  ]
 [ 47.492714]
 [ 78.96421 ]
 [ 73.05045 ]
 [ 54.168556]
 [ 72.30034 ]
 [ 81.02796 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0.  8. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  4.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.39969635009766



buy possibilites: [-1] 
expected returns: [[35.72908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0.  8. 25.] 
cards in discard: [11. 25. 29.  1.  0. 25.  3. 29.  8. 25. 29.  0. 29.  3.  0. 25. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 595 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 133.8585662841797






Player: 1 
cards in hand: [8. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 29. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
adversary victory points: 3
player victory points: -7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[60.177612]
 [88.821754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.72908020019531



action possibilites: [-1. 29.] 
expected returns: [[ 80.33052 ]
 [108.352264]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 75.21449279785156



action possibilites: [-1.] 
expected returns: [[103.337524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [1. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 97.30036163330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.9509  ]
 [124.56746 ]
 [107.92532 ]
 [119.83513 ]
 [124.38614 ]
 [112.41172 ]
 [135.64354 ]
 [ 66.50062 ]
 [ 95.769585]
 [ 95.11714 ]
 [106.311516]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [1. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.3375244140625



buy possibilites: [-1] 
expected returns: [[125.82138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  8. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 463 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 135.64352416992188






Player: 1 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 25. 25.  0. 25.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 25. 25.  0. 25.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 25. 25.  0. 25.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 25. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 25.] 
expected returns: [[ 64.89597]
 [ 82.25687]
 [121.14943]
 [121.14943]
 [121.14943]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  0. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.82138061523438



action possibilites: [-1] 
expected returns: [[51.138344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0. 25. 25. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.5546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.265335]
 [50.943512]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0. 25. 25. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.138343811035156






Player: 1 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25. 29.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25. 29.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [3. 8. 6. 0. 0. 6. 3. 3. 0. 0. 6. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 25. 29.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[29.782677]
 [78.69078 ]
 [53.07084 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 25. 29.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.94351577758789



action possibilites: [-1] 
expected returns: [[48.138264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 29.  0. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.69078063964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[43.53733 ]
 [68.60336 ]
 [53.674522]
 [64.3243  ]
 [68.07702 ]
 [57.562813]
 [78.31321 ]
 [17.66674 ]
 [42.973164]
 [42.231102]
 [50.951706]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29.  0. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.13826370239258



buy possibilites: [-1] 
expected returns: [[58.565918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 29.  0. 25.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 78.31320190429688






Player: 1 
cards in hand: [3. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0.  8.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1. 29.  0.  8.] 
adversary cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  1. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[45.696663]
 [64.32686 ]
 [64.32686 ]
 [49.769493]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  0.  8.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.56591796875



action possibilites: [-1. 29.  8.] 
expected returns: [[ 83.05676 ]
 [100.9298  ]
 [ 86.566086]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  3.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.43827819824219



action possibilites: [-1.] 
expected returns: [[31.043922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.99642944335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.775074 ]
 [54.43309  ]
 [36.59612  ]
 [49.518448 ]
 [53.305477 ]
 [41.305706 ]
 [65.13118  ]
 [-6.0030603]
 [23.745972 ]
 [22.718487 ]
 [31.98074  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.043922424316406



buy possibilites: [-1] 
expected returns: [[9.255178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 1.  8. 29. 29. 29.  0.  3.  0. 25. 11. 25.  0. 25. 25. 25. 29. 25.  3.
  1.  0. 29.  0. 25.  1.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 403 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 65.13117980957031






Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [3. 0. 6. 6. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [3. 0. 6. 6. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  4.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [3. 0. 6. 6. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 29.] 
expected returns: [[ 83.119865]
 [111.96988 ]
 [100.84277 ]
 [111.96988 ]
 [111.96988 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.255178451538086



action possibilites: [-1. 11. 29.] 
expected returns: [[ 96.38648]
 [114.10936]
 [125.23651]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 99.70751190185547



action possibilites: [-1. 11.] 
expected returns: [[127.24548]
 [147.58267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [29. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 114.22395324707031



action possibilites: [-1] 
expected returns: [[123.17467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 25. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 164.2649688720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.849625]
 [143.71735 ]
 [125.7724  ]
 [138.49083 ]
 [143.05075 ]
 [130.3083  ]
 [155.54617 ]
 [ 83.71901 ]
 [113.36982 ]
 [112.580246]
 [123.179504]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 25. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  2. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.17466735839844



buy possibilites: [-1] 
expected returns: [[122.91777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 25. 15. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 423 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 155.54617309570312






Player: 1 
cards in hand: [3. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3.  1.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3.  1.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 86.50148]
 [139.29504]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.91777038574219



action possibilites: [-1] 
expected returns: [[90.1915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  1. 29.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 139.29498291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.343346]
 [105.40689 ]
 [ 92.46056 ]
 [ 60.723984]
 [101.76569 ]
 [105.03821 ]
 [ 95.92096 ]
 [136.9365  ]
 [113.74066 ]
 [ 60.36611 ]
 [ 88.21672 ]
 [ 82.97463 ]
 [ 66.19128 ]
 [ 82.37441 ]
 [ 90.46235 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  1. 29.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  3.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.19149780273438



buy possibilites: [-1] 
expected returns: [[146.34074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  1. 29.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 0. 6. 8.] 
adversary cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 505 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 136.93643188476562






Player: 1 
cards in hand: [6. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 8.] 
cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 8.] 
cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 8.] 
cards in discard: [3. 0. 6. 6. 6. 8. 8. 3. 0. 0. 3. 3. 6. 6. 6. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[135.36066]
 [158.72263]
 [158.72263]
 [181.19016]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 25.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.3407440185547



action possibilites: [-1] 
expected returns: [[113.84387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 25.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 181.190185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[106.406425]
 [127.21283 ]
 [115.104164]
 [127.05769 ]
 [118.35999 ]
 [106.25133 ]
 [113.830574]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 29. 25.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.8438720703125



buy possibilites: [-1] 
expected returns: [[100.55638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 29. 25.  1.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 127.21282958984375






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25.  8. 29.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25.  8. 29.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25.  8. 29.] 
adversary cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.  8. 29.] 
expected returns: [[ 75.57519]
 [134.1191 ]
 [134.1191 ]
 [ 83.79702]
 [105.75573]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  8. 29.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.55638122558594



action possibilites: [-1] 
expected returns: [[34.770367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8. 29.  0.  8.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.1190948486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.46    ]
 [35.54796 ]
 [38.19835 ]
 [34.525276]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8. 29.  0.  8.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  3.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.77036666870117



buy possibilites: [-1] 
expected returns: [[65.70007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8. 29.  0.  8.] 
cards in discard: [29. 25. 15. 29. 29. 29. 11.  0.  0. 25. 25.  0.  3.  3.  1. 29.  1.  1.
 25. 29.  0.  3. 29. 25.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0.] 
adversary owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 38.19834899902344






Player: 1 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 0 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [0. 8. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[115.53506]
 [169.20308]
 [140.84091]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.7000732421875



action possibilites: [-1] 
expected returns: [[115.21851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 169.20306396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.132225]
 [137.5379  ]
 [120.03956 ]
 [ 81.1596  ]
 [132.47461 ]
 [137.26811 ]
 [124.52586 ]
 [182.74538 ]
 [149.32373 ]
 [ 81.27576 ]
 [114.596306]
 [107.921005]
 [ 87.71912 ]
 [107.33583 ]
 [118.25656 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  2.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 115.21851348876953



buy possibilites: [-1] 
expected returns: [[103.59597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1. 25.] 
cards in discard: [25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
adversary owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -20   0   0 250   0] 
sum of rewards: 485 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 182.74539184570312






Player: 1 
cards in hand: [8. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 3.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 6 3 6 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[65.09013 ]
 [56.35588 ]
 [89.251526]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3. 29.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.5959701538086



action possibilites: [-1. 15.] 
expected returns: [[73.38315]
 [65.44328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 80.08548736572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[67.19412]
 [89.43121]
 [76.32951]
 [88.9633 ]
 [79.82791]
 [66.72621]
 [74.01647]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.38311767578125



buy possibilites: [-1] 
expected returns: [[79.5408]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 89.43121337890625






Player: 1 
cards in hand: [6. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 6.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  8. 29. 11.  8.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 6.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  8. 29. 11.  8.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 6.] 
cards in discard: [0. 8. 0. 0. 0. 0. 8. 6. 6. 6. 0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  8. 29. 11.  8.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  8. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11.  8.] 
expected returns: [[ 96.94453]
 [123.50081]
 [103.7551 ]
 [123.50081]
 [113.75247]
 [103.7551 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29. 11.  8.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.54080200195312



action possibilites: [-1.  8. 11.  8.] 
expected returns: [[104.71284]
 [112.36821]
 [122.8815 ]
 [112.36821]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  1.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 114.38790893554688



action possibilites: [-1] 
expected returns: [[105.74084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.27455139160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 99.878456]
 [123.40416 ]
 [109.265366]
 [122.821   ]
 [112.96198 ]
 [ 99.26116 ]
 [106.40907 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.74083709716797



buy possibilites: [-1] 
expected returns: [[125.38875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 123.4041748046875






Player: 1 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  2.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[36.71544 ]
 [62.366776]
 [86.23143 ]
 [62.366776]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  0. 29.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [8. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.38874816894531



action possibilites: [-1] 
expected returns: [[66.031624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [8. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.2314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[56.189587]
 [84.50431 ]
 [67.49432 ]
 [79.84451 ]
 [83.26064 ]
 [71.95589 ]
 [94.87888 ]
 [27.135456]
 [54.94593 ]
 [53.830963]
 [62.40339 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 29.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  1. 10. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [8. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.03162384033203



buy possibilites: [-1] 
expected returns: [[80.079544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 29.  0.  3.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [8. 0. 0. 3. 6. 6.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.8788833618164






Player: 1 
cards in hand: [8. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [8. 0. 0. 3. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 25. 25.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1. 29. 25.  1. 29.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1 29] -> size -> 41 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [8. 0. 0. 3. 6. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  1.  1.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 25. 25.  3. 29.] 
adversary cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1. 29. 25.  1. 29.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1 29] -> size -> 41 
adversary victory points: 3
player victory points: -3 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 6 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 9 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8. 25. 25.  3. 29.] 
cards in discard: [25. 25.  0.  0. 29.  0.  1. 25. 29.  1. 29.  0. 15.  0.  3. 29. 15.  1.
 29. 11.  8.  8.  1. 29. 25.  1. 29.  0. 29.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 25 29 25 29 29 29 25  1 25  8
 25 11  8 25 29 29 29 15 29 25  1  8 25  1 15  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 26. 30.  8.  0. 10.  9.  0.  1.  0. 10. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [8. 0. 0. 3. 6. 6. 8.] 
adversary owned cards: [8 8 3 6 6 0 6 0 6 0 6 0 6 0 6 0 3 3 3 8 0 0 0 0 8 8] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000175 

action type: buy - action -1
Learning step: 120003.796875
desired expected reward: 120083.875



