 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[336.71597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -90    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -627 

action type: buy - action 0.0
Learning step: -33.51853561401367
desired expected reward: 9.85219955444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[319.5827 ]
 [320.83752]
 [320.7501 ]
 [319.587  ]
 [324.01685]
 [322.40906]
 [322.32162]
 [335.0913 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.62186336517334
desired expected reward: 328.16461181640625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[351.96722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.387839317321777
desired expected reward: 325.7034606933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[329.53763]
 [331.04388]
 [330.9407 ]
 [329.54282]
 [332.71448]
 [334.8756 ]
 [332.93988]
 [339.32965]
 [333.47614]
 [332.83664]
 [335.51517]
 [348.22458]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.668940544128418
desired expected reward: 343.40777587890625



buy possibilites: [-1] 
expected returns: [[323.74512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  3.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 10.0
Learning step: -9.732566833496094
desired expected reward: 323.10406494140625






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.26578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.359599113464355
desired expected reward: 313.3855285644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.27792]
 [294.699  ]
 [294.60028]
 [293.28275]
 [296.24683]
 [298.2688 ]
 [296.45422]
 [302.42282]
 [296.9498 ]
 [296.35553]
 [298.86307]
 [310.7152 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.690410614013672
desired expected reward: 298.20550537109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[318.61713]
 [303.13367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -10.044679641723633
desired expected reward: 300.6705322265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[299.56302]
 [300.97333]
 [299.56824]
 [302.98776]
 [318.3651 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.642670631408691
desired expected reward: 309.4440612792969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.9202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -11.016366958618164
desired expected reward: 307.3487548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[295.45636]
 [297.01285]
 [296.908  ]
 [295.46173]
 [298.7221 ]
 [300.88754]
 [298.94946]
 [305.08786]
 [299.49902]
 [298.84467]
 [301.4893 ]
 [313.3888 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.798210144042969
desired expected reward: 300.3968505859375



buy possibilites: [-1] 
expected returns: [[248.49118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -10 

action type: buy - action 29.0
Learning step: -10.16334056854248
desired expected reward: 294.92449951171875






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[291.01804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -7.981052398681641
desired expected reward: 240.5101318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[272.87784]
 [274.4916 ]
 [274.3808 ]
 [272.88333]
 [278.5763 ]
 [276.50647]
 [276.3957 ]
 [292.81305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0] -> size -> 15 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.274057388305664
desired expected reward: 280.5484619140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[243.51874]
 [236.14847]
 [230.75653]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -11.342076301574707
desired expected reward: 281.470947265625



action possibilites: [-1. 29.] 
expected returns: [[260.1091 ]
 [252.75589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -21 

action type: take_action - action 10.0
Learning step: -6.822491645812988
desired expected reward: 224.62338256835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[241.0179 ]
 [242.2741 ]
 [242.18622]
 [241.02222]
 [245.43997]
 [243.83403]
 [243.74619]
 [256.4787 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.506235122680664
desired expected reward: 251.60289001464844






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[239.08798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0. 29.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -9.254165649414062
desired expected reward: 241.24537658691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[224.10724]
 [225.4422 ]
 [225.33847]
 [224.10724]
 [226.92143]
 [228.83255]
 [227.12215]
 [232.78328]
 [227.57207]
 [227.01842]
 [229.3862 ]
 [240.65706]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0. 29.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -8.797693252563477
desired expected reward: 229.90505981445312



buy possibilites: [-1] 
expected returns: [[229.7952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0. 29.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -10 

action type: buy - action 29.0
Learning step: -6.9687724113464355
desired expected reward: 225.81451416015625






Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[252.66125]
 [245.83182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -7.973217964172363
desired expected reward: 221.8219757080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[235.91132]
 [236.81006]
 [236.74   ]
 [235.91132]
 [239.23328]
 [237.93414]
 [237.86412]
 [249.49057]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 26. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -9.230345726013184
desired expected reward: 242.5672149658203



buy possibilites: [-1] 
expected returns: [[277.57074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -353.0 

action type: buy - action 6.0
Learning step: -23.200223922729492
desired expected reward: 212.71109008789062






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 3. 3. 1. 0. 0. 0. 8. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[258.23624]
 [245.71216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -10.85223388671875
desired expected reward: 266.718505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[244.81487]
 [245.98375]
 [245.89217]
 [244.81487]
 [248.95648]
 [247.45819]
 [247.36661]
 [259.54636]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  0.  0. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -9.788061141967773
desired expected reward: 246.49172973632812



buy possibilites: [-1] 
expected returns: [[281.23547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  0.  0. 29.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -40.0 

action type: buy - action 3.0
Learning step: -7.966809272766113
desired expected reward: 237.9253387451172






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[261.78305]
 [256.5414 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -10.840288162231445
desired expected reward: 270.3951721191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[249.89125]
 [250.71129]
 [249.89125]
 [251.89893]
 [260.91028]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  9. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -9.867704391479492
desired expected reward: 250.53311157226562



buy possibilites: [-1] 
expected returns: [[257.81787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -363.0 

action type: buy - action 6.0
Learning step: -24.843660354614258
desired expected reward: 225.04757690429688






Player: 1 
cards in hand: [3. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  0.  3.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  0.  3.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[252.04077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 6.  0.  3.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 3. 3. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -10.438796043395996
desired expected reward: 247.3790740966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[234.13835]
 [235.4523 ]
 [235.3527 ]
 [234.13835]
 [238.81831]
 [237.12416]
 [237.02454]
 [250.55002]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 6.  0.  3.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 3. 3. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -10.143969535827637
desired expected reward: 238.83816528320312



buy possibilites: [-1] 
expected returns: [[221.50513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 6.  0.  3.  3. 29.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 3. 3. 8. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -61.0 

action type: buy - action 8.0
Learning step: -9.922342300415039
desired expected reward: 227.20181274414062






Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3. 3. 3. 8. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 29.  0.  8.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3. 3. 3. 8. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 3 3 0 8 8 1 0 3] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 29.  0.  8.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  3.  3.  8.  3.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 29.  0.  8.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[215.48566]
 [202.4437 ]
 [207.76826]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [ 6.  0.  3.  3. 29.  0.  8.  0.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -9.490992546081543
desired expected reward: 212.01412963867188



action possibilites: [-1. 29.] 
expected returns: [[233.97469]
 [227.34378]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 10.0
Learning step: -6.6148881912231445
desired expected reward: 187.02188110351562



action possibilites: [-1.] 
expected returns: [[220.32013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: -22 

action type: take_action - action 29.0
Learning step: -7.509985446929932
desired expected reward: 219.8337860107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[216.10974]
 [216.91614]
 [216.85188]
 [216.10974]
 [217.81912]
 [218.97887]
 [217.94377]
 [221.38129]
 [218.21541]
 [217.8795 ]
 [219.31474]
 [226.6055 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -7.1809258460998535
desired expected reward: 213.1392059326172






Player: 1 
cards in hand: [1. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[254.41824]
 [246.05043]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -8.849996566772461
desired expected reward: 217.7555389404297



action possibilites: [-1.] 
expected returns: [[277.8831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 29.0
Learning step: -8.09818172454834
desired expected reward: 235.912841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[264.48386]
 [265.81955]
 [265.72107]
 [264.48386]
 [267.34216]
 [269.2793 ]
 [267.5444 ]
 [273.29422]
 [268.00635]
 [267.4459 ]
 [269.83975]
 [281.3113 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [10. 29.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -9.895052909851074
desired expected reward: 267.988037109375



buy possibilites: [-1] 
expected returns: [[280.40005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [10. 29.  0.  0.  3.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [0. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -11 

action type: buy - action 29.0
Learning step: -7.905708312988281
desired expected reward: 265.38848876953125






Player: 1 
cards in hand: [0. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [0. 8. 1. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [0. 8. 1. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [0. 8. 1. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  8.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  8.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[242.13689]
 [225.56009]
 [225.6824 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -11.965143203735352
desired expected reward: 268.4349060058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[223.15475]
 [223.15475]
 [242.694  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -9.792694091796875
desired expected reward: 228.54251098632812



buy possibilites: [-1] 
expected returns: [[269.29333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  3.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -93.0 

action type: buy - action 0.0
Learning step: -9.748637199401855
desired expected reward: 213.40609741210938






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 24. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[259.62888]
 [250.38763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -11.340837478637695
desired expected reward: 257.9524841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[237.2678 ]
 [238.52269]
 [237.2678 ]
 [240.37592]
 [256.15372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  6.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3] -> size -> 22 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -11.068199157714844
desired expected reward: 248.4874267578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3. 0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3. 0. 3. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 8. 1. 3. 0. 0. 3. 0. 8. 3. 3. 0. 3. 3. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[322.906  ]
 [314.94424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -9.274554252624512
desired expected reward: 246.87916564941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[307.616  ]
 [308.94513]
 [308.84814]
 [307.616  ]
 [312.38235]
 [310.65695]
 [310.55994]
 [325.053  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -12.620183944702148
desired expected reward: 309.1639099121094



buy possibilites: [-1] 
expected returns: [[308.13855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 0. 10.  8.  6.  3.  0.  0. 29.  3.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -13.597683906555176
desired expected reward: 294.0183410644531






Player: 1 
cards in hand: [ 0.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[224.21642]
 [214.58475]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -14.650311470031738
desired expected reward: 293.4882507324219



action possibilites: [-1.] 
expected returns: [[258.10226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -62 

action type: take_action - action 29.0
Learning step: -7.267833232879639
desired expected reward: 192.23483276367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[240.54546]
 [241.77528]
 [241.68735]
 [240.77013]
 [240.54546]
 [243.141  ]
 [244.72635]
 [243.3094 ]
 [247.53539]
 [247.988  ]
 [243.68233]
 [245.01054]
 [243.22969]
 [243.51393]
 [245.17897]
 [254.62454]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -10.475295066833496
desired expected reward: 247.62696838378906



buy possibilites: [-1] 
expected returns: [[232.23886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -55.0 

action type: buy - action 15.0
Learning step: -9.78357219696045
desired expected reward: 235.39537048339844






Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [15. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [15. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  3.] 
adversary cards in discard: [15. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[223.63368]
 [210.15097]
 [210.05699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  3.] 
cards in discard: [15. 29.  0.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -10.89258861541748
desired expected reward: 221.3462677001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[207.54279]
 [208.69551]
 [207.54279]
 [210.36823]
 [223.43378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  3.] 
cards in discard: [15. 29.  0.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -10.40087604522705
desired expected reward: 211.7484893798828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [15. 29.  0.  0.  0.  3.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [15. 29.  0.  0.  0.  3.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.48032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [15. 29.  0.  0.  0.  3.  0.  0.  0.  8. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.  8.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -8.825812339782715
desired expected reward: 214.6079559326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.6672 ]
 [279.78018]
 [278.6672 ]
 [281.4198 ]
 [295.04797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [15. 29.  0.  0.  0.  3.  0.  0.  0.  8. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.  8.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -12.123302459716797
desired expected reward: 276.58233642578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.  8.  0.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.  8.  0.  3.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.  1.  0.  0.  8.  0.  3.  8.  0.  3.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[192.80238]
 [185.58191]
 [185.58191]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -14.693124771118164
desired expected reward: 280.3548889160156



action possibilites: [-1. 29.] 
expected returns: [[216.71129]
 [206.95508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action 29.0
Learning step: -7.492863655090332
desired expected reward: 175.48728942871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[197.08983]
 [198.72719]
 [198.61194]
 [197.08983]
 [202.98846]
 [200.85165]
 [200.73639]
 [217.78326]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -9.315272331237793
desired expected reward: 207.39601135253906






Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
adversary victory points: 2
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[194.31483]
 [186.04318]
 [180.23454]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  8.] 
cards in discard: [29.  0.  0.  3. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -10.816489219665527
desired expected reward: 206.96678161621094



action possibilites: [-1.  8. 15.] 
expected returns: [[186.28229]
 [176.61102]
 [178.22588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 15.] 
cards in discard: [29.  0.  0.  3. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action 29.0
Learning step: -8.247621536254883
desired expected reward: 175.8393096923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[174.1111 ]
 [175.06573]
 [174.99101]
 [174.1111 ]
 [176.12395]
 [177.49133]
 [176.26917]
 [180.31386]
 [176.58708]
 [176.19441]
 [177.884  ]
 [185.94012]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 15.] 
cards in discard: [29.  0.  0.  3. 29.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  7. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -8.40720272064209
desired expected reward: 177.87509155273438



buy possibilites: [-1] 
expected returns: [[214.02614]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 15.] 
cards in discard: [29.  0.  0.  3. 29.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -61.0 

action type: buy - action 8.0
Learning step: -7.0478692054748535
desired expected reward: 169.22128295898438






Player: 1 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [29.  0.  0.  3. 29.  6.  8. 29.  0.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [29.  0.  0.  3. 29.  6.  8. 29.  0.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [29.  0.  0.  3. 29.  6.  8. 29.  0.  0.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[169.85767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [29.  0.  0.  3. 29.  6.  8. 29.  0.  0.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -11.029509544372559
desired expected reward: 202.9966278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.92284]
 [157.92284]
 [169.06108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [29.  0.  0.  3. 29.  6.  8. 29.  0.  0.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -8.94534969329834
desired expected reward: 160.91232299804688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6. 10. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[190.94772]
 [178.13004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14] -> size -> 28 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -8.054198265075684
desired expected reward: 152.6002197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[171.65749]
 [172.76355]
 [172.68147]
 [171.65749]
 [174.01941]
 [175.6705 ]
 [174.19565]
 [179.07182]
 [174.58008]
 [174.11143]
 [176.13914]
 [186.03957]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14] -> size -> 28 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -9.495226860046387
desired expected reward: 178.0269012451172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 15. 29. 29.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 15. 29. 29.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 15. 29. 29.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  0. 15. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 29.] 
expected returns: [[108.36781 ]
 [102.843864]
 [100.786766]
 [102.843864]
 [102.843864]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15. 29. 29.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -11.099929809570312
desired expected reward: 174.9396209716797



action possibilites: [-1. 15. 29. 29.] 
expected returns: [[148.52531]
 [143.55887]
 [145.05414]
 [145.05414]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 29.  3.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action 29.0
Learning step: -4.96004581451416
desired expected reward: 97.22452545166016



action possibilites: [-1. 15. 29.] 
expected returns: [[215.28714]
 [205.97339]
 [208.7818 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29.  3.  6.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 29.0
Learning step: -4.6342620849609375
desired expected reward: 140.4198760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[199.89304]
 [200.99065]
 [200.90608]
 [199.89304]
 [203.79584]
 [202.38312]
 [202.29865]
 [213.55719]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29.  3.  6.] 
cards in discard: [ 0.  0.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.261015892028809
desired expected reward: 207.026123046875



buy possibilites: [-1] 
expected returns: [[233.94012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29.  3.  6.] 
cards in discard: [ 0.  0.  0. 10.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: -25 

action type: buy - action 1.0
Learning step: -6.035879611968994
desired expected reward: 194.95477294921875






Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3
  1 10 15 14  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  8.  3.  0.  0. 15.  3.  3.  0.  0.  1. 14. 29.  3.  0.  0.  0. 10.
  1.  0.  0.  1.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[121.80013]
 [113.13997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -12.6685152053833
desired expected reward: 221.2716064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.478065]
 [110.33007 ]
 [110.263115]
 [109.478065]
 [112.507545]
 [111.41274 ]
 [111.34588 ]
 [120.08578 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.15584135055542
desired expected reward: 114.64429473876953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  8.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0] -> size -> 28 
action values: 2 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[114.92785]
 [104.64765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 14.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -7.14202356338501
desired expected reward: 112.9437484741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.92835]
 [103.92835]
 [116.50705]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 14.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -6.895077705383301
desired expected reward: 108.03276824951172



buy possibilites: [-1] 
expected returns: [[155.8198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 0.  0.  0. 10.  0.  1. 29. 29.  0. 15. 29.  3.  6.  0.  0.  0.  8.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 14.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -6.84047269821167
desired expected reward: 97.08788299560547






Player: 1 
cards in hand: [ 3.  0.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 14.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 14.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[190.57211]
 [185.48065]
 [185.48065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -7.267653942108154
desired expected reward: 148.55213928222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[180.4744 ]
 [180.4744 ]
 [190.83504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -8.835383415222168
desired expected reward: 178.76971435546875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6. 10.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 15.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[126.89523]
 [120.32404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 15.  3.] 
cards in discard: [29.  3. 29.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 15.  0.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0 25] -> size -> 30 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -10.383662223815918
desired expected reward: 180.45135498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.987144]
 [115.987144]
 [125.483635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 15.  3.] 
cards in discard: [29.  3. 29.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  1. 15.  0.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0 25] -> size -> 30 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.262046813964844
desired expected reward: 119.63318634033203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 15.  0.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  0.  8.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  3  0  8  8  1  0  3 29  0  0  3  0  3  1 10
 15 14  1  0  0 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[128.23561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.
 29.  8. 15.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -6.707579135894775
desired expected reward: 112.1500244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[118.85167 ]
 [119.687294]
 [119.61308 ]
 [118.98775 ]
 [118.85167 ]
 [120.7924  ]
 [122.20608 ]
 [120.94501 ]
 [124.720406]
 [125.11943 ]
 [121.27008 ]
 [122.45249 ]
 [120.87106 ]
 [121.11749 ]
 [122.60509 ]
 [130.94872 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.
 29.  8. 15.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.24623966217041
desired expected reward: 120.98937225341797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.
 29.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  8.  8. 29.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.
 29.  8. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  8.  8. 29.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 10.  3.  3.  8.  3.  3.  3.  0.  3.  3. 14. 25.  0.  0.  0.  1.  1.
 29.  8. 15.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  8.  8. 29.  3.] 
adversary cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[85.991394]
 [76.509995]
 [76.509995]
 [80.472565]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 29.  3.] 
cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -8.35028076171875
desired expected reward: 122.59844970703125



action possibilites: [-1] 
expected returns: [[127.65167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.] 
cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.4426193237304688
desired expected reward: 69.85301971435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.16968]
 [115.16968]
 [127.30688]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.] 
cards in discard: [29.  3. 29.  0.  3.  0.  6.  6. 15.  3.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -6.2840576171875
desired expected reward: 121.36761474609375






Player: 1 
cards in hand: [ 3.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 22. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[165.18481]
 [154.45096]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3.  3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -6.9342241287231445
desired expected reward: 120.37264251708984



action possibilites: [-1.] 
expected returns: [[127.167786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3.  3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action 10.0
Learning step: -7.880963325500488
desired expected reward: 143.96380615234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.37829 ]
 [122.35197 ]
 [122.277985]
 [121.37829 ]
 [123.45759 ]
 [124.879684]
 [123.6089  ]
 [127.907455]
 [123.93457 ]
 [123.53519 ]
 [125.28404 ]
 [134.02325 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3.  3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -6.6292290687561035
desired expected reward: 120.53855895996094






Player: 1 
cards in hand: [ 3.  1. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  3.  3.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 25.  3.  3.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 21. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 25.  3.  3.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  0. 29.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [15.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[188.59352]
 [178.47075]
 [181.51968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  8. 10.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -7.189901828765869
desired expected reward: 126.83338165283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[170.03279]
 [171.09334]
 [170.03279]
 [172.69745]
 [184.68996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 29.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  8. 10.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -10.081406593322754
desired expected reward: 178.51210021972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 10.  0.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 11 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 1.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 1.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[163.23083]
 [155.44455]
 [158.70076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -10.270599365234375
desired expected reward: 174.41937255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[153.26099]
 [153.96617]
 [153.26099]
 [155.0019 ]
 [162.7882 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 20. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -9.250953674316406
desired expected reward: 153.97988891601562



buy possibilites: [-1] 
expected returns: [[181.18002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
adversary victory points: 11
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -74 

action type: buy - action 3.0
Learning step: -7.321757793426514
desired expected reward: 146.64439392089844






Player: 1 
cards in hand: [0. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1
  0  0 25  1  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[129.90202]
 [120.91509]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1
Learning step: -9.300557136535645
desired expected reward: 171.8794708251953



action possibilites: [-1] 
expected returns: [[109.50284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: trash_cards_n_from_hand - action 3
Learning step: -5.265651702880859
desired expected reward: 107.32365417480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.81661 ]
 [100.81661 ]
 [110.051315]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  8. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1
Learning step: -5.187154293060303
desired expected reward: 104.31568145751953



buy possibilites: [-1] 
expected returns: [[101.33438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [10.  0.  0.  0.  0.  3. 15.  3.  0. 29.  0.  3.  8. 29.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  3.  0.] 
adversary cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -353 

action type: buy - action 6.0
Learning step: -20.410808563232422
desired expected reward: 80.40580749511719






Player: 1 
cards in hand: [ 1.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  3.  0.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3.  0.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  3.  0.] 
cards in discard: [ 3.  3.  0. 14.  0.  0.  3.  3.  1. 25.  3.  3. 10.  3.  3.  8.  0.  1.
  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  6.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[106.268326]
 [102.19266 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0  0] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -6.4293532371521
desired expected reward: 94.905029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.975174]
 [ 96.975174]
 [105.319214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0  0] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -6.507869243621826
desired expected reward: 96.44988250732422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 15.] 
adversary cards in discard: [ 3.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  3  0  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1
  3  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 15.] 
adversary cards in discard: [ 3.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 15.] 
adversary cards in discard: [ 3.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 29. 15.] 
adversary cards in discard: [ 3.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[145.44304]
 [141.314  ]
 [141.314  ]
 [139.5168 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 15.] 
cards in discard: [ 3.  3.  6.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -5.711157321929932
desired expected reward: 99.6080551147461



action possibilites: [-1] 
expected returns: [[95.24161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.] 
cards in discard: [ 3.  3.  6.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 15.0
Learning step: -7.445390224456787
desired expected reward: 131.32113647460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[91.15658 ]
 [91.607864]
 [91.56822 ]
 [91.15658 ]
 [92.11316 ]
 [92.76271 ]
 [92.18462 ]
 [94.12157 ]
 [92.327705]
 [92.1455  ]
 [92.9449  ]
 [97.19488 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.] 
cards in discard: [ 3.  3.  6.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 3. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -5.29089879989624
desired expected reward: 89.9507064819336






Player: 1 
cards in hand: [3. 0. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 1.] 
cards in discard: [29. 15.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  3  8  8  0  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [29. 15.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [29. 15.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[114.56822]
 [103.29736]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  0.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -5.546123027801514
desired expected reward: 91.64875030517578



action possibilites: [-1.] 
expected returns: [[137.67459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 6.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action 10.0
Learning step: -4.154262542724609
desired expected reward: 97.88455200195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[128.37198]
 [128.947  ]
 [128.37198]
 [129.842  ]
 [136.69427]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 6.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -6.047598361968994
desired expected reward: 131.6269989013672



buy possibilites: [-1] 
expected returns: [[78.80829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 6.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -73.0 

action type: buy - action 0.0
Learning step: -8.29541301727295
desired expected reward: 120.07658386230469






Player: 1 
cards in hand: [0. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0. 10.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0. 10.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0. 10.  6.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[38.763626]
 [34.360638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0. 10.  6.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3. 10.  0.  0.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -6.249760627746582
desired expected reward: 72.55852508544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.7371  ]
 [35.055897]
 [35.02648 ]
 [34.7371  ]
 [35.860836]
 [35.45627 ]
 [35.427208]
 [39.783916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 3.  3.  6.  3. 29. 15. 29.  0. 29.  0. 10.  6.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3. 10.  0.  0.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -4.250661373138428
desired expected reward: 34.51296615600586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [25.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10.  0.  0.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 25. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 14.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0. 14.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 19. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0. 14.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[155.15797]
 [147.43993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3. 10. 25.  3.
  0.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -2.289642095565796
desired expected reward: 37.49427795410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[145.22064]
 [145.94348]
 [145.88313]
 [145.22064]
 [147.82257]
 [146.8826 ]
 [146.8231 ]
 [154.85709]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3. 10. 25.  3.
  0.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.836487770080566
desired expected reward: 143.4235076904297



buy possibilites: [-1] 
expected returns: [[119.74364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3. 10. 25.  3.
  0.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -9.26370906829834
desired expected reward: 126.89510345458984






Player: 1 
cards in hand: [3. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3. 10. 25.  3.
  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [29. 15.  3.  3.  0.  8.  3.  1.  1.  0.  3.  3.  0.  1.  3. 10. 25.  3.
  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
adversary victory points: 2
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[155.00604]
 [149.32329]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [0. 0. 0. 6. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -6.223910808563232
desired expected reward: 113.51972961425781



action possibilites: [-1.] 
expected returns: [[169.2986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 6. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -52 

action type: take_action - action 29.0
Learning step: -6.182116985321045
desired expected reward: 141.64459228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[154.84435]
 [155.92566]
 [155.82768]
 [155.03166]
 [154.84435]
 [157.16425]
 [158.7277 ]
 [157.3287 ]
 [161.57207]
 [162.0129 ]
 [157.67162]
 [159.00179]
 [157.2331 ]
 [157.50716]
 [159.16669]
 [168.56357]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 6. 0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  9.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -7.4695725440979
desired expected reward: 161.8290252685547



buy possibilites: [-1] 
expected returns: [[177.80066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: -3 

action type: buy - action 25.0
Learning step: -4.228087425231934
desired expected reward: 157.3439483642578






Player: 1 
cards in hand: [ 3. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 18. 30.  8.  7. 10. 10.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[123.89611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  7. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 3. 0. 3.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1
Learning step: -9.752370834350586
desired expected reward: 168.0482940673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.46913]
 [115.46913]
 [125.36839]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 18. 30.  8.  7. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 3. 0. 3.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -7.118528842926025
desired expected reward: 116.77758026123047



buy possibilites: [-1] 
expected returns: [[194.31847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [1. 1. 3. 0. 3.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -384.0 

action type: buy - action 6.0
Learning step: -20.60129165649414
desired expected reward: 94.86782836914062






Player: 1 
cards in hand: [1. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 0. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 10.  3.  6. 15.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  6.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 10.  3.  6. 15.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29. 10.  3.  6. 15.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [29. 10.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
expected returns: [[127.037544]
 [122.34944 ]
 [119.34796 ]
 [120.56603 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  6. 15.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  1. 10. 25.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -11.1250638961792
desired expected reward: 183.1934051513672



action possibilites: [-1] 
expected returns: [[154.26979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  6.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  1. 10. 25.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action 15.0
Learning step: -5.75723123550415
desired expected reward: 114.80879974365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.76259]
 [140.76259]
 [152.6758 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  3.  6.] 
cards in discard: [ 0.  0.  0.  6.  0.  8. 25. 29.  0.  0.  0.  3.  0.  6.  3.  3.  3.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [14.  1. 10. 25.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -7.592024326324463
desired expected reward: 146.67776489257812






Player: 1 
cards in hand: [14.  1. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1. 10. 25.  0.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 25.  0.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 25.  0.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 25.  0.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 3. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[84.94081]
 [77.94221]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0
 25  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: discard_down_to_3_cards - action 5
Learning step: -8.08530330657959
desired expected reward: 106.28841400146484



action possibilites: [-1] 
expected returns: [[68.261345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: trash_cards_n_from_hand - action 1
Learning step: -5.40880012512207
desired expected reward: 69.48480987548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.78282]
 [66.78282]
 [68.20364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -5.092050075531006
desired expected reward: 63.16929626464844






Player: 1 
cards in hand: [3. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29.  8.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29.  8.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29.  8.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.27015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [ 3. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 1.  3. 15.  0.  8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23  0] -> size -> 31 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.792148113250732
desired expected reward: 55.707618713378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.496494]
 [59.902786]
 [59.496494]
 [60.540752]
 [65.252975]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [ 3. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 18. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 1.  3. 15.  0.  8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23  0] -> size -> 31 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -6.088804721832275
desired expected reward: 59.81519317626953



buy possibilites: [-1] 
expected returns: [[62.620407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [ 3. 29.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 17. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 1.  3. 15.  0.  8.] 
adversary cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23  0] -> size -> 31 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -65 

action type: buy - action 3.0
Learning step: -4.836180210113525
desired expected reward: 55.06660461425781






Player: 1 
cards in hand: [ 1.  3. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.  0.  8.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  0  3  0  3  1 10 15 14  1  0  0 25  1  3  3  0
  0  1  3 11  8 23  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 17. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3. 25.  6.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 17. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3. 25.  6.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 17. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3. 25.  6.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [11. 29.  3.  3.  0.  3.  0.  8.  1.  1.  3.  0.  3. 23. 14.  1. 10. 25.
  0.  0.  3.  0.  3.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6. 10.  3. 25.  6.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  3. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[66.382744]
 [63.02318 ]
 [64.31136 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3. 25.  6.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -5.8133344650268555
desired expected reward: 56.807071685791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.30082 ]
 [63.30082 ]
 [67.372215]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3. 25.  6.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  6. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -5.992134094238281
desired expected reward: 60.390625



buy possibilites: [-1] 
expected returns: [[95.86918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3. 25.  6.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  5. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -394 

action type: buy - action 6.0
Learning step: -20.707983016967773
desired expected reward: 42.59284210205078






Player: 1 
cards in hand: [ 0.  3. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  5. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6] -> size -> 26 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  0.  8.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
adversary owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6  6] -> size -> 27 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[110.41827 ]
 [105.831924]
 [104.944786]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  8.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 10 29 29  6  3  6  8 29  0  0 15  8  0  3  6  0  0 25  6
  3  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -405 

action type: buy - action -1
Learning step: -22.60706901550293
desired expected reward: 73.2621078491211



action possibilites: [-1] 
expected returns: [[84.49735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: trash_cards_n_from_hand - action 9
Learning step: -7.17055082321167
desired expected reward: 100.26427459716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.319664]
 [75.319664]
 [85.00947 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 14.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1
Learning step: -6.1046671867370605
desired expected reward: 78.39268493652344






Player: 1 
cards in hand: [ 0.  0. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 14.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0. 29.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 14.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0. 29.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 14.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 29.  0. 29.] 
adversary cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[43.654427]
 [40.612595]
 [40.612595]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 29.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [1. 3. 3. 1. 8.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -7.997290134429932
desired expected reward: 77.01217651367188



action possibilites: [-1. 29.] 
expected returns: [[116.486305]
 [109.92419 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [1. 3. 3. 1. 8.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -73 

action type: take_action - action 29.0
Learning step: -3.106675863265991
desired expected reward: 37.50591278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.26591 ]
 [101.151924]
 [101.064125]
 [100.26591 ]
 [102.35349 ]
 [103.92553 ]
 [102.52335 ]
 [107.23277 ]
 [102.8635  ]
 [102.420685]
 [104.368355]
 [113.79489 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  9.  9.  8. 10.  8.] 
adversary cards in hand: [1. 3. 3. 1. 8.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -7.111090183258057
desired expected reward: 109.37522888183594



buy possibilites: [-1] 
expected returns: [[98.13394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [ 3. 29.  8.  3.  6.  0.  0.  3.  3.  6.  6. 10.  3. 25.  6.  6.  8.  0.
 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  8.] 
adversary cards in hand: [1. 3. 3. 1. 8.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -42 

action type: buy - action 14.0
Learning step: -5.035161972045898
desired expected reward: 97.8283462524414






Player: 1 
cards in hand: [1. 3. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  8.] 
adversary cards in hand: [25.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  8.] 
adversary cards in hand: [25.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [25.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[37.31978 ]
 [35.162746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1 15] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -8.791810035705566
desired expected reward: 89.34213256835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.33391 ]
 [33.610233]
 [33.33391 ]
 [34.04234 ]
 [37.311577]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.] 
adversary owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1 15] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -5.747934818267822
desired expected reward: 31.14594841003418



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  8  3 29  0  3  0  3  1 10 14  1  0  0 25  1  3  3  0  0  1
  3 11  8 23  0  3  0  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 6.  3.  3. 14.  8.] 
adversary cards in discard: [25.  3.  0.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 6.  3.  3. 14.  8.] 
adversary cards in discard: [25.  3.  0.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 6.  3.  3. 14.  8.] 
adversary cards in discard: [25.  3.  0.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[26.721746]
 [25.01227 ]
 [24.975388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 14.  8.] 
cards in discard: [25.  3.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 11. 23.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.225174427032471
desired expected reward: 26.97315216064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.64028 ]
 [24.64028 ]
 [26.758684]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14.  8.] 
cards in discard: [25.  3.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 0. 29.  0. 11. 23.] 
adversary cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.95424222946167
desired expected reward: 21.767499923706055



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0. 11. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11. 23.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 1 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15] -> size -> 30 
action values: 0 
buys: 2 
player value: 4 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  5.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 16. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0. 25.  0.  3.  1.  3.  3.  8.  1.  0.  0. 10.  0. 14. 15.  1.  3.  3.
  1.  8.  8.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  6. 10.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[50.228287]
 [47.83896 ]
 [47.81591 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  6.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -4.93071985244751
desired expected reward: 21.827966690063477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.918335]
 [46.918335]
 [49.724785]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  6.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -6.119400978088379
desired expected reward: 44.10888671875



buy possibilites: [-1] 
expected returns: [[78.234055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  6.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -124.0 

action type: buy - action 0.0
Learning step: -6.785650730133057
desired expected reward: 40.13267517089844






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  4.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[44.02226]
 [43.15929]
 [43.15929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 29.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [15.  3.  3.  3. 10.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -7.629441261291504
desired expected reward: 70.6046142578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.37815]
 [43.37815]
 [45.00393]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 29.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [15.  3.  3.  3. 10.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -5.904046535491943
desired expected reward: 38.11821746826172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  3. 10.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.  3.  3.
 29. 29.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  3. 10.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  3.  0.  6.  0.] 
adversary cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.  3.  3.
 29. 29.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
adversary victory points: 1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[66.52405]
 [62.07862]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  6.  0.] 
cards in discard: [25.  3.  0.  6.  0.  6.  3.  3. 14.  8.  0.  8.  6. 10.  6.  0.  3.  3.
 29. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 29.  3. 14. 23.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -5.485237121582031
desired expected reward: 39.51869583129883



action possibilites: [-1.] 
expected returns: [[67.45891]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 29.  3. 14. 23.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action 29.0
Learning step: -5.286105632781982
desired expected reward: 56.79250717163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.014427]
 [61.5493  ]
 [61.49423 ]
 [61.014427]
 [62.939537]
 [62.244015]
 [62.190678]
 [67.95431 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 29.  3. 14. 23.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: take_action - action -1.0
Learning step: -5.621367454528809
desired expected reward: 61.83753967285156



buy possibilites: [-1] 
expected returns: [[26.313555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 29.  3. 14. 23.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -56 

action type: buy - action 1.0
Learning step: -5.285409450531006
desired expected reward: 56.263885498046875






Player: 1 
cards in hand: [ 8. 29.  3. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 14. 23.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 23.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3. 23.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  3.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3. 23.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[90.74606 ]
 [86.674866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  8. 25.  3.  1.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8  8] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: discard_down_to_3_cards - action 6
Learning step: -7.268853664398193
desired expected reward: 84.36090850830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.94197 ]
 [84.94197 ]
 [89.919586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  8. 25.  3.  1.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8  8] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -7.261635780334473
desired expected reward: 83.48442840576172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  8. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25.  3.  1.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0 25  1  3  3  0  0  1  3 11  8
 23  0  3  0  1 15  8  3  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  6.  0. 10.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  6.  0. 10.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  6.  0. 10.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [29.  6.  0. 10.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [29.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[41.286346]
 [38.539017]
 [37.060844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0. 10.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -8.300323486328125
desired expected reward: 81.61927795410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.692253]
 [36.99595 ]
 [36.692253]
 [37.45984 ]
 [42.149704]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0. 10.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 15. 30.  8.  4. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -5.875405788421631
desired expected reward: 35.41093826293945



buy possibilites: [-1] 
expected returns: [[77.32938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0. 10.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -405.0 

action type: buy - action 6.0
Learning step: -19.8593807220459
desired expected reward: 7.126422882080078






Player: 1 
cards in hand: [ 3.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  2.  8.  6.  8.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  2.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  2.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3. 29.  6. 14.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[25.462263]
 [21.280413]
 [18.561235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  6. 14.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -8.596473693847656
desired expected reward: 68.73290252685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.04566 ]
 [16.04566 ]
 [24.585583]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6. 14.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 15. 30.  8.  3. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -6.05147123336792
desired expected reward: 19.410778045654297



buy possibilites: [-1] 
expected returns: [[35.41776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  6. 14.  0.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 1. 1. 1. 0.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -416.0 

action type: buy - action 6.0
Learning step: -20.805383682250977
desired expected reward: -4.759731292724609






Player: 1 
cards in hand: [0. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 1. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8. 11.  3.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  6.  3.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.  3. 29.  6. 14.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6] -> size -> 29 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 1. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 15.  3.  3.  3. 10.  8. 14.  8. 29.  3. 23.  0.
  8.  8.  3.  1. 14.  8. 11.  3.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 8 
card supply: [12. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 25.  6.  3.] 
adversary cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.  3. 29.  6. 14.  0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6] -> size -> 29 
adversary victory points: -1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[157.48183]
 [154.35335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  6.  3.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.  3. 29.  6. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -4.049948215484619
desired expected reward: 31.36781120300293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[150.40468]
 [150.40468]
 [156.57382]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  6.  3.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.  3. 29.  6. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -10.21008014678955
desired expected reward: 147.27174377441406



buy possibilites: [-1] 
expected returns: [[47.53751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 25.  6.  3.] 
cards in discard: [ 1. 29.  3.  0.  6.  0.  6.  0.  8.  3.  8.  0.  6. 29.  6.  0. 10.  0.
  6.  3. 29.  6. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [10.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: buy - action 0.0
Learning step: -13.750640869140625
desired expected reward: 136.65403747558594






Player: 1 
cards in hand: [10.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [29.  3.  8.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [29.  8.  6.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  6.  7.  9.  8. 10.  7.] 
adversary cards in hand: [29.  8.  6.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [29.  8.  6.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 10 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [29.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[34.49144 ]
 [32.326847]
 [31.328598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.] 
cards in discard: [3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: discard_down_to_3_cards - action 4
Learning step: -6.516723155975342
desired expected reward: 22.83025550842285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.795918]
 [30.795918]
 [34.3195  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  6.] 
cards in discard: [3. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -6.7860236167907715
desired expected reward: 27.705411911010742



buy possibilites: [-1] 
expected returns: [[36.161205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  6.] 
cards in discard: [3. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: buy - action 0.0
Learning step: -8.026168823242188
desired expected reward: 22.769742965698242






Player: 1 
cards in hand: [ 8.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [29. 14. 10.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [29. 14. 10.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 14.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[80.74556]
 [78.36958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 14.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [23.  1.  3.  8.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -5.808298587799072
desired expected reward: 30.352907180786133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.90944 ]
 [79.014915]
 [78.90944 ]
 [79.1934  ]
 [80.83494 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 14.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [23.  1.  3.  8.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1.0
Learning step: -8.039437294006348
desired expected reward: 72.70613098144531



buy possibilites: [-1] 
expected returns: [[122.60576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  0. 14.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [23.  1.  3.  8.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
adversary owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -146.0 

action type: buy - action 0.0
Learning step: -8.486842155456543
desired expected reward: 70.42259979248047






Player: 1 
cards in hand: [23.  1.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  3.  8.  0.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  8  3 29  3  0  3 10 14  1  0  0  1  3  3  0  0  1  3 11  8 23
  0  3  0  1 15  8  3  8  8  0 14  8 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 29.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  0  1  3  3  0  0  1  3 11  8 23  0  3  0
  1 15  8  3  8  8  0 14  8 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 29.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  0  1  3  3  0  0  1  3 11  8 23  0  3  0
  1 15  8  3  8  8  0 14  8 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 29.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[114.45156]
 [110.16806]
 [110.16806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.  6.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  1.  3. 15.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  0  1  3  3  0  0  1  3 11  8 23  0  3  0
  1 15  8  3  8  8  0 14  8 29] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -8.896024703979492
desired expected reward: 113.70973205566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.356155]
 [108.356155]
 [117.197174]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 29.  6.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  1.  3. 15.  0.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  0  1  3  3  0  0  1  3 11  8 23  0  3  0
  1 15  8  3  8  8  0 14  8 29] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: take_action - action -1.0
Learning step: -8.470049858093262
desired expected reward: 105.98150634765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  1.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 15.  0.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  0  1  3  3  0  0  1  3 11  8 23  0  3  0
  1 15  8  3  8  8  0 14  8 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 22. 30. 15. 30.  8.  2. 10.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
adversary owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 9 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[40.166553]
 [37.143723]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 3.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 10 29 29  3  6  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6
 14  0  1  6  6  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 3. 3. 3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -9.478938102722168
desired expected reward: 91.74186706542969



action possibilites: [-1] 
expected returns: [[45.594685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 3. 3. 3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: trash_cards_n_from_hand - action 3
Learning step: -5.158242225646973
desired expected reward: 32.524208068847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.24322 ]
 [40.24322 ]
 [44.439106]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 3. 3. 3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -5.619914531707764
desired expected reward: 39.974769592285156



buy possibilites: [-1] 
expected returns: [[67.60343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 3. 3. 3.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
adversary owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -116.0 

action type: buy - action 0.0
Learning step: -6.291082859039307
desired expected reward: 33.95212173461914






Player: 1 
cards in hand: [8. 8. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 3. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1
 15  8  3  8  8  0 14  8 29 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  6.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15
  8  3  8  8  0 14  8 29 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  6.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15
  8  3  8  8  0 14  8 29 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 6. 10.  0.  6.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[113.607475]
 [106.92846 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.  6.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [14.  8.  0.  3.  8.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.] 
adversary owned cards: [ 8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15
  8  3  8  8  0 14  8 29 16] -> size -> 33 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -5.671828746795654
desired expected reward: 61.931602478027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.25133]
 [103.25133]
 [111.40959]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.  6.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [14.  8.  0.  3.  8.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.] 
adversary owned cards: [ 8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15
  8  3  8  8  0 14  8 29 16] -> size -> 33 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -8.05154800415039
desired expected reward: 105.55592346191406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  8.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  3.  8.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3 29  3  3 10 14  0  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15
  8  3  8  8  0 14  8 29 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  1.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  1.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  1.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  0. 25.  1.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[110.32854]
 [107.75365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  1.  0.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  1.  1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -7.906524658203125
desired expected reward: 103.50305938720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[103.43762 ]
 [103.65571 ]
 [103.62637 ]
 [103.43762 ]
 [103.92041 ]
 [104.24935 ]
 [103.954155]
 [105.02641 ]
 [104.017555]
 [103.9259  ]
 [104.341   ]
 [107.4698  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1.  0.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  1.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  1.  1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -7.944392681121826
desired expected reward: 102.3841323852539



buy possibilites: [-1] 
expected returns: [[79.8847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1.  0.] 
cards in discard: [ 3.  0.  0. 29.  8.  6.  0.  3.  6.  0.  0. 14.  0.  3. 29. 29.  6.  0.
  8.  0.  3.  6. 10.  0.  6.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 29.  1.  1.] 
adversary cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -94.0 

action type: buy - action 8.0
Learning step: -8.100302696228027
desired expected reward: 95.85385131835938






Player: 1 
cards in hand: [ 8.  3. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  1.  1.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 0.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 0.] 
cards in discard: [29. 14. 10.  0.  0.  3.  8.  3.  0. 11.  0.  8. 23. 16. 15.  3.  1.  3.
  8.  8.  3.  3.  0.  8.  3.  8. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  6.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[19.587595]
 [18.919094]
 [19.201662]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 29 29  3  8 29  0  0  8  0  3  6  0  0 25  6  3  6  6 14  0
  1  6  6  0  0  0  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -8.358548164367676
desired expected reward: 71.5261459350586



action possibilites: [-1] 
expected returns: [[15.761025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.40316104888916
desired expected reward: 14.752514839172363





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.933574]
 [13.933574]
 [13.257785]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  2.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -4.277771949768066
desired expected reward: 11.483253479003906



buy possibilites: [-1] 
expected returns: [[49.615402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -387 

action type: buy - action 6.0
Learning step: -18.93033218383789
desired expected reward: -4.996761322021484






Player: 1 
cards in hand: [ 3.  3. 14.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  1. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  0. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  1. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  0. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  1. 29.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  0. 29.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[21.342928]
 [19.48045 ]
 [20.2604  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  0. 29.] 
cards in discard: [6. 8. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 1. 14.  3. 10.  3.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -7.364612579345703
desired expected reward: 42.250789642333984



action possibilites: [-1.  8.  8.] 
expected returns: [[9.47217 ]
 [6.309786]
 [6.309786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 8.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 1. 14.  3. 10.  3.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: discard_n_cards - action 3
Learning step: -4.907986164093018
desired expected reward: 9.910358428955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.4466515]
 [5.4466515]
 [9.143102 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 8.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 1. 14.  3. 10.  3.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.] 
adversary owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -4.653180122375488
desired expected reward: 4.8189897537231445






Player: 1 
cards in hand: [ 1. 14.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3. 10.  3.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  3.  8.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 29  3  3 10  1  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8
  8  0 14  8 29 16  0 14  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 22. 30. 15. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
adversary victory points: -2
player victory points: 9 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.88999116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0  3] -> size -> 33 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: discard_down_to_3_cards - action 0
Learning step: -7.121522426605225
desired expected reward: 17.908432006835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[-0.8899913]
 [-0.8899913]
 [-0.8899913]
 [-0.8899913]
 [-0.8899913]
 [-0.8899913]
 [-0.8899913]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0  3] -> size -> 33 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1.0
Learning step: -5.825525283813477
desired expected reward: -6.715516567230225



buy possibilites: [-1] 
expected returns: [[3.9997895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
adversary owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0  3] -> size -> 33 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -147.0 

action type: buy - action 0.0
Learning step: -7.215505123138428
desired expected reward: -8.105496406555176






Player: 1 
cards in hand: [ 3.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  8.  0.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8
  0 14  8 29 16  0 14  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [29.  0.  0. 14.  3.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [29.  0.  0. 14.  3.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [29.  0.  0. 14.  3.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[-0.88999116]
 [-0.88999116]
 [-0.88999116]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 14.  3.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 23. 15. 29.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -5.570014476776123
desired expected reward: -1.5702250003814697



action possibilites: [-1] 
expected returns: [[63.372505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 23.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action 14.0
Learning step: -2.8796193599700928
desired expected reward: -3.7696104049682617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[59.46855 ]
 [59.63967 ]
 [59.605682]
 [59.46855 ]
 [59.973156]
 [60.372223]
 [61.23995 ]
 [60.093895]
 [59.98295 ]
 [60.483177]
 [62.943226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 23.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -6.140294551849365
desired expected reward: 57.23221206665039






Player: 1 
cards in hand: [ 0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 25.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 25.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3] -> size -> 32 
action values: 0 
buys: 2 
player value: 5 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  9.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 25.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 22. 30. 14. 30.  8.  1.  8.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 25.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 22. 30. 14. 30.  8.  1.  8.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  6.  0. 25.] 
adversary cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[14.634985]
 [13.582179]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 25.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 14. 30.  8.  1.  8.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0] -> size -> 34 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1.0
Learning step: -8.17541217803955
desired expected reward: 54.76780319213867



action possibilites: [-1] 
expected returns: [[40.219254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 1. 6.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    2] 
sum of rewards: -85 

action type: take_action - action 25.0
Learning step: -4.02417516708374
desired expected reward: 9.55799674987793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.579662]
 [32.951244]
 [32.902073]
 [32.638725]
 [33.373634]
 [33.90163 ]
 [34.88936 ]
 [35.03468 ]
 [33.529976]
 [33.987644]
 [33.38535 ]
 [33.471363]
 [34.04625 ]
 [37.303455]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1. 6.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  5.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -5.570994853973389
desired expected reward: 34.648258209228516



buy possibilites: [-1] 
expected returns: [[90.745445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1. 6.] 
cards in discard: [ 6.  8.  6.  0. 29.  3.  6.  8.  8.  6.  0.  0.  0.  0.  0. 14. 29.  0.
  0.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    8.    0.] 
sum of rewards: -79.0 

action type: buy - action 29.0
Learning step: -3.659961700439453
desired expected reward: 31.37472152709961






Player: 1 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29] -> size -> 32 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29] -> size -> 32 
adversary victory points: -2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[14.541342 ]
 [14.8446045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  8.  0. 16.  8.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -9.055439949035645
desired expected reward: 81.69000244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.814953]
 [15.782473]
 [15.4043  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  8.  0. 16.  8.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -5.22334623336792
desired expected reward: 9.317989349365234



buy possibilites: [-1] 
expected returns: [[-0.89214766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 3.  8.  0. 16.  8.] 
adversary cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -127.0 

action type: buy - action 0.0
Learning step: -6.903328895568848
desired expected reward: 3.761777877807617






Player: 1 
cards in hand: [ 3.  8.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 16.  8.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3  3 10  3  3  0  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0
 14  8 29 16  0 14  0  3 16  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [ 0.  3.  3. 14.  1. 29.  3. 10.  8. 14.  3.  3.  8.  3. 11.  0. 15. 29.
 16.  0. 23.  0.  0.  1.  6.  8.  3.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.960585]
 [25.047663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 29.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [14. 16. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -3.742443561553955
desired expected reward: -4.634591102600098





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[24.709059]
 [24.70117 ]
 [24.536224]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 29.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [14. 16. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.042938232421875
desired expected reward: 19.917644500732422



buy possibilites: [-1] 
expected returns: [[30.000107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 29.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [14. 16. 10. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -117.0 

action type: buy - action 0.0
Learning step: -6.4104509353637695
desired expected reward: 18.298606872558594






Player: 1 
cards in hand: [14. 16. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16. 10. 11.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [6. 1. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16. 10. 11.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [6. 1. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [6. 1. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.667496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 29.  8.] 
adversary cards in discard: [14. 16. 10. 11.  6.] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -4.282486915588379
desired expected reward: 25.717620849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[62.788773]
 [63.23002 ]
 [63.172955]
 [63.7608  ]
 [64.40263 ]
 [65.79066 ]
 [63.94978 ]
 [63.77612 ]
 [64.576294]
 [68.6144  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 29.  8.] 
adversary cards in discard: [14. 16. 10. 11.  6.] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -6.34981632232666
desired expected reward: 63.31768035888672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 16.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0. 29.  8.] 
cards in discard: [14. 16. 10. 11.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.  6.  1.  6.  0.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0. 29.  8.] 
cards in discard: [14. 16. 10. 11.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.  6.  1.  6.  0.  0.] 
adversary owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 0 
Workshop: 0 
Chapel: 3 
Witch: 1 
Poacher: 4 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 8. 0. 3. 0.] 
cards in discard: [ 0.  0.  0.  3.  3. 10.  0.  0.  0.  3.  6. 29.  6.  1.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 29  3  8 29  0  0  8  0  3  0  0 25  6  3  6  6 14  0  1  6  6
  0  0  0  0  8  6  0 29  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 14. 30.  8.  0.  8.  9.  0.  8.  4.  6.  9.  8. 10.  7.] 
adversary cards in hand: [ 8. 16.  0. 29.  8.] 
adversary cards in discard: [14. 16. 10. 11.  6.  0.] 
adversary owned cards: [ 8 29  3 10  3  3  0  1  3 11  8 23  0  3  0  1 15  8  3  8  8  0 14  8
 29 16  0 14  0  3 16  0  6  0  0] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -587 

action type: buy - action -1.0
Learning step: -32.78071975708008
desired expected reward: 35.83369064331055



