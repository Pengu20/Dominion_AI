 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.212965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.855730056762695
desired expected reward: 7.668607711791992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.604347]
 [21.439528]
 [21.111284]
 [19.606647]
 [22.662077]
 [22.155136]
 [21.826899]
 [22.479376]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5998503565788269
desired expected reward: 21.997493743896484



buy possibilites: [-1] 
expected returns: [[22.354427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.018464241176843643
desired expected reward: 21.42106056213379






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.663761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5698182582855225
desired expected reward: 21.784608840942383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.522552]
 [23.35773 ]
 [23.029493]
 [21.524857]
 [22.895933]
 [24.580282]
 [24.073345]
 [24.61244 ]
 [23.075644]
 [23.745106]
 [23.910824]
 [24.397583]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6177189350128174
desired expected reward: 23.269384384155273



buy possibilites: [-1] 
expected returns: [[23.666464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5771786570549011
desired expected reward: 21.94537353515625






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [1. 0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.92572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6163008213043213
desired expected reward: 23.05016326904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.329138]
 [22.164316]
 [21.836077]
 [20.659676]
 [20.331438]
 [21.702517]
 [23.386868]
 [22.879927]
 [24.088488]
 [23.419024]
 [21.88223 ]
 [21.539995]
 [22.55169 ]
 [20.704815]
 [22.717407]
 [23.204165]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6096213459968567
desired expected reward: 22.599245071411133



buy possibilites: [-1] 
expected returns: [[25.332623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 14.0
Learning step: -0.3004743158817291
desired expected reward: 21.581754684448242






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.451786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6411507725715637
desired expected reward: 24.691471099853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.874708]
 [24.709888]
 [24.38165 ]
 [22.877012]
 [24.24809 ]
 [25.932438]
 [25.4255  ]
 [25.964598]
 [24.4278  ]
 [25.097263]
 [25.262978]
 [25.749739]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6549877524375916
desired expected reward: 24.94766616821289



buy possibilites: [-1] 
expected returns: [[25.378988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.29754146933555603
desired expected reward: 26.262136459350586






Player: 1 
cards in hand: [1. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[27.28535 ]
 [25.963413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6280804872512817
desired expected reward: 24.75090789794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.612785]
 [26.119722]
 [24.615088]
 [27.163572]
 [27.487812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6974579691886902
desired expected reward: 26.81123161315918



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.392231]
 [26.60709 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [ 3. 14.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 1. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6945858597755432
desired expected reward: 26.79322624206543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.749716]
 [25.58489 ]
 [25.256653]
 [23.752012]
 [26.807442]
 [26.300503]
 [25.972265]
 [26.62474 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [ 3. 14.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 1. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6746747493743896
desired expected reward: 25.867692947387695



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 1. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 1. 0. 0. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.32592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  1. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.649185061454773
desired expected reward: 25.975555419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.446196]
 [27.27284 ]
 [26.119343]
 [26.945986]
 [25.780792]
 [25.45478 ]
 [26.81403 ]
 [28.480759]
 [27.98097 ]
 [29.175453]
 [28.510048]
 [26.988714]
 [26.648424]
 [27.654116]
 [25.821781]
 [27.815361]
 [28.287409]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  1. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7057483196258545
desired expected reward: 27.474136352539062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  1. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 16.  0.  3.] 
cards in discard: [22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.016138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6714256405830383
desired expected reward: 27.615983963012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.284792]
 [29.78458 ]
 [28.293373]
 [30.819561]
 [31.126003]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7686449289321899
desired expected reward: 30.3929386138916



buy possibilites: [-1] 
expected returns: [[31.612476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0. 0. 1. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.47160640358924866
desired expected reward: 29.312973022460938






Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [22.  1.  1. 16.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [22.  1.  1. 16.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 29. 30.  8. 10.  9. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [22.  1.  1. 16.  0.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8. 10.  8. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[30.91547 ]
 [31.138107]
 [29.616776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7748000025749207
desired expected reward: 30.837677001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.208443]
 [30.035084]
 [29.70823 ]
 [28.217024]
 [31.243004]
 [30.743212]
 [30.416359]
 [31.049656]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8. 10.  8. 10.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7635080218315125
desired expected reward: 30.29550552368164



buy possibilites: [-1] 
expected returns: [[30.560425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 14.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.22640568017959595
desired expected reward: 31.016597747802734






Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [22.  1.  1. 16.  0.  3. 16.  0.  0.  0.  1.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.597454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  1. 22. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7026731967926025
desired expected reward: 29.857751846313477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.279064]
 [34.10571 ]
 [33.778854]
 [32.28765 ]
 [35.31363 ]
 [34.81384 ]
 [34.486988]
 [35.12028 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  8.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  1. 22. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8293948173522949
desired expected reward: 33.850563049316406



buy possibilites: [-1] 
expected returns: [[31.065975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  7.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 8.  1. 22. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.343216210603714
desired expected reward: 34.97041702270508






Player: 1 
cards in hand: [ 8.  1. 22. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 22. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 22 16 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  7.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  7.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  7.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.649525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [11.  8.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7800562977790833
desired expected reward: 30.285919189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.494406]
 [28.321053]
 [27.994202]
 [26.50299 ]
 [27.862244]
 [29.528973]
 [29.02918 ]
 [29.558262]
 [28.03693 ]
 [28.70233 ]
 [28.863575]
 [29.335625]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  9. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [11.  8.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7117039561271667
desired expected reward: 28.042865753173828



buy possibilites: [-1] 
expected returns: [[29.893307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [11.  0. 29. 14.  0.  0. 11.  3.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [11.  8.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.6469957232475281
desired expected reward: 28.382186889648438






Player: 1 
cards in hand: [ 0.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [11.  8.  1. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [11.  8.  1. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[28.459887]
 [28.653236]
 [28.153446]
 [28.682524]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7457216382026672
desired expected reward: 29.147584915161133



action possibilites: [-1. 11.  8.] 
expected returns: [[33.664837]
 [33.85819 ]
 [33.358395]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8. 10.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.06133752688765526
desired expected reward: 28.768918991088867



action possibilites: [-1] 
expected returns: [[32.316124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -265 

action type: gain_card_n - action 3
Learning step: -8.563620567321777
desired expected reward: 23.201072692871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.13578 ]
 [31.950693]
 [31.62661 ]
 [30.478045]
 [30.157635]
 [31.496801]
 [33.139156]
 [32.648335]
 [33.824253]
 [33.16652 ]
 [31.666513]
 [31.329895]
 [32.32425 ]
 [30.514984]
 [32.481422]
 [32.93612 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.419757604598999
desired expected reward: 32.73588180541992



buy possibilites: [-1] 
expected returns: [[32.48925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1.] 
cards in discard: [ 6. 23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 23.0
Learning step: 1.9512405395507812
desired expected reward: 33.281131744384766






Player: 1 
cards in hand: [3. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 26. 30. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [11.  8.  1. 11.  0.  0.  0.  3.  3. 16.  2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[26.13108 ]
 [24.861473]
 [26.334118]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 11.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 29. 30.  8.  9.  8.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8518033027648926
desired expected reward: 31.637447357177734



action possibilites: [-1] 
expected returns: [[30.449167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 29. 30.  8.  9.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.5366711020469666
desired expected reward: 24.304845809936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.872034]
 [29.362864]
 [27.893887]
 [30.384584]
 [30.672375]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 29. 29. 30.  8.  9.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15179094672203064
desired expected reward: 30.29737663269043



buy possibilites: [-1] 
expected returns: [[29.612928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 28. 30.  8.  9.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.12004995346069336
desired expected reward: 29.48291015625






Player: 1 
cards in hand: [ 3. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 28. 30.  8.  9.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 29. 28. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 29. 28. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 29. 28. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.051804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 29. 28. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [11.  1.  0.  8.  1.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7228055000305176
desired expected reward: 28.89012336730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.459946]
 [29.274855]
 [28.950775]
 [27.481802]
 [30.463322]
 [29.972494]
 [29.648415]
 [30.260284]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 29. 28. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [11.  1.  0.  8.  1.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7414532899856567
desired expected reward: 29.314006805419922



buy possibilites: [-1] 
expected returns: [[31.179317]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 23. 29. 11.  0.  0.  8.  1. 16.  3. 11.  0.  0.  3. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [11.  1.  0.  8.  1.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.631140410900116
desired expected reward: 28.31963348388672






Player: 1 
cards in hand: [11.  1.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  8.  1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  8. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.83454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  8. 10.] 
adversary cards in hand: [ 2.  0.  1. 16. 11.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1 22] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7290313243865967
desired expected reward: 30.450286865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.32558 ]
 [33.140488]
 [32.816406]
 [31.667843]
 [31.347433]
 [32.686592]
 [34.328957]
 [33.83813 ]
 [35.014053]
 [34.35632 ]
 [32.856308]
 [32.519688]
 [33.514046]
 [31.704782]
 [33.67122 ]
 [34.12592 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8. 10.  9.  9.  9. 10.  8. 10.] 
adversary cards in hand: [ 2.  0.  1. 16. 11.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1 22] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8164034485816956
desired expected reward: 33.12152099609375



buy possibilites: [-1] 
expected returns: [[36.70037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8.  9.  9.  9.  9. 10.  8. 10.] 
adversary cards in hand: [ 2.  0.  1. 16. 11.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1 22] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 25.0
Learning step: 0.684932291507721
desired expected reward: 35.6989860534668






Player: 1 
cards in hand: [ 2.  0.  1. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0.  1. 16. 11.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11 11  2  6  0  1 22] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8.  9.  9.  9.  9. 10.  8. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  9.  9. 10.  8. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 25. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  9.  9. 10.  8. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 1.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 24. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  9.  9. 10.  8. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[33.41156 ]
 [33.614597]
 [33.64196 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  3.  3.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  9.  9. 10.  8. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8980281352996826
desired expected reward: 35.80234146118164



action possibilites: [-1. 11.] 
expected returns: [[39.402813]
 [39.6201  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  3.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 24. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  9.  9. 10.  8. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.1395931988954544
desired expected reward: 33.546566009521484



action possibilites: [-1] 
expected returns: [[42.670067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 24. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0.8044699430465698
desired expected reward: 39.9233283996582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.030582]
 [41.51421 ]
 [40.059635]
 [42.53021 ]
 [42.79655 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 29. 27. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.20909510552883148
desired expected reward: 42.8791618347168



buy possibilites: [-1] 
expected returns: [[38.09901]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 3.0
Learning step: 0.4446132481098175
desired expected reward: 41.95882797241211






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  0. 16.  6. 14.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  0. 16.  6. 14.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6.  0. 16.  3.  0.  0.  1. 22. 11.  1.  0.  8.  1. 29.  1. 16.  2.  0.
  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  0. 16.  6. 14.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[28.454414]
 [27.045305]
 [27.210009]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  6. 14.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0016287565231323
desired expected reward: 37.097381591796875



action possibilites: [-1] 
expected returns: [[30.50776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  6.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 1. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.04596879705786705
desired expected reward: 27.164039611816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.811302]
 [29.619146]
 [29.294931]
 [27.840353]
 [29.168163]
 [30.79456 ]
 [30.310928]
 [30.821785]
 [29.332867]
 [29.986715]
 [30.140713]
 [30.577272]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  6.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 29. 26. 30.  8.  8.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 1. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1508179008960724
desired expected reward: 30.35694122314453



buy possibilites: [-1] 
expected returns: [[33.531033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  6.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [3. 1. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.033134460449219
desired expected reward: 18.807220458984375






Player: 1 
cards in hand: [3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6. 14.  0.  0.
 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  6.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6. 14.  0.  0.
 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6. 14.  0.  0.
 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[29.205132]
 [27.625807]
 [28.93879 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 23.  8.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6. 14.  0.  0.
 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 1. 11.  6.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8544449210166931
desired expected reward: 32.67658615112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.45141 ]
 [27.935041]
 [26.480463]
 [28.951038]
 [29.21738 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 23.  8.] 
cards in discard: [25.  0.  0.  1.  3.  0. 14.  3. 29. 11.  0.  3.  3.  3.  6. 14.  0.  0.
 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 1. 11.  6.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.729538083076477
desired expected reward: 28.47559356689453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.  0.  0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9. 10.  8. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[33.98089 ]
 [34.225403]
 [34.198174]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 26. 30.  8.  7.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [22.  1. 16.  1.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6673791408538818
desired expected reward: 28.55000114440918



action possibilites: [-1] 
expected returns: [[36.847984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [22.  1. 16.  1.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -9.145560264587402
desired expected reward: 23.603248596191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.34782]
 [34.37687]
 [37.11379]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [22.  1. 16.  1.  0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2783527970314026
desired expected reward: 36.56962966918945






Player: 1 
cards in hand: [22.  1. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1. 16.  1.  0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  0  1 16  8  1 16 11  2  6  0  1 22 29  1
  0 11 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  1.  0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  1.  0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.680847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9097647666931152
desired expected reward: 36.20402526855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.117416]
 [32.925266]
 [32.60105 ]
 [31.146473]
 [34.100677]
 [33.617046]
 [33.29283 ]
 [33.88339 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 29. 26. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8119456768035889
desired expected reward: 32.868900299072266



buy possibilites: [-1] 
expected returns: [[29.097801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [3. 0. 8. 1. 0.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.7621539235115051
desired expected reward: 31.82720947265625






Player: 1 
cards in hand: [3. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 16  8  1 16 11  2  6  0  1 22 29  1  0
 11 10  0 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [23.  0.  6.  0.  1.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [23.  0.  6.  0.  1.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  8.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [23.  0.  6.  0.  1.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [23.  0.  6.  0.  1.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [23.  0.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[32.805935]
 [31.238123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  0.  1.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [ 0.  0. 29. 16.  2.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.
  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6850565075874329
desired expected reward: 28.412744522094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.300758]
 [32.108234]
 [31.78096 ]
 [30.327919]
 [31.65702 ]
 [33.281532]
 [32.801327]
 [33.310055]
 [31.819048]
 [32.474052]
 [32.626526]
 [33.050022]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  0.  1.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  8.  9.  9.  8.  9.] 
adversary cards in hand: [ 0.  0. 29. 16.  2.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.
  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7936506271362305
desired expected reward: 32.01227951049805



buy possibilites: [-1] 
expected returns: [[27.264757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  6.  0.  1.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [ 0.  0. 29. 16.  2.] 
adversary cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.
  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.14170852303504944
desired expected reward: 31.96075439453125






Player: 1 
cards in hand: [ 0.  0. 29. 16.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 16.  2.] 
cards in discard: [ 3.  0. 11.  3.  1.  0. 10.  0. 11.  1.  6.  0.  0. 15. 16. 22.  1.  0.
  8.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [25.  3.  3. 14. 16.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  2.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [25.  3.  3. 14. 16.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  2.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  9.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [25.  3.  3. 14. 16.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  2.  3.] 
cards in discard: [25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  8.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [25.  3.  3. 14. 16.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25.  3.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 16.] 
expected returns: [[30.184998]
 [31.100037]
 [28.95402 ]
 [28.79199 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3. 14. 16.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 14 29  3 11 11  8  6 23 16  3  3 25
 14  3  6  6  3 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  8.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6526674032211304
desired expected reward: 26.612089157104492



action possibilites: [-1] 
expected returns: [[29.421371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  7.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 40 

action type: gain_card_n - action 9
Learning step: 0.6381481885910034
desired expected reward: 29.664018630981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.643604]
 [26.670765]
 [29.392868]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  6.  7.  5.  7.  7.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1365358531475067
desired expected reward: 29.284835815429688



buy possibilites: [-1] 
expected returns: [[29.395061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -9.041475296020508
desired expected reward: 17.629289627075195






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [ 0. 11.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  9.] 
adversary cards in hand: [ 0. 11.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 0. 11.  6.  8. 14.] 
adversary cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
expected returns: [[31.952116]
 [32.183624]
 [31.703419]
 [30.721142]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  8. 14.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [10.  0.  0.  1. 11.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6984895467758179
desired expected reward: 28.696571350097656



action possibilites: [-1] 
expected returns: [[33.6091]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  8.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.11873874068260193
desired expected reward: 30.60240364074707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.06996 ]
 [32.877434]
 [32.55016 ]
 [31.09712 ]
 [34.05073 ]
 [33.570526]
 [33.243256]
 [33.819225]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  8.] 
cards in discard: [ 6. 11.  3. 29.  0.  3.  3.  0.  3.  0.  3.  0. 14. 23.  0.  6.  0.  1.
 25.  6. 16. 25.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.21032409369945526
desired expected reward: 33.39877700805664






Player: 1 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11.  6.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  6.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[38.638977]
 [38.870483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  1.  8.  1. 22.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7574089765548706
desired expected reward: 33.06181716918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.010677]
 [37.490883]
 [36.037838]
 [38.511246]
 [38.759945]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  7.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  1.  8.  1. 22.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9122515916824341
desired expected reward: 37.726722717285156



buy possibilites: [-1] 
expected returns: [[40.495922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  6.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  1.  8.  1. 22.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.6381446123123169
desired expected reward: 37.87310028076172






Player: 1 
cards in hand: [ 0.  1.  8.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  1. 22.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  6.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11. 25.  3. 16.  6.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6  8] -> size -> 32 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  1. 22.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 24. 29. 25. 30.  8.  5.  7.  5.  6.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11. 25.  3. 16.  6.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6  8] -> size -> 32 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  1. 22.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  6.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [11. 25.  3. 16.  6.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6  8] -> size -> 32 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 25.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 16.] 
expected returns: [[34.063175]
 [34.307606]
 [34.99291 ]
 [32.678417]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3. 16.  6.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8  6 23 16  3  3 25 14
  3  6  6  3 14 25  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  6.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [15. 11.  6.  8.  0.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0057041645050049
desired expected reward: 39.49021911621094



action possibilites: [-1] 
expected returns: [[30.76665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  5.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [15. 11.  6.  8.  0.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 3
Learning step: -0.08856113255023956
desired expected reward: 32.63180160522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.232283]
 [28.255266]
 [30.972654]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  5.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [15. 11.  6.  8.  0.] 
adversary cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16026832163333893
desired expected reward: 30.606380462646484






Player: 1 
cards in hand: [15. 11.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  6.  8.  0.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  5.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 1.  0. 25. 23.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  8.  0.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 1.  0. 25. 23.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  8.  0.] 
cards in discard: [25. 29.  0.  0. 16.  2.  3. 15.  0.  0.  0.  0.  3. 10. 11.  0.  0.  0.
  1.  4.  0.  1.  8.  1. 22.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 1.  0. 25. 23.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 25. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 23.] 
expected returns: [[29.07485 ]
 [29.966461]
 [27.57647 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25. 23.  0.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  3. 15.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8] -> size -> 32 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7737202644348145
desired expected reward: 30.19893455505371



action possibilites: [-1. 25.] 
expected returns: [[33.55716 ]
 [34.460094]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  0.  0.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  5.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  3. 15.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8] -> size -> 32 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: -0.01925542764365673
desired expected reward: 27.557214736938477



action possibilites: [-1] 
expected returns: [[36.433228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3. 3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  4.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  3. 15.  8. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8  6] -> size -> 33 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0.3987460136413574
desired expected reward: 34.85884094238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.16105 ]
 [35.969822]
 [34.831356]
 [35.640125]
 [34.504204]
 [34.18403 ]
 [35.51666 ]
 [37.145847]
 [36.66676 ]
 [37.831154]
 [37.174316]
 [35.680237]
 [35.33891 ]
 [36.337074]
 [34.530132]
 [36.48901 ]
 [36.901413]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3. 3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8] -> size -> 32 
action values: 0 
buys: 2 
player value: 6 
card supply: [24. 24. 29. 25. 29.  8.  4.  7.  5.  4.  7.  8.  7.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  3. 15.  8. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8  6] -> size -> 33 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.3378119468688965
desired expected reward: 36.77103805541992



buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.342323]
 [32.365307]
 [35.082695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3. 3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  4.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 4.  3. 15.  8. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8  6] -> size -> 33 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 25  0] 
sum of rewards: 60 

action type: buy - action 22.0
Learning step: 1.1199826002120972
desired expected reward: 35.650115966796875






Player: 1 
cards in hand: [ 4.  3. 15.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3. 15.  8. 16.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10
  0 15  8 25 15  0  4  8  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  4.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 6.  3.  3. 14.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 15.  8.] 
cards in discard: [6. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  3.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 6.  3.  3. 14.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15.  8.] 
cards in discard: [6. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  3.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 6.  3.  3. 14.  0.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[27.88211]
 [26.69619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 14.  0.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  3.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  2.  0. 25.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9146994948387146
desired expected reward: 34.16799545288086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.300367]
 [25.351543]
 [27.990492]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14.  0.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  3.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  2.  0. 25.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7046844959259033
desired expected reward: 27.17742347717285



buy possibilites: [-1] 
expected returns: [[25.013601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14.  0.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  2.  0. 25.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.647902488708496
desired expected reward: 15.703640937805176






Player: 1 
cards in hand: [29.  0.  2.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  2.  0. 25.] 
cards in discard: [ 6.  6. 16.  4. 15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  6. 14.  3.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1. 25. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  0. 25. 11.] 
cards in discard: [ 6.  6. 16.  4. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  6. 14.  3.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0. 25. 11.] 
cards in discard: [ 6.  6. 16.  4. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  8.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  6. 14.  3.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0. 25. 11.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [29.  0.  6. 14.  3.] 
adversary cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  0.  6. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[28.083874]
 [28.348917]
 [26.897955]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6. 14.  3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 0. 10.  1.  0. 16.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6075491905212402
desired expected reward: 24.406051635742188



action possibilites: [-1] 
expected returns: [[26.678705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.07681223005056381
desired expected reward: 26.821142196655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.102491]
 [25.878077]
 [25.56193 ]
 [24.165552]
 [27.005857]
 [26.54642 ]
 [26.230272]
 [26.771408]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  3.] 
cards in discard: [ 8. 11.  6.  0.  3.  0.  8. 16. 11. 25.  3. 22. 23. 25.  1.  0.  0.  0.
  3.  3.  6.  6.  3.  3. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07602372765541077
desired expected reward: 26.60268211364746






Player: 1 
cards in hand: [10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 3. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 3. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  5.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 3. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 3. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[33.88744 ]
 [34.14573 ]
 [33.666435]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  9.  7.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.586413562297821
desired expected reward: 25.84286880493164



action possibilites: [-1] 
expected returns: [[38.432198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.08923530578613281
desired expected reward: 34.56599426269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.80819]
 [35.82616]
 [38.54058]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3107408583164215
desired expected reward: 38.121456146240234






Player: 1 
cards in hand: [ 1.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[34.205112]
 [32.9946  ]
 [32.9946  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 14.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0] -> size -> 36 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9538424611091614
desired expected reward: 37.586734771728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.651924]
 [33.462246]
 [33.131218]
 [31.669899]
 [34.642605]
 [34.16331 ]
 [33.832275]
 [34.384315]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 14.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 29. 25. 29.  8.  2.  7.  4.  4.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0] -> size -> 36 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8220693469047546
desired expected reward: 33.3830451965332



buy possibilites: [-1] 
expected returns: [[30.262466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 14.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [11.  6.  3.  8.  0.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0] -> size -> 36 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: -4.0 

action type: buy - action 8.0
Learning step: -0.8271433115005493
desired expected reward: 33.33616256713867






Player: 1 
cards in hand: [11.  6.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  8.  0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0.  3. 16.  1.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0.  3. 16.  1.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0.  3. 16.  1.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 0.  3. 16.  1.  0.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[29.167376]
 [27.830173]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  1.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3
  6  6  3 14 25  6  8  8 22  6 10  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  4.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 1.  0. 22.  0.  8.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0. 11.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7572327852249146
desired expected reward: 29.505233764648438



action possibilites: [-1] 
expected returns: [[25.625679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 1.  0. 22.  0.  8.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0. 11.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 5
Learning step: 0.23840463161468506
desired expected reward: 24.260570526123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.697275]
 [24.507603]
 [24.176573]
 [22.715252]
 [24.052483]
 [25.68796 ]
 [25.208664]
 [25.715714]
 [24.219154]
 [24.87763 ]
 [25.029478]
 [25.429672]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  8.  7.  8.] 
adversary cards in hand: [ 1.  0. 22.  0.  8.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0. 11.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05804511904716492
desired expected reward: 25.56763458251953



buy possibilites: [-1] 
expected returns: [[27.400122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  7.  7.  8.] 
adversary cards in hand: [ 1.  0. 22.  0.  8.] 
adversary cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0. 11.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
  4.5  0. ] 
sum of rewards: 17.5 

action type: buy - action 10.0
Learning step: 0.06637229770421982
desired expected reward: 24.94400405883789






Player: 1 
cards in hand: [ 1.  0. 22.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 22.  0.  8.] 
cards in discard: [ 6.  6. 16.  4. 15.  8. 29. 29.  0.  2.  0. 25. 11.  0. 16. 11. 10.  1.
  0.  0.  0.  1.  0. 15.  0.  0.  0.  0. 11.  6.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  7.  7.  8.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  7.  7.  8.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  7.  7.  8.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [22. 16.] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [6. 6. 8. 6. 3.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.467436]
 [22.252865]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 3.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  6
  6  3 14 25  6  8  8 22  6 10  8 11 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [29.  8.  0.  6. 11.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7369967699050903
desired expected reward: 26.663124084472656



action possibilites: [-1] 
expected returns: [[28.281881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [29.  8.  0.  6. 11.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.14897094666957855
desired expected reward: 20.051376342773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.777893]
 [25.823648]
 [28.467396]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [29.  8.  0.  6. 11.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11168191581964493
desired expected reward: 28.17020034790039



buy possibilites: [-1] 
expected returns: [[27.276346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [29.  8.  0.  6. 11.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.06693511456251144
desired expected reward: 26.71095848083496






Player: 1 
cards in hand: [29.  8.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  6. 11.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0 16  8  1 16 11  2  6  0  1 22 29  1  0 11 10  0
 15  8 25 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3.  3. 29.  8.  6.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3.  3. 29.  8.  6.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3.  3. 29.  8.  6.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3.  3. 29.  8.  6.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[25.210144]
 [25.498262]
 [25.012217]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  8.  6.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0 29  3 11 11  8 23 16  3  3 25 14  3  3 14
 25  8  8 22  6 10  8 11 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7027262449264526
desired expected reward: 26.573619842529297



action possibilites: [-1] 
expected returns: [[27.124163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.026859913021326065
desired expected reward: 23.62498664855957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.55321 ]
 [24.570349]
 [27.270012]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0] -> size -> 37 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0897558405995369
desired expected reward: 27.034406661987305






Player: 1 
cards in hand: [ 0.  0.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.  8.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 25. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  3. 22. 23. 11.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 24. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  3. 22. 23. 11.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 24. 29.  8.  2.  7.  3.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  3. 22. 23. 11.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 29. 24. 29.  8.  2.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  3. 22. 23. 11.] 
adversary cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25.  3. 22. 23. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22. 23. 11.] 
expected returns: [[15.722245]
 [16.62118 ]
 [13.544599]
 [14.286022]
 [15.977693]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 22. 23. 11.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 24. 29.  8.  2.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 6.  6.  1. 10. 29.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.805260956287384
desired expected reward: 26.464750289916992



action possibilites: [-1] 
expected returns: [[16.49906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 23. 11. 25.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 6.  6.  1. 10. 29.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.12460470199584961
desired expected reward: 16.745784759521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.953869]
 [14.04857 ]
 [16.564428]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22. 23. 11. 25.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 6.  6.  1. 10. 29.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11740075796842575
desired expected reward: 16.6164608001709



buy possibilites: [-1] 
expected returns: [[19.972616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22. 23. 11. 25.  0.] 
cards in discard: [10. 11.  3.  8.  3.  0.  8.  0. 14.  0. 14.  0. 11. 10. 16.  0.  1.  0.
  0.  8.  8.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 6.  6.  1. 10. 29.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.21109642088413239
desired expected reward: 15.16496467590332






Player: 1 
cards in hand: [ 6.  6.  1. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1. 10. 29.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1. 10.  0.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 10.  0.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  3.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 10.  0.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  2.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [25.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[31.762331]
 [32.71844 ]
 [31.555809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  2.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  0.  3.  0. 15.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8] -> size -> 41 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4115673303604126
desired expected reward: 19.56104850769043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.155577]
 [30.633781]
 [29.172714]
 [31.665857]
 [31.87238 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  2.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  0.  3.  0. 15.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8] -> size -> 41 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7780574560165405
desired expected reward: 30.98427391052246



buy possibilites: [-1] 
expected returns: [[27.876251]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.  0.  3.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  1.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  0.  3.  0. 15.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8] -> size -> 41 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5672751665115356
desired expected reward: 31.09858512878418






Player: 1 
cards in hand: [11.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 15.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 29. 24. 29.  8.  1.  7.  2.  1.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  3.  0.  0. 11.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 24. 29.  8.  1.  7.  2.  1.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  3.  0.  0. 11.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 29. 24. 29.  8.  1.  7.  2.  1.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  3.  0.  0. 11.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 24. 29.  8.  1.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [11.  3.  0.  0. 11.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[24.397535]
 [24.669212]
 [24.669212]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 24. 29.  8.  1.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 4. 25. 15. 16.  2.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.728021502494812
desired expected reward: 27.148229598999023



action possibilites: [-1] 
expected returns: [[23.631987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 29.  8.  1.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 4. 25. 15. 16.  2.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.26858922839164734
desired expected reward: 23.758684158325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[22.141844]
 [22.613398]
 [21.168707]
 [23.822863]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 24. 29.  8.  1.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 4. 25. 15. 16.  2.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02046329528093338
desired expected reward: 23.611522674560547



buy possibilites: [-1] 
expected returns: [[25.951033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 29. 24. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 4. 25. 15. 16.  2.] 
adversary cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -286.0 

action type: buy - action 6.0
Learning step: -8.942575454711914
desired expected reward: 12.226133346557617






Player: 1 
cards in hand: [ 4. 25. 15. 16.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 25. 15. 16.  2.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 22. 11.  0.  8.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 25. 16.  2.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 22. 11.  0.  8.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 25. 16.  2.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 29. 24. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 22. 11.  0.  8.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 25. 16.  2.] 
cards in discard: [10. 22. 16.  1.  0.  0.  8.  0.  0.  0.  0.  8. 11.  3. 11. 11.  0.  0.
  1.  8.  6.  8. 29.  6.  6.  1. 10.  0.  0.  8. 11.  0.  3.  0. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 22. 11.  0.  8.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 22. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 11.  8.] 
expected returns: [[21.121412]
 [20.631214]
 [18.92148 ]
 [21.392445]
 [20.94445 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 22. 11.  0.  8.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8 22 10  8 11 10  0  0  8  1  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7105482816696167
desired expected reward: 25.2404842376709



action possibilites: [-1] 
expected returns: [[24.624292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.06082294508814812
desired expected reward: 21.65189552307129





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.916357]
 [24.597376]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03751659393310547
desired expected reward: 24.586776733398438



buy possibilites: [-1] 
expected returns: [[24.394735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.01865404099225998
desired expected reward: 22.93501091003418






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25
 15  0  4  8  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[18.903677]
 [18.726717]
 [18.726717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [15.  1. 11.  2.  4.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6843444108963013
desired expected reward: 23.710390090942383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[17.370659]
 [17.818655]
 [18.967623]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [15.  1. 11.  2.  4.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 40 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5256388783454895
desired expected reward: 18.37803840637207



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  1. 11.  2.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 11.  2.  4.] 
cards in discard: [8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 23. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  2.  4.] 
cards in discard: [8. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 22. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  2.  4.] 
cards in discard: [8. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 29. 22. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  2.  4.] 
cards in discard: [8. 3. 1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.018404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 11.  8.  3.  8.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5718355178833008
desired expected reward: 18.395790100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[12.637167]
 [13.370924]
 [13.067869]
 [14.447382]
 [13.706506]
 [14.182669]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  2.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 11.  8.  3.  8.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4262350797653198
desired expected reward: 13.592168807983398



buy possibilites: [-1] 
expected returns: [[13.269239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10. 11.  8.  3.  8.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 12 

action type: buy - action 11.0
Learning step: 0.06590554863214493
desired expected reward: 14.513287544250488






Player: 1 
cards in hand: [10. 11.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3.  8.] 
cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3. 10. 14. 14. 23.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  3.  8.] 
cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3. 10. 14. 14. 23.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8.  3.  8.] 
cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 3. 10. 14. 14. 23.] 
adversary cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 14. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 14. 23.] 
expected returns: [[11.943549]
 [11.472209]
 [10.876252]
 [10.876252]
 [10.560326]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14. 14. 23.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 1.  3.  6.  0. 16.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4293716847896576
desired expected reward: 12.83986759185791



action possibilites: [-1. 14. 14. 23.] 
expected returns: [[12.063648]
 [10.996353]
 [10.996353]
 [10.680428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 14. 23.  1.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 1.  3.  6.  0. 16.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.22511465847492218
desired expected reward: 11.697322845458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.566353]
 [10.997054]
 [12.10174 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 14. 23.  1.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 29. 22. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 1.  3.  6.  0. 16.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.20776662230491638
desired expected reward: 12.271414756774902



buy possibilites: [-1] 
expected returns: [[14.698302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 14. 23.  1.] 
cards in discard: [ 8. 25.  0.  8.  0.  3.  1.  6. 11.  3.  0.  0. 11.  0.  8. 11.  0.  0.
  8.  8.  0.  3. 11.  3.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 21. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 1.  3.  6.  0. 16.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 21 

action type: buy - action 3.0
Learning step: 0.45699989795684814
desired expected reward: 11.45405387878418






Player: 1 
cards in hand: [ 1.  3.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6.  0. 16.] 
cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 21. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10.  6.  1. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11  3] -> size -> 37 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6.  0. 16.] 
cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 29. 21. 29.  8.  0.  7.  1.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [10.  6.  1. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11  3] -> size -> 37 
adversary victory points: 6
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 0 
Workshop: 3 
Chapel: 4 
Witch: 1 
Poacher: 1 
Militia: 2 
Market: 1 
Village: 1 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  6.  1. 25. 16.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  1  0  3 11 11  8 23 16  3  3 25 14  3  3 14 25
  8  8  8 11 10  0  0  8  1  6  0 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 21. 29.  8.  0.  7.  0.  0.  7.  7.  7.  9.  6.  7.  8.] 
adversary cards in hand: [ 1.  3.  6.  0. 16.] 
adversary cards in discard: [ 8.  3.  1. 11. 15.  1.  2.  4.  0. 10. 11.  8.  3.  8. 11.] 
adversary owned cards: [ 0  3  0 16  8  1 16 11  2  0  1 22  1  0 11 10  0 15  8 25 15  0  4  8
  6  6 29 11  0  0  0 10  0  3 11  6  8  0  8  3  3  1  0 11] -> size -> 44 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.409050941467285
desired expected reward: 29.10735321044922



