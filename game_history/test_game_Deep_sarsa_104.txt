 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[36.53864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1.0
Learning step: -300005.0
desired expected reward: -299989.9375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.696014]
 [67.92541 ]
 [53.665897]
 [16.318394]
 [73.5852  ]
 [57.35843 ]
 [43.044792]
 [35.568417]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.603477478027344



buy possibilites: [-1] 
expected returns: [[22.593746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.58518981933594






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.740612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.593746185302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[36.4792  ]
 [65.82897 ]
 [51.865395]
 [15.16623 ]
 [55.85528 ]
 [71.89944 ]
 [55.34579 ]
 [96.256516]
 [29.91901 ]
 [41.726143]
 [58.415627]
 [35.20599 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.50089645385742



buy possibilites: [-1] 
expected returns: [[10.631764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.25652313232422






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[11.608804]
 [39.225597]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.63176441192627



action possibilites: [-1. 11.] 
expected returns: [[19.649616]
 [47.150845]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.482669830322266



action possibilites: [-1] 
expected returns: [[28.980782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.445064544677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.954758]
 [68.49025 ]
 [52.728207]
 [22.081768]
 [60.100075]
 [70.69915 ]
 [57.238304]
 [99.540955]
 [33.15089 ]
 [42.831486]
 [58.954773]
 [32.05317 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.98078155517578



buy possibilites: [-1] 
expected returns: [[11.562776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 99.54096221923828






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[56.35571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.562775611877441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.408947]
 [83.76818 ]
 [70.86961 ]
 [44.407963]
 [87.03623 ]
 [73.814354]
 [63.600643]
 [56.429028]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.06223678588867



buy possibilites: [-1] 
expected returns: [[32.342087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  3.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.03624725341797






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.682625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.34208679199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 42.744324]
 [ 69.109116]
 [ 53.596664]
 [ 35.423912]
 [ 25.0209  ]
 [ 60.40946 ]
 [ 71.76194 ]
 [ 57.797993]
 [116.68613 ]
 [101.769714]
 [ 36.2245  ]
 [ 62.464054]
 [ 45.243526]
 [ 38.503696]
 [ 59.828613]
 [ 36.550217]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.166698455810547



buy possibilites: [-1] 
expected returns: [[13.787631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 116.68612670898438






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  3. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[-14.205865 ]
 [ 21.036411 ]
 [  2.1263752]
 [  2.1263752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 11.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.787631034851074



action possibilites: [-1. 11. 11.] 
expected returns: [[31.389294]
 [58.660027]
 [58.660027]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.86876392364502



action possibilites: [-1] 
expected returns: [[10.354701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 69.2732162475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.38557  ]
 [ 6.7412767]
 [19.543648 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.354701042175293



buy possibilites: [-1] 
expected returns: [[34.931038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [25.  0.  0.  0.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 24.385570526123047






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 1.2789717]
 [ 6.29311  ]
 [42.19395  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.93103790283203



action possibilites: [-1. 10. 25.] 
expected returns: [[20.131542]
 [26.149921]
 [70.20579 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.8226318359375



action possibilites: [-1] 
expected returns: [[14.472796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.2057876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.448044 ]
 [40.583633 ]
 [30.559612 ]
 [15.128051 ]
 [ 7.2472963]
 [34.75363  ]
 [43.153385 ]
 [33.36927  ]
 [71.0646   ]
 [61.534916 ]
 [15.757573 ]
 [36.29509  ]
 [23.345234 ]
 [17.805504 ]
 [34.910713 ]
 [16.717201 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.472796440124512



buy possibilites: [-1] 
expected returns: [[23.4598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0. 29.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.06460571289062






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9. 10.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3. 10. 11.  3.  0.  0. 11.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.972516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.459800720214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.54156  ]
 [33.65259  ]
 [23.803474 ]
 [ 1.6701488]
 [36.319363 ]
 [26.367031 ]
 [17.64859  ]
 [13.6574545]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  6. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.510648727416992



buy possibilites: [-1] 
expected returns: [[15.275929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.31935501098633






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11. 10.  0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5. 10.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11. 10.  0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11. 10.  0.] 
adversary cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[ 1.2778444 ]
 [18.756725  ]
 [18.756725  ]
 [-0.15488791]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 10.  0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16. 11.  3.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.27592945098877



action possibilites: [-1] 
expected returns: [[42.647247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16. 11.  3.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.87655258178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.255936]
 [12.268045]
 [45.974827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.] 
cards in discard: [25. 29. 25.  0.  0. 10.  0.  0. 29. 11.  0.  3.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [16. 11.  3.  0.  3.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.647247314453125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [16. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3.  0.  3.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[45.302624]
 [69.64894 ]
 [85.36938 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.974884033203125



action possibilites: [-1. 11. 29.] 
expected returns: [[ 66.393456]
 [ 89.01593 ]
 [104.07004 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 78.023193359375



action possibilites: [-1. 11.] 
expected returns: [[72.41749]
 [90.86971]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.07002258300781



action possibilites: [-1] 
expected returns: [[18.087765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 100.3735580444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.377583]
 [38.16079 ]
 [32.42486 ]
 [19.980412]
 [35.82191 ]
 [38.413387]
 [34.146477]
 [49.040855]
 [25.066639]
 [28.72504 ]
 [34.537285]
 [24.453854]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.087764739990234



buy possibilites: [-1] 
expected returns: [[39.760498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 49.04084396362305






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  9.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3.  0. 29.  0. 11. 16.  3.  0.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11. 25.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 25.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[25.64841 ]
 [33.72456 ]
 [48.811985]
 [17.882782]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 14. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.760498046875



action possibilites: [-1] 
expected returns: [[26.485802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 25.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  5.  8.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 14. 11. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.03746795654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.796505 ]
 [31.742664 ]
 [ 1.9156394]
 [32.926147 ]
 [25.851002 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10. 25.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  5.  8.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 14. 11. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.485801696777344



buy possibilites: [-1] 
expected returns: [[20.737858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10. 25.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 14. 11. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.9261360168457






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [29.  0. 14. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14. 11. 10.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14. 10.] 
cards in discard: [6. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 14. 10.] 
cards in discard: [6. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 14. 10.] 
cards in discard: [6. 1. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[31.61737 ]
 [60.293484]
 [31.675632]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.737857818603516



action possibilites: [-1] 
expected returns: [[73.232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.08930206298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 69.939255]
 [ 96.21409 ]
 [ 84.72383 ]
 [ 49.93517 ]
 [106.39712 ]
 [ 86.83079 ]
 [ 76.61275 ]
 [ 75.19896 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  5.  7.  8.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.23200225830078



buy possibilites: [-1] 
expected returns: [[88.13861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  0.  3.  8. 25. 11.  0.  0. 10. 25.  3. 10.
 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  4.  7.  8.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 106.39708709716797






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  4.  7.  8.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  4.  7.  8.  6.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[21.334839]
 [45.16878 ]
 [40.042294]
 [22.831848]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0 10] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.13861083984375



action possibilites: [-1] 
expected returns: [[45.323444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0 10  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.22286605834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.071686]
 [42.215466]
 [16.754879]
 [41.43866 ]
 [44.52112 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 3.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0 10  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.32344436645508






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 6. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 3.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  0 11 11 14  3  6 16  8 29  0  8  6
  1  0 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  0. 25. 11.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  0. 25. 11.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  0. 25. 11.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[66.930984]
 [59.241695]
 [98.53885 ]
 [81.29065 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 25. 11.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.52113723754883



action possibilites: [-1] 
expected returns: [[52.365444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11. 29.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.88771057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.85439 ]
 [44.91464 ]
 [26.332687]
 [42.941483]
 [53.08824 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 11. 29.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 16.] 
adversary cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.36544418334961






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 16.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [ 6.  1.  0. 11. 29.  0. 14. 10. 10.  0.  3.  0.  0.  0.  6.  8.  3.  6.
  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[101.45309]
 [ 98.07779]
 [122.51926]
 [130.53691]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  3.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.08823776245117



action possibilites: [-1. 10. 11.] 
expected returns: [[51.37794 ]
 [50.701313]
 [68.3926  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.53689575195312



action possibilites: [-1] 
expected returns: [[70.04185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.05388641357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[61.315563]
 [81.730934]
 [74.86697 ]
 [44.67567 ]
 [89.24379 ]
 [75.692116]
 [68.82814 ]
 [69.513626]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  4.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.0418472290039



buy possibilites: [-1] 
expected returns: [[38.402092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.2437744140625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6
  6  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 10.  0.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 10.  0.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 10.  0.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  8. 10.  0.] 
adversary cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[41.625904]
 [65.18282 ]
 [52.01549 ]
 [44.817055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.40209197998047



action possibilites: [-1] 
expected returns: [[35.185795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.69849395751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.584156]
 [37.16272 ]
 [19.062782]
 [37.636616]
 [33.988457]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  7.  8.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.185794830322266



buy possibilites: [-1] 
expected returns: [[47.460308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.] 
cards in discard: [25.  0. 29. 10.  0. 11. 10. 25. 10.  3.  0. 11. 29.  0. 10. 11. 29. 11.
 10.  0.  3.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.636627197265625






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  1.] 
cards in discard: [ 0.  8. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 0.  8. 29.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1.] 
cards in discard: [ 0.  8. 29.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[78.00076]
 [72.12777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [16. 10.  6. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0 15] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.46030807495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.14725 ]
 [77.47047 ]
 [49.867207]
 [77.853   ]
 [77.86456 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [16. 10.  6. 10.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0 15] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.86131286621094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [16. 10.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  6. 10.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3
  0  0 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 10. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25. 29. 10. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25. 29. 10. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11.] 
expected returns: [[50.23109]
 [83.83892]
 [72.77459]
 [47.24986]
 [69.85284]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 10. 11.] 
cards in discard: [ 3.  0.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  6.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15] -> size -> 27 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.86457824707031



action possibilites: [-1] 
expected returns: [[98.430855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11.  8. 29.] 
cards in discard: [ 3.  0.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.83892822265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 73.386116]
 [ 49.963207]
 [101.07142 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10. 11.  8. 29.] 
cards in discard: [ 3.  0.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.43085479736328






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 11. 11.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[50.565   ]
 [71.76233 ]
 [58.452557]
 [58.452557]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11. 11.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  5.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0] -> size -> 29 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.07142639160156



action possibilites: [-1] 
expected returns: [[90.13107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.76233673095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[73.94084 ]
 [94.3944  ]
 [50.494164]
 [94.21135 ]
 [93.6044  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.13107299804688



buy possibilites: [-1] 
expected returns: [[122.405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 94.39441680908203






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [14.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3] -> size -> 31 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3] -> size -> 31 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [ 0.  8. 29.  3. 15. 11.  8.  0.  0.  1. 15. 16.  6. 10.  0.  6.  0.  3.
  3.  6.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  8. 10. 10.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3] -> size -> 31 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 10.] 
expected returns: [[55.79707 ]
 [78.37171 ]
 [65.98851 ]
 [57.822475]
 [57.822475]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.40499877929688



action possibilites: [-1] 
expected returns: [[34.985855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.4261703491211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.489353]
 [21.175674]
 [40.487637]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.98585510253906






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 26. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  6.  3.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[96.00573]
 [97.07811]
 [94.42823]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 29.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  8.  0.  1. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.487640380859375



action possibilites: [-1] 
expected returns: [[83.24523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  8.  0.  1. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.43936157226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.70985 ]
 [83.22429 ]
 [46.261295]
 [83.16351 ]
 [81.16218 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 25. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  8.  0.  1. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.24523162841797



buy possibilites: [-1] 
expected returns: [[63.726337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.] 
cards in discard: [ 3.  0.  0. 10.  3. 25.  0. 29. 10. 11.  8. 29.  3. 25.  0.  0. 11. 11.
 10. 10. 10. 11.  0.  8. 10. 10. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  8.  0.  1. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 83.22428131103516






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  8.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  1. 15.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0
  0 15 15  6  0  6  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 24. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 24. 30.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[42.560513]
 [78.04109 ]
 [60.549267]
 [40.176857]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 11. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  4.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0.  0.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4] -> size -> 32 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.72633743286133



action possibilites: [-1] 
expected returns: [[62.992527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0.  0.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6] -> size -> 33 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.04106903076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.778706]
 [69.87729 ]
 [38.736248]
 [70.57911 ]
 [65.48678 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  6.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0.  0.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6] -> size -> 33 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.99252700805664



buy possibilites: [-1] 
expected returns: [[60.575016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 10.  3.  0.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  5.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0.  0.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6] -> size -> 33 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 70.57917022705078






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  5.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [15. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10.] 
expected returns: [[78.04382 ]
 [80.76067 ]
 [62.897785]
 [62.897785]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.  0. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8
 10 11 10 11 10  8  3 10 15  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.575016021728516



action possibilites: [-1] 
expected returns: [[27.243408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 80.76068115234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[30.679802]
 [49.558918]
 [40.680687]
 [16.51368 ]
 [51.48241 ]
 [43.187717]
 [28.24802 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  3.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.243408203125



buy possibilites: [-1] 
expected returns: [[89.25774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  8. 10.  0.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 51.48237228393555






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 10.  0.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0 10  6  6  3  0  0
 15 15  6  0  6  0  3  4  6 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 25.  0.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 25.  0.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 25.  0.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 25.  0.  3. 29.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 8. 25.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29.] 
expected returns: [[108.70712]
 [100.02376]
 [159.16537]
 [135.92514]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  3. 29.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  3.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.25773620605469



action possibilites: [-1] 
expected returns: [[78.59082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 29. 10. 29.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.16537475585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.37105]
 [38.53803]
 [78.23747]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 29. 10. 29.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.5908203125






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  2.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  1.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[117.916794]
 [129.19974 ]
 [113.1778  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  1.  5.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.23744201660156



action possibilites: [-1] 
expected returns: [[106.810974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  1.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.1162567138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 93.041954]
 [122.08838 ]
 [113.59799 ]
 [ 73.29911 ]
 [135.51224 ]
 [114.38249 ]
 [108.521545]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  1.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.81097412109375



buy possibilites: [-1] 
expected returns: [[118.33415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14.  6.  0.  3.  6.] 
adversary cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 135.5122528076172






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14.  6.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  3.  6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 11. 11.  8.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [ 3.  0. 29.  0.  6.  3.  4. 15.  6.  8.  1.  6. 29.  3. 11. 11.  0.  0.
  6.  0.  8. 16.  0.  6. 11.  0.  0.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[59.376217]
 [82.65521 ]
 [53.155895]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0 -20   0   0 646   0] 
sum of rewards: 711 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 74.01582336425781



action possibilites: [-1.] 
expected returns: [[77.670364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10. 11. 11.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.66933059692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.357044]
 [73.81022 ]
 [47.117043]
 [72.33375 ]
 [77.845   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 25.  0.  3. 11. 10.  3.  0. 11. 15. 10.  3. 10. 25.  8.  0.  3. 29.
 10. 29. 15. 11. 11.  0.  0.  0. 10. 11. 11.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  3. 16. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.67036437988281






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 16. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 16. 11.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15
  6  0  6  0  3  4  6 29  3  0  6 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 23. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [1. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[ 80.396866]
 [111.46101 ]
 [ 76.86118 ]
 [ 76.86118 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.84498596191406



action possibilites: [-1] 
expected returns: [[129.74625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 95.89705657958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.56999]
 [ 96.87349]
 [128.25253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.74624633789062






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  5.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11.  0. 10.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[70.45241 ]
 [91.17438 ]
 [66.739044]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 10.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29. 11.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.25253295898438



action possibilites: [-1] 
expected returns: [[78.18375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29. 11.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 79.7820816040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.05081]
 [80.07294]
 [58.27537]
 [79.97388]
 [79.77013]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 22. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29. 11.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.18374633789062



buy possibilites: [-1] 
expected returns: [[115.75906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 29. 11.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 80.07294464111328






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 21. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  0. 15.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 11.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 21. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  0. 15.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 11.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 29. 10.  0. 15.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 15.] 
expected returns: [[142.6143 ]
 [142.50037]
 [126.09825]
 [135.24023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 15.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15.  0. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.75906372070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[116.574425]
 [140.14896 ]
 [ 99.49722 ]
 [136.66872 ]
 [151.89952 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0. 15.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15.  0. 29.  0.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 142.61431884765625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [15.  0. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 29.  0.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29. 11. 10. 11. 11.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29. 11. 10. 11. 11.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 20. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29. 11. 10. 11. 11.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [29. 11. 10. 11. 11.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [29. 11. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 11. 11.] 
expected returns: [[122.99472]
 [134.31471]
 [137.88559]
 [113.79054]
 [137.88559]
 [137.88559]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 11. 11.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 14. 15.  6.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.89952087402344



action possibilites: [-1] 
expected returns: [[96.64903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 11.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 14. 15.  6.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 122.30732727050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.346886]
 [62.03931 ]
 [99.30662 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 11.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6. 14. 15.  6.  6.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.64903259277344






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6. 14. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 15.  6.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 25. 15.  8.  8.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 25. 15.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  6.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 25. 15.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [10. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 15.] 
expected returns: [[123.09053]
 [118.77071]
 [160.00218]
 [128.993  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 15.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  2.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 4. 8. 3. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3] -> size -> 40 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0 -60   0   0 665   0] 
sum of rewards: 660 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 48.335113525390625



action possibilites: [-1] 
expected returns: [[143.30943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0. 29.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 4. 8. 3. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 41 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 160.00218200683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.08313 ]
 [ 95.969574]
 [143.30943 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0. 29.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 4. 8. 3. 0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 41 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.30943298339844






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 4. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 8. 3. 0.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6
  0  6  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  3. 11.  0.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8. 25. 10. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6  0  6
  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  3. 11.  0.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8. 25. 10. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3.] 
cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6  0  6
  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 25.  3. 11.  0.] 
adversary cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8. 25. 10. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 61.838444]
 [113.96017 ]
 [ 90.520935]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 11.  0.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8. 25. 10. 15.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  1.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.  8.  4.  3.] 
adversary owned cards: [ 3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6  0  6
  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.30943298339844



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 0 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 3 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  3. 11.  0.  3. 11.] 
cards in discard: [ 1. 11.  3.  3. 10. 10.  1.  3. 11.  3.  0.  0. 10.  0. 29. 10.  0. 15.
  1. 11. 29. 10. 11. 11.  8.  8. 25. 10. 15.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 10 29 11 25 10  0 25 11 10 10 29  8 10
 11 10 11 10  8  3 10 15  3  8 11 15 11  1  1  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 19. 29.  8.  0.  9.  0.  4.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [ 1.  3. 16.  1. 11.  3.  8.  3.  3.  6.  0.  0.  3.  0.  0. 29. 11.  6.
 15.  3.  3. 29.  0.  0.  6. 14.  6. 15.  6.  6.  6.  8.  4.  3.  6.] 
adversary owned cards: [ 3  0 11 11 14  3 16  8 29  0  8  6  1  0  6  6  3  0  0 15 15  6  0  6
  0  3  4  6 29  3  0  6 11  1  3  8  3  3  6  6] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000105 

action type: take_action - action 25.0
Learning step: 299999.09375
desired expected reward: 300113.0625



