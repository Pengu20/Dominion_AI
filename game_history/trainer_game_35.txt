 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.71525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0 -27   0   0   9   0] 
sum of rewards: 497 

action type: gain_card_n - action 5
Learning step: 14.733755111694336
desired expected reward: 20.608579635620117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.030182]
 [20.316088]
 [18.869732]
 [14.81598 ]
 [21.73759 ]
 [20.884333]
 [19.437975]
 [19.921326]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.546088695526123
desired expected reward: 19.56896209716797



buy possibilites: [-1] 
expected returns: [[19.682156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: 0.013523425906896591
desired expected reward: 19.451496124267578






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.659645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5315595269203186
desired expected reward: 19.150596618652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.525404 ]
 [20.825022 ]
 [19.378666 ]
 [15.2554245]
 [19.214128 ]
 [22.246525 ]
 [21.393263 ]
 [22.557173 ]
 [18.122475 ]
 [19.946909 ]
 [20.422094 ]
 [20.43026  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5326797366142273
desired expected reward: 19.36305046081543



buy possibilites: [-1] 
expected returns: [[22.941504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.3741706311702728
desired expected reward: 22.93134117126465






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.151953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6025274991989136
desired expected reward: 22.33897590637207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.633041]
 [22.891935]
 [21.467833]
 [17.446138]
 [21.306898]
 [24.313442]
 [23.460178]
 [24.624086]
 [20.239643]
 [22.023779]
 [22.489008]
 [22.497175]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5873928666114807
desired expected reward: 21.861896514892578



buy possibilites: [-1] 
expected returns: [[21.15943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.47958406805992126
desired expected reward: 22.412351608276367






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.554686]
 [20.610315]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5761133432388306
desired expected reward: 20.583316802978516



action possibilites: [-1.] 
expected returns: [[25.633703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.09818126261234283
desired expected reward: 20.797269821166992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.947237]
 [26.24758 ]
 [24.797451]
 [20.716026]
 [24.633514]
 [27.69755 ]
 [26.827219]
 [28.014421]
 [23.545753]
 [25.363674]
 [25.837149]
 [25.845295]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.04774978384375572
desired expected reward: 25.585952758789062



buy possibilites: [-1] 
expected returns: [[27.655596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1.  3.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.8599510788917542
desired expected reward: 28.874372482299805






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[23.596375]
 [25.729132]
 [23.113024]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7203420400619507
desired expected reward: 26.935253143310547



action possibilites: [-1. 10.] 
expected returns: [[25.957914]
 [25.47479 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.058353252708911896
desired expected reward: 25.904386520385742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.003923]
 [26.295984]
 [24.85383 ]
 [20.746004]
 [24.689848]
 [27.721128]
 [26.86398 ]
 [28.03879 ]
 [23.602575]
 [25.419806]
 [25.893194]
 [25.90124 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.05703471973538399
desired expected reward: 25.90087890625



buy possibilites: [-1] 
expected returns: [[24.128601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 14.0
Learning step: 0.9584642648696899
desired expected reward: 24.56104278564453






Player: 1 
cards in hand: [ 3.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  0. 14.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.967278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11. 10.  3.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6109729409217834
desired expected reward: 23.517627716064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.93594 ]
 [26.219364]
 [24.770214]
 [22.137463]
 [20.710152]
 [24.608849]
 [27.641151]
 [26.791428]
 [29.783909]
 [27.948448]
 [23.533413]
 [23.644646]
 [25.337711]
 [21.38306 ]
 [25.809414]
 [25.786583]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [14. 29.  3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11. 10.  3.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6285321116447449
desired expected reward: 24.40814208984375



buy possibilites: [-1] 
expected returns: [[28.67934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [14. 29.  3.  0.  0. 10.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11. 10.  3.  0.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5431013107299805
desired expected reward: 27.098045349121094






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11. 10.  3.  0.  1.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11. 10.  3.  0.  1.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.05352]
 [28.31976]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7209737300872803
desired expected reward: 27.95836639404297



action possibilites: [-1. 11.] 
expected returns: [[28.507141]
 [30.407017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.09277644753456116
desired expected reward: 28.376243591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.962341]
 [29.321934]
 [27.83279 ]
 [23.596859]
 [30.778385]
 [29.90794 ]
 [28.4188  ]
 [28.878513]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10359717905521393
desired expected reward: 28.40354347229004



buy possibilites: [-1] 
expected returns: [[29.580948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.44803595542907715
desired expected reward: 28.866836547851562






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1.  0. 10.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.106228]
 [24.677116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7752820253372192
desired expected reward: 28.805665969848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.419926]
 [25.652409]
 [24.236221]
 [20.279331]
 [24.07603 ]
 [27.03751 ]
 [26.209702]
 [27.336777]
 [23.027924]
 [24.793514]
 [25.25298 ]
 [25.230743]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6391445994377136
desired expected reward: 24.498821258544922



buy possibilites: [-1] 
expected returns: [[26.852097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.5026252269744873
desired expected reward: 25.149784088134766






Player: 1 
cards in hand: [ 0.  0. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0. 14.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0. 14.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [0. 3. 0. 0. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0. 14.] 
adversary cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[23.403324]
 [25.52044 ]
 [21.183514]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 14.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7052565813064575
desired expected reward: 26.146839141845703



action possibilites: [-1] 
expected returns: [[29.687706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.12487243115901947
desired expected reward: 21.3531551361084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.266285]
 [30.530594]
 [29.090141]
 [26.490314]
 [25.092155]
 [28.930767]
 [31.969963]
 [31.109608]
 [34.166134]
 [32.285477]
 [27.86884 ]
 [27.978657]
 [29.644806]
 [25.74543 ]
 [30.115734]
 [30.092636]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12245910614728928
desired expected reward: 29.56524658203125



buy possibilites: [-1] 
expected returns: [[34.911903]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [10. 29.  0.  3.  3.  0. 11.  1.  0.  3.  1.  0. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 29.0
Learning step: 0.08801066875457764
desired expected reward: 32.37348556518555






Player: 1 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  3.  0.  0. 11. 14.  0. 10.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.13866 ]
 [30.397552]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8866298198699951
desired expected reward: 34.025272369384766



action possibilites: [-1.] 
expected returns: [[33.73861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.11416265368461609
desired expected reward: 30.382469177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.11391 ]
 [34.4703  ]
 [32.975536]
 [28.740898]
 [32.810043]
 [35.92337 ]
 [35.06175 ]
 [36.23505 ]
 [31.687756]
 [33.56698 ]
 [34.044147]
 [33.972607]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.20494301617145538
desired expected reward: 33.53366470336914



buy possibilites: [-1] 
expected returns: [[31.922647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.6581363081932068
desired expected reward: 36.893184661865234






Player: 1 
cards in hand: [ 1. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 14. 29.  3.  0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 14. 29.  3.  0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 14. 29.  3.  0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10. 14. 29.  3.  0.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10. 14. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29.] 
expected returns: [[26.090797]
 [25.689356]
 [23.86405 ]
 [28.337841]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 29.  3.  0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8292931318283081
desired expected reward: 31.093355178833008



action possibilites: [-1. 10. 14.] 
expected returns: [[31.31917 ]
 [30.91071 ]
 [29.066938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  3.  0.  0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.0801936686038971
desired expected reward: 28.306306838989258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.610064]
 [31.949102]
 [30.465322]
 [26.33027 ]
 [33.408363]
 [32.536198]
 [31.05242 ]
 [31.455177]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  0.  0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.16027021408081055
desired expected reward: 31.158897399902344



buy possibilites: [-1] 
expected returns: [[30.765116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  3.  0.  0.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.3107829689979553
desired expected reward: 33.71914291381836






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 11. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[24.012625]
 [25.6835  ]
 [23.678928]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8132932186126709
desired expected reward: 29.95182228088379



action possibilites: [-1. 11.] 
expected returns: [[25.77051]
 [27.45004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  1.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.01999906450510025
desired expected reward: 23.72574234008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.470284]
 [26.497847]
 [23.184156]
 [25.21172 ]
 [22.853065]
 [21.567781]
 [25.069437]
 [27.753529]
 [27.006815]
 [29.66933 ]
 [28.025934]
 [24.103464]
 [24.193657]
 [25.720684]
 [22.166096]
 [26.131031]
 [26.069687]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  1.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10. 10.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.04848998785018921
desired expected reward: 25.722017288208008



buy possibilites: [-1] 
expected returns: [[27.534264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  1.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 11. 29. 10. 14.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 25.0
Learning step: 0.22402982413768768
desired expected reward: 29.893362045288086






Player: 1 
cards in hand: [ 0.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  3.  3.  6.  0. 11.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[30.076359]
 [29.682878]
 [31.968225]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 107   0] 
sum of rewards: 102 

action type: discard_down_to_3_cards - action 3
Learning step: 2.7820169925689697
desired expected reward: 22.892568588256836



action possibilites: [-1. 11. 29.] 
expected returns: [[32.586357]
 [34.351357]
 [34.633434]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.] 
cards in discard: [ 0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.08725249767303467
desired expected reward: 29.725481033325195



action possibilites: [-1. 29.] 
expected returns: [[38.829605]
 [41.098763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [ 0. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0.6710343956947327
desired expected reward: 36.37010955810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.9998 ]
 [33.6927 ]
 [38.82346]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [ 0. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.27328571677207947
desired expected reward: 39.1028938293457



buy possibilites: [-1] 
expected returns: [[29.911438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.] 
cards in discard: [ 0. 29. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.657705307006836
desired expected reward: 25.4014835357666






Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10. 29.  0.  1.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10. 29.  0.  1.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29. 10. 29.  0.  1.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 10. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[29.371147]
 [31.546028]
 [29.056515]
 [31.546028]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  0.  1.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7256913781166077
desired expected reward: 29.185747146606445



action possibilites: [-1. 10. 29.] 
expected returns: [[30.844193]
 [30.529911]
 [33.017307]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  1.  0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.16335909068584442
desired expected reward: 31.40302085876465



action possibilites: [-1. 29.] 
expected returns: [[29.992199]
 [32.13019 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.4624900817871094
desired expected reward: 30.992401123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.622938]
 [30.756634]
 [27.283564]
 [29.390793]
 [26.943102]
 [25.638556]
 [29.243032]
 [32.087807]
 [31.303408]
 [34.10385 ]
 [32.368008]
 [28.22681 ]
 [28.311647]
 [29.926048]
 [26.226751]
 [30.35196 ]
 [30.230013]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.  0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.4694124758243561
desired expected reward: 30.461610794067383



buy possibilites: [-1] 
expected returns: [[29.641062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.  0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  1.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 39.5 

action type: buy - action 1.0
Learning step: 0.5735323429107666
desired expected reward: 31.330162048339844






Player: 1 
cards in hand: [ 6.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  1.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  1.  0.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  1. 29.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  1.  0.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  1.  0.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  1.  0.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  1.  0.] 
adversary cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.966242]
 [29.834728]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  1.  0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7. 10.  9.  5.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7338148355484009
desired expected reward: 28.90724754333496



action possibilites: [-1] 
expected returns: [[28.158924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7. 10.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.4648893177509308
desired expected reward: 25.824199676513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.741589]
 [28.812067]
 [27.488052]
 [23.784864]
 [30.102715]
 [29.340546]
 [28.008408]
 [28.303146]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7. 10.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09784160554409027
desired expected reward: 28.06108283996582



buy possibilites: [-1] 
expected returns: [[32.038586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [ 0. 29. 10.  6. 10. 11.  0. 29.  1. 29. 10. 29.  0.  1.  0.  0. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.03381122648715973
desired expected reward: 29.306734085083008






Player: 1 
cards in hand: [14.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 25. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [ 0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [ 0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [ 0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[31.991089]
 [36.070217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.] 
cards in discard: [ 0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14. 14.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 129   0] 
sum of rewards: 124 

action type: discard_down_to_3_cards - action 9
Learning step: 3.420065402984619
desired expected reward: 25.490976333618164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.375523]
 [27.103832]
 [32.10292 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.] 
cards in discard: [ 0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 29. 28. 30.  8.  8. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14. 14.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7931659817695618
desired expected reward: 31.253915786743164



buy possibilites: [-1] 
expected returns: [[26.836159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.] 
cards in discard: [ 0. 14.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14. 14.  0.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.681334495544434
desired expected reward: 17.422496795654297






Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14. 14.  0.  3.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1. 10. 11. 11.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.  2. 10. 29.  6.  0.  0.  1.  0. 14. 14.  0.  3.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  1. 10. 11. 11.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6] -> size -> 28 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 6.  1. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[29.870792]
 [29.547508]
 [31.812878]
 [31.812878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10. 11. 11.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.629885196685791
desired expected reward: 26.206274032592773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.351692]
 [29.159348]
 [25.12608 ]
 [31.165804]
 [29.983433]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10. 11. 11.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7376793026924133
desired expected reward: 29.08527374267578



buy possibilites: [-1] 
expected returns: [[27.175676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10. 11. 11.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.7152061462402344
desired expected reward: 27.636486053466797






Player: 1 
cards in hand: [0. 1. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 2. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29. 29. 29.  3.  1.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 2. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29. 29. 29.  3.  1.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[31.036842]
 [33.098473]
 [33.098473]
 [33.098473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  1.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [0. 1. 2. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6220657229423523
desired expected reward: 26.55360984802246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.59778 ]
 [30.325394]
 [26.69192 ]
 [32.13345 ]
 [31.067776]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  3.  1.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 29. 28. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [0. 1. 2. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7619336247444153
desired expected reward: 30.2749080657959



buy possibilites: [-1] 
expected returns: [[30.017881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  3.  1.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 3. 6. 0.] 
adversary cards in discard: [0. 1. 2. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.5045740604400635
desired expected reward: 29.820819854736328






Player: 1 
cards in hand: [3. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [0. 1. 2. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  1.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 6. 0.] 
cards in discard: [0. 1. 2. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 29. 10.  1.] 
adversary cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[35.46118 ]
 [37.74264 ]
 [37.74264 ]
 [35.211483]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  1.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6643452048301697
desired expected reward: 29.35353660583496



action possibilites: [-1. 29. 29.] 
expected returns: [[37.19351 ]
 [39.388874]
 [39.388874]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.  0.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.19890820980072021
desired expected reward: 35.012569427490234



action possibilites: [-1. 29.] 
expected returns: [[34.246548]
 [36.476925]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.241973876953125
desired expected reward: 39.6308479309082



action possibilites: [-1.] 
expected returns: [[35.217705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 2 
buys: 0 
player value: 2 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0.9254779815673828
desired expected reward: 37.40240478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.97893 ]
 [36.147533]
 [32.611286]
 [34.75825 ]
 [32.270657]
 [34.40479 ]
 [30.983912]
 [34.604485]
 [37.47855 ]
 [36.694313]
 [39.540325]
 [37.75699 ]
 [33.562565]
 [33.641064]
 [35.30503 ]
 [31.551321]
 [35.73089 ]
 [35.55334 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 8 
card supply: [25. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0.9689048528671265
desired expected reward: 36.18661117553711



buy possibilites: [-1] 
expected returns: [[35.965946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [ 0. 14.  6. 25.  3.  0.  0.  6.  1. 10. 11. 11.  3. 29. 29. 29.  3.  1.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 8 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 55.0 

action type: buy - action 0.0
Learning step: 1.0082743167877197
desired expected reward: 34.98720932006836






Player: 1 
cards in hand: [14.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [0. 1. 2. 0. 0. 3. 3. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  7.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[29.48831 ]
 [30.726807]
 [29.223454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9138959646224976
desired expected reward: 35.05205154418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.869091]
 [24.549461]
 [29.54838 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 27. 30.  8.  7. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7434180974960327
desired expected reward: 28.75581932067871



buy possibilites: [-1] 
expected returns: [[28.818111]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  8. 10.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 27. 30.  8.  6. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.583893775939941
desired expected reward: 14.965567588806152






Player: 1 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11. 29.  0.  1.  1.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  6. 10.  6.  9.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11. 29.  0.  1.  1.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6. 10.  6.  8.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11. 29.  0.  1.  1.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[27.216337]
 [29.151653]
 [29.425919]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  1.  1.] 
cards in discard: [ 6.  3.  0.  3.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6. 10.  6.  8.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0. 10.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7125259637832642
desired expected reward: 28.1055850982666



action possibilites: [-1] 
expected returns: [[30.212803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  1.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  8.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0. 10.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.5523061752319336
desired expected reward: 23.716583251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[28.420315]
 [30.722397]
 [29.241201]
 [26.568037]
 [25.112963]
 [29.07883 ]
 [32.123253]
 [31.302366]
 [34.262966]
 [32.410686]
 [27.968893]
 [28.047443]
 [29.821173]
 [25.745358]
 [30.270971]
 [30.034193]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  1.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  8.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0. 10.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1370880901813507
desired expected reward: 30.075714111328125



buy possibilites: [-1] 
expected returns: [[28.60318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  1.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0. 10.  0. 10.] 
adversary cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.12873761355876923
desired expected reward: 31.173627853393555






Player: 1 
cards in hand: [14.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0. 10.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 29.  6. 14. 10.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29. 14. 10.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 0.  1.  2.  0.  0.  3.  3.  3.  6.  0. 11. 14.  0. 11.  0.  0.  8. 29.
  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29. 14. 10.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10.] 
expected returns: [[23.383474]
 [25.34213 ]
 [21.69178 ]
 [23.208939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 10.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
  136    0] 
sum of rewards: -469 

action type: discard_down_to_3_cards - action 9
Learning step: -14.359902381896973
desired expected reward: 3.6313047409057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.117062]
 [19.408121]
 [23.438953]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14. 10.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  6.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6203828454017639
desired expected reward: 22.763092041015625



buy possibilites: [-1] 
expected returns: [[22.377422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14. 10.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.49728012084961
desired expected reward: 9.910839080810547






Player: 1 
cards in hand: [ 0.  1.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 14.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 27. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 14.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 26. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  6. 29.  0. 11.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[27.008806]
 [29.167162]
 [28.899097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  0. 11.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5218614339828491
desired expected reward: 21.855560302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.623833]
 [22.82196 ]
 [27.004345]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  0. 11.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 26. 30.  8.  5.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6922946572303772
desired expected reward: 26.316509246826172



buy possibilites: [-1] 
expected returns: [[29.445665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  0. 11.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11.  6.  0.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -9.555479049682617
desired expected reward: 13.266481399536133






Player: 1 
cards in hand: [10. 11.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.  0.  3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  0.  3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  0.  3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.83693 ]
 [25.940594]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  2.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7698290944099426
desired expected reward: 28.67583656311035



action possibilites: [-1. 29.] 
expected returns: [[25.174164]
 [27.233027]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 29.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  2.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.050918255001306534
desired expected reward: 25.88967514038086



action possibilites: [-1. 25.] 
expected returns: [[26.864094]
 [30.486076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  2.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0.5379006266593933
desired expected reward: 27.77092742919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.652416]
 [27.55854 ]
 [24.43833 ]
 [26.326593]
 [24.13422 ]
 [22.941544]
 [26.192165]
 [28.76104 ]
 [28.051346]
 [30.610924]
 [29.00952 ]
 [25.282372]
 [25.346657]
 [26.806215]
 [23.45973 ]
 [27.178291]
 [26.982359]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  9.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  2.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5300865173339844
desired expected reward: 27.394180297851562



buy possibilites: [-1] 
expected returns: [[26.351505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [ 6.  3.  0.  3.  8. 10. 16.  8. 11. 29.  0.  1.  1.  6. 10.  6. 29. 14.
 10.  6.  3.  6. 29.  0. 11. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  2.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.  -2.   0.   0.
 12.5  0. ] 
sum of rewards: 45.5 

action type: buy - action 25.0
Learning step: 0.7233629822731018
desired expected reward: 31.33428955078125






Player: 1 
cards in hand: [10.  0.  0.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  2.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 2. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 2. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 2. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[31.568787]
 [33.752422]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5953160524368286
desired expected reward: 25.756189346313477



action possibilites: [-1.] 
expected returns: [[33.096935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.20043593645095825
desired expected reward: 33.06468963623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.915949]
 [34.19112 ]
 [30.44607 ]
 [32.72124 ]
 [30.093935]
 [28.716488]
 [32.56545 ]
 [35.569775]
 [34.76448 ]
 [37.714867]
 [35.86093 ]
 [31.465374]
 [31.54152 ]
 [33.294605]
 [29.2947  ]
 [33.740547]
 [33.47074 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.18830159306526184
desired expected reward: 32.908634185791016



buy possibilites: [-1] 
expected returns: [[30.058064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 6 
card supply: [22. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  0.  0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: -0.28186890482902527
desired expected reward: 31.634082794189453






Player: 1 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 25. 11.  3.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [25.  3.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [25.  3.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [25.  3.  3.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[23.692055]
 [27.543629]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 30.  8.  4.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 29.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1] -> size -> 31 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -3
     0 -1200   161     0] 
sum of rewards: -1047 

action type: discard_down_to_3_cards - action 6
Learning step: -31.482494354248047
desired expected reward: -19.96495819091797



action possibilites: [-1] 
expected returns: [[30.81518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 29.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1  6] -> size -> 32 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.05274948105216026
desired expected reward: 27.49087905883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.554081]
 [30.270638]
 [26.641918]
 [32.088673]
 [30.937525]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  7.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 29.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1  6] -> size -> 32 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15592122077941895
desired expected reward: 30.659257888793945



buy possibilites: [-1] 
expected returns: [[27.796198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 29.  3.] 
adversary cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1  6] -> size -> 32 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 19 

action type: buy - action 8.0
Learning step: -0.10080007463693619
desired expected reward: 31.987873077392578






Player: 1 
cards in hand: [ 8. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 29.  3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1 11  0  3  0 10  6  0 29  3  2
 14 11  8  3  0 22  1  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [29.  6.  0.  8. 10.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [29.  6.  0.  8. 10.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [29.  6.  0.  8. 10.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3.  0.  1.  3.  3. 14.  0. 10. 11.  6.  0.  3. 22. 10.  0.  0.  0.  2.
  0.  1. 14.  0.  0.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [29.  6.  0.  8. 10.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29.  6.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[18.069016]
 [19.96016 ]
 [19.081572]
 [17.93145 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  8. 10.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7843810319900513
desired expected reward: 27.011816024780273



action possibilites: [-1.  8. 10.] 
expected returns: [[22.487446]
 [23.560127]
 [22.34224 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 10.  6.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.09216287732124329
desired expected reward: 20.052324295043945



action possibilites: [-1.  8. 16.] 
expected returns: [[23.32858 ]
 [24.393919]
 [22.583319]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  6
  1 29  8  6  0  3  0  6 16  8  6  6 25  0  8] -> size -> 39 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 26. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.6278164386749268
desired expected reward: 22.97005271911621



action possibilites: [-1.  8.] 
expected returns: [[20.480858]
 [21.657995]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  6  0  3  0  6 16  8  6  6 25  0  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0 -4  0  0  4  0] 
sum of rewards: 55 

action type: gain_card_n - action 1
Learning step: 1.198646903038025
desired expected reward: 23.65924835205078



action possibilites: [-1] 
expected returns: [[22.245102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 16.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.8529422283172607
desired expected reward: 22.767053604125977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.188242]
 [21.84557 ]
 [18.55853 ]
 [23.586962]
 [22.444754]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 16.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 1.8129878044128418
desired expected reward: 24.058090209960938



buy possibilites: [-1] 
expected returns: [[24.503988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 16.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 80.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 71.0 

action type: buy - action 0.0
Learning step: 1.7516446113586426
desired expected reward: 22.93988609313965






Player: 1 
cards in hand: [ 3.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 10.  3.  6. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 10.  3.  6. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 10.  3.  6. 29.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[19.941717]
 [19.831202]
 [21.965403]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  6. 29.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6661249995231628
desired expected reward: 23.83786392211914



action possibilites: [-1. 10. 10.] 
expected returns: [[23.18481 ]
 [23.069407]
 [23.069407]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  6. 10.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.03383222594857216
desired expected reward: 21.99923324584961



action possibilites: [-1. 10. 14.] 
expected returns: [[23.6174  ]
 [23.507998]
 [22.001177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10. 14.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.6010687947273254
desired expected reward: 23.670475006103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.39358 ]
 [19.734564]
 [23.630535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 10. 14.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 2 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  3. 22.  0.  6.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5752263069152832
desired expected reward: 24.192628860473633






Player: 1 
cards in hand: [ 3.  3. 22.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 22.  0.  6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  1. 29. 11.  1.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 22.  0.  6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  1. 29. 11.  1.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 22.  0.  6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  1. 29. 11.  1.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  1. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[21.445772]
 [23.331617]
 [23.099922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 29. 11.  1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 10.  0.  8.  0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6198632121086121
desired expected reward: 23.01067352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.305115]
 [22.03094 ]
 [20.910471]
 [17.911657]
 [20.794855]
 [23.099924]
 [22.47183 ]
 [23.33162 ]
 [19.955328]
 [21.344994]
 [21.681154]
 [21.445772]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 29. 11.  1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  4.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 10.  0.  8.  0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5656781792640686
desired expected reward: 20.880094528198242



buy possibilites: [-1] 
expected returns: [[24.028982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 29. 11.  1.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 10.  0.  8.  0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -5  0  0 32  0] 
sum of rewards: 22 

action type: buy - action 29.0
Learning step: 0.21235576272010803
desired expected reward: 23.543975830078125






Player: 1 
cards in hand: [ 6. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  8.  0.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  8. 25.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11
  8  3  0 22  1  6  0  0  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  8. 25.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  8. 25.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  8. 25.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  8. 25.] 
adversary cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[23.516058]
 [25.611341]
 [24.642004]
 [27.254122]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8. 25.] 
cards in discard: [ 0. 29.  0.  0.  0.  0.  0.  0. 11.  8. 25.  3.  3.  6.  1.  3.  0. 29.
 10. 16.  8.  0. 29. 10.  3.  3.  6. 10. 14. 29.  6.  1. 29. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 30.  8.  3.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [0. 2. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6014863848686218
desired expected reward: 23.4274959564209



action possibilites: [-1] 
expected returns: [[22.815714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  8.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 25. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [0. 2. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: -0.128058522939682
desired expected reward: 27.12605857849121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.676678]
 [22.391823]
 [18.831934]
 [24.242647]
 [23.028854]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  8.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 29. 25. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [0. 2. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0015269850846379995
desired expected reward: 22.817241668701172



buy possibilites: [-1] 
expected returns: [[27.604696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  8.  6.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [0. 2. 1. 3. 0.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: 0.1280946284532547
desired expected reward: 22.519916534423828






Player: 1 
cards in hand: [0. 2. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 1. 3. 0.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 3. 0.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [17. 25. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 3. 0.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 24. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.246424]
 [22.350018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 14.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.748100757598877
desired expected reward: 26.856595993041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.952702]
 [21.824524]
 [20.597685]
 [17.304401]
 [23.011595]
 [22.320576]
 [21.061432]
 [21.170664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 14.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.563462495803833
desired expected reward: 20.682958602905273



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 14.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 14.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 14.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3. 10.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[21.538095]
 [20.047665]
 [21.437193]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3. 10.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  1.  0. 11.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5634256601333618
desired expected reward: 20.60723876953125



action possibilites: [-1] 
expected returns: [[24.737278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1. 11.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.10371477156877518
desired expected reward: 20.304601669311523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.739222]
 [25.545164]
 [24.365276]
 [21.18066 ]
 [26.62564 ]
 [25.99959 ]
 [24.819698]
 [24.876945]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  6.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1. 11.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.029194679111242294
desired expected reward: 24.708084106445312



buy possibilites: [-1] 
expected returns: [[25.88932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1. 11.  3.] 
adversary cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 18  0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: 0.2530686855316162
desired expected reward: 26.87870979309082






Player: 1 
cards in hand: [ 1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [ 0.  3.  0. 14.  0.  3.  0.  3.  3. 22.  0.  6.  0. 10.  8.  6.  6.  1.
  0.  2.  1.  3.  0.  1.  0. 10.  0.  0. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0. 29.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11] -> size -> 42 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[19.414635]
 [21.275911]
 [21.275911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.  0. 29.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7084940671920776
desired expected reward: 25.18082618713379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.278551]
 [19.978525]
 [18.867878]
 [16.905388]
 [15.839834]
 [18.755491]
 [20.995626]
 [20.406301]
 [22.62547 ]
 [21.20774 ]
 [17.92018 ]
 [17.96934 ]
 [19.295652]
 [16.273457]
 [19.620152]
 [19.349459]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.  0. 29.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5251738429069519
desired expected reward: 18.889461517333984



buy possibilites: [-1] 
expected returns: [[19.620113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.  0. 29.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 5 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -8.  0.  0.  0.  0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -0.7323452830314636
desired expected reward: 17.546205520629883






Player: 1 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 10. 16. 29.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  7. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 10. 16. 29.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 10. 16. 29.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25.  0. 10. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 16. 29.] 
expected returns: [[17.838451]
 [21.277143]
 [17.781153]
 [17.217514]
 [19.812386]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 16. 29.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  2.  0. 10. 11.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5361246466636658
desired expected reward: 19.083988189697266



action possibilites: [-1. 25. 16. 29.] 
expected returns: [[17.850029]
 [21.19693 ]
 [17.236778]
 [19.771523]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 16. 29.  6.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29  1 29 14 11 10  1 29 29 11 25 10  1
 29  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  2.  0. 10. 11.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.12079507857561111
desired expected reward: 17.901945114135742



action possibilites: [-1. 25.] 
expected returns: [[13.628762]
 [16.348442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  2.  0. 10. 11.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -8  0  0 16  0] 
sum of rewards: 43 

action type: gain_card_n - action 15
Learning step: 1.0215355157852173
desired expected reward: 15.311548233032227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.758038]
 [10.817989]
 [13.628762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  6.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  2.  0. 10. 11.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7739309668540955
desired expected reward: 14.402690887451172






Player: 1 
cards in hand: [ 0.  2.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  0. 10. 11.] 
cards in discard: [14.  3.  1.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9.  9.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0. 10. 11.] 
cards in discard: [14.  3.  1.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  9.  9.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0. 10. 11.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[19.603298]
 [19.545643]
 [21.389088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [0. 1. 3. 6. 3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.34443923830986023
desired expected reward: 13.284320831298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.462194 ]
 [19.088581 ]
 [15.9110155]
 [20.741304 ]
 [19.603298 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  6.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [0. 1. 3. 6. 3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5369474291801453
desired expected reward: 19.06635093688965



buy possibilites: [-1] 
expected returns: [[19.210972]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [0. 1. 3. 6. 3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -9  0  0  8  0] 
sum of rewards: -6 

action type: buy - action 8.0
Learning step: -0.6005239486694336
desired expected reward: 20.14078140258789






Player: 1 
cards in hand: [0. 1. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [ 1. 11. 29.  6.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [ 1. 11. 29.  6.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [ 1. 11. 29.  6.  0.] 
adversary cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[17.88379 ]
 [19.432888]
 [19.636602]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  6.  0.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5256231427192688
desired expected reward: 18.685348510742188



action possibilites: [-1. 11.] 
expected returns: [[17.510586]
 [19.215765]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.  0.  3.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  5.  8.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.06805045902729034
desired expected reward: 19.286495208740234



action possibilites: [-1] 
expected returns: [[19.926083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 3.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  4.  8.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -10   0   0   9   0] 
sum of rewards: 34 

action type: gain_card_n - action 9
Learning step: 0.6128686666488647
desired expected reward: 21.158042907714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.962955]
 [20.573524]
 [19.515924]
 [16.631058]
 [19.408499]
 [21.530916]
 [20.977947]
 [21.724628]
 [18.610918]
 [19.920351]
 [20.221489]
 [19.926083]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  4.  8.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.664442241191864
desired expected reward: 20.590524673461914



buy possibilites: [-1] 
expected returns: [[21.829098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 3.] 
cards in discard: [ 3. 25.  0. 29.  0.  8.  8.  6.  8.  0.  0.  3.  0. 11. 14.  3.  0.  3.
 10.  0.  1.  1. 29.  0. 29. 15. 10. 16. 25.  0.  6.  8. 10. 11.  3.  0.
  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.  -11.
   0.    0.    4.5   0. ] 
sum of rewards: 28.5 

action type: buy - action 10.0
Learning step: 0.4865950047969818
desired expected reward: 20.406944274902344






Player: 1 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 10 14  1  0  3  0 10  6  0  3  2 14 11  8  3  0
 22  1  6  0  0  0  0  6  1  1 14 22  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0.  0.  8. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
expected returns: [[22.249687]
 [23.413435]
 [22.243408]
 [24.248304]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 22.  0.  3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5604262948036194
desired expected reward: 21.2686710357666



action possibilites: [-1.  8. 29. 25.] 
expected returns: [[21.459099]
 [22.630564]
 [23.4621  ]
 [24.920303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29. 25.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 22.  0.  3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.02922174334526062
desired expected reward: 22.27263069152832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.393646]
 [21.005684]
 [17.93543 ]
 [22.63386 ]
 [21.462393]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 29. 25.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  5.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 22.  0.  3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.027522295713424683
desired expected reward: 21.48661994934082



buy possibilites: [-1] 
expected returns: [[22.39548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 29. 25.] 
cards in discard: [8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10. 22.  0.  3.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -12   0   0   8   0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: -0.11386333405971527
desired expected reward: 22.51999855041504






Player: 1 
cards in hand: [ 0. 10. 22.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 22.  0.  3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 22.  0.  3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 22.  0.  3.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.024124]
 [19.856663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  1.  0.  1. 14.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6210660338401794
desired expected reward: 21.7744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.055992]
 [14.757348]
 [18.035837]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 22. 29. 24. 30.  8.  2.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  1.  0.  1. 14.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5132707953453064
desired expected reward: 17.510854721069336



buy possibilites: [-1] 
expected returns: [[18.303198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  3. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 29. 24. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  1.  0.  1. 14.] 
adversary cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -13.
    0. -300.    0.    0.] 
sum of rewards: -318.0 

action type: buy - action 6.0
Learning step: -9.790536880493164
desired expected reward: 4.9668121337890625






Player: 1 
cards in hand: [ 6.  1.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0.  1. 14.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 29. 24. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3. 15. 14. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6] -> size -> 48 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  1. 14.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 22. 29. 24. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3. 15. 14. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6] -> size -> 48 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0.  1. 14.] 
cards in discard: [14.  3.  1.  0.  0.  0. 22.  0.  2.  0. 10. 11.  1.  0.  1.  3.  6.  3.
  0.  8.  0.  3.  0.  0. 10. 22.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 24. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3. 15. 14. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6] -> size -> 48 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 14. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 11.] 
expected returns: [[17.0696  ]
 [17.341734]
 [15.880922]
 [18.558449]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 14. 11.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 24. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5155367255210876
desired expected reward: 17.787660598754883



action possibilites: [-1] 
expected returns: [[15.949032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 14.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -14   0   0   4   0] 
sum of rewards: 5 

action type: gain_card_n - action 2
Learning step: -0.14006681740283966
desired expected reward: 15.110987663269043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.039254]
 [15.578939]
 [12.874747]
 [17.038834]
 [15.986937]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 14.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  4.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.13586202263832092
desired expected reward: 16.08489418029785



buy possibilites: [-1] 
expected returns: [[15.395048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 14.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  3.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0   8   0] 
sum of rewards: 8 

action type: buy - action 8.0
Learning step: -0.11138677597045898
desired expected reward: 16.98977279663086






Player: 1 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  3.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [29.  0. 11.  8.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  3.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  3.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  1.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.134533]
 [19.842587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0  -15    0 -600
  231    0] 
sum of rewards: -389 

action type: discard_down_to_3_cards - action 9
Learning step: -11.794400215148926
desired expected reward: -0.9419288635253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.180569]
 [18.848244]
 [17.74731 ]
 [14.84033 ]
 [19.842587]
 [19.268116]
 [18.166365]
 [18.134533]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  5.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5011371374130249
desired expected reward: 17.63339614868164



buy possibilites: [-1] 
expected returns: [[16.223658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  1.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  4.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -16   0   0  18   0] 
sum of rewards: -3 

action type: buy - action 11.0
Learning step: -0.5149292349815369
desired expected reward: 19.327659606933594






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  4.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [10. 10.  3.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  4.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [10. 10.  3.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [10. 10.  3.  3. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[13.852526 ]
 [13.8823395]
 [13.8823395]
 [15.64833  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 1.  1.  6.  0. 14.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.48359057307243347
desired expected reward: 15.740067481994629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.976403]
 [10.794538]
 [13.852526]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 1.  1.  6.  0. 14.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4311397671699524
desired expected reward: 13.421385765075684



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  1.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  6.  0. 14.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  6.  0. 14.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  6.  0. 14.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[13.143366]
 [13.16828 ]
 [14.638535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  8.] 
adversary cards in hand: [ 1.  1.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.42017433047294617
desired expected reward: 13.432351112365723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.392209 ]
 [13.703662 ]
 [12.8387375]
 [10.545516 ]
 [14.483223 ]
 [14.033203 ]
 [13.168279 ]
 [13.143366 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  3.  8.  8.] 
adversary cards in hand: [ 1.  1.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.40436261892318726
desired expected reward: 12.739004135131836



buy possibilites: [-1] 
expected returns: [[14.250195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 1.  1.  0.  0. 11.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -17   0   0  18   0] 
sum of rewards: -4 

action type: buy - action 10.0
Learning step: -0.3654213845729828
desired expected reward: 12.80285930633545






Player: 1 
cards in hand: [ 1.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  0. 11.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  2.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [14. 21. 29. 23. 30.  8.  1.  9.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  1.  8.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[13.546857]
 [16.347261]
 [13.573882]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 10.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  1.  8.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4214661717414856
desired expected reward: 13.828728675842285



action possibilites: [-1] 
expected returns: [[19.383455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.  0.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0.1631084531545639
desired expected reward: 16.5103702545166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.410255]
 [20.11417 ]
 [18.989252]
 [18.873848]
 [21.14846 ]
 [20.55261 ]
 [21.351482]
 [18.03957 ]
 [19.415762]
 [19.72865 ]
 [19.383457]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.  0.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  2.  8.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07828565686941147
desired expected reward: 19.461740493774414



buy possibilites: [-1] 
expected returns: [[17.750122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.  0.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  3. 14.  8.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -18.
   0.    0.    4.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 10.0
Learning step: -0.35109657049179077
desired expected reward: 19.064664840698242






Player: 1 
cards in hand: [ 0.  0.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  6.  8.  1. 16.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 6.  1. 16.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  1.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 6.  1. 16.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 6.  1. 16.] 
adversary cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[15.047641]
 [14.550061]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 16.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  1 29 14 11 10  1 29 29 11 25 10  1 29
  8  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6
  3  8 11 10 10] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  3.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  2.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0  -18    0 -300
  209    0] 
sum of rewards: -114 

action type: discard_down_to_3_cards - action 9
Learning step: -3.4668326377868652
desired expected reward: 3.2912707328796387



action possibilites: [-1] 
expected returns: [[12.231867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  2.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -18   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 7
Learning step: 0.2453232705593109
desired expected reward: 9.34903335571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.510637]
 [12.231867]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  2.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.20844943821430206
desired expected reward: 12.440316200256348



buy possibilites: [-1] 
expected returns: [[10.645277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10.  0.  0.  8. 29. 25.  6.  6.  3.  0.  3. 29.  3.  8. 11.  3. 15.
 14.  1. 29.  8. 11.  0. 11.  1. 10. 10.  3.  3. 29. 10.  0. 10.  0.  0.
 29. 10. 25.  0.  0.  0. 10.  8.  0.  0.  8. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  2.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -19   0   0   0   0] 
sum of rewards: -4 

action type: buy - action 0.0
Learning step: -0.3535436987876892
desired expected reward: 11.15709400177002






Player: 1 
cards in hand: [ 0.  6.  0. 22.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 22.  2.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 22.  2.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 21. 29. 23. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 22.  2.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 8.  6. 11.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[16.816822]
 [17.946564]
 [18.4945  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 11.  3.  6.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.  0.  6.  0.
 22.  2.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3] -> size -> 46 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2813977897167206
desired expected reward: 10.363879203796387





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.003649]
 [16.883541]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.  3.  6.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 10.] 
adversary cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.  0.  6.  0.
 22.  2.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3] -> size -> 46 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48092302680015564
desired expected reward: 16.335899353027344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.  0.  6.  0.
 22.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [29. 15. 14.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.  0.  6.  0.
 22.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [29. 15. 14.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 10.] 
cards in discard: [ 8. 14.  3.  0.  0.  3. 11.  3.  0.  0.  3.  0. 15.  1.  1.  6.  0. 14.
  8. 16. 11.  1.  1.  0.  0.  6.  8. 14.  0.  0.  3.  8.  3.  0.  6.  0.
 22.  2.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [29. 15. 14.  3. 10.] 
adversary cards in discard: [ 8.  6. 11.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [29. 15. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 14. 10.] 
expected returns: [[11.578863]
 [13.20719 ]
 [11.884424]
 [10.522988]
 [11.631037]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 14.  3. 10.] 
cards in discard: [ 8.  6. 11.  3.  6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [14.  0.  1.  1. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.529945969581604
desired expected reward: 16.353595733642578



action possibilites: [-1] 
expected returns: [[14.025651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3. 10.] 
cards in discard: [ 8.  6. 11.  3.  6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [14. 22.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.2815796434879303
desired expected reward: 10.804569244384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.26524 ]
 [13.778122]
 [14.102707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  3. 10.] 
cards in discard: [ 8.  6. 11.  3.  6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [0. 1. 1.] 
adversary cards in discard: [14. 22.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17405515909194946
desired expected reward: 14.199706077575684






Player: 1 
cards in hand: [0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [14. 22.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [14. 22.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6. 10.  1.  8.  8.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [14. 22. 23.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[14.361341]
 [16.00473 ]
 [14.414114]
 [15.841771]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0.  0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.41216519474983215
desired expected reward: 13.690543174743652



action possibilites: [-1. 29. 11.  8.] 
expected returns: [[13.563402]
 [15.194803]
 [15.033175]
 [14.550377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  8.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.172003373503685
desired expected reward: 14.5861177444458



action possibilites: [-1. 11. 10.] 
expected returns: [[13.415259]
 [14.87487 ]
 [13.467174]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0] -> size -> 54 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 22. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 6
Learning step: 0.8719652891159058
desired expected reward: 11.745046615600586



action possibilites: [-1. 10.] 
expected returns: [[15.921432]
 [15.986642]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 21. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0 -20   0   0   4   0] 
sum of rewards: 39 

action type: gain_card_n - action 2
Learning step: 0.9801061153411865
desired expected reward: 12.79327392578125



action possibilites: [-1.] 
expected returns: [[15.98104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 29. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3] -> size -> 55 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 21. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 1.9382015466690063
desired expected reward: 17.924842834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[15.296845]
 [16.590086]
 [15.724979]
 [17.398092]
 [16.049007]
 [15.981041]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 29. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 29. 21. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 1.9429607391357422
desired expected reward: 17.923999786376953



buy possibilites: [-1] 
expected returns: [[19.73905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10. 29. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  80.   0.   0.   0.   0. -21.   0.   0.
   2.   0.] 
sum of rewards: 56.0 

action type: buy - action 3.0
Learning step: 1.415510654449463
desired expected reward: 17.140491485595703






Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [14. 22. 23.  0.  1.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [29. 11.  0.  3.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [29. 11.  0.  3.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  2.  6.  9.  1.  8.  8.] 
adversary cards in hand: [29. 11.  0.  3.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [29. 11.  0.  3.  0.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [29. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[13.77275 ]
 [15.321406]
 [15.173275]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3.  0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5860477089881897
desired expected reward: 19.15300178527832



action possibilites: [-1.] 
expected returns: [[15.394248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.20639808475971222
desired expected reward: 13.714448928833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[14.648619]
 [16.03306 ]
 [15.115992]
 [15.020843]
 [16.869455]
 [17.032078]
 [14.329154]
 [15.465632]
 [15.712945]
 [15.394248]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 29. 20. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.15466240048408508
desired expected reward: 15.548910140991211



buy possibilites: [-1] 
expected returns: [[13.773389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 29. 19. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -22.   0.   0.
   2.   0.] 
sum of rewards: -5.0 

action type: buy - action 3.0
Learning step: -0.4588592052459717
desired expected reward: 14.657133102416992






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 19. 30.  8.  0.  8.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 29. 19. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 29. 19. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 21. 29. 19. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[10.902239]
 [10.980708]
 [14.079415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10. 25.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 29. 19. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.432940274477005
desired expected reward: 13.340448379516602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.082774]
 [10.596651]
 [10.902239]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10. 25.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 29. 19. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.36574381589889526
desired expected reward: 10.536495208740234



buy possibilites: [-1] 
expected returns: [[9.626169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10. 25.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -23   0   0   8   0] 
sum of rewards: -20 

action type: buy - action 3.0
Learning step: -0.816824734210968
desired expected reward: 9.779826164245605






Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [11. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 6 
card supply: [10. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 0.  3.  6. 10. 25.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[12.077399]
 [12.151271]
 [14.938827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 10. 25.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0. 16.  3. 14.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2977445423603058
desired expected reward: 9.328424453735352





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.315618]
 [12.077399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 10. 25.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 6.  0. 16.  3. 14.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3887087404727936
desired expected reward: 11.688689231872559



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  0. 16.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  3. 14.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [10.  1.  3.  3.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3. 14.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [10.  1.  3.  3.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3. 14.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [10.  1.  3.  3.  1.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[11.65462 ]
 [11.724502]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  3.  1.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [3. 1. 6. 3. 2.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3895081877708435
desired expected reward: 11.68789005279541



action possibilites: [-1.  8.] 
expected returns: [[11.429246 ]
 [12.4479475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [3. 1. 6. 3. 2.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.22468982636928558
desired expected reward: 11.949191093444824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[10.670627 ]
 [12.0876045]
 [11.142508 ]
 [11.044434 ]
 [12.930961 ]
 [13.088247 ]
 [10.357047 ]
 [11.50285  ]
 [11.757719 ]
 [11.429247 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  7.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [3. 1. 6. 3. 2.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.23205742239952087
desired expected reward: 11.661303520202637



buy possibilites: [-1] 
expected returns: [[12.375094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 1. 8.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3 16] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  6.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [3. 1. 6. 3. 2.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -24   0   0  32   0] 
sum of rewards: 23 

action type: buy - action 16.0
Learning step: 0.48337072134017944
desired expected reward: 11.70229721069336






Player: 1 
cards in hand: [3. 1. 6. 3. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 3. 2.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  6.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25. 16. 10.  1.  3.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3 16] -> size -> 59 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 3. 2.] 
cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  6.  3.  0.  8.  1.  6.  9.  1.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25. 16. 10.  1.  3.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3 16] -> size -> 59 
adversary victory points: 7
player victory points: 4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 3 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 4 
Chapel: 6 
Witch: 2 
Poacher: 5 
Militia: 1 
Market: 0 
Village: 5 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [ 8.  6. 11.  3.  6. 14. 29. 15.  3. 10.  0.  8.  3.  3. 10. 29. 11. 10.
  0.  0. 11.  3.  3. 29.  0.  0.  0.  3.  6.  0.  0. 10. 25.  0.  3.  6.
 10. 25. 16. 10.  1.  3.  3.  1.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 14 11 10  1 29 29 11 25 10  1 29  8
  0  3  0  6 16  8  6  6 25  0  8  3  0 29  3 11  0 15  8 10 10  8  6  3
  8 11 10 10 29  0  3  3  3  3 16] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 29. 18. 30.  8.  0.  6.  3.  0.  8.  0.  6.  9.  1.  8.  8.] 
adversary cards in hand: [3. 1. 6. 3. 2.] 
adversary cards in discard: [14. 22. 23.  0.  1.  1. 29. 10.  0.  0.  0.  3.  1. 16.  0. 11.  0.  0.
  3.  0.  0.  0.  0.  0.  0.  1.  0.  6.  0. 16.  3. 14. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  0 10 14  1  0  3  0 10  0  3  2 14 11  8  3  0 22  1
  6  0  0  0  0  6  1  1 14 22  1  0  0  1  8 11 15  8 16  6  8  3  0 23
 29 16  0  0  0 29] -> size -> 54 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.478747367858887
desired expected reward: 26.85384178161621



