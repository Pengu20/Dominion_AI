 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.43802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -4  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -569 

action type: buy - action -1
Learning step: -33.59180450439453
desired expected reward: 69.24422454833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[295.74332]
 [303.7431 ]
 [302.9573 ]
 [286.81943]
 [313.0004 ]
 [305.15295]
 [304.37006]
 [321.4767 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.209970474243164
desired expected reward: 310.7344055175781



buy possibilites: [-1] 
expected returns: [[323.31723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -9.112528800964355
desired expected reward: 286.63079833984375






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[356.94077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.192625999450684
desired expected reward: 315.1246032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[339.68173]
 [346.82025]
 [345.9324 ]
 [331.66824]
 [344.66006]
 [354.71848]
 [348.1009 ]
 [354.1748 ]
 [340.45428]
 [347.21494]
 [347.95782]
 [361.81805]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.196965217590332
desired expected reward: 348.6134948730469



buy possibilites: [-1] 
expected returns: [[288.14542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 29.0
Learning step: -9.72547435760498
desired expected reward: 344.4494323730469






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 3. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[281.53308]
 [274.55655]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.219436645507812
desired expected reward: 279.92596435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.35114]
 [267.1163 ]
 [254.1108 ]
 [268.972  ]
 [281.59442]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.190911293029785
desired expected reward: 274.365478515625



buy possibilites: [-1] 
expected returns: [[290.02948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.141892433166504
desired expected reward: 253.20921325683594






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.9321417808532715
desired expected reward: 282.09735107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[276.89062]
 [285.26584]
 [284.80743]
 [270.14795]
 [268.12778]
 [282.81577]
 [295.38644]
 [286.711  ]
 [302.49548]
 [294.50214]
 [278.2632 ]
 [283.47302]
 [286.25662]
 [274.34317]
 [287.39307]
 [304.63373]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.456812858581543
desired expected reward: 287.95794677734375



buy possibilites: [-1] 
expected returns: [[287.38593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.978349685668945
desired expected reward: 267.91229248046875






Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[275.91074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.266916275024414
desired expected reward: 279.1190185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[248.76431]
 [255.58932]
 [254.85373]
 [241.1348 ]
 [263.3139 ]
 [256.79868]
 [256.0653 ]
 [270.5259 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.0888032913208
desired expected reward: 267.57257080078125



buy possibilites: [-1] 
expected returns: [[304.006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.1980814933776855
desired expected reward: 241.5662384033203






Player: 1 
cards in hand: [1. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.3668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [8. 1. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.892210483551025
desired expected reward: 296.1138000488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.77588]
 [303.1009 ]
 [302.43582]
 [283.7322 ]
 [300.1253 ]
 [315.05743]
 [304.88177]
 [314.1575 ]
 [295.03717]
 [304.22153]
 [305.61615]
 [325.64905]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [8. 1. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.668150901794434
desired expected reward: 319.580322265625



buy possibilites: [-1] 
expected returns: [[291.67874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  0.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [8. 1. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -8.929476737976074
desired expected reward: 303.4154968261719






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8. 1. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8. 1. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [8. 1. 0. 0. 0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[256.00375]
 [247.81807]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.967269897460938
desired expected reward: 282.71148681640625



action possibilites: [-1.] 
expected returns: [[214.73845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 29.0
Learning step: -6.6945037841796875
desired expected reward: 242.827880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[205.5113 ]
 [211.38565]
 [204.41081]
 [210.59636]
 [200.59204]
 [198.89091]
 [209.59554]
 [217.63756]
 [212.43388]
 [222.52837]
 [217.35558]
 [206.12653]
 [209.46387]
 [211.64638]
 [203.27832]
 [212.31206]
 [222.8275 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -5.071811676025391
desired expected reward: 209.66664123535156






Player: 1 
cards in hand: [ 3. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 30. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.6259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 0
Learning step: -7.952929973602295
desired expected reward: 276.7500915527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[278.9403 ]
 [287.4127 ]
 [286.78442]
 [269.9924 ]
 [298.6925 ]
 [288.89032]
 [288.3427 ]
 [309.2926 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.349249839782715
desired expected reward: 296.5273132324219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  7. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  6. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[269.22324]
 [262.09158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  6. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.070159912109375
desired expected reward: 299.2224426269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[247.97693]
 [254.81502]
 [239.98364]
 [256.52463]
 [271.90582]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  6. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.314349174499512
desired expected reward: 261.27252197265625



buy possibilites: [-1] 
expected returns: [[259.17142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.  3.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 8.0
Learning step: -7.1948747634887695
desired expected reward: 249.3297576904297






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  0 14  8  8  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 14.  3.  0.  3.  0.  8.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[257.93826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.249209880828857
desired expected reward: 251.92221069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[237.9959 ]
 [245.26288]
 [244.70557]
 [229.98381]
 [243.12437]
 [253.80777]
 [246.52353]
 [253.15439]
 [239.07948]
 [245.96954]
 [246.91768]
 [261.75842]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  9.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.44111967086792
desired expected reward: 250.75270080566406



buy possibilites: [-1] 
expected returns: [[251.92577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -6.897059917449951
desired expected reward: 246.9107208251953






Player: 1 
cards in hand: [8. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  1  0 14  8  8  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[319.6598 ]
 [304.75565]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.154402256011963
desired expected reward: 246.7713623046875



action possibilites: [-1] 
expected returns: [[298.01367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.803708553314209
desired expected reward: 292.9455261230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[277.66333]
 [269.52185]
 [300.44208]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -7.098317623138428
desired expected reward: 290.91534423828125



buy possibilites: [-1] 
expected returns: [[288.03064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  3.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -21.145401000976562
desired expected reward: 248.3763885498047






Player: 1 
cards in hand: [ 0. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [0. 8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [0. 8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  3.] 
cards in discard: [ 0.  8.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[302.5943 ]
 [294.28424]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -7.817468166351318
desired expected reward: 280.2131652832031



action possibilites: [-1] 
expected returns: [[243.19818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 21 

action type: gain_card_n - action 6
Learning step: -7.048069953918457
desired expected reward: 264.3525085449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[226.86127]
 [232.93185]
 [232.12776]
 [220.15584]
 [240.41924]
 [234.08308]
 [233.28113]
 [247.93324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.  6.  8.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -6.020259380340576
desired expected reward: 237.17791748046875






Player: 1 
cards in hand: [0. 0. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 1.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[232.49265]
 [226.29166]
 [225.82974]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  8. 10.] 
adversary cards in discard: [16.  0.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -7.400479316711426
desired expected reward: 240.5327606201172



action possibilites: [-1. 11.] 
expected returns: [[315.0322 ]
 [307.37906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  8. 10.] 
adversary cards in discard: [16.  0.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 29.0
Learning step: -3.37876296043396
desired expected reward: 222.43209838867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[291.58728]
 [298.9017 ]
 [298.42358]
 [283.57037]
 [296.78436]
 [307.50146]
 [300.1607 ]
 [306.85852]
 [292.7419 ]
 [299.68628]
 [300.65076]
 [315.15454]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  8. 10.] 
adversary cards in discard: [16.  0.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -8.126655578613281
desired expected reward: 306.905517578125



buy possibilites: [-1] 
expected returns: [[232.2084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 14.  8.  8. 10.] 
adversary cards in discard: [16.  0.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 49 

action type: buy - action 15.0
Learning step: -7.357847690582275
desired expected reward: 293.2928771972656






Player: 1 
cards in hand: [ 0. 14.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  8. 10.] 
cards in discard: [16.  0.  0.  8.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  8.  3.] 
cards in discard: [16.  0.  0.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  1  0 14  8  8  3  8  0 10 16] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.] 
cards in discard: [16.  0.  0.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [16.  0.  0.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [16.  0.  0.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [16.  0.  0.  8.  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8. 14.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[214.86264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16  3] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    2    0    0    0    0 -150    0    0    0    0    0 -300
   58    0] 
sum of rewards: -395 

action type: discard_down_to_3_cards - action 0
Learning step: -25.882434844970703
desired expected reward: 193.478759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[193.42375]
 [199.59766]
 [186.23167]
 [201.09482]
 [215.48224]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  4. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16  3] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.37343168258667
desired expected reward: 208.54324340820312



buy possibilites: [-1] 
expected returns: [[216.03778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16  3] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -4.943892955780029
desired expected reward: 196.1509552001953






Player: 1 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 10 16  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  8.  8. 11.] 
adversary cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[200.45245]
 [185.70338]
 [185.70338]
 [192.35736]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  8. 11.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 29  0  0  0 11  8 11  6  8 15  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -6.652623653411865
desired expected reward: 209.38516235351562



action possibilites: [-1] 
expected returns: [[269.3434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 13
Learning step: -1.4516388177871704
desired expected reward: 176.78565979003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[250.8787 ]
 [242.98181]
 [274.35947]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -6.2593841552734375
desired expected reward: 263.08404541015625



buy possibilites: [-1] 
expected returns: [[270.8625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [15. 29. 11.  3.  0.  0.  0.  0.  0.  8.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3. 14.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: buy - action 0.0
Learning step: -6.5495285987854
desired expected reward: 244.32916259765625






Player: 1 
cards in hand: [ 8.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  0.  3.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0 14  8  8  3  8  0 16  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[201.71399]
 [195.38216]
 [195.38216]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -7.665167331695557
desired expected reward: 263.19732666015625



action possibilites: [-1] 
expected returns: [[212.5028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 63 

action type: gain_card_n - action 2
Learning step: -1.2616287469863892
desired expected reward: 182.59719848632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[193.15154]
 [197.51509]
 [187.8302 ]
 [198.80684]
 [209.62479]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  3. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -3.203083038330078
desired expected reward: 209.2997283935547



buy possibilites: [-1] 
expected returns: [[194.56204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [3. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 16.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 67 

action type: buy - action 8.0
Learning step: -2.2126967906951904
desired expected reward: 196.5941619873047






Player: 1 
cards in hand: [ 8.  0. 16.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  8.  1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  8  8  8  0 16 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  0  8  8  0 16 10 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  0  8  8  0 16 10 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 15.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
expected returns: [[235.72064]
 [229.01816]
 [223.82756]
 [223.79445]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  0.  8.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 29  0  0  0 11 11  8 15  8  0  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [29.  0. 16.  0.  8.  1.] 
adversary owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -2.6636528968811035
desired expected reward: 191.8983917236328



action possibilites: [-1] 
expected returns: [[228.34483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [29.  0. 16.  0.  8.  1.] 
adversary owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.782738447189331
desired expected reward: 214.62718200683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[216.54474]
 [221.21455]
 [210.8126 ]
 [222.78127]
 [234.75984]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 30.  8.  9.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [29.  0. 16.  0.  8.  1.] 
adversary owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -3.455577850341797
desired expected reward: 224.88925170898438



buy possibilites: [-1] 
expected returns: [[236.74295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [29.  0. 16.  0.  8.  1.] 
adversary owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -252.0 

action type: buy - action 6.0
Learning step: -17.813915252685547
desired expected reward: 192.9987030029297






Player: 1 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [29.  0. 16.  0.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  0  8  8  0 16 10 29  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29.  0. 16.  0.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0  8  8  0 16 29  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  0. 16.  0.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0  8  8  0 16 29  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29.  0. 16.  0.  8.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[192.29448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -6.05853271484375
desired expected reward: 230.68441772460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.87549]
 [178.74553]
 [178.17851]
 [165.07013]
 [186.97379]
 [179.9632 ]
 [179.39949]
 [194.87573]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.255005359649658
desired expected reward: 190.35009765625



buy possibilites: [-1] 
expected returns: [[153.42685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3.  8. 11.  0. 11.  0.  3.  6.  8.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 1.0
Learning step: -3.1909291744232178
desired expected reward: 175.55458068847656






Player: 1 
cards in hand: [ 0. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0  8  8  0 16 29  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  8.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6  1] -> size -> 20 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[216.47142]
 [204.43364]
 [204.43364]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0  0 11 11  8  8  0  3  8  6  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  1. 16.] 
adversary cards in discard: [10.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -1.5941463708877563
desired expected reward: 151.83270263671875



action possibilites: [-1] 
expected returns: [[212.13277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  1. 16.] 
adversary cards in discard: [10.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.787792921066284
desired expected reward: 196.42779541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[184.93639]
 [178.17793]
 [208.53682]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  1. 16.] 
adversary cards in discard: [10.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -3.8738746643066406
desired expected reward: 208.25889587402344



buy possibilites: [-1] 
expected returns: [[205.36678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  1. 16.] 
adversary cards in discard: [10.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 18.0 

action type: buy - action 0.0
Learning step: -3.7260689735412598
desired expected reward: 181.21034240722656






Player: 1 
cards in hand: [ 8.  8.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  1. 16.] 
cards in discard: [10.  0. 29.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  0  8  8  0 16 29  0  8 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.] 
cards in discard: [10.  0. 29.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [10.  0. 29.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[219.95155]
 [209.2754 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -4.0687408447265625
desired expected reward: 201.29803466796875



action possibilites: [-1] 
expected returns: [[204.24905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.971653938293457
desired expected reward: 212.3734893798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[183.48476]
 [177.11237]
 [201.91011]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -4.657297611236572
desired expected reward: 199.5917510986328






Player: 1 
cards in hand: [ 8.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  8  0 16 29  0  8 10] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [0. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[229.05347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0. 8. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  8.  0.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -4.646701335906982
desired expected reward: 197.26339721679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[208.73393]
 [213.87361]
 [212.91985]
 [202.77853]
 [219.12086]
 [214.80663]
 [213.8537 ]
 [224.06155]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0. 8. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 27. 30.  8.  8.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  8.  0.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -6.306024074554443
desired expected reward: 222.52969360351562



buy possibilites: [-1] 
expected returns: [[197.62032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0. 8. 0. 8. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  8.  0.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -20.942468643188477
desired expected reward: 181.83604431152344






Player: 1 
cards in hand: [29. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  8.  0.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  1.] 
adversary cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  0 16 29  0  8 10] -> size -> 8 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  1.] 
adversary cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 16 29  0  8 10] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  1.] 
adversary cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 16 29  0  8 10] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  1.] 
adversary cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[193.30754]
 [186.58052]
 [186.58052]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  1.] 
cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8. 16. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  0  8 10] -> size -> 6 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -5.8592634201049805
desired expected reward: 191.76104736328125



action possibilites: [-1] 
expected returns: [[238.779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8. 16. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  0  8 10] -> size -> 6 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: -2.428150177001953
desired expected reward: 177.5854034423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[212.88011]
 [220.16264]
 [219.38478]
 [204.96358]
 [229.46725]
 [221.48624]
 [220.71143]
 [240.02426]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8. 16. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  0  8 10] -> size -> 6 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -6.165754318237305
desired expected reward: 232.61325073242188



buy possibilites: [-1] 
expected returns: [[260.48288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  1.] 
cards in discard: [0. 8. 0. 8. 0. 6. 0. 6. 0. 0. 3. 1. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 27. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8. 16. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  0  8 10] -> size -> 6 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: -5.2903218269348145
desired expected reward: 202.7333984375






Player: 1 
cards in hand: [ 8.  8. 16. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 16. 10.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 29  0  8 10] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1  0] -> size -> 18 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16 29  8 10  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1  0] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16 29  8 10  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1  0] -> size -> 18 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[179.34929]
 [165.21806]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0  0  0 11 11  8  0  3  8  6  1  0  6  1  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  8 10  3] -> size -> 6 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -9.837541580200195
desired expected reward: 250.6453399658203



action possibilites: [-1] 
expected returns: [[160.18578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  8 10  3] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 5
Learning step: -5.375100135803223
desired expected reward: 168.21047973632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.0463 ]
 [149.26718]
 [139.36325]
 [151.14322]
 [160.05019]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  8 10  3] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -4.929427623748779
desired expected reward: 155.25634765625



buy possibilites: [-1] 
expected returns: [[139.10704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 29  8 10  3] -> size -> 6 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 2 

action type: buy - action 8.0
Learning step: -4.32725191116333
desired expected reward: 146.81594848632812






Player: 1 
cards in hand: [ 8.  8.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 10. 29.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 29  8 10  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  1.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 10  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  1.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8 10  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  1.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[163.69005]
 [156.80981]
 [156.80981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  1.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -4.6148905754089355
desired expected reward: 134.49215698242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[140.85535]
 [146.87155]
 [146.35223]
 [134.1989 ]
 [145.11615]
 [153.86993]
 [153.389  ]
 [141.71663]
 [147.4083 ]
 [148.17827]
 [160.34337]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  1.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -6.253978729248047
desired expected reward: 159.69610595703125



buy possibilites: [-1] 
expected returns: [[127.7067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  1.] 
cards in discard: [ 8.  8.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 6 

action type: buy - action 14.0
Learning step: -3.912431478500366
desired expected reward: 137.80421447753906






Player: 1 
cards in hand: [ 8.  3. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 10  3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8 14] -> size -> 18 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 10  3] -> size -> 4 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8 14] -> size -> 18 
adversary victory points: -1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[125.50492]
 [117.93308]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  3  8  6  0  6  1  0  8 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -4.9167070388793945
desired expected reward: 122.78999328613281



action possibilites: [-1] 
expected returns: [[163.95981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 4
Learning step: -2.1243443489074707
desired expected reward: 108.14445495605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[143.30525]
 [148.6196 ]
 [136.76225]
 [162.08946]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -5.138552665710449
desired expected reward: 158.82125854492188



buy possibilites: [-1] 
expected returns: [[179.59767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0.  0. 14.  0.  0. 11. 11.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 26. 30.  8.  6.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16. 10.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8 10  3] -> size -> 4 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -317.0 

action type: buy - action 6.0
Learning step: -18.647165298461914
desired expected reward: 118.1150894165039






Player: 1 
cards in hand: [16. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  3.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8 10  3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  9.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 10  3 16] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 10  3 16] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 10  3 16  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[133.9825 ]
 [131.27467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 16.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -7.772765636444092
desired expected reward: 171.8249053955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[124.7887 ]
 [128.05731]
 [127.40826]
 [121.63225]
 [131.29713]
 [128.01413]
 [134.35318]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 16.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -5.830259799957275
desired expected reward: 131.6698760986328



buy possibilites: [-1] 
expected returns: [[132.61841]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10. 16.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0] -> size -> 5 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -19 

action type: buy - action 1.0
Learning step: -3.9826486110687256
desired expected reward: 116.34860229492188






Player: 1 
cards in hand: [10. 16.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3 16  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1] -> size -> 18 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3 16  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1] -> size -> 18 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3. 16.  0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3 16  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 11.  8.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1] -> size -> 18 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[174.00742]
 [167.76291]
 [162.0296 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.  8.] 
cards in discard: [ 1. 11.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -4.667969703674316
desired expected reward: 127.950439453125



action possibilites: [-1] 
expected returns: [[165.04941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 11.  0.  6.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: -4.7904744148254395
desired expected reward: 164.29122924804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[157.08752]
 [160.6119 ]
 [160.21523]
 [152.22398]
 [159.61537]
 [164.37796]
 [164.15616]
 [157.64189]
 [160.81752]
 [161.20235]
 [167.79492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 11.  0.  6.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 10  3 16  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -5.472370624542236
desired expected reward: 159.57704162597656






Player: 1 
cards in hand: [ 0. 16.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 10  3 16  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  0. 14.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 10 16  0  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  0. 14.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 10 16  0  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  0. 14.] 
adversary cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[166.019  ]
 [153.49942]
 [153.49942]
 [147.13411]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  0. 14.] 
cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 11  8  0  8  0  6  1  0  8 14  6  1 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -6.212179183959961
desired expected reward: 161.58274841308594



action possibilites: [-1] 
expected returns: [[127.716736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.534302234649658
desired expected reward: 155.624267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.29346 ]
 [108.520584]
 [127.242584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 1. 11.  0.  6.  0.  0. 15. 11.  0.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16.  0.  0. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -4.090435981750488
desired expected reward: 123.62629699707031






Player: 1 
cards in hand: [16.  0.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 10 16  0  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 16. 10.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 10 16  0  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[135.56853]
 [128.8566 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -4.669595718383789
desired expected reward: 122.57295989990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[120.55774 ]
 [124.780716]
 [114.80351 ]
 [136.03467 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -5.46441125869751
desired expected reward: 133.24871826171875



buy possibilites: [-1] 
expected returns: [[132.35822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16. 16. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 10 16  0  0  0] -> size -> 6 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -57.0 

action type: buy - action 0.0
Learning step: -5.899827003479004
desired expected reward: 114.65790557861328






Player: 1 
cards in hand: [16. 16. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16 10 16  0  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 30.  8.  6.  8.  8.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16  0  0  0 11] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16  0  0  0 11] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 16  0  0  0 11  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0. 14.  0. 11.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  0. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
expected returns: [[51.11106 ]
 [46.68198 ]
 [38.394463]
 [46.68198 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0. 11.] 
cards in discard: [ 0.  0.  6. 15.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  0  0  0 11  0] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -6.896538734436035
desired expected reward: 125.46167755126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[37.40805 ]
 [40.85435 ]
 [33.319286]
 [51.38187 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14.  0. 11.] 
cards in discard: [ 0.  0.  6. 15.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [16.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 16  0  0  0 11  0] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -3.0378785133361816
desired expected reward: 49.59003448486328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 16  0  0  0 11  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  7. 10.  8.] 
adversary cards in hand: [1. 0. 8. 1. 8.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0 11  0 10] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 8. 1. 8.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0 11  0 10] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 8. 1. 8.] 
adversary cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [1. 0. 8. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[67.71973]
 [60.15504]
 [60.15504]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 1. 8.] 
cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  8  0  6  1  0  8 14  6  1 15  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -2.5110270977020264
desired expected reward: 48.87084197998047



action possibilites: [-1] 
expected returns: [[138.26161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.6081861853599548
desired expected reward: 43.66218566894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[126.31726 ]
 [128.08716 ]
 [127.20397 ]
 [124.46812 ]
 [123.680855]
 [127.46995 ]
 [129.71252 ]
 [132.49706 ]
 [129.79295 ]
 [125.980354]
 [126.49418 ]
 [127.57996 ]
 [124.99337 ]
 [127.48191 ]
 [131.8004  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -4.380311489105225
desired expected reward: 133.8813018798828



buy possibilites: [-1] 
expected returns: [[93.9813]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [ 0.  0.  6. 15.  6.  0. 11.  0. 14.  0. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10] -> size -> 7 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -2.5 

action type: buy - action 10.0
Learning step: -4.389418125152588
desired expected reward: 123.1905288696289






Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 11  0 10] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  7.  0. 10.  8.  8. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0 11  0 10 11] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  6.  0. 10.  8.  8. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0 11  0 10 11] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  6.  0. 10.  8.  8. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0 11  0 10 11 15] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  6.  0. 10.  8.  8. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[82.09241 ]
 [73.858475]
 [77.84664 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  6.  8.  6.  0. 10.  8.  8. 10.  5. 10.  7.] 
adversary cards in hand: [15. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10 11 15] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -4.259643077850342
desired expected reward: 89.7216567993164



action possibilites: [-1] 
expected returns: [[81.211174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5. 10.  7.] 
adversary cards in hand: [15. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10 11 15] -> size -> 9 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -318 

action type: gain_card_n - action 3
Learning step: -17.76874351501465
desired expected reward: 56.15119171142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[73.85266 ]
 [76.61473 ]
 [76.21362 ]
 [70.728065]
 [79.60666 ]
 [76.71388 ]
 [82.391335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5. 10.  7.] 
adversary cards in hand: [15. 11.  0. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 11  0 10 11 15] -> size -> 9 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -3.222672700881958
desired expected reward: 77.9885025024414






Player: 1 
cards in hand: [15. 11.  0. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 11  0 10 11 15] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 14. 15.  0.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.] 
cards in discard: [22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15 22] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [ 6.  0. 14. 15.  0.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.] 
cards in discard: [22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15 22] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [ 6.  0. 14. 15.  0.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.] 
cards in discard: [22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [ 6.  0. 14. 15.  0.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
adversary victory points: -3
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[132.32555]
 [119.28816]
 [123.58428]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14. 15.  0.] 
cards in discard: [ 6. 11. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1.0
Learning step: -3.196949005126953
desired expected reward: 79.19438171386719



action possibilites: [-1] 
expected returns: [[127.54136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  0.] 
cards in discard: [ 6. 11. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action 14.0
Learning step: -3.9620416164398193
desired expected reward: 114.67239379882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[113.33994 ]
 [117.68078 ]
 [117.19817 ]
 [108.79308 ]
 [116.40248 ]
 [122.57072 ]
 [122.25485 ]
 [113.8466  ]
 [117.96404 ]
 [118.453285]
 [127.01833 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  0.] 
cards in discard: [ 6. 11. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  8. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -4.603814601898193
desired expected reward: 122.93754577636719



buy possibilites: [-1] 
expected returns: [[96.87392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.  0.] 
cards in discard: [ 6. 11. 10.  0.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  5.  9.  7.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 14 

action type: buy - action 14.0
Learning step: -2.8126683235168457
desired expected reward: 111.0339584350586






Player: 1 
cards in hand: [11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0 10 11 15 22  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  5.  9.  7.] 
adversary cards in hand: [ 1.  0.  1. 11.  8.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0  0 10 11 15 22  0 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  0.  1. 11.  8.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0  0 10 11 15 22  0 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  0.  1. 11.  8.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [16  0  0  0  0 10 11 15 22  0 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 1.  0.  1. 11.  8.] 
adversary cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
adversary victory points: -3
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[72.93783]
 [68.01317]
 [63.93758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 11.  8.] 
cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [15. 22.  0. 16. 10.] 
adversary cards in discard: [ 0.  0. 10.  0. 11.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -5.216439723968506
desired expected reward: 91.65747833251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[59.99699 ]
 [63.666637]
 [63.269917]
 [56.93784 ]
 [55.891766]
 [62.580692]
 [68.505684]
 [72.72068 ]
 [68.11776 ]
 [60.43858 ]
 [62.61977 ]
 [63.915714]
 [58.701088]
 [64.357254]
 [73.41046 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 11.  8.] 
cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 26. 30. 26. 30.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [15. 22.  0. 16. 10.] 
adversary cards in discard: [ 0.  0. 10.  0. 11.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -4.0569167137146
desired expected reward: 68.22657012939453



buy possibilites: [-1] 
expected returns: [[59.997345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 11.  8.] 
cards in discard: [ 6. 11. 10.  0.  0.  0. 14. 14.  6.  0. 15.  0.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [15. 22.  0. 16. 10.] 
adversary cards in discard: [ 0.  0. 10.  0. 11.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15 22  0 10  0] -> size -> 12 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 4.0
Learning step: 0.7530488967895508
desired expected reward: 57.69087219238281






Player: 1 
cards in hand: [15. 22.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 22.  0. 16. 10.] 
cards in discard: [ 0.  0. 10.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0 10 11 15 22  0 10  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  4.  9.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.] 
cards in discard: [ 0.  0. 10.  0. 11.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.] 
cards in discard: [ 0.  0. 10.  0. 11.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.] 
cards in discard: [ 0.  0. 10.  0. 11.  0.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[131.39445]
 [125.15491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.379986971616745
desired expected reward: 59.61735916137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[115.021515]
 [119.94181 ]
 [109.920586]
 [132.40865 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 26. 29.  8.  5.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.048415660858154
desired expected reward: 126.27560424804688



buy possibilites: [-1] 
expected returns: [[103.34749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  6.  0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -316.0 

action type: buy - action 6.0
Learning step: -18.74055290222168
desired expected reward: 86.57685852050781






Player: 1 
cards in hand: [ 0. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  9.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[119.02766]
 [112.26195]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  1  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0. 10.  0. 11. 16.] 
adversary cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0 22] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.3670601844787598
desired expected reward: 99.98043060302734



action possibilites: [-1] 
expected returns: [[145.90442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0. 10.  0. 11. 16.] 
adversary cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0 22] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.4631675481796265
desired expected reward: 97.4571762084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[124.90119]
 [130.51842]
 [130.16895]
 [118.98225]
 [137.40787]
 [131.1577 ]
 [143.5873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0. 10.  0. 11. 16.] 
adversary cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0 22] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -4.1167521476745605
desired expected reward: 141.7876739501953






Player: 1 
cards in hand: [ 0. 10.  0. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11. 16.] 
cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0 10 11 15  0 10  0 10  0 22] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 10.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 10.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [22. 10. 10.  0.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 10.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[100.16007]
 [ 87.31398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  0. 10.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -5.845218181610107
desired expected reward: 137.74209594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.67062 ]
 [ 88.47324 ]
 [ 88.01797 ]
 [ 76.594284]
 [ 86.79583 ]
 [ 95.2982  ]
 [ 94.77586 ]
 [ 83.478584]
 [ 89.02959 ]
 [ 89.747215]
 [101.63319 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 10.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  8.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.816755771636963
desired expected reward: 97.11555480957031



buy possibilites: [-1] 
expected returns: [[81.03233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 10.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  7. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 16 

action type: buy - action 29.0
Learning step: -2.1155664920806885
desired expected reward: 92.66030883789062






Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  7. 10.  3.  8.  7.] 
adversary cards in hand: [14.  4. 14. 15. 11.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  7. 10.  3.  8.  7.] 
adversary cards in hand: [14.  4. 14. 15. 11.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [14.  4. 14. 15. 11.] 
adversary cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [14.  4. 14. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 15. 11.] 
expected returns: [[59.5651  ]
 [48.696594]
 [48.696594]
 [52.422073]
 [55.748398]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  4. 14. 15. 11.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [10. 10.  0. 22. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0. 15.] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.7000114917755127
desired expected reward: 77.33232116699219



action possibilites: [-1] 
expected returns: [[67.98181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14. 15. 11.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 14.0
Learning step: -0.5831672549247742
desired expected reward: 45.67198944091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[54.824905]
 [57.885536]
 [51.12172 ]
 [66.27749 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14. 15. 11.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 26. 29.  8.  4.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.882647156715393
desired expected reward: 66.09916687011719



buy possibilites: [-1] 
expected returns: [[119.01977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14. 15. 11.] 
cards in discard: [ 6.  0.  6. 11.  6.  0.  8.  0.  0.  0. 29.  6.  0.  1.  0. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 26. 29.  8.  3.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
adversary owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: -15.228140830993652
desired expected reward: 35.89356994628906






Player: 1 
cards in hand: [10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  3.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  3.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  3.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [16  0  0  0 10 11 15  0 10  0 10  0 22  0 14  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 26. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 11. 16.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 11. 16.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  0.  0.  0.  0. 15.  0. 22.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 11. 16.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 14.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[84.611725]
 [73.39077 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [15.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -5.494992733001709
desired expected reward: 113.52477264404297



action possibilites: [-1] 
expected returns: [[25.454187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [15. 10.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 14.0
Learning step: -3.4729244709014893
desired expected reward: 70.43994903564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.682623]
 [16.03394 ]
 [15.737568]
 [11.713071]
 [11.061432]
 [15.333513]
 [19.066923]
 [21.635668]
 [18.833542]
 [13.925593]
 [15.289692]
 [16.158936]
 [12.800687]
 [16.414629]
 [21.949907]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [15. 10.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -1.2481801509857178
desired expected reward: 24.20600700378418



buy possibilites: [-1] 
expected returns: [[61.811024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  2.  8.  7.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [15. 10.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -2.5 

action type: buy - action 10.0
Learning step: 0.5489117503166199
desired expected reward: 16.707860946655273






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  2.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 23 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  2.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 23 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 23 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[50.358803]
 [46.91713 ]
 [43.74636 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [10. 14.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 11  0  0  6  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  0.  0. 10. 22.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -3.4404003620147705
desired expected reward: 58.37062454223633



action possibilites: [-1] 
expected returns: [[21.36948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 14.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  0.  0. 10. 22.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.5976876020431519
desired expected reward: 43.97233200073242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.47858 ]
 [10.611292]
 [22.671202]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 14.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  0.  0. 10. 22.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -0.4998924434185028
desired expected reward: 20.869586944580078






Player: 1 
cards in hand: [14.  0.  0. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10. 22.] 
cards in discard: [15. 10. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 1. 29.  6. 14.  6.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 22.] 
cards in discard: [15. 10. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 1. 29.  6.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 22.] 
cards in discard: [15. 10. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 25. 29.  8.  2.  8.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 1. 29.  6.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 22.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 1. 29.  6.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[37.14507 ]
 [34.818504]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  2.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 3.  6. 16. 10. 11.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -10    0    0    0    0    0    0    0    0    0 -900
   70    0] 
sum of rewards: -846 

action type: discard_down_to_3_cards - action 4
Learning step: -43.533321380615234
desired expected reward: -3.453571319580078



action possibilites: [-1.] 
expected returns: [[34.626743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 25. 29.  8.  2.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 3.  6. 16. 10. 11.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: discard_n_cards - action 1
Learning step: -0.5875765085220337
desired expected reward: 30.745988845825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[21.298843]
 [24.60731 ]
 [17.570118]
 [33.297657]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  2.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 3.  6. 16. 10. 11.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -0.9640138745307922
desired expected reward: 33.6627311706543



buy possibilites: [-1] 
expected returns: [[71.54389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 3.  6. 16. 10. 11.] 
adversary cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: -14.618766784667969
desired expected reward: 2.9513416290283203






Player: 1 
cards in hand: [ 3.  6. 16. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16. 10. 11.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16. 11.  0.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  0.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  0.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  0.] 
cards in discard: [15. 10. 10.  0.  0.  0. 16. 14.  0.  0. 10. 22.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [10.  6. 11.  4.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[45.042507]
 [39.801525]
 [42.437584]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  4.  0.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 14. 22. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -4.008101940155029
desired expected reward: 67.5357894897461



action possibilites: [-1. 11. 15.] 
expected returns: [[62.914032]
 [59.43261 ]
 [56.60324 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  4.  0. 15.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 14. 22. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 10.0
Learning step: -0.8962969779968262
desired expected reward: 37.03683090209961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.592022]
 [49.980843]
 [61.88053 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  4.  0. 15.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 14. 22. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1.0
Learning step: -2.2444825172424316
desired expected reward: 60.66956329345703



buy possibilites: [-1] 
expected returns: [[90.678185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  4.  0. 15.] 
cards in discard: [10. 14.  0.  0.  0.  6.  8. 14.  6.  1.  6. 29.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 14. 22. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -37.0 

action type: buy - action 0.0
Learning step: -2.439342737197876
desired expected reward: 50.15269470214844






Player: 1 
cards in hand: [ 0. 14. 22. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 22. 10.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  7.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  0.  0. 11.  0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [22.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11.  6.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[52.55178]
 [49.59225]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  1.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 6.  0. 10.  1. 10.] 
adversary cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -4.794114589691162
desired expected reward: 85.88407135009766



action possibilites: [-1] 
expected returns: [[68.82084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 6.  0. 10.  1. 10.] 
adversary cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -318 

action type: gain_card_n - action 3
Learning step: -16.395084381103516
desired expected reward: 24.475967407226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[59.19216 ]
 [60.539745]
 [64.63535 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 6.  0. 10.  1. 10.] 
adversary cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -2.950265645980835
desired expected reward: 65.87057495117188






Player: 1 
cards in hand: [ 6.  0. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  1. 10.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [29. 15.  0.  4.  0.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 10.  3.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [29. 15.  0.  4.  0.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 10.  3.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [29. 15.  0.  4.  0.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 10.  3.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [29. 15.  0.  4.  0.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29. 15.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[25.907192]
 [22.437588]
 [19.79699 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0.  4.  0.] 
cards in discard: [ 6. 11.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 15. 10.  0. 16.] 
adversary cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3. 10.  6.  0.  1. 10.  3.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3] -> size -> 23 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -5.163619518280029
desired expected reward: 59.471717834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.916557]
 [19.577036]
 [26.62083 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  0.  4.  0.] 
cards in discard: [ 6. 11.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0. 15. 10.  0. 16.] 
adversary cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3. 10.  6.  0.  1. 10.  3.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3] -> size -> 23 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -3.0911123752593994
desired expected reward: 20.48000144958496



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15. 10.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0. 16.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3. 10.  6.  0.  1. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  8. 10.  6.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0. 16.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3. 10.  6.  0.  1. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  8. 10.  6.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  0. 16.] 
cards in discard: [16. 22.  0. 14. 10.  0.  0. 11.  0.  3. 10.  6.  0.  1. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [14.  8. 10.  6.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [14.  8. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
expected returns: [[70.03744 ]
 [60.31847 ]
 [63.503307]
 [63.2936  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 10.  6.  6.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -2.3072948455810547
desired expected reward: 24.313528060913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.491493]
 [68.647575]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 10.  6.  6.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -4.37598180770874
desired expected reward: 64.00617980957031



buy possibilites: [-1] 
expected returns: [[42.56718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 10.  6.  6.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [15.  0.  6.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action 0.0
Learning step: -5.866813659667969
desired expected reward: 52.62468338012695






Player: 1 
cards in hand: [15.  0.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 14.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 24. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 14.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0. 16.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 23. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 14.] 
adversary cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
adversary owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[15.08746 ]
 [ 6.549528]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  1. 14.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 23. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [ 3.  1. 10.  0.  3.] 
adversary cards in discard: [ 3. 15.  0.  6.  0. 16.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -4.774172306060791
desired expected reward: 37.793006896972656



action possibilites: [-1] 
expected returns: [[24.02948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 25. 30. 23. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [3. 1. 3.] 
adversary cards in discard: [ 3. 15.  0.  6.  0. 16. 10.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action 14.0
Learning step: -1.6868129968643188
desired expected reward: 4.86271333694458





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.286434]
 [17.715086]
 [14.985962]
 [17.692991]
 [13.288956]
 [17.040283]
 [20.893183]
 [23.573835]
 [20.517853]
 [15.745277]
 [17.359581]
 [18.104736]
 [14.652555]
 [18.452305]
 [24.70325 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 25. 30. 23. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  1.  8.  7.] 
adversary cards in hand: [3. 1. 3.] 
adversary cards in discard: [ 3. 15.  0.  6.  0. 16. 10.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -2.6795451641082764
desired expected reward: 21.34993553161621



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 0 
Estate: 0 
Duchy: 1 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 2 
Chapel: 4 
Witch: 0 
Poacher: 2 
Militia: 2 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [ 6. 11.  6.  0.  0.  6. 29. 15.  0.  4.  0.  0. 14.  8. 10.  6.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 11  0  0  0  8 14  6  1 15  0 10  6 14  4  6 29  6 10  6  0  6  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 25. 30. 23. 29.  8.  0.  6.  6.  0. 10.  7.  6. 10.  0.  8.  7.] 
adversary cards in hand: [3. 1. 3.] 
adversary cards in discard: [ 3. 15.  0.  6.  0. 16. 10.  0.] 
adversary owned cards: [16  0  0 10 11 15  0 10  0 10  0 22  0 14  6  3  0 10 16  1  0 16  3  0
  3] -> size -> 25 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5 -500   -3  -50    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -529 

action type: buy - action 10.0
Learning step: -27.35523796081543
desired expected reward: -9.250499725341797



