 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.28906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -8 -180    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -723 

action type: buy - action 0.0
Learning step: -36.24204635620117
desired expected reward: -34.40114212036133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[278.1351 ]
 [290.21695]
 [287.13498]
 [257.81628]
 [298.9126 ]
 [287.31165]
 [284.82324]
 [306.36157]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.877436637878418
desired expected reward: 298.7837219238281



buy possibilites: [-1] 
expected returns: [[285.44116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.118389129638672
desired expected reward: 235.69789123535156






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.79324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.785640239715576
desired expected reward: 277.655517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[301.56116]
 [312.74252]
 [307.86676]
 [282.6607 ]
 [306.69528]
 [317.70572]
 [310.35107]
 [314.37732]
 [291.95984]
 [305.71466]
 [303.94992]
 [321.354  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.492807388305664
desired expected reward: 307.68133544921875



buy possibilites: [-1] 
expected returns: [[302.15857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 3. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 3.0
Learning step: -8.594770431518555
desired expected reward: 299.2720031738281






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[288.72656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.72025203704834
desired expected reward: 293.4383239746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[260.8803 ]
 [268.5273 ]
 [243.13835]
 [268.86282]
 [284.84335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.38942813873291
desired expected reward: 279.9517517089844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 6. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.63922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 0. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.41885232925415
desired expected reward: 277.42449951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[291.01263]
 [302.08063]
 [298.3747 ]
 [272.07965]
 [296.24158]
 [308.66782]
 [299.5614 ]
 [304.4163 ]
 [282.3746 ]
 [296.25354]
 [294.7871 ]
 [313.4736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 0. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.674137115478516
desired expected reward: 299.0287780761719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [1. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [1. 0. 0. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [1. 0. 0. 0. 0. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[283.26172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.403006553649902
desired expected reward: 304.07061767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[255.07492]
 [262.41364]
 [237.01823]
 [263.20273]
 [278.53854]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.26691722869873
desired expected reward: 274.87420654296875



buy possibilites: [-1] 
expected returns: [[280.56952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 6 

action type: buy - action 8.0
Learning step: -6.547323703765869
desired expected reward: 256.6554260253906






Player: 1 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.68323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  1.] 
adversary cards in discard: [23.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.556647777557373
desired expected reward: 273.01287841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.46558]
 [288.24838]
 [285.18048]
 [254.46014]
 [281.7383 ]
 [297.73276]
 [285.05527]
 [291.29297]
 [266.33887]
 [282.5886 ]
 [280.979  ]
 [306.49738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  1.] 
adversary cards in discard: [23.  0.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.145787239074707
desired expected reward: 283.93548583984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  1.] 
cards in discard: [23.  0.  1.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [23.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [23.  0.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [23.  0.  1.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[275.3343 ]
 [258.26593]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.297642707824707
desired expected reward: 297.19970703125



action possibilites: [-1] 
expected returns: [[304.3041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.731438636779785
desired expected reward: 263.83416748046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[276.7544 ]
 [260.42923]
 [297.65735]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.896159648895264
desired expected reward: 296.407958984375



buy possibilites: [-1] 
expected returns: [[261.7296]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -12.0 

action type: buy - action 0.0
Learning step: -8.54880428314209
desired expected reward: 268.2055969238281






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.51904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.651435375213623
desired expected reward: 255.07818603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[256.06842]
 [268.53125]
 [265.24402]
 [235.17134]
 [262.00195]
 [277.59088]
 [265.45923]
 [271.8603 ]
 [247.11252]
 [262.78482]
 [261.3976 ]
 [285.23367]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.520891189575195
desired expected reward: 281.9255676269531



buy possibilites: [-1] 
expected returns: [[342.01074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 14.0
Learning step: -3.1603851318359375
desired expected reward: 243.9521484375






Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [29.  3.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [29.  3.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [29.  3.  0.  0.  0.  1. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[282.23468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 23.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.840505599975586
desired expected reward: 331.17022705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[262.77737]
 [272.33258]
 [270.59872]
 [246.76143]
 [280.25854]
 [269.90942]
 [268.75333]
 [286.6599 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 23.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.02628231048584
desired expected reward: 274.6418151855469



buy possibilites: [-1] 
expected returns: [[294.42462]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 23.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -6.192075252532959
desired expected reward: 266.1405029296875






Player: 1 
cards in hand: [ 0.  3.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 23.] 
cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 23.] 
cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 23.] 
cards in discard: [29.  3.  0.  0.  0.  1. 22.  0.  0.  3.  0.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[337.40848]
 [301.48642]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.564239501953125
desired expected reward: 286.8603820800781



action possibilites: [-1] 
expected returns: [[331.5954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 14.0
Learning step: -6.52986478805542
desired expected reward: 291.28533935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[312.15976]
 [324.3647 ]
 [321.18365]
 [298.91342]
 [292.27237]
 [318.07755]
 [332.84064]
 [321.41608]
 [342.88885]
 [327.29907]
 [303.46884]
 [313.04422]
 [318.78372]
 [299.4053 ]
 [317.2509 ]
 [339.73465]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -8.326556205749512
desired expected reward: 323.2688293457031






Player: 1 
cards in hand: [ 0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.] 
cards in discard: [3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0. 3. 0.] 
cards in discard: [3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 23. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 3. 0.] 
cards in discard: [3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 23. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 23. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[274.706  ]
 [253.89647]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 14  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [1. 1. 8. 0. 0.] 
adversary cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -11.052363395690918
desired expected reward: 328.6822509765625



action possibilites: [-1] 
expected returns: [[253.94896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [1. 1. 8. 0. 0.] 
adversary cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 7
Learning step: -5.620565891265869
desired expected reward: 228.06777954101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[219.87718]
 [202.94904]
 [244.90776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [1. 1. 8. 0. 0.] 
adversary cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -7.1576666831970215
desired expected reward: 246.79129028320312






Player: 1 
cards in hand: [1. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8. 0. 0.] 
cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3.  3.  2. 22. 23. 29.  0.  0.  0.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.09775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [1. 0. 2. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -5.533249855041504
desired expected reward: 226.88955688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.41913]
 [285.99518]
 [283.38528]
 [257.40698]
 [280.50867]
 [293.95062]
 [283.46985]
 [289.02533]
 [267.91165]
 [281.4198 ]
 [280.36267]
 [301.0395 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [1. 0. 2. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.128012657165527
desired expected reward: 290.33380126953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 0. 2. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 2. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 2. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 27. 29. 29. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 2. 3. 0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[246.4714 ]
 [215.81569]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 14.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [23.  3.  1.  0.  8.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -10.854159355163574
desired expected reward: 290.18536376953125



action possibilites: [-1] 
expected returns: [[245.67558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [23.  1.  8.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 14.0
Learning step: -5.430701732635498
desired expected reward: 210.7373504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[205.97865]
 [218.19006]
 [200.9199 ]
 [214.91025]
 [192.24962]
 [185.32607]
 [211.9447 ]
 [226.44879]
 [215.20636]
 [236.67952]
 [221.00345]
 [196.87186]
 [206.75067]
 [212.45522]
 [192.76218]
 [210.8467 ]
 [233.56744]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8. 10.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [23.  1.  8.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -7.481364727020264
desired expected reward: 238.1942138671875



buy possibilites: [-1] 
expected returns: [[191.83772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [23.  1.  8.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: 9.5 

action type: buy - action 25.0
Learning step: -7.042628765106201
desired expected reward: 229.63690185546875






Player: 1 
cards in hand: [23.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  8.] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  1  0 23  0 22  8  2 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[187.76926]
 [175.7204 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [25. 14.  0.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.645265102386475
desired expected reward: 185.1924591064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.89139]
 [184.91269]
 [181.85588]
 [160.42056]
 [190.21657]
 [182.83257]
 [180.10066]
 [194.16597]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [25. 14.  0.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.2654032707214355
desired expected reward: 179.7222442626953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 29. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 22.] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [3. 1. 0. 2. 3. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  0.  0.] 
cards in discard: [ 3.  1.  0.  2.  3.  0.  3.  0.  0.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 22.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[189.56288]
 [171.1938 ]
 [190.15549]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 25.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 30.  8.  9. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -6.606441497802734
desired expected reward: 187.55955505371094



action possibilites: [-1] 
expected returns: [[228.65732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 30.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: 0 

action type: take_action - action 25.0
Learning step: -4.514638423919678
desired expected reward: 188.67391967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[206.46484]
 [215.80577]
 [213.18703]
 [195.9609 ]
 [190.49814]
 [210.95393]
 [222.24303]
 [213.5887 ]
 [230.44633]
 [218.25163]
 [199.56136]
 [207.04912]
 [211.41223]
 [196.21832]
 [210.38275]
 [227.69711]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 29. 28. 30.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -6.6826982498168945
desired expected reward: 221.97462463378906



buy possibilites: [-1] 
expected returns: [[190.60928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 1. 0.] 
cards in discard: [4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 29.  1.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 80 

action type: buy - action 4.0
Learning step: -1.5093376636505127
desired expected reward: 194.4515838623047






Player: 1 
cards in hand: [ 0. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 29. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 22.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 29. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 22.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 29. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 22.] 
cards in discard: [6. 2.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 4. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[255.76268]
 [221.89316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  3.  3.  2. 15.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -3.0733871459960938
desired expected reward: 187.535888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[232.39273]
 [240.23874]
 [212.64526]
 [241.20232]
 [256.71985]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  3.  3.  2. 15.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -6.188539981842041
desired expected reward: 247.3394012451172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  3.  2. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  2. 15.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [25.  1.  8.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  2. 15.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [25.  1.  8.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  2. 15.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [25.  1.  8.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25.  1.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[226.79958]
 [230.77455]
 [210.68199]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  8.  0.  0.] 
cards in discard: [ 4. 14.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 28. 28. 29.  8.  8. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -6.8413987159729
desired expected reward: 249.87841796875



action possibilites: [-1] 
expected returns: [[245.30493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 3. 0.] 
cards in discard: [ 4. 14.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 41 

action type: take_action - action 25.0
Learning step: -3.6568832397460938
desired expected reward: 223.4449462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[223.39551]
 [234.24474]
 [230.33311]
 [210.89293]
 [204.26291]
 [228.44923]
 [240.82108]
 [231.82881]
 [251.83484]
 [236.49321]
 [214.61302]
 [222.87634]
 [228.30649]
 [210.57558]
 [226.87105]
 [247.13814]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3. 0.] 
cards in discard: [ 4. 14.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -4.945762634277344
desired expected reward: 240.35916137695312



buy possibilites: [-1] 
expected returns: [[193.10358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 3. 0.] 
cards in discard: [ 4. 14.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6] -> size -> 23 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.   0.   5.  20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 44.5 

action type: buy - action 1.0
Learning step: -5.142405033111572
desired expected reward: 229.102294921875






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 6.  2. 29.  0.  1.  0.  0. 22.  0. 29.  3.  3.  2. 15.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[165.63045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -4.467635154724121
desired expected reward: 188.6359405517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[146.20926]
 [154.07379]
 [151.47957]
 [137.451  ]
 [132.81223]
 [149.89182]
 [159.02393]
 [152.2972 ]
 [166.13977]
 [155.97438]
 [140.21066]
 [146.19363]
 [150.03688]
 [137.32866]
 [149.1266 ]
 [164.08585]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  9.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -3.195035219192505
desired expected reward: 160.69580078125



buy possibilites: [-1] 
expected returns: [[93.04828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 80 

action type: buy - action 25.0
Learning step: -2.213402509689331
desired expected reward: 163.92636108398438






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4.  0.  0. 25.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 28. 28. 29.  8.  7. 10. 10.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4.  0.  0. 25.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 4.  0.  0. 25.  3.] 
adversary cards in discard: [25.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 4.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[148.19833]
 [151.58807]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  0. 25.  3.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  7. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [15.  2.  1.  0. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11] -> size -> 25 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: 0.13878631591796875
desired expected reward: 93.18706512451172



action possibilites: [-1] 
expected returns: [[218.44296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  0.  3. 14.  8.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [15.  2.  1.  0. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action 25.0
Learning step: 0.050032805651426315
desired expected reward: 147.3487091064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[190.44824]
 [198.81535]
 [173.1551 ]
 [198.38895]
 [214.99356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  0.  3. 14.  8.] 
cards in discard: [25.  0.  0.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [15.  2.  1.  0. 29.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: -3.869589328765869
desired expected reward: 214.57337951660156






Player: 1 
cards in hand: [15.  2.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  2.  1.  0. 29.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  2.  1.  0. 29.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  1.  0. 29.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  9.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  1.  0. 29.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[81.6031  ]
 [57.244244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -7.117379188537598
desired expected reward: 207.87619018554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[65.063194]
 [73.26335 ]
 [70.97105 ]
 [51.410934]
 [69.06332 ]
 [78.66168 ]
 [71.25153 ]
 [75.084526]
 [58.857605]
 [69.30351 ]
 [68.20323 ]
 [83.26956 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -0.3400131165981293
desired expected reward: 79.98674011230469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 3. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 3. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 3. 25.  0.  8.  0.] 
adversary cards in discard: [ 0. 14.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[237.00128]
 [242.00427]
 [223.62479]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  8.  0.] 
cards in discard: [ 0. 14.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  6. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3.  2.  3. 22.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: 3.050785779953003
desired expected reward: 86.32035064697266



action possibilites: [-1] 
expected returns: [[212.33742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0. 4.] 
cards in discard: [ 0. 14.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  5. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3.  2.  3. 22.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 61 

action type: take_action - action 25.0
Learning step: -4.007179260253906
desired expected reward: 232.688232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[196.05415]
 [205.02225]
 [202.47662]
 [180.56348]
 [211.0652 ]
 [202.99162]
 [200.93324]
 [215.88179]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0. 4.] 
cards in discard: [ 0. 14.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 28. 28. 29.  8.  5. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3.  2.  3. 22.] 
adversary cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: -2.960681915283203
desired expected reward: 209.37673950195312






Player: 1 
cards in hand: [ 0.  3.  2.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  2.  3. 22.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  5. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3. 25. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  2.  3. 22.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 28. 28. 29.  8.  5. 10.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3. 25. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  2.  3. 22.] 
cards in discard: [11.  8.  0.  0.  0.  3.  6. 11. 29. 15.  2.  1.  0. 29.  0.  0.  0.  1.
  6.  6.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  5.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [ 0.  3. 25. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[119.02606]
 [121.53078]
 [121.53078]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  5.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  2.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -5.615078926086426
desired expected reward: 210.26675415039062



action possibilites: [-1] 
expected returns: [[194.35556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 29.  8.  4.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  2.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 72 

action type: take_action - action 25.0
Learning step: 1.9929955005645752
desired expected reward: 121.59307861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[173.79018]
 [181.05464]
 [180.0481 ]
 [165.87799]
 [162.15794]
 [177.44872]
 [187.43124]
 [179.15324]
 [192.88837]
 [183.38124]
 [169.00244]
 [175.41888]
 [178.6098 ]
 [166.78748]
 [177.89894]
 [193.4573 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 28. 28. 29.  8.  4.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  2.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: -2.0901718139648438
desired expected reward: 192.265380859375



buy possibilites: [-1] 
expected returns: [[132.03229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  1.  0.  0.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  2.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6] -> size -> 31 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[-5  0  8 80  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 153 

action type: buy - action 4.0
Learning step: 2.3881471157073975
desired expected reward: 167.03973388671875






Player: 1 
cards in hand: [29.  2.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  2.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [4. 0. 8. 3. 0.] 
adversary cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 15 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 28. 28. 28.  8.  4.  9.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [4. 0. 8. 3. 0.] 
adversary cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 15 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  2.  0.  0.  3.] 
cards in discard: [ 6. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [4. 0. 8. 3. 0.] 
adversary cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 15 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [4. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[221.10489]
 [206.69919]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 8. 3. 0.] 
cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  1.  0.  1.  6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1
Learning step: 2.8384201526641846
desired expected reward: 134.87071228027344



action possibilites: [-1] 
expected returns: [[59.021835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 0.] 
cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  1.  0.  1.  6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 113 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.740617513656616
desired expected reward: 191.63156127929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.98213]
 [38.75246]
 [62.50601]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0.] 
cards in discard: [ 4. 25.  0.  3. 25.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [29.  1.  0.  1.  6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 113 

action type: take_action - action -1
Learning step: 3.922078847885132
desired expected reward: 62.943912506103516






Player: 1 
cards in hand: [29.  1.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  1.  6.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [25.  0.  0.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1.  6.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  9.  9.] 
adversary cards in hand: [25.  0.  0.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1.  6.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [25.  0.  0.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[139.9111  ]
 [141.72026 ]
 [104.810585]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0. 22.  3.  2. 15.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1.0
Learning step: 4.486242771148682
desired expected reward: 66.99224090576172



action possibilites: [-1] 
expected returns: [[75.2309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0.  3. 15.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 113 

action type: take_action - action 14.0
Learning step: 2.159437894821167
desired expected reward: 105.82459259033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[60.896687]
 [67.81753 ]
 [57.78586 ]
 [65.538704]
 [53.25368 ]
 [49.350533]
 [64.197296]
 [71.964516]
 [66.21533 ]
 [77.98483 ]
 [69.241356]
 [55.571545]
 [60.808052]
 [64.190506]
 [53.24051 ]
 [63.227337]
 [75.09318 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  8.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0.  3. 15.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 113 

action type: take_action - action -1
Learning step: 3.432481050491333
desired expected reward: 78.66338348388672



buy possibilites: [-1] 
expected returns: [[120.81786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  1.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0.  3. 15.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5.  0.  8. 90.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 115.0 

action type: buy - action 8.0
Learning step: 5.1576361656188965
desired expected reward: 71.37296295166016






Player: 1 
cards in hand: [ 0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1
 11  6 11  0  6 16  6 16 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 3. 25.  4.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 3. 25.  4.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 3. 25.  4.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 3. 25.  4.  0.  1.] 
adversary cards in discard: [ 8. 14. 25.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  4.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[142.10231]
 [145.24359]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  4.  0.  1.] 
cards in discard: [ 8. 14. 25.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 28. 28.  8.  4.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 93 

action type: buy - action -1
Learning step: 1.742838740348816
desired expected reward: 122.56069946289062



action possibilites: [-1] 
expected returns: [[183.59825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0. 1. 8. 0.] 
cards in discard: [ 8. 14. 25.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 114 

action type: take_action - action 25.0
Learning step: 2.8158204555511475
desired expected reward: 143.11862182617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[173.59679]
 [180.26996]
 [178.31009]
 [162.11687]
 [176.76488]
 [184.57776]
 [178.7166 ]
 [182.05028]
 [168.64914]
 [177.07993]
 [176.40088]
 [188.1437 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 1. 8. 0.] 
cards in discard: [ 8. 14. 25.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[-5  0  8 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 113 

action type: take_action - action -1
Learning step: 0.5465065240859985
desired expected reward: 184.14476013183594



buy possibilites: [-1] 
expected returns: [[134.90353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0. 1. 8. 0.] 
cards in discard: [ 8. 14. 25.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8.  90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 83.0 

action type: buy - action 0.0
Learning step: -1.4945091009140015
desired expected reward: 172.10226440429688






Player: 1 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [8. 8. 4. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [8. 8. 4. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 8. 4. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[152.88547]
 [138.8113 ]
 [138.8113 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 4. 4. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: buy - action -1
Learning step: 1.6289780139923096
desired expected reward: 136.5325164794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.81903]
 [115.45923]
 [150.07321]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 4. 4. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: take_action - action -1.0
Learning step: 0.8091728091239929
desired expected reward: 149.90614318847656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  9.] 
adversary cards in hand: [0. 1. 1. 3. 0.] 
adversary cards in discard: [8. 8. 4. 4. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  8.] 
adversary cards in hand: [0. 1. 1. 3. 0.] 
adversary cards in discard: [8. 8. 4. 4. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  8.] 
adversary cards in hand: [0. 1. 1. 3. 0.] 
adversary cards in discard: [8. 8. 4. 4. 3.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 1. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[140.03458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 3. 0.] 
cards in discard: [8. 8. 4. 4. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  8.] 
adversary cards in hand: [ 6. 16. 11.  3.  0.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15] -> size -> 35 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: buy - action -1.0
Learning step: 0.7276024222373962
desired expected reward: 150.80079650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[110.57679 ]
 [119.38948 ]
 [107.249756]
 [117.96692 ]
 [101.09596 ]
 [ 96.458275]
 [114.94471 ]
 [127.15644 ]
 [117.18625 ]
 [133.60428 ]
 [122.361984]
 [104.62229 ]
 [112.348854]
 [116.29987 ]
 [101.68463 ]
 [115.53019 ]
 [133.81848 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3. 0.] 
cards in discard: [8. 8. 4. 4. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  8.] 
adversary cards in hand: [ 6. 16. 11.  3.  0.] 
adversary cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15] -> size -> 35 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: take_action - action -1.0
Learning step: 0.9965759515762329
desired expected reward: 138.83322143554688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 16. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 11.  3.  0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9. 10.  8.  8.] 
adversary cards in hand: [ 0.  0. 25. 14.  0.] 
adversary cards in discard: [8. 8. 4. 4. 3. 0. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  0. 25. 14.  0.] 
adversary cards in discard: [8. 8. 4. 4. 3. 0. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  0. 25. 14.  0.] 
adversary cards in discard: [8. 8. 4. 4. 3. 0. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  0.] 
cards in discard: [ 6. 16. 29.  2.  0.  0.  3. 22. 29.  1.  0.  1.  6. 22.  2.  1. 15.  3.
  6.  0.  6.  0.  0.  6. 15. 11.  0.  8.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  0. 25. 14.  0.] 
adversary cards in discard: [8. 8. 4. 4. 3. 0. 1. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[147.26451]
 [149.7803 ]
 [121.9153 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 14.  0.] 
cards in discard: [8. 8. 4. 4. 3. 0. 1. 1. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 28. 28. 28.  8.  3.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0] -> size -> 37 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: buy - action -1.0
Learning step: 1.6837135553359985
desired expected reward: 135.50222778320312



action possibilites: [-1] 
expected returns: [[78.15008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 124 

action type: take_action - action 25.0
Learning step: 0.4693618714809418
desired expected reward: 150.24966430664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[76.505615]
 [83.041336]
 [81.30075 ]
 [65.01917 ]
 [79.748   ]
 [87.36562 ]
 [81.43438 ]
 [84.56712 ]
 [71.25069 ]
 [79.92483 ]
 [79.06586 ]
 [91.19001 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 123 

action type: take_action - action -1
Learning step: 4.134083271026611
desired expected reward: 82.28416442871094



buy possibilites: [-1] 
expected returns: [[171.40668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  0. 25.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 11.  6.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    8.  100.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 127.5 

action type: buy - action 1.0
Learning step: 6.079582214355469
desired expected reward: 89.12093353271484






Player: 1 
cards in hand: [ 3.  0. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  6.  8.] 
cards in discard: [6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [4. 4. 3. 0. 1.] 
adversary cards in discard: [ 1. 25.  0.  0. 14.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1] -> size -> 17 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  6.  8.] 
cards in discard: [6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [4. 4. 3. 0. 1.] 
adversary cards in discard: [ 1. 25.  0.  0. 14.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1] -> size -> 17 
adversary victory points: 8
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [4. 4. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.45351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 4. 3. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 14.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0.  2.  6. 29.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: buy - action -1
Learning step: -0.2326301634311676
desired expected reward: 171.17404174804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[104.58142 ]
 [112.26727 ]
 [109.72082 ]
 [ 92.82065 ]
 [117.16198 ]
 [110.37436 ]
 [108.12937 ]
 [120.733604]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 4. 3. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 14.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  7.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0.  2.  6. 29.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 113 

action type: take_action - action -1.0
Learning step: 2.2321441173553467
desired expected reward: 121.68565368652344



buy possibilites: [-1] 
expected returns: [[54.40761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 4. 3. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 14.  0.  0. 25.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0.  2.  6. 29.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   8. 110.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 115.0 

action type: buy - action 8.0
Learning step: 1.455452799797058
desired expected reward: 111.82982635498047






Player: 1 
cards in hand: [ 3.  0.  2.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  2.  6. 29.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [1. 8. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1  8] -> size -> 18 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  2.  6. 29.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 23. 28. 28. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [1. 8. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1  8] -> size -> 18 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  2.  6. 29.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 23. 28. 27. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [1. 8. 1. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1  8] -> size -> 18 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [1. 8. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[109.84298]
 [102.77732]
 [102.77732]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 1. 8. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 14  1 25  4  1 25  4  8  0  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  1. 15.  6.  1.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 103 

action type: buy - action -1
Learning step: 4.795840740203857
desired expected reward: 59.203453063964844



action possibilites: [-1] 
expected returns: [[77.13806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  1. 15.  6.  1.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 123 

action type: trash_cards_n_from_hand - action 9
Learning step: 2.4999072551727295
desired expected reward: 110.2138900756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.561817]
 [41.45728 ]
 [74.60244 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  2.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  1. 15.  6.  1.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   8 100   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 123 

action type: take_action - action -1
Learning step: 3.712292432785034
desired expected reward: 80.85035705566406



buy possibilites: [-1] 
expected returns: [[121.48889]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  1. 15.  6.  1.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    7   90    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -188 

action type: buy - action 6.0
Learning step: -8.739364624023438
desired expected reward: 32.71792221069336






Player: 1 
cards in hand: [ 6.  1. 15.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 15.  6.  1.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  4.  4.  0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 15.  6.  1.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  9.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  4.  4.  0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 15.  6.  1.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  4.  4.  0.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [14.  0.  4.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[129.95335 ]
 [102.179054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  4.  4.  0.] 
cards in discard: [6. 8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 1. 16.  0. 10. 15.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: buy - action -1
Learning step: 1.2500938177108765
desired expected reward: 122.73898315429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[104.84545 ]
 [111.140976]
 [ 93.89096 ]
 [111.195145]
 [126.84792 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  4.  4.  0.] 
cards in discard: [6. 8. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 1. 16.  0. 10. 15.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1.0
Learning step: 0.7085113525390625
desired expected reward: 130.66184997558594



buy possibilites: [-1] 
expected returns: [[26.626074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  4.  4.  0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 1. 16.  0. 10. 15.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 62.0 

action type: buy - action 0.0
Learning step: -1.5452839136123657
desired expected reward: 103.3001708984375






Player: 1 
cards in hand: [ 1. 16.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 10. 15.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 15.  0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11
  6 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6
 11  0  6 16  6 16 22  1  6 15 10  0  6  3 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 23. 28. 27. 28.  8.  1.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 15. 16.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[72.708145]
 [74.97937 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 22.  0.  0.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1
Learning step: 5.439425468444824
desired expected reward: 32.06549835205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[61.07073 ]
 [66.062584]
 [64.436935]
 [69.06621 ]
 [64.88273 ]
 [63.442425]
 [71.30576 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [ 6.  8.  3.  0. 14.  0.  4.  4.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 3.  0. 22.  0.  0.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   7 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: take_action - action -1.0
Learning step: 2.989229917526245
desired expected reward: 75.69738006591797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 22.  0.  0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  0.  8.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 2. 0. 0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  0.  8.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 2. 0. 0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 23. 28. 27. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  0.  8.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 2. 0. 0.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 6 
card supply: [21. 23. 28. 26. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  0.  8.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
adversary victory points: 7
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[26.920664]
 [18.435568]
 [28.358673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  1. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 26. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: buy - action -1.0
Learning step: 1.5973732471466064
desired expected reward: 72.90315246582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[13.1636915]
 [17.953758 ]
 [16.679193 ]
 [21.513243 ]
 [16.673141 ]
 [15.712605 ]
 [24.844507 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  1. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 28. 26. 28.  8.  0.  8.  8.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1.0
Learning step: 3.762789487838745
desired expected reward: 29.743518829345703



buy possibilites: [-1] 
expected returns: [[11.441296]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  1. 25.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 26. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 16.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3] -> size -> 40 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[-5  0  7 90  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 110 

action type: buy - action 11.0
Learning step: 4.681766986846924
desired expected reward: 26.195009231567383






Player: 1 
cards in hand: [ 6.  3. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  0.  6.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  6  2  0  6  1 11  6 11
  0  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 26. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  4.  0.  8. 25.] 
adversary cards in discard: [11.  6.  0.  8.  1. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  4.  0.  8. 25.] 
adversary cards in discard: [11.  6.  0.  8.  1. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6.  3.  0. 11.  6.  8.  3.  3.  0.  2.  6. 29. 14.  6.  1. 15.  6.  1.
  6. 10. 15. 16.  1.  3. 22.  3.  0.  0.  0.  2.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 4.  4.  0.  8. 25.] 
adversary cards in discard: [11.  6.  0.  8.  1. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 4.  4.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[20.604109]
 [14.983695]
 [22.051443]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  4.  0.  8. 25.] 
cards in discard: [11.  6.  0.  8.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 22. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1
Learning step: 3.483335256576538
desired expected reward: 14.924631118774414



action possibilites: [-1] 
expected returns: [[77.41774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 4. 0. 8. 0. 3.] 
cards in discard: [11.  6.  0.  8.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 22. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 93 

action type: take_action - action 25.0
Learning step: 5.289327144622803
desired expected reward: 27.340768814086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[64.253784]
 [68.96901 ]
 [69.12698 ]
 [78.62024 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 4. 0. 8. 0. 3.] 
cards in discard: [11.  6.  0.  8.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 6.  3. 22. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1
Learning step: 2.3777687549591064
desired expected reward: 79.7955093383789






Player: 1 
cards in hand: [ 6.  3. 22. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 22. 11. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [11.  6.  0.  8.  1. 25. 25.  4.  4.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 22. 11. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [11.  6.  0.  8.  1. 25. 25.  4.  4.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[72.79199 ]
 [55.662243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [11.  6.  0.  8.  1. 25. 25.  4.  4.  0.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 2.  0. 10.  6.  1.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: 1.1838207244873047
desired expected reward: 79.80406188964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[60.961353]
 [66.38376 ]
 [65.620705]
 [70.99674 ]
 [64.93974 ]
 [64.50092 ]
 [75.41656 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [11.  6.  0.  8.  1. 25. 25.  4.  4.  0.  8.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [ 2.  0. 10.  6.  1.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 1.536047339439392
desired expected reward: 74.32801818847656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 2.  0. 10.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0. 10.  6.  1.] 
cards in discard: [ 6.  3. 22. 11. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0.  6.  1. 29.] 
cards in discard: [ 6.  3. 22. 11. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0.  6. 11.] 
cards in discard: [ 6.  3. 22. 11. 29.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  6. 11.] 
cards in discard: [ 6.  3. 22. 11. 29.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  8.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  0.  6. 11.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[46.453873]
 [36.764057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [0. 2. 6. 6. 1.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: 0.8048152923583984
desired expected reward: 76.22135162353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[33.28705 ]
 [36.091175]
 [35.157845]
 [42.56908 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [0. 2. 6. 6. 1.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 2.1519298553466797
desired expected reward: 48.605796813964844



buy possibilites: [-1] 
expected returns: [[32.628338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [0. 2. 6. 6. 1.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 42.0 

action type: buy - action 0.0
Learning step: 1.169785737991333
desired expected reward: 34.45682144165039






Player: 1 
cards in hand: [0. 2. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 6. 6. 1.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [25. 11.  6.  4.  0.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 6. 6. 1.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  9.  9.  8.  8.] 
adversary cards in hand: [25. 11.  6.  4.  0.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 6. 6. 1.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [25. 11.  6.  4.  0.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 11.  6.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[102.342255]
 [104.221634]
 [ 98.82303 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  6.  4.  0.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1
Learning step: 4.278733730316162
desired expected reward: 36.90707015991211



action possibilites: [-1] 
expected returns: [[71.84405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  4.  0. 25.  8.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action 25.0
Learning step: 1.0054092407226562
desired expected reward: 105.22704315185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[62.72662]
 [71.92721]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  4.  0. 25.  8.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [3. 3. 3. 0. 3.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1
Learning step: 2.5601022243499756
desired expected reward: 74.4041519165039






Player: 1 
cards in hand: [3. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [4. 0. 0. 1. 0.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0. 25. 11.  6.  4.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 3.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [4. 0. 0. 1. 0.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0. 25. 11.  6.  4.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [4. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[92.23555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 1. 0.] 
cards in discard: [ 0. 14.  0.  3.  3.  0. 25. 11.  6.  4.  0. 25.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [15.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: 1.8814884424209595
desired expected reward: 77.7577133178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[77.27641 ]
 [84.44726 ]
 [82.33744 ]
 [69.285614]
 [80.80203 ]
 [89.15517 ]
 [82.69273 ]
 [95.5594  ]
 [85.95941 ]
 [71.81973 ]
 [77.56548 ]
 [80.84281 ]
 [69.51717 ]
 [79.86675 ]
 [93.36969 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 1. 0.] 
cards in discard: [ 0. 14.  0.  3.  3.  0. 25. 11.  6.  4.  0. 25.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [15.  0.  0. 16.  0.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 0.9345062375068665
desired expected reward: 93.17005920410156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 16.  0.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0
  6 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [ 0. 11.  6.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [ 0. 11.  6.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  8.  9.  8.  8.] 
adversary cards in hand: [ 0. 11.  6.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  9.  8.  8.] 
adversary cards in hand: [ 0. 11.  6.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[41.739372]
 [38.504787]
 [33.495457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  1.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  9.  8.  8.] 
adversary cards in hand: [ 0.  6.  3. 14. 16.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: -0.1842903196811676
desired expected reward: 93.1854019165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[27.714642]
 [32.91113 ]
 [31.74814 ]
 [36.592255]
 [31.582914]
 [30.6429  ]
 [39.826836]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  1.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  9.  8.  8.] 
adversary cards in hand: [ 0.  6.  3. 14. 16.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 2.3111445903778076
desired expected reward: 44.050506591796875



buy possibilites: [-1] 
expected returns: [[19.654602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  1.  8.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  6.  3. 14. 16.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 90 

action type: buy - action 10.0
Learning step: 3.410083770751953
desired expected reward: 34.05298614501953






Player: 1 
cards in hand: [ 0.  6.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 14. 16.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25.  0.  4.  0. 14.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 16.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25.  4. 14.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 16.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25.  4. 14.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 16.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25.  4. 14.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [25.  4. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[101.74765]
 [103.64574]
 [ 81.67717]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  4. 14.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  8.  1.  3.  6.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: discard_down_to_3_cards - action 3
Learning step: 5.834133148193359
desired expected reward: 5.50730037689209



action possibilites: [-1] 
expected returns: [[86.4926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14.  3.  0.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  8.  1.  3.  6.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 93 

action type: take_action - action 25.0
Learning step: 1.413795828819275
desired expected reward: 105.05953979492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[75.56951]
 [87.39653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14.  3.  0.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  8.  1.  3.  6.] 
adversary cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1
Learning step: 2.156877279281616
desired expected reward: 88.64947509765625






Player: 1 
cards in hand: [15.  8.  1.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  1.  3.  6.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [4. 8. 0. 0. 3.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1.  3.  6.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  6.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [4. 8. 0. 0. 3.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1.  3.  6.] 
cards in discard: [ 6.  3. 22. 11. 29.  1. 29. 10. 29.  2.  0.  6. 11. 23.  0.  2.  6.  6.
  1.  3.  3.  3.  0.  3. 23. 15.  0. 16.  0.  0. 14.  0.  6.  3. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  5.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [4. 8. 0. 0. 3.] 
adversary cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [4. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[57.874325]
 [46.612522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 8. 0. 0. 3.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  5.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  2.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1.0
Learning step: 0.4514888823032379
desired expected reward: 87.84803009033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[40.578312]
 [46.109753]
 [46.28404 ]
 [57.54584 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 8. 0. 0. 3.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  5.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  2.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: take_action - action -1.0
Learning step: 1.8586721420288086
desired expected reward: 59.73299026489258



buy possibilites: [-1] 
expected returns: [[27.740244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 8. 0. 0. 3.] 
cards in discard: [10.  0. 11.  6.  1.  8.  0.  0. 25.  4. 14.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  2.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 80 

action type: buy - action 8.0
Learning step: 2.3099544048309326
desired expected reward: 48.59397506713867






Player: 1 
cards in hand: [ 0.  2.  0.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  0.  6. 22.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2.  0.  6.  3. 11.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [22. 22.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0.  6.  3. 11.  6.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [22. 22.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 23. 28. 25. 28.  8.  0.  8.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2.  0.  6.  3. 11.  6.] 
cards in discard: [16.] 
cards in deck: 35 
card top of deck: [] 
played cards: [22. 22.] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 28. 25. 28.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[17.24294 ]
 [10.401425]
 [18.684145]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3. 16.  1. 14.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16] -> size -> 45 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 72 

action type: buy - action -1
Learning step: 2.5868377685546875
desired expected reward: 30.32708168029785



action possibilites: [-1] 
expected returns: [[31.822718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3. 16.  1. 14.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16] -> size -> 45 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 93 

action type: take_action - action 25.0
Learning step: 4.4318037033081055
desired expected reward: 23.115955352783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.483908]
 [24.0502  ]
 [22.509651]
 [21.056585]
 [27.914309]
 [22.627691]
 [25.308096]
 [14.934926]
 [21.353268]
 [20.624872]
 [30.730173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 28. 25. 28.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3. 16.  1. 14.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.] 
adversary owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16] -> size -> 45 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[-5  0  7 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 92 

action type: take_action - action -1
Learning step: 3.5848453044891357
desired expected reward: 35.407562255859375






Player: 1 
cards in hand: [ 3. 16.  1. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1. 14.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  1  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6
 16  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 28.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  4.  6. 11.  4.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  4.  6. 11.  4.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  4.  6. 11.  4.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  4.  6. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[58.33552]
 [57.62712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  6. 11.  4.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3.  1. 11.  0. 23.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: 1.8709545135498047
desired expected reward: 32.60112380981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[55.790665]
 [62.84285 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  6. 11.  4.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3.  1. 11.  0. 23.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: 0.4556984007358551
desired expected reward: 60.60835647583008



buy possibilites: [-1] 
expected returns: [[78.7796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  6. 11.  4.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 3.  1. 11.  0. 23.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: -0.41699257493019104
desired expected reward: 55.373680114746094






Player: 1 
cards in hand: [ 3.  1. 11.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  0. 23.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 10.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 23.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 10.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 23.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  7.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 10.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 23.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 10.] 
adversary cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  8. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[111.034454]
 [100.021034]
 [114.07733 ]
 [ 97.81818 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 25. 10.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  3.  6.  8.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1
Learning step: 0.6080078482627869
desired expected reward: 79.38761138916016



action possibilites: [-1] 
expected returns: [[83.13013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 10.  3. 14.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  3.  6.  8.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action 25.0
Learning step: -0.7334384918212891
desired expected reward: 113.34388732910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[67.498535]
 [74.01148 ]
 [72.47495 ]
 [78.52343 ]
 [72.388016]
 [71.22778 ]
 [82.3911  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 10.  3. 14.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  3.  6.  8.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1
Learning step: 0.6778587698936462
desired expected reward: 83.8079833984375



buy possibilites: [-1] 
expected returns: [[248.38383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 10.  3. 14.] 
cards in discard: [25.  0.  8.  0.  0.  0.  8.  0.  0.  4.  6. 11.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [15.  3.  6.  8.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 32.0 

action type: buy - action 0.0
Learning step: 3.8137097358703613
desired expected reward: 71.31224060058594






Player: 1 
cards in hand: [15.  3.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  8.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [0. 4. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  8.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [0. 4. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  8.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [0. 4. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 4. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[76.53052 ]
 [67.727585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0. 23.  3.  6.  0.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1
Learning step: -8.660457611083984
desired expected reward: 239.72337341308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[62.38759]
 [66.15125]
 [65.88996]
 [74.69289]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [ 0. 23.  3.  6.  0.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: -0.1523750275373459
desired expected reward: 76.37814331054688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 23.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  3.  6.  0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [0. 4. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [0. 4. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0] -> size -> 48 
action values: 0 
buys: 2 
player value: 4 
card supply: [16. 22. 28. 25. 27.  8.  0.  7.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [0. 4. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [0. 4. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [25. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[52.47306 ]
 [53.800667]
 [36.407635]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14.  0.  0.  0.] 
cards in discard: [0. 4. 8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [16.  0.  1. 29. 29.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1.0
Learning step: -0.5137359499931335
desired expected reward: 74.17916107177734



action possibilites: [-1] 
expected returns: [[91.29563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  6.  1.] 
cards in discard: [0. 4. 8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [16.  0.  1. 29. 29.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 64 

action type: take_action - action 25.0
Learning step: 2.5641191005706787
desired expected reward: 56.364776611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 80.68999 ]
 [ 88.80481 ]
 [ 87.52146 ]
 [ 74.02098 ]
 [ 84.79648 ]
 [ 95.48875 ]
 [ 86.644485]
 [101.747406]
 [ 91.15868 ]
 [ 75.97234 ]
 [ 82.3591  ]
 [ 85.7995  ]
 [ 74.292496]
 [ 84.90003 ]
 [101.75734 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  6.  1.] 
cards in discard: [0. 4. 8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  7.  8.  8.  8.] 
adversary cards in hand: [16.  0.  1. 29. 29.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1
Learning step: 0.604191243648529
desired expected reward: 91.89982604980469



buy possibilites: [-1] 
expected returns: [[75.73335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  6.  1.] 
cards in discard: [ 0.  4.  8.  0.  3. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [16.  0.  1. 29. 29.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 112 

action type: buy - action 23.0
Learning step: 3.1860458850860596
desired expected reward: 85.5451431274414






Player: 1 
cards in hand: [16.  0.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 29. 29.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6  1 11  6 11  0  6 16
  6 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0
 16] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  6.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [25.  8. 10.  3.  0.] 
adversary cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [25.  8. 10.  3.  0.] 
adversary cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [25.  8. 10.  3.  0.] 
adversary cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [25.  8. 10.  3.  0.] 
adversary cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25.  8. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[82.648285]
 [85.04272 ]
 [75.568436]
 [73.61454 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 10.  3.  0.] 
cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [10.  8.  2.  0.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11  0] -> size -> 50 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 42 

action type: buy - action -1
Learning step: 0.1431606262922287
desired expected reward: 75.87651062011719



action possibilites: [-1] 
expected returns: [[73.262924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  0.  0.] 
cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [10.  8.  2.  0.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11  0] -> size -> 50 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 64 

action type: take_action - action 25.0
Learning step: 0.5962799191474915
desired expected reward: 85.63899993896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[67.40649 ]
 [71.40335 ]
 [70.467545]
 [74.14598 ]
 [70.38962 ]
 [69.61251 ]
 [76.758575]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.  0.  0.] 
cards in discard: [ 0.  4.  8.  0.  3. 23. 25. 14.  0.  0.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [10.  8.  2.  0.  6.] 
adversary cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11  0] -> size -> 50 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-5  0  7 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 62 

action type: take_action - action -1
Learning step: 1.0877631902694702
desired expected reward: 74.3506851196289






Player: 1 
cards in hand: [10.  8.  2.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  2.  0.  6.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0  6 11  6 11  0  6 16  6
 16 22  1  6 15 10  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16
 11  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  5.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [16. 22. 22.  0.  2.  0.  6.  3. 11.  6.  4. 16.  3. 14.  6.  1. 11. 11.
  3.  1.  0. 23.  0. 15.  3.  6.  8.  6. 16. 23.  0.  3.  6.  0.  0. 11.
  0. 16.  0. 29. 29. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[47.531937]
 [42.304615]
 [45.384926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  4.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: -1.20375657081604
desired expected reward: 75.55480194091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[43.28602 ]
 [45.606052]
 [45.254482]
 [50.495914]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  4.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: 0.19590206444263458
desired expected reward: 49.75597381591797



buy possibilites: [-1] 
expected returns: [[102.33634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  4.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 6. 29.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 2.0 

action type: buy - action 0.0
Learning step: 0.23826657235622406
desired expected reward: 43.5242919921875






Player: 1 
cards in hand: [ 6. 29.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [8. 8. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [15.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [8. 8. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [15.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [8. 8. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6.] 
cards in discard: [15.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [8. 8. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [8. 8. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[77.98529]
 [66.56122]
 [66.56122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 4.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [14.  0. 15.  0. 11.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: -1.8715107440948486
desired expected reward: 100.46482849121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[63.985424]
 [69.03108 ]
 [68.544044]
 [79.261444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 4.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [14.  0. 15.  0. 11.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: -0.6459202170372009
desired expected reward: 77.33936309814453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15.  0. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 3. 10. 14.  1.  6.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 3. 14.  6.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 3. 14.  6.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[63.090893]
 [48.7139  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [16. 11.  0. 11.  3.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: discard_down_to_3_cards - action 4
Learning step: 0.011837196536362171
desired expected reward: 58.10153579711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.35551 ]
 [63.673763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [16. 11.  0. 11.  3.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: -0.2103263884782791
desired expected reward: 62.880558013916016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0. 11.  3.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  8.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  3.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  3.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  3.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[57.719723]
 [57.314854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 22.  8.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: -0.2879020869731903
desired expected reward: 63.3858757019043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.504055]
 [49.650635]
 [49.05158 ]
 [47.555   ]
 [53.316288]
 [48.54978 ]
 [51.05774 ]
 [43.180904]
 [48.208633]
 [47.8689  ]
 [57.363007]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [ 0.  0.  0.  8. 11.  4.  8.  8.  0.  0.  4. 10.  1.  3. 14.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 6.  0.  0. 22.  8.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.] 
adversary owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: -0.11239605396986008
desired expected reward: 57.60733413696289



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  0.  0. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 22.  8.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 29  0  0 22  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16
 22  1  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0
 11  0 14  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0. 23. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0. 23. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [ 0.  0. 23. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 23. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 25.] 
expected returns: [[26.335917]
 [22.894445]
 [26.089087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23. 25.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [16.  3. 22. 23.  2.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: -0.6932468414306641
desired expected reward: 56.669769287109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.268682]
 [24.022284]
 [23.917652]
 [26.357199]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23. 25.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [16.  3. 22. 23.  2.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: 0.8480149507522583
desired expected reward: 27.183916091918945



buy possibilites: [-1] 
expected returns: [[53.155277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23. 25.  3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [16.  3. 22. 23.  2.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   7.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 2.0 

action type: buy - action 0.0
Learning step: 0.13255968689918518
desired expected reward: 23.4012393951416






Player: 1 
cards in hand: [16.  3. 22. 23.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 22. 23.  2.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 16. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 22.  2.  4.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  2.  4.  0.  3. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 22.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  2.  4.  0.  3. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 22.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0] -> size -> 50 
action values: 0 
buys: 2 
player value: 5 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  8.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  2.  4.  0.  3. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 22.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22] -> size -> 51 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  2.  4.  0.  3. 11.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23. 22.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [25.  6.  1. 14. 11.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [25.  6.  1. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 11.] 
expected returns: [[16.6337  ]
 [16.43711 ]
 [ 7.256605]
 [14.198355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  1. 14. 11.] 
cards in discard: [ 0.  0.  0. 23. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 1. 11.  3.  0.  6.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: -0.7266165018081665
desired expected reward: 52.42866134643555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.386902]
 [11.318238]
 [10.46706 ]
 [17.081835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  1. 14. 11.] 
cards in discard: [ 0.  0.  0. 23. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 1. 11.  3.  0.  6.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0] -> size -> 52 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: 1.0770061016082764
desired expected reward: 17.710704803466797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 11.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  0.  6.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [4. 0. 0. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.  6.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  4.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [4. 0. 0. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.  6.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [4. 0. 0. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [4. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[52.451294]
 [48.18035 ]
 [48.18035 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 8. 8.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25  4 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 0. 16.  6.  1. 23.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1.0
Learning step: 1.8851765394210815
desired expected reward: 18.967018127441406



action possibilites: [-1] 
expected returns: [[22.221685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 0. 16.  6.  1. 23.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.7159079909324646
desired expected reward: 42.60200881958008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[13.589102]
 [16.71749 ]
 [16.555803]
 [23.345896]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 0. 16.  6.  1. 23.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: 0.28100213408470154
desired expected reward: 22.502687454223633



buy possibilites: [-1] 
expected returns: [[50.926167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [ 0. 16.  6.  1. 23.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -0.08361663669347763
desired expected reward: 13.505489349365234






Player: 1 
cards in hand: [ 0. 16.  6.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  1. 23.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [10.  8.  0.  4.  0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 16. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  1. 29.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [10.  8.  0.  4.  0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  1. 29.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8] -> size -> 53 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  8.] 
adversary cards in hand: [10.  8.  0.  4.  0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 4 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  1. 29.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [10.  8.  0.  4.  0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [10.  8.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[32.278168]
 [24.661283]
 [24.897306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  4.  0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -1.9418362379074097
desired expected reward: 48.98432922363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.650677]
 [25.862585]
 [25.294535]
 [32.372234]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  4.  0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  3.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.0192089080810547
desired expected reward: 31.25895881652832



buy possibilites: [-1] 
expected returns: [[-2.138751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  4.  0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -0.9628490805625916
desired expected reward: 24.331693649291992






Player: 1 
cards in hand: [ 0.  3.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 29.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 16.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 16.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 16.] 
cards in discard: [15.  0. 29.  6.  3.  3.  6. 14.  0. 15.  0. 11. 14.  0. 11. 16.  0. 11.
  3.  8.  6.  0. 22.  0. 23. 22. 16.  3.  2.  4.  0.  3. 11.  8.  1. 11.
  3.  0.  6. 15. 23.  0. 16.  6.  1. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-12.045992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [ 6. 15.  3.  8.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -0.214097261428833
desired expected reward: -2.3528482913970947





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -9.677788 ]
 [-11.6359005]
 [-10.47135  ]
 [-10.5356045]
 [-12.056326 ]
 [-11.151613 ]
 [-11.690115 ]
 [ -7.901601 ]
 [ -9.8960085]
 [ -9.575492 ]
 [-12.511801 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  7.  6.  8.  7.  7.] 
adversary cards in hand: [ 6. 15.  3.  8.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: 0.33510860800743103
desired expected reward: -11.710883140563965



buy possibilites: [-1] 
expected returns: [[89.4492]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0. 23. 25.  3. 25.  6.  1. 14. 11.  0.  8.  0.  0.  8.  8. 10.
  8.  0.  4.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 6. 15.  3.  8.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 14.0
Learning step: 3.95768666267395
desired expected reward: -3.943910837173462






Player: 1 
cards in hand: [ 6. 15.  3.  8.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  8.  2.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 1. 4. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  8.  2.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 22. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 1. 4. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  8.  2.] 
cards in discard: [1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 1. 4. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [0. 1. 4. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.25338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 4. 0. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [29. 16.  6.  1. 11.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.3117592334747314
desired expected reward: 87.13744354248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[88.284584]
 [91.64845 ]
 [90.27957 ]
 [89.763565]
 [93.68601 ]
 [90.9913  ]
 [92.67158 ]
 [85.69896 ]
 [89.77018 ]
 [89.557556]
 [95.20727 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 0. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  2.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [29. 16.  6.  1. 11.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.885411500930786
desired expected reward: 95.36796569824219



buy possibilites: [-1] 
expected returns: [[37.47959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 0. 6.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [29. 16.  6.  1. 11.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 8.0
Learning step: -3.656273365020752
desired expected reward: 87.33500671386719






Player: 1 
cards in hand: [29. 16.  6.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  6.  1. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [11.  0. 14.  0. 25.] 
adversary cards in discard: [8. 0. 1. 4. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  6.  1. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [11.  0. 14.  0. 25.] 
adversary cards in discard: [8. 0. 1. 4. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  6.  1. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [11.  0. 14.  0. 25.] 
adversary cards in discard: [8. 0. 1. 4. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [11.  0. 14.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 25.] 
expected returns: [[111.69383]
 [106.39036]
 [ 89.95751]
 [110.95861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0. 25.] 
cards in discard: [8. 0. 1. 4. 0. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 3.  1. 15.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1  0] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: 0.489423006772995
desired expected reward: 37.96901321411133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 97.72312 ]
 [103.552345]
 [102.50051 ]
 [114.581215]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14.  0. 25.] 
cards in discard: [8. 0. 1. 4. 0. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 3.  1. 15.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1  0] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -3.200092315673828
desired expected reward: 108.49372863769531



buy possibilites: [-1] 
expected returns: [[89.14809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 14.  0. 25.] 
cards in discard: [8. 0. 1. 4. 0. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 3.  1. 15.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
adversary owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1  0] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -4.430324077606201
desired expected reward: 93.29279327392578






Player: 1 
cards in hand: [ 3.  1. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  0.  3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1
  6 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0
 14  0 22  0  8 15  0  1  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [10.  0. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [10.  0. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  8.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [10.  0. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25.] 
cards in deck: 40 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [10.  0. 14.  0.  8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [10.  0. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
expected returns: [[45.77854 ]
 [34.50493 ]
 [28.830957]
 [35.139206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  0.  8.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0. 16. 29.  3. 29.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -3.616891622543335
desired expected reward: 85.53119659423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[32.937214]
 [35.93336 ]
 [35.974392]
 [45.26462 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.  0.  8.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0. 16. 29.  3. 29.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.4210187196731567
desired expected reward: 44.146385192871094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 29.  3. 29.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  4.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 0.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 0.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.852219]
 [ 8.51457 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0
  0  0  8 14  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3. 14. 11. 23.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -1.9939186573028564
desired expected reward: 43.27070999145508



action possibilites: [-1] 
expected returns: [[81.59384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3. 14. 11. 23.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.689910888671875
desired expected reward: 12.608922958374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[74.070526]
 [77.966606]
 [77.2036  ]
 [80.85793 ]
 [77.02868 ]
 [76.45703 ]
 [83.4349  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  3. 14. 11. 23.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -1.878358244895935
desired expected reward: 79.71548461914062






Player: 1 
cards in hand: [ 0.  3. 14. 11. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 11. 23.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [25.  8.  8.  0.  0.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 23.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 23.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 20. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 23.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[85.14766 ]
 [85.590256]
 [80.10463 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 6.  8.  0. 11.  6.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 3
Learning step: 1.7300928831100464
desired expected reward: -6.923653602600098



action possibilites: [-1] 
expected returns: [[153.37296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 23.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 6.  8.  0. 11.  6.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 25.0
Learning step: -0.4286212921142578
desired expected reward: 85.16163635253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[135.9593 ]
 [150.13142]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 23.] 
cards in discard: [ 8.  0.  1.  4.  0.  6.  0. 11.  0. 14.  0. 25. 10.  0. 14.  0.  8.  8.
  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 6.  8.  0. 11.  6.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -3.9924428462982178
desired expected reward: 149.38050842285156






Player: 1 
cards in hand: [ 6.  8.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 11.  6.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 11.  6.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 11.  6.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 0.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[87.54174 ]
 [78.871475]
 [87.74426 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [23.  2. 14.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.17576265335083
desired expected reward: 143.95562744140625



action possibilites: [-1] 
expected returns: [[9.726445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [23.  2. 14.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 25.0
Learning step: -3.7683682441711426
desired expected reward: 83.97589111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 6.437969 ]
 [ 7.6409407]
 [ 7.547261 ]
 [ 8.884214 ]
 [ 7.375437 ]
 [ 7.372118 ]
 [10.799505 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 19. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [23.  2. 14.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: 0.11658501625061035
desired expected reward: 9.843029975891113



buy possibilites: [-1] 
expected returns: [[82.82669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 11.  8.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [23.  2. 14.  0.  3.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 1.0
Learning step: 2.781553268432617
desired expected reward: 10.422496795654297






Player: 1 
cards in hand: [23.  2. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  2. 14.  0.  3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 8.  8.  0. 14. 14.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  2. 14.  0.  3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0] -> size -> 60 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  7.] 
adversary cards in hand: [ 8.  8.  0. 14. 14.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  2. 14.  0.  3.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 8.  8.  0. 14. 14.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 14.] 
expected returns: [[9.368181 ]
 [7.8611984]
 [7.8611984]
 [6.046131 ]
 [6.046131 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14. 14.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [16.  0. 22.  0.  0.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -4.558287620544434
desired expected reward: 78.26840209960938



action possibilites: [-1] 
expected returns: [[19.785313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [22.  0.  0.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 14.0
Learning step: 0.5428630113601685
desired expected reward: 6.588994026184082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[16.111563]
 [17.977514]
 [17.347336]
 [19.141539]
 [17.535269]
 [16.967113]
 [19.788647]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 14.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 18. 28. 25. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [22.  0.  0.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -0.17202520370483398
desired expected reward: 19.6132869720459



buy possibilites: [-1] 
expected returns: [[26.284363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 14.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [22.  0.  0.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 21.0 

action type: buy - action 3.0
Learning step: 0.7581049203872681
desired expected reward: 18.42397117614746






Player: 1 
cards in hand: [22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  0.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [23.  8.  3.  0.  0.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  0.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [23.  8.  3.  0.  0.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [23.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[17.565735]
 [13.757748]
 [14.23201 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  3.  0.  0.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 22. 16. 11. 11.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -1.0031728744506836
desired expected reward: 25.28118896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[12.644031]
 [13.886902]
 [13.735994]
 [17.1669  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  8.  3.  0.  0.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 22. 16. 11. 11.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.5823600888252258
desired expected reward: 16.9833927154541



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 22. 16. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 16. 11. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  7.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 16. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22. 16. 11.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.090336]
 [21.813679]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 25 25  4  8  0  1  8  6  0 11  0 10  8  0  0 23  0  0
  0  8 14  8  0  1  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -0.3520185947418213
desired expected reward: 16.814899444580078



action possibilites: [-1] 
expected returns: [[69.23511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 2
Learning step: 2.250051498413086
desired expected reward: 18.404821395874023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[58.45999 ]
 [62.218033]
 [62.552605]
 [70.20761 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  8.] 
adversary cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
adversary owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -0.4804184138774872
desired expected reward: 68.75469207763672






Player: 1 
cards in hand: [ 0. 15.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  3.  8.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  0  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6
 15  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14
  0 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [ 1.  6. 15.  3.  8.  2.  0. 29. 16.  6.  1. 11. 25. 15.  3.  1.  3. 16.
  0.  1. 29. 29.  3.  4.  0.  1. 14.  0.  3. 11. 23.  0.  6.  8.  0. 11.
  6. 15. 23.  2. 14.  0.  3. 16.  0. 22.  0.  0. 29. 11.  0. 22. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [0. 4. 0. 0. 1.] 
adversary cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 4. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[75.07597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [25.  8.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -1.321170449256897
desired expected reward: 68.88642883300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[70.89122 ]
 [74.41176 ]
 [73.214874]
 [67.33061 ]
 [72.408775]
 [77.19583 ]
 [73.415276]
 [81.13115 ]
 [75.42441 ]
 [68.5071  ]
 [71.00316 ]
 [72.50507 ]
 [67.36458 ]
 [72.14481 ]
 [79.52091 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  7.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [25.  8.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -1.543700098991394
desired expected reward: 73.53227233886719



buy possibilites: [-1] 
expected returns: [[95.47241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 1.] 
cards in discard: [ 1. 25.  0.  0. 10.  0. 11.  8.  3. 14.  8.  8.  0. 14. 23.  8.  3.  0.
  0.  8.  0.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [25.  8.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 60 

action type: buy - action 25.0
Learning step: 1.091570258140564
desired expected reward: 82.22274780273438






Player: 1 
cards in hand: [25.  8.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 56 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3  0 15  2  0 11  6 11  0  6 16  6 16 22  1  6 15
  0  6  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0
 22  0  8 15  0  1  0 25  1  1  0 15 29] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [23.  0.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3 25] -> size -> 30 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.] 
cards in discard: [] 
cards in deck: 56 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [23.  0.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3 25] -> size -> 30 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [] 
cards in deck: 56 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [23.  0.  8. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3 25] -> size -> 30 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [23.  0.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 25.] 
expected returns: [[105.30785 ]
 [ 93.782455]
 [ 94.89264 ]
 [104.2592  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8. 25.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0 23  0  0  0  8
 14  8  0  1  3 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [11.  1.  3.  3. 22.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -1.9867223501205444
desired expected reward: 93.48568725585938



action possibilites: [-1] 
expected returns: [[27.721994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [11.  1.  3.  3. 22.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 5
Learning step: -2.3595774173736572
desired expected reward: 87.3068618774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.6589 ]
 [26.26915]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [11.  1.  3.  3. 22.] 
adversary cards in discard: [ 8. 25.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: 0.6574963927268982
desired expected reward: 28.37948989868164






Player: 1 
cards in hand: [11.  1.  3.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3. 22.] 
cards in discard: [ 8. 25.  6.] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0.  0.  8.  4. 25.] 
adversary cards in discard: [ 8. 25.  0.] 
adversary owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 11.  1. 15. 22.] 
cards in discard: [ 8. 25.  6.] 
cards in deck: 45 
card top of deck: [] 
played cards: [22. 11.  8. 29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0.  0.  8.  4. 25.] 
adversary cards in discard: [ 8. 25.  0.] 
adversary owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 11.  1. 15. 22.] 
cards in discard: [ 8. 25.  6.] 
cards in deck: 45 
card top of deck: [] 
played cards: [22. 11.  8. 29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  6.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0.  0.  8.  4. 25.] 
adversary cards in discard: [ 8. 25.  0.] 
adversary owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 11.  1. 15. 22.] 
cards in discard: [ 8. 25.  6. 29.] 
cards in deck: 45 
card top of deck: [] 
played cards: [22. 11.  8. 29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29 29] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0.  0.  8.  4. 25.] 
adversary cards in discard: [ 8. 25.  0.] 
adversary owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  4. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[39.13138 ]
 [30.402578]
 [38.0316  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  4. 25.] 
cards in discard: [ 8. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 25 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8
  0  1  3 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 2. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: 0.019954396411776543
desired expected reward: 26.289098739624023



action possibilites: [-1] 
expected returns: [[84.21565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [ 8. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 2. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.5889571905136108
desired expected reward: 37.70685577392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[73.832275]
 [86.313095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 8. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 2. 16.  0.  0.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29 29] -> size -> 60 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -0.8583469390869141
desired expected reward: 83.35730743408203






Player: 1 
cards in hand: [ 2. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 16.  0.  0.  0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  0  6 16  6 16 22  1  6 15  0  6
  3 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0
  8 15  0  1  0 25  1  1  0 15 29 29] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  1.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 14.  3.  0. 25.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 14.  3.  0. 25.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8] -> size -> 60 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  7.  6.] 
adversary cards in hand: [ 0. 14.  3.  0. 25.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0. 0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 0. 14.  3.  0. 25.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[ 0.5884681 ]
 [-5.073933  ]
 [-0.03069305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 25.] 
cards in discard: [ 8. 25.  0.  8.  4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 3.  0. 23.  6. 29.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -3.8324811458587646
desired expected reward: 82.4806137084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-5.604966 ]
 [-3.9398143]
 [-0.5710362]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0. 25.] 
cards in discard: [ 8. 25.  0.  8.  4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 3.  0. 23.  6. 29.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: 0.41750940680503845
desired expected reward: 1.0059655904769897



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 23.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  6. 29.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 1. 11.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 1. 11.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 18. 28. 24. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 1. 11.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 23. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [ 1. 11.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.910011]
 [19.07016 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  1.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 23. 27.  8.  0.  6.  4.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [15. 29. 11.  4.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: 0.5011378526687622
desired expected reward: -0.06990182399749756



action possibilites: [-1] 
expected returns: [[7.791857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [15. 29. 11.  4.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 29 

action type: gain_card_n - action 4
Learning step: 1.0053982734680176
desired expected reward: 13.403768539428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 5.5137863]
 [ 7.39898  ]
 [ 4.888861 ]
 [ 7.0074463]
 [ 3.1111994]
 [ 6.381406 ]
 [ 9.076457 ]
 [10.781007 ]
 [ 8.014774 ]
 [ 4.2430477]
 [ 5.8283215]
 [ 6.5911217]
 [ 3.4721766]
 [ 6.398431 ]
 [10.584101 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [15. 29. 11.  4.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: 0.7932214736938477
desired expected reward: 8.585078239440918



buy possibilites: [-1] 
expected returns: [[4.4663405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [15. 29. 11.  4.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.6751968264579773
desired expected reward: 4.838592529296875






Player: 1 
cards in hand: [15. 29. 11.  4.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11.  4.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  6.  6.  8.  6.  6.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  4.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  4.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[50.47093 ]
 [44.463955]
 [44.59126 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [16.  3.  0.  3.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: 0.8553835153579712
desired expected reward: 5.321723937988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[40.248856]
 [42.76595 ]
 [48.162052]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [16.  3.  0.  3.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -1.503605842590332
desired expected reward: 48.96733856201172



buy possibilites: [-1] 
expected returns: [[37.801556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [16.  3.  0.  3.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -30.0 

action type: buy - action 0.0
Learning step: -2.6619083881378174
desired expected reward: 37.58695983886719






Player: 1 
cards in hand: [16.  3.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [ 0.  8.  0.  8. 14.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.  0.
 10.  3.  0.  8.  0.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  3.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [ 0.  8.  0.  8. 14.] 
adversary cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.  0.
 10.  3.  0.  8.  0.] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[48.451748]
 [43.864357]
 [43.864357]
 [41.140507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8. 14.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.  0.
 10.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [16.  0. 15. 29. 23.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -0.8590961694717407
desired expected reward: 36.94245910644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[40.10528]
 [41.7472 ]
 [46.18739]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 14.] 
cards in discard: [ 8. 25.  0.  8.  4.  0. 14.  3.  0. 25. 11.  0. 11.  1.  0.  0.  1.  0.
 10.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [16.  0. 15. 29. 23.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -1.4337363243103027
desired expected reward: 47.01802062988281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0. 15. 29. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 29. 23.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 15. 29. 23.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  0  6  3
 14  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8
 15  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 23.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 62 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 23.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14] -> size -> 62 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  8.  6.  6.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 23.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 3.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[69.79761 ]
 [61.395954]
 [54.24913 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  4  8  0  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3
 25 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [14. 16.  8.  3.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -0.853560745716095
desired expected reward: 45.33383560180664



action possibilites: [-1] 
expected returns: [[38.665604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [14. 16.  8.  3.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: trash_cards_n_from_hand - action 5
Learning step: -1.0087989568710327
desired expected reward: 56.56669998168945





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.823246]
 [35.99096 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [14. 16.  8.  3.  0.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
adversary owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 63 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1
Learning step: -0.15340672433376312
desired expected reward: 38.5121955871582






Player: 1 
cards in hand: [14. 16.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  8.  3.  0.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3 14
  6  3  3 29 23 23  0  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15
  0  1  0 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  0.  3.  4. 25.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  0.  3.  4. 25.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10] -> size -> 60 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  0.  3.  4. 25.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  0.  3.  4. 25.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  4. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[84.24394 ]
 [80.73932 ]
 [83.928696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  4. 25.] 
cards in discard: [8. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 1. 14. 11.  2.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16.] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: 0.5776578783988953
desired expected reward: 36.568603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[75.573  ]
 [85.68758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  4. 25.] 
cards in discard: [8. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 1. 14. 11.  2.  6.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16.] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -1.8568470478057861
desired expected reward: 82.38710021972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 14. 11.  2.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 11.  2.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [0. 1. 0. 8. 1.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  2.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  2.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0] -> size -> 61 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  6.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  2.  6.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16] -> size -> 62 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  5.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [0. 8. 1.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.364426]
 [21.73249 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  5.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  1.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16] -> size -> 62 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: discard_down_to_3_cards - action 5
Learning step: 0.5154820680618286
desired expected reward: 12.630332946777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[21.644756]
 [26.716679]
 [25.783934]
 [30.74157 ]
 [24.654812]
 [34.514847]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  5.  3.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  1.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16] -> size -> 62 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -0.34462451934814453
desired expected reward: 30.01980209350586



buy possibilites: [-1] 
expected returns: [[12.035912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  5.  2.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [11.  1.  0.  0.  1.] 
adversary cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16] -> size -> 62 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 11.0
Learning step: 0.13373032212257385
desired expected reward: 30.87528419494629






Player: 1 
cards in hand: [11.  1.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0.  1.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 28. 23. 27.  8.  0.  5.  2.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 0.  8. 25.  0. 11.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0] -> size -> 63 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  2.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 0.  8. 25.  0. 11.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0] -> size -> 63 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  2.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 0.  8. 25.  0. 11.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1.] 
cards in discard: [ 8. 25.  6. 29. 22. 11.  8. 29.  1.  3.  3. 11.  1. 15. 22.  8. 22. 16.
  2.  0.  0.  3.  0.  3. 29. 23.  6.  0. 14. 11. 15. 29.  4.  6. 16.  3.
  0.  3.  6. 10. 15. 16. 29. 23.  0.  8. 16. 16. 14.  1. 11.  2.  6.  0.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0 11] -> size -> 64 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  1.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [ 0.  8. 25.  0. 11.] 
adversary cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
expected returns: [[85.79816]
 [80.54353]
 [85.2241 ]
 [83.4265 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  0. 11.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  4  8  1  8  0 11  0 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11
  0  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  1.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [23.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0 11] -> size -> 64 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: 1.7992247343063354
desired expected reward: 13.835136413574219



action possibilites: [-1] 
expected returns: [[-25.357452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  4  8  1  8 11 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11  0  0
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  1.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [23.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0 11] -> size -> 64 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: trash_cards_n_from_hand - action 4
Learning step: -3.018268346786499
desired expected reward: 75.93624877929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-23.15535 ]
 [-24.162678]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  4  8  1  8 11 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11  0  0
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 18. 28. 23. 27.  8.  0.  5.  1.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [23.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0 11] -> size -> 64 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: 2.239645004272461
desired expected reward: -23.117807388305664



Player 0 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 4 
Gold: 0 
Estate: 2 
Duchy: 2 
Province: 0 
Curse: 2 

Remodel: 0 
Workshop: 2 
Chapel: 6 
Witch: 3 
Poacher: 0 
Militia: 2 
Market: 1 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25. 11.] 
cards in discard: [ 8.  3.  0. 11.  0.  3.  4. 25.  1.  0. 11.  0.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  4  8  1  8 11 10  8  0  0  0  0  0  8 14  8  0  1  3 25 11  0  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 18. 28. 23. 27.  8.  0.  5.  1.  0.  6.  5.  5.  6.  7.  6.  6.] 
adversary cards in hand: [23.  0.  3. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  8  2 29  3 15  2 11  6 11  6 16  6 16 22  1  6 15  6  3  6  3
  3 29 23 23  8 16  4  1 11  0 16 11  0 11  0 14  0 22  0  8 15  0  1  0
 25  1  1  0 15 29 29  8 22  3 14 10  0 16  0 11] -> size -> 64 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5 500   5  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 500 

action type: buy - action 0.0
Learning step: 26.157766342163086
desired expected reward: 3.002408981323242



