 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.424353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action 0.0
Learning step: -119993.515625
desired expected reward: -120190.4609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 25.74106  ]
 [ 44.073914 ]
 [ 36.699966 ]
 [-53.947754 ]
 [ 44.904434 ]
 [ 44.23979  ]
 [ 32.265015 ]
 [ 52.786232 ]
 [  1.1022205]
 [ 38.384346 ]
 [ 32.29856  ]
 [ 30.686842 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.11787986755371



buy possibilites: [-1] 
expected returns: [[37.623665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.786231994628906






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.679235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.62366485595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  8.098932]
 [ 26.957388]
 [ 19.857056]
 [-65.55142 ]
 [ 27.93418 ]
 [ 15.404503]
 [ 22.434326]
 [ 12.770678]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.54312515258789



buy possibilites: [-1] 
expected returns: [[25.428122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.934175491333008






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.079802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.42812156677246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 13.166428]
 [ 32.137657]
 [ 24.948664]
 [-69.60649 ]
 [ 32.847603]
 [ 19.994795]
 [ 26.7324  ]
 [ 18.029707]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.547727584838867



buy possibilites: [-1] 
expected returns: [[11.653755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 32.84760284423828






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 8. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[20.072012]
 [34.395775]
 [42.688446]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.653755187988281



action possibilites: [-1. 11.] 
expected returns: [[10.822855]
 [23.111479]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.923980712890625



action possibilites: [-1] 
expected returns: [[25.128405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.752948760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.787233 ]
 [ 42.971085 ]
 [ 34.79589  ]
 [ 11.290504 ]
 [-17.516275 ]
 [ 43.88179  ]
 [ 42.41889  ]
 [ 32.354103 ]
 [ 54.70201  ]
 [ 50.58081  ]
 [  3.7873936]
 [ 38.910835 ]
 [ 36.994804 ]
 [ 17.625496 ]
 [ 28.924292 ]
 [ 28.375437 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.12840461730957



buy possibilites: [-1] 
expected returns: [[30.238585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 54.702003479003906






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[12.22489 ]
 [18.200397]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.238584518432617



action possibilites: [-1] 
expected returns: [[21.15328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 22.68970489501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 20.294212]
 [ 28.760897]
 [-62.33612 ]
 [ 26.727457]
 [ 22.598028]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.15328025817871



buy possibilites: [-1] 
expected returns: [[18.735909]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 28.760892868041992






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8  8  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 25.  0. 10.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  8 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 25.  0. 10.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  8 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 25.  0. 10.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  8 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 11. 25.  0. 10.] 
adversary cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [29. 11. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 10.] 
expected returns: [[36.45082 ]
 [51.22262 ]
 [46.48812 ]
 [55.642433]
 [40.901237]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 25.  0. 10.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8 29  0] -> size -> 11 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.73590850830078



action possibilites: [-1] 
expected returns: [[5.0356665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8 29  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.88197326660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  1.9939928]
 [ 17.231062 ]
 [ 10.591711 ]
 [-37.49581  ]
 [ 17.713245 ]
 [  7.842518 ]
 [ 12.346645 ]
 [  6.57862  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8 29  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.035666465759277



buy possibilites: [-1] 
expected returns: [[-4.7821784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [11.  3. 11.  0.  3.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  8.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8 29  0  6] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 17.713232040405273






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8 29  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8  8 29  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 9.560926]
 [20.095943]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  6.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.7821784019470215



action possibilites: [-1] 
expected returns: [[6.709059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 29.05120277404785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  7.824238]
 [ 24.327276]
 [ 10.027538]
 [-82.36735 ]
 [ 22.301857]
 [ 13.854855]
 [ 16.807756]
 [  9.83436 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.70905876159668



buy possibilites: [-1] 
expected returns: [[17.370726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0. 29.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 24.327281951904297






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6.  0. 29.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6.  0. 29.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6.  0. 29.  8.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.565638]
 [47.544785]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  8.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.370725631713867



action possibilites: [-1. 11.] 
expected returns: [[15.715315]
 [29.393732]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  8.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.47257995605469



action possibilites: [-1] 
expected returns: [[29.62652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  8.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.79930877685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 31.168013]
 [ 44.525085]
 [ 38.057922]
 [-35.25452 ]
 [ 44.13011 ]
 [ 36.232887]
 [ 40.973083]
 [ 33.504616]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  8.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.62652015686035



buy possibilites: [-1] 
expected returns: [[48.713318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  8.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.52507781982422






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [29.  8.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  8 29  0  6  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 11.  3.] 
adversary cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 3.5793467]
 [15.99375  ]
 [15.99375  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  3.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  3.] 
adversary cards in discard: [0. 8. 6. 8.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.71331787109375



action possibilites: [-1] 
expected returns: [[20.342638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  3.] 
adversary cards in discard: [0. 8. 6. 8.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.57917594909668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 16.551634]
 [ 26.995989]
 [-30.771297]
 [ 22.789623]
 [ 20.500225]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  3.] 
adversary cards in discard: [0. 8. 6. 8.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.34263801574707



buy possibilites: [-1] 
expected returns: [[19.339115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [11.  1. 11.  0.  3.  0.  0. 10.  1. 29. 11.  0.  3.  3.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 14.  3.] 
adversary cards in discard: [0. 8. 6. 8.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 26.995988845825195






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  3.] 
cards in discard: [0. 8. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  3.] 
cards in discard: [0. 8. 6. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  3.] 
cards in discard: [0. 8. 6. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[16.078215]
 [23.412018]
 [40.355186]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  9. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.339115142822266



action possibilites: [-1] 
expected returns: [[10.844955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.552574157714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  2.769556 ]
 [ 20.07164  ]
 [  5.6162786]
 [-81.33328  ]
 [ 18.859879 ]
 [ 11.250902 ]
 [ 13.998043 ]
 [  9.036493 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 28. 30.  8.  8. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.844955444335938



buy possibilites: [-1] 
expected returns: [[5.3016148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.  0.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 20.071630477905273






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 11. 11. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [11. 11. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 29.] 
expected returns: [[-0.69237995]
 [11.115004  ]
 [11.115004  ]
 [11.115004  ]
 [17.65695   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 29.  0.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.301614761352539



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[21.839605]
 [33.157684]
 [33.157684]
 [33.157684]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.  3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  5.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.839868545532227



action possibilites: [-1] 
expected returns: [[16.315771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 37.763206481933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 11.71648 ]
 [ 18.156797]
 [-29.017925]
 [ 17.949821]
 [ 17.51643 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.315771102905273



buy possibilites: [-1] 
expected returns: [[-8.877861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 6. 8. 8.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 18.156789779663086






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 8.] 
cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  8  0  6  0 14  0  0  6 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  3.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  3.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 6. 25.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  0.  3.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 1. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[4.842785 ]
 [6.4600735]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.877861022949219



action possibilites: [-1. 11.] 
expected returns: [[16.75047 ]
 [30.152094]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  3. 11.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 6.774293899536133



action possibilites: [-1.] 
expected returns: [[-4.5705833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.614168167114258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.103514  ]
 [  5.1406765 ]
 [ -0.379663  ]
 [-75.66049   ]
 [  5.53401   ]
 [ -3.8360276 ]
 [  0.33184767]
 [ -5.7106915 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.570583343505859



buy possibilites: [-1] 
expected returns: [[11.6047535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 5.534005165100098






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  1.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.
 10. 11.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.
 10. 11.  1.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  7.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.
 10. 11.  1.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.
 10. 11.  1.  3.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[15.665487]
 [19.936457]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 1. 25.  0.  3.  0. 10.  3.  0. 11.  3. 29. 11. 11. 11.  0.  3. 10. 11.
 10. 11.  1.  3.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0 474   0] 
sum of rewards: 649 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -42.501129150390625



action possibilites: [-1.] 
expected returns: [[-22.84081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 19.936460494995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -27.050734]
 [ -11.463039]
 [ -19.924229]
 [-112.18858 ]
 [ -11.773389]
 [ -21.236675]
 [ -17.344082]
 [ -23.621973]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -22.840810775756836



buy possibilites: [-1] 
expected returns: [[-2.090817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  6.  0.  8.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  0.  3.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -11.463033676147461






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [25.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  0.  8.  0.] 
cards in discard: [ 8. 14.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1] -> size -> 30 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  0.  8.  0.] 
cards in discard: [ 8. 14.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 27. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1] -> size -> 30 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  0.  8.  0.] 
cards in discard: [ 8. 14.  0.  6.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 11.  0.] 
adversary cards in discard: [ 1. 10.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1] -> size -> 30 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 3.4838848]
 [13.437693 ]
 [18.733267 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.  0.] 
cards in discard: [ 1. 10.  1.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  8. 10.  3.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.0908169746398926



action possibilites: [-1] 
expected returns: [[12.00338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 18.257070541381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.399347]
 [ 25.466074]
 [ 17.257214]
 [-52.426323]
 [ 24.021671]
 [ 16.093367]
 [ 18.671074]
 [ 12.374832]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.003379821777344



buy possibilites: [-1] 
expected returns: [[6.742977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 25.466079711914062






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  1.  3. 11. 11.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  1.  3. 11. 11.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[13.590836]
 [39.539536]
 [28.808168]
 [28.808168]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3. 11. 11.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  8. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 14.  6. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.742977142333984



action possibilites: [-1] 
expected returns: [[2.8001795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11. 11. 11. 10.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  7. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 14.  6. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.241127014160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -1.726001 ]
 [  7.4535503]
 [-55.876915 ]
 [  4.4345837]
 [  3.23034  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11. 11. 11. 10.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 26. 30.  8.  7. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 14.  6. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.8001794815063477



buy possibilites: [-1] 
expected returns: [[28.800138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11. 11. 11. 10.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  3. 14.  6. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 211 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 7.453551292419434






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 14.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  6. 25.] 
cards in discard: [0. 0. 0. 3. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29. 11.  3.  3.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3] -> size -> 33 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  6.  0.  6.] 
cards in discard: [0. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29. 11.  3.  3.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6] -> size -> 34 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  6.  0.  6.] 
cards in discard: [0. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29. 11.  3.  3.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6] -> size -> 34 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [11. 29. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[-31.486753]
 [-23.26101 ]
 [-17.583519]
 [-23.26101 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11.  3.  3.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  180    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.800138473510742



action possibilites: [-1. 11. 11.] 
expected returns: [[-21.721916]
 [-10.700999]
 [-10.700999]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  3.  3.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -17.58352279663086



action possibilites: [-1] 
expected returns: [[-25.305077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -9.479562759399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-29.7351  ]
 [-56.75113 ]
 [-25.344397]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.305076599121094






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  1. 11.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  2.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  1.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1.] 
adversary cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-5.8891544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  1.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 25.  6.  8.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0 582   0] 
sum of rewards: 757 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -2.69560170173645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-13.578949 ]
 [  1.3736167]
 [ -5.7427945]
 [-89.957886 ]
 [  2.166347 ]
 [ -8.86112  ]
 [ -3.1428251]
 [ -5.7355275]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  1.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 25.  6.  8.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.889154434204102



buy possibilites: [-1] 
expected returns: [[-23.69085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 10.  1.  0.  3. 11.  1. 11.  0. 10.  0.  0.  3. 25.  1.  3. 11. 11.
 11. 10.  6. 10. 29. 11. 11.  3.  3.  3.  0. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 25.  6.  8.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.] 
adversary owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 2.166354179382324






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 25.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25.  6.  8.] 
cards in discard: [11. 14.  3.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  6.] 
cards in discard: [11. 14.  3.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.] 
cards in discard: [11. 14.  3.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  6.] 
cards in discard: [11. 14.  3.  0.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
adversary victory points: 6
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-38.3496  ]
 [-28.808321]
 [-28.808321]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.69084930419922



action possibilites: [-1. 10.] 
expected returns: [[-39.135994]
 [-24.967707]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -33.292396545410156



action possibilites: [-1. 11.] 
expected returns: [[-14.085939 ]
 [ -2.3786561]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11] -> size -> 36 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -24.967695236206055



action possibilites: [-1.] 
expected returns: [[-36.339813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 279 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 1.3093109130859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -45.52233 ]
 [ -35.047455]
 [-116.81098 ]
 [ -35.07486 ]
 [ -29.304247]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -36.339813232421875






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11.  3. 11.  1.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [11. 14.  3.  0.  3.  8.  0.  8.  6. 25.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 11.  3. 11.  1.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15] -> size -> 37 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[ 0.1781807]
 [11.609411 ]
 [11.609411 ]
 [11.609411 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 11.  1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -29.30426788330078



action possibilites: [-1] 
expected returns: [[-28.453756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.069665908813477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-27.617666]
 [-18.142555]
 [-98.66454 ]
 [-23.222668]
 [-28.45729 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -28.45375633239746



buy possibilites: [-1] 
expected returns: [[-14.720709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -18.142555236816406






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 11. 25. 10. 10.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 11. 25. 10. 10.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 24. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 11. 25. 10. 10.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 25. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 10.] 
expected returns: [[-69.16844 ]
 [-62.769066]
 [-52.38806 ]
 [-61.748642]
 [-61.748642]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25. 10. 10.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 30.  8.  6. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  0. 14.] 
adversary cards in discard: [10. 11.  0.  0.  6.  3.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10] -> size -> 17 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.720708847045898



action possibilites: [-1] 
expected returns: [[5.9276342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10.  1.  0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 30.  8.  5. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  0. 14.] 
adversary cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -52.38804626464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[  2.5210056]
 [ 15.768599 ]
 [  8.824995 ]
 [-72.808914 ]
 [  7.7857914]
 [ 11.284496 ]
 [  6.2964993]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 10.  1.  0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 24. 30.  8.  5. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  0. 14.] 
adversary cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.927634239196777



buy possibilites: [-1] 
expected returns: [[-17.651989]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10. 10.  1.  0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  5. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 25.  0. 14.] 
adversary cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 15.768606185913086






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 25.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 14.] 
cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  5. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1] -> size -> 40 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  6.  8.] 
cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6] -> size -> 41 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  6.  8.] 
cards in discard: [10. 11.  0.  0.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  6.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6] -> size -> 41 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.  6.  8.] 
cards in discard: [10. 11.  0.  0.  6.  3.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 1. 1. 0.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6] -> size -> 41 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [3. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-18.031464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [25.  8.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0  -60    0 -300
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.651988983154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.42952213e+01]
 [-1.02424965e+01]
 [-2.84928570e+01]
 [-1.71707191e+01]
 [-4.78366928e+01]
 [-1.07165031e+02]
 [-8.33623695e+00]
 [-1.90619659e+01]
 [ 8.09979439e-02]
 [-2.80287528e+00]
 [-5.31295853e+01]
 [-1.30383062e+01]
 [-1.52368212e+01]
 [-3.32510147e+01]
 [-2.28313179e+01]
 [-1.70259438e+01]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  8.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [25.  8.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -18.031463623046875



buy possibilites: [-1] 
expected returns: [[-5.1354265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 0.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [25.  8.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.    0.    0.    0.    0.    0.  -70.
   0.    0.   62.5   0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 0.08099842071533203






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [25.  8.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25] -> size -> 42 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25] -> size -> 42 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-26.601215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  3.] 
adversary cards in discard: [25.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.1354265213012695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-30.403883]
 [-18.588   ]
 [-24.632824]
 [-69.489235]
 [-27.16424 ]
 [-24.239   ]
 [-26.601213]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  3.] 
adversary cards in discard: [25.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -26.601215362548828



buy possibilites: [-1] 
expected returns: [[-22.038288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  3.] 
adversary cards in discard: [25.  8.  6.  0.  3.] 
adversary owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -18.588008880615234






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  3.] 
cards in discard: [25.  8.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11. 11.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [25.  8.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  8  0  6  0 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11. 11.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [25.  8.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11. 11.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [25.  8.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [29. 10.  0. 11. 11.] 
adversary cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [29. 10.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[-58.931717]
 [-25.95458 ]
 [-46.896904]
 [-45.79265 ]
 [-45.79265 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 11. 11.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
adversary owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.038288116455078



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[-27.399397]
 [-25.24887 ]
 [-21.372057]
 [-21.372057]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
adversary owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -53.56944274902344



action possibilites: [-1] 
expected returns: [[-37.3154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.
 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
adversary owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -18.89604377746582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -44.613747]
 [ -36.501335]
 [-113.38026 ]
 [ -34.511414]
 [ -37.315414]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.
 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  5.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
adversary owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.315399169921875



buy possibilites: [-1] 
expected returns: [[-62.642067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [15. 10. 10. 11.  0.  3.  0.  3. 15.  3. 11. 11.  3. 11.  1.  1. 25.  3.
 11. 10. 10.  1.  0.  6. 25.  3.  0.  1.  1.  0.  1.  3.  3.  0.  6.  1.
 11. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
adversary owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 191 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -34.511409759521484






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 0.] 
cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 14  0  0  6 25  8  3  6 11  0 10  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15. 25. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15. 25. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15. 25. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [25.  8.  6.  0.  3. 10.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15. 25. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [15. 25. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29. 11.] 
expected returns: [[-46.96885 ]
 [-65.16356 ]
 [-38.15828 ]
 [-34.443848]
 [-45.60164 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -62.642066955566406



action possibilites: [-1. 15. 11. 11.] 
expected returns: [[-17.31055 ]
 [-23.732191]
 [ -8.676364]
 [ -8.676364]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 11.] 
cards in discard: [25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -59.67866516113281



action possibilites: [-1] 
expected returns: [[-2.4434795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.] 
cards in discard: [25. 15.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -110    0    0
   64    0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -8.353185653686523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.628928 ]
 [  0.7892852]
 [-83.364876 ]
 [ -5.3882184]
 [ -3.0083365]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.] 
cards in discard: [25. 15.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 24. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.443479537963867



buy possibilites: [-1] 
expected returns: [[-8.053918]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11.] 
cards in discard: [25. 15.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 0.7892656326293945






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  3. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3.  0. 10. 15. 11.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  4.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [ 0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-17.752583]
 [-14.555767]
 [-21.890562]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25.  6. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0 -120    0    0
 1014    0] 
sum of rewards: 1159 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 35.265235900878906



action possibilites: [-1. 15.] 
expected returns: [[-19.537376]
 [-23.589914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25.  6. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -14.555774688720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-23.5708  ]
 [-90.98188 ]
 [-19.913664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 3. 25.  6. 10.  0.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -19.537384033203125






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3. 25.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  6. 10.  0.] 
cards in discard: [ 8. 14.  0.  6. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  3. 11. 11. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  6.  0.  6.] 
cards in discard: [ 8. 14.  0.  6. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  3. 11. 11. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  6.  0.  6.] 
cards in discard: [ 8. 14.  0.  6. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  3. 11. 11. 15.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [ 1.  3. 11. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[15.946302]
 [36.54017 ]
 [36.54017 ]
 [20.28615 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11. 11. 15.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  6.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.91366195678711



action possibilites: [-1] 
expected returns: [[13.43845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11. 15.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.80858612060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  4.582613]
 [ 18.425415]
 [-51.6978  ]
 [  9.174143]
 [ 12.938669]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11. 15.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 22. 30. 23. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.43844985961914



buy possibilites: [-1] 
expected returns: [[-35.494644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11. 15.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [8. 0. 8. 8. 6.] 
adversary cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
adversary owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -140    0    0
   16    0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 18.425424575805664






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 6.] 
cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6 14  0  6 25  8  3  6 11  0 10  6  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [11.  1.  0. 11.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [11.  1.  0. 11.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [11.  1.  0. 11.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 14.  0.  6. 11.  3. 10.  3. 25.  6.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [11.  1.  0. 11.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [11.  1.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-5.671061]
 [-0.950582]
 [-0.950582]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 11.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  3.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [14.  6. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -35.49464416503906



action possibilites: [-1] 
expected returns: [[-28.476952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [14.  6. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -150    0    0
    8    0] 
sum of rewards: 143 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 6.373876571655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ -40.475853]
 [ -26.270279]
 [ -28.181704]
 [-117.7071  ]
 [ -32.556892]
 [ -19.88831 ]
 [ -28.476948]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  4. 10.  5.] 
adversary cards in hand: [14.  6. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -28.476951599121094



buy possibilites: [-1] 
expected returns: [[-2.381734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [14.  6. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -160    0    0
   54    0] 
sum of rewards: 179 

action type: buy - action 10.0
Learning step: 0
desired expected reward: -19.888309478759766






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14.  6. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10. 10.  0.  3. 25.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-0.7863245 ]
 [ 0.17564917]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [14.  6. 10.  0.  6.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0 -160    0    0
 1113    0] 
sum of rewards: 1218 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 13.573770523071289



action possibilites: [-1.] 
expected returns: [[10.69701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [14.  6. 10.  0.  6.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 0.17558908462524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[-11.203511 ]
 [  2.7276316]
 [-12.843828 ]
 [-92.927185 ]
 [  4.109105 ]
 [  9.287111 ]
 [ 10.697027 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  6.  3.] 
adversary cards in discard: [14.  6. 10.  0.  6.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.697010040283203






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [14.  6. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10.  3. 11.  1.  0.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [14.  6. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10.  3. 11.  1.  0.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.  3.] 
cards in discard: [14.  6. 10.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [10.  3. 11.  1.  0.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [10.  3. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-33.62146 ]
 [-33.771626]
 [-30.750137]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  1.  0.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.697010040283203



action possibilites: [-1] 
expected returns: [[-37.952156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -170    0    0
   64    0] 
sum of rewards: 179 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -28.914443969726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ -46.20185 ]
 [ -32.515125]
 [ -42.045372]
 [-114.88872 ]
 [ -38.843483]
 [ -34.458282]
 [ -37.95215 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.95215606689453



buy possibilites: [-1] 
expected returns: [[-82.65695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 8.  0.  3. 25.  8.] 
adversary cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
adversary owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -32.51513671875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 25.  8.] 
cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  0  6 25  3  6 11  0 10  6  8  0  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1] -> size -> 53 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [14.  6. 10.  0.  6.  0.  0. 11.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1] -> size -> 53 
adversary victory points: 8
player victory points: -2 





Player: 0 
cards in hand: [ 3. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-39.455833]
 [-34.748962]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -82.65695190429688



action possibilites: [-1] 
expected returns: [[-47.871727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -190    0    0
   64    0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -31.822450637817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ -59.4617  ]
 [ -40.36505 ]
 [ -52.029625]
 [-123.76378 ]
 [ -47.805534]
 [ -38.167793]
 [ -47.87175 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -47.871726989746094



buy possibilites: [-1] 
expected returns: [[-30.276237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  8.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -200    0    0
   54    0] 
sum of rewards: 169 

action type: buy - action 10.0
Learning step: 0
desired expected reward: -38.16777801513672






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 10.  0.  1.  8.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6. 14.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 21. 30. 22. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 10.  0.  1.  8.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6. 14.  0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 1. 10.  0.  1.  8.] 
adversary cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [ 1. 10.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-21.529823]
 [-19.12867 ]
 [-22.02727 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  1.  8.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 3.  0.  8.  6. 14.  0.] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -30.27623748779297



action possibilites: [-1.  8.] 
expected returns: [[-17.447102]
 [-17.5954  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 8. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 3.  0.  8.  6. 14.  0.] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -19.12866973876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-20.96559  ]
 [ -8.263745 ]
 [-13.807506 ]
 [-32.626564 ]
 [-60.711075 ]
 [ -8.487312 ]
 [-17.5954   ]
 [ -1.6328344]
 [ -3.8099103]
 [-38.840683 ]
 [-11.137989 ]
 [-13.554746 ]
 [-27.980373 ]
 [-18.971466 ]
 [-17.447102 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 8. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  7.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 3.  0.  8.  6. 14.  0.] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -17.447097778320312



buy possibilites: [-1] 
expected returns: [[-16.357845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 8. 3.] 
cards in discard: [25. 15.  3. 29. 11. 15.  0. 11.  3. 11. 10.  0. 15.  6. 15.  3. 11.  1.
  3. 11. 15.  8. 10. 11.  1.  0. 11.  3. 10. 25. 10.  0.  3.  1. 15.  1.
 11. 10.  3.  1.  0. 15. 10. 11.  3.  1.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 3.  0.  8.  6. 14.  0.] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -210    0    0
  250    0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -1.6328449249267578






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 3.  0.  8.  6. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  3. 15. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25] -> size -> 56 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 3.  0.  8.  6. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 21. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  3. 15. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25] -> size -> 56 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 3.  0.  8.  6. 14.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  3. 15. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25] -> size -> 56 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3. 15. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[ 5.7859554]
 [ 0.5798125]
 [13.540792 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 11.  6.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 3.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3  3] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.357845306396484



action possibilites: [-1] 
expected returns: [[24.386442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.] 
cards in discard: [15.] 
cards in deck: 51 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3  3] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -220    0    0
   64    0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 16.489151000976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 22.883894]
 [-44.1838  ]
 [ 24.06727 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  6.] 
cards in discard: [15.] 
cards in deck: 51 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3  3] -> size -> 16 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.386442184448242






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  3  6 11  0 10  6  8  0  8  0  0  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  1. 29. 11.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  1. 29. 11.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  1. 29. 11.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3.  3.  1. 29. 11.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [ 3.  3.  1. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[37.852623]
 [51.784035]
 [39.699425]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29. 11.] 
cards in discard: [15. 11.  0.  3. 15.  6.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 11.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.067289352416992



action possibilites: [-1. 11. 10.] 
expected returns: [[21.26636 ]
 [24.85964 ]
 [21.632864]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  2.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 11.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.678550720214844



action possibilites: [-1] 
expected returns: [[42.0224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 11.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -230    0    0
   64    0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.909799575805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 32.039444]
 [-17.713327]
 [ 41.37668 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  3. 11.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.02239990234375






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [11.  8.  3. 11.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [11.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[13.478086]
 [20.993351]
 [13.201891]
 [20.993351]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 11.  0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  1.] 
adversary cards in hand: [ 0.  3. 14.  6.  0.] 
adversary cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.376686096191406



action possibilites: [-1] 
expected returns: [[16.767431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 14.  6.  0.] 
adversary cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -240    0    0
   64    0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.99542808532715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 13.566717]
 [-22.961199]
 [ 16.76742 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0.  3. 14.  6.  0.] 
adversary cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.767431259155273






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  6.  0.] 
cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [11.  3.  3.  3.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [11.  3.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 0.  8.  3. 11.  0.  6.  6.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [11.  3.  0.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[19.217031]
 [26.00537 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  2.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0 -240    0    0
 1764    0] 
sum of rewards: 1789 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 3.7293405532836914



action possibilites: [-1] 
expected returns: [[31.502584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  1.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -250    0    0
    8    0] 
sum of rewards: 43 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 26.98634147644043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 26.778639]
 [-49.664604]
 [ 31.502584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15  8] -> size -> 60 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  1.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.50258445739746






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  6.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  1.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [15. 15.  1.  0.  1.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15  8] -> size -> 60 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  6.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  1.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [15. 15.  1.  0.  1.] 
adversary cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15  8] -> size -> 60 
adversary victory points: 8
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 1 
Witch: 3 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 15.  1.  0.  1.] 
cards in discard: [15. 11.  0.  3. 15.  6.  1. 15. 29. 11.  3.  3. 10. 15. 11.  8.  3. 11.
  0.  3.  3.  8. 11.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 25 11  3 11 11  1 10  1 10  3
  1 11  3 10 11  1 11  1  3  6 10 11 15 15  3  1  6 25  1 15  8 15  3 15
  3  8 10 15  1 15 10 25 15 15 15  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 20. 30.  8.  4. 10.  0.  0.  6.  8.  9. 10.  2. 10.  0.] 
adversary cards in hand: [ 0. 11.  8.  6.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [14  0  6  6 11  0  6  8  0  8  0  0  3  3  0  0  8] -> size -> 17 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[     -5 3000000       0     270       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000265 

action type: buy - action -1.0
Learning step: 120009.3359375
desired expected reward: 120040.8359375



