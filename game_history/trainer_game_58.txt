 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[299.10608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   5  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 500 

action type: buy - action 0.0
Learning step: 26.157766342163086
desired expected reward: 3.002408981323242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[275.93512]
 [286.95584]
 [284.13806]
 [255.43433]
 [294.7589 ]
 [284.41684]
 [282.1876 ]
 [302.00183]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.803988456726074
desired expected reward: 293.4894104003906



buy possibilites: [-1] 
expected returns: [[276.01205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -8.010571479797363
desired expected reward: 276.4062805175781






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.74216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.11440372467041
desired expected reward: 268.89764404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.14294]
 [288.9186 ]
 [285.6579 ]
 [256.56906]
 [282.9085 ]
 [297.1718 ]
 [286.03625]
 [291.45068]
 [267.7045 ]
 [283.36176]
 [281.58917]
 [304.74512]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.756501197814941
desired expected reward: 292.85235595703125



buy possibilites: [-1] 
expected returns: [[281.29248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  3.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 14.0
Learning step: -5.556143283843994
desired expected reward: 262.1483154296875






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  3.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[277.13394]
 [244.5816 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.26305103302002
desired expected reward: 273.0294189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[253.46973]
 [261.01654]
 [233.81358]
 [262.08328]
 [277.20676]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.125113487243652
desired expected reward: 269.0581359863281



buy possibilites: [-1] 
expected returns: [[293.158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  3.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: -5.604770660400391
desired expected reward: 255.4117431640625






Player: 1 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[319.02988]
 [301.76865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.23956823348999
desired expected reward: 285.9184265136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[291.35846]
 [302.66986]
 [299.67   ]
 [271.44318]
 [311.1558 ]
 [299.76834]
 [297.40594]
 [318.4398 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.665992736816406
desired expected reward: 308.9871520996094



buy possibilites: [-1] 
expected returns: [[291.41055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  0. 14.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 8.0
Learning step: -7.881678104400635
desired expected reward: 291.8866271972656






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[284.12067]
 [249.09334]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.571222305297852
desired expected reward: 282.8393249511719



action possibilites: [-1] 
expected returns: [[281.41922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -5.175960540771484
desired expected reward: 243.9818878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[241.18413]
 [255.06937]
 [250.98166]
 [225.28548]
 [217.31926]
 [248.01845]
 [264.89813]
 [251.67378]
 [277.14554]
 [258.02664]
 [230.06216]
 [241.2621 ]
 [248.1305 ]
 [225.40356]
 [245.89185]
 [273.4564 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -7.500062465667725
desired expected reward: 273.9191589355469



buy possibilites: [-1] 
expected returns: [[281.6037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 11.0
Learning step: -5.733825206756592
desired expected reward: 259.1643371582031






Player: 1 
cards in hand: [16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 8.] 
adversary cards in discard: [11. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[257.1426 ]
 [243.54114]
 [243.54114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11. 14.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.539769172668457
desired expected reward: 273.0639343261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[227.41293]
 [234.00064]
 [210.56213]
 [234.74866]
 [247.74707]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11. 14.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -7.230922222137451
desired expected reward: 240.97291564941406



buy possibilites: [-1] 
expected returns: [[230.95453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 8.] 
cards in discard: [11. 14.  3.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -6.190957069396973
desired expected reward: 228.55770874023438






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8.  0. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  6. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8.  0. 16.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[239.27995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.241407871246338
desired expected reward: 224.71311950683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[216.65033]
 [228.0708 ]
 [224.53049]
 [196.61702]
 [234.41647]
 [225.46234]
 [222.18819]
 [239.49661]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -6.893218994140625
desired expected reward: 231.16539001464844



buy possibilites: [-1] 
expected returns: [[211.85666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -20.664077758789062
desired expected reward: 175.95297241210938






Player: 1 
cards in hand: [16.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 14.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[237.66475]
 [230.88591]
 [205.74362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.151488780975342
desired expected reward: 205.70516967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[217.7862 ]
 [225.75342]
 [200.34258]
 [225.8702 ]
 [243.47021]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.3450026512146
desired expected reward: 228.5890655517578



buy possibilites: [-1] 
expected returns: [[261.44894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 14.] 
cards in discard: [6. 0. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -7.1067094802856445
desired expected reward: 210.67950439453125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [8. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[220.34496]
 [204.37129]
 [204.37129]
 [204.37129]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14  3  8 11  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.058215141296387
desired expected reward: 252.39073181152344



action possibilites: [-1] 
expected returns: [[313.15952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.858266592025757
desired expected reward: 203.22885131835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[287.4714 ]
 [295.48734]
 [268.31287]
 [295.8397 ]
 [312.26248]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  0.  0. 11.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -8.649482727050781
desired expected reward: 304.5100402832031






Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16  3  8  0 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[279.3287 ]
 [258.71228]
 [242.7665 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8. 14.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -9.29642391204834
desired expected reward: 302.9660949707031



action possibilites: [-1] 
expected returns: [[246.1747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 14.0
Learning step: -5.255972385406494
desired expected reward: 238.64208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[219.04799]
 [229.78435]
 [227.30989]
 [200.89458]
 [237.93486]
 [227.08653]
 [225.22067]
 [245.16045]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  5. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -5.773549556732178
desired expected reward: 240.40115356445312



buy possibilites: [-1] 
expected returns: [[234.29012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 30.0 

action type: buy - action 8.0
Learning step: -4.3655619621276855
desired expected reward: 222.72097778320312






Player: 1 
cards in hand: [8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [ 8. 14.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[283.54312]
 [280.15726]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -4.912315368652344
desired expected reward: 229.3778076171875



action possibilites: [-1] 
expected returns: [[240.06297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    2    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -283 

action type: gain_card_n - action 3
Learning step: -22.396320343017578
desired expected reward: 250.5584259033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[224.68074]
 [232.68611]
 [230.07399]
 [210.6585 ]
 [237.59764]
 [230.79137]
 [228.51236]
 [241.48935]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  9.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -5.963850975036621
desired expected reward: 234.09912109375



buy possibilites: [-1] 
expected returns: [[189.10437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [8. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: -5.875033855438232
desired expected reward: 231.7226104736328






Player: 1 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [8. 0. 0. 0. 8. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8 16  3  8  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  4. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 8. 3. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0. 0. 0. 8. 3. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[176.01404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -5.708605766296387
desired expected reward: 183.39576721191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[156.40865]
 [165.29147]
 [162.45126]
 [141.0339 ]
 [160.76797]
 [170.86823]
 [163.12082]
 [166.66995]
 [148.98427]
 [160.60645]
 [158.89702]
 [175.08382]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.161201000213623
desired expected reward: 168.0216064453125



buy possibilites: [-1] 
expected returns: [[173.09912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  6.  8.  3.  6. 11. 11.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 29 

action type: buy - action 29.0
Learning step: -2.988767623901367
desired expected reward: 163.68118286132812






Player: 1 
cards in hand: [ 3.  8.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  3  8  0 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  3. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [8. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[227.1122]
 [209.0863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.9104344844818115
desired expected reward: 169.18869018554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[205.34189]
 [187.35175]
 [233.34753]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.694713115692139
desired expected reward: 219.10536193847656



buy possibilites: [-1] 
expected returns: [[241.70505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 8.  0. 16.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -6.47873067855835
desired expected reward: 198.8631591796875






Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8.  0. 16.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [0. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8.  0. 16.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  2. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [0. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 8.  0. 16.  3.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  1. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 29.  0.] 
adversary cards in discard: [0. 6. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[257.8565 ]
 [244.32033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 29.  0.] 
cards in discard: [0. 6. 0. 8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  1. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -6.613089084625244
desired expected reward: 235.0919647216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[236.98085]
 [245.52702]
 [218.86053]
 [244.81834]
 [263.71844]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 29.  0.] 
cards in discard: [0. 6. 0. 8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  1. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.463006496429443
desired expected reward: 248.56951904296875



buy possibilites: [-1] 
expected returns: [[214.7325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 29.  0.] 
cards in discard: [0. 6. 0. 8. 3. 3. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -7.159436225891113
desired expected reward: 237.65890502929688






Player: 1 
cards in hand: [ 3.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8 16  3  8  0 16  8  8  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[190.53345]
 [185.53526]
 [177.01134]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3 11  8  6  0  8  6 11 29  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.276679992675781
desired expected reward: 207.455810546875



action possibilites: [-1] 
expected returns: [[192.92795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.783198118209839
desired expected reward: 146.69833374023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[177.31046]
 [161.33514]
 [198.80507]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  8.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -5.225690841674805
desired expected reward: 187.70225524902344



buy possibilites: [-1] 
expected returns: [[204.12758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -18.673887252807617
desired expected reward: 142.66127014160156






Player: 1 
cards in hand: [0. 8. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 14.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 14.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 14.] 
adversary cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[160.0625 ]
 [154.6596 ]
 [130.52063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 14.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -7.617146968841553
desired expected reward: 196.51043701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[143.5844 ]
 [153.47266]
 [150.86969]
 [126.42929]
 [160.47513]
 [148.90019]
 [166.6594 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 14.] 
cards in discard: [ 0.  6.  0.  8.  3.  3.  8.  6.  3.  0. 29.  0.  6.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0.  8.] 
adversary cards in discard: [ 0.  3. 16.  3.  0.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.121733665466309
desired expected reward: 151.51092529296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0.  8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.  8.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  3  8  0 16  8  8  0  8  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.  8.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  3. 16.  3.  0.  0.  8.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[180.33545]
 [174.7078 ]
 [164.37161]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  7.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -5.167809009552002
desired expected reward: 161.49154663085938



action possibilites: [-1] 
expected returns: [[183.3374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: gain_card_n - action 3
Learning step: -19.20100212097168
desired expected reward: 142.32086181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[154.90851]
 [163.12483]
 [137.53302]
 [181.00378]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  6.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -5.791865825653076
desired expected reward: 177.5455322265625



buy possibilites: [-1] 
expected returns: [[204.55513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [6. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -316.0 

action type: buy - action 6.0
Learning step: -18.074159622192383
desired expected reward: 119.45883178710938






Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 3.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[175.23306]
 [165.72934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  8.  0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -8.16460132598877
desired expected reward: 196.39053344726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[165.30222]
 [171.1886 ]
 [148.36081]
 [183.65332]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  8.  0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -6.786675930023193
desired expected reward: 168.82342529296875



buy possibilites: [-1] 
expected returns: [[225.44131]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 3.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 16.  0.  8.  0.] 
adversary cards in discard: [8. 3. 0.] 
adversary owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -6.492681980133057
desired expected reward: 158.80953979492188






Player: 1 
cards in hand: [ 8. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  8.  0.] 
cards in discard: [8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  8  0 16  8  8  0  8  0  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0. 14.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0. 14.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0. 14.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [8. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.  0. 14.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29.  0.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 14.] 
expected returns: [[141.24664]
 [132.60443]
 [129.21028]
 [118.07465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0. 14.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -10.219683647155762
desired expected reward: 215.2216339111328



action possibilites: [-1.  8. 14.] 
expected returns: [[147.62643]
 [136.59793]
 [124.57773]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: discard_n_cards - action 0
Learning step: -3.4943008422851562
desired expected reward: 115.80004119873047



action possibilites: [-1] 
expected returns: [[175.10243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.056896209716797
desired expected reward: 121.87712097167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[152.37325]
 [159.02222]
 [135.15408]
 [173.39813]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -5.030609607696533
desired expected reward: 170.0718231201172






Player: 1 
cards in hand: [ 0.  0.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 27. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.16736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0. 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 16.] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -8.76978588104248
desired expected reward: 164.6283416748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 81.047676]
 [ 67.34296 ]
 [100.48915 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 6.  6. 11.  0.  0.  8.  6.  0.  3.  0.  0.  8.  3.  0. 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 16.] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -5.287040710449219
desired expected reward: 92.49612426757812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  8.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  8. 16. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[173.18156]
 [160.14108]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.6069705486297607
desired expected reward: 96.88219451904297



action possibilites: [-1] 
expected returns: [[90.11032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 2
Learning step: -6.783107280731201
desired expected reward: 132.42868041992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[74.08707]
 [77.97478]
 [64.42313]
 [87.80656]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -4.620100498199463
desired expected reward: 85.49021911621094



buy possibilites: [-1] 
expected returns: [[123.25809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -67.0 

action type: buy - action 0.0
Learning step: -4.281047344207764
desired expected reward: 69.80603790283203






Player: 1 
cards in hand: [ 0. 16.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  8.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 21 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[166.33498]
 [157.55006]
 [153.57027]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  8.  3.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 16.  3.  8.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -5.506807327270508
desired expected reward: 117.75128173828125



action possibilites: [-1] 
expected returns: [[136.5173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 16.  3.  8.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: trash_cards_n_from_hand - action 5
Learning step: -5.989341735839844
desired expected reward: 127.23027801513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.340775]
 [101.21485 ]
 [134.43893 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  5.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 16.  3.  8.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -6.551241397857666
desired expected reward: 129.966064453125



buy possibilites: [-1] 
expected returns: [[128.06134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.] 
cards in discard: [0. 8. 0. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  0.] 
adversary cards in discard: [ 8. 16.  3.  8.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -359 

action type: buy - action 6.0
Learning step: -20.129362106323242
desired expected reward: 81.08547973632812






Player: 1 
cards in hand: [ 0.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  0.] 
cards in discard: [ 8. 16.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6] -> size -> 20 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.  0.] 
cards in discard: [ 8. 16.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  7.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6] -> size -> 20 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.  0.] 
cards in discard: [ 8. 16.  3.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  6.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6] -> size -> 20 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[134.07535]
 [130.51617]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  6.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -7.44314432144165
desired expected reward: 120.61819458007812



action possibilites: [-1] 
expected returns: [[111.61189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  5.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -50 

action type: gain_card_n - action 5
Learning step: -5.016711711883545
desired expected reward: 95.5428695678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[102.78437 ]
 [109.1975  ]
 [107.128456]
 [ 91.86831 ]
 [113.332504]
 [105.8629  ]
 [116.78457 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  5.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -6.109239101409912
desired expected reward: 105.50265502929688



buy possibilites: [-1] 
expected returns: [[133.91956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
adversary owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: -4.703436374664307
desired expected reward: 108.62908172607422






Player: 1 
cards in hand: [11.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8.  0.] 
cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  8  0  8  0  3  0  0  0  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 16.  3.  8. 11.  0.  0.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[51.078976]
 [40.608406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 6.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -9.161749839782715
desired expected reward: 124.75780487060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.363052]
 [24.907589]
 [52.0249  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8. 6.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  4.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -4.995275497436523
desired expected reward: 43.482452392578125



buy possibilites: [-1] 
expected returns: [[42.96774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8. 6.] 
cards in discard: [ 0.  8.  0.  0.  6.  8.  6. 29. 11. 11. 11.  0.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -380.0 

action type: buy - action 6.0
Learning step: -19.278608322143555
desired expected reward: 5.629001617431641






Player: 1 
cards in hand: [ 8.  0. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  8.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  8  8  3  0  0  0  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[89.21126]
 [84.6046 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  6.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11. 16.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: buy - action -1
Learning step: -4.2112627029418945
desired expected reward: 38.75647735595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.61931]
 [68.32867]
 [89.57318]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  3.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11. 16.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action -1.0
Learning step: -6.615780830383301
desired expected reward: 81.61296081542969



buy possibilites: [-1] 
expected returns: [[103.879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  6.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11. 16.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -391.0 

action type: buy - action 6.0
Learning step: -20.6291561126709
desired expected reward: 47.69950866699219






Player: 1 
cards in hand: [ 3.  3.  0. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 16.] 
cards in discard: [8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  0  0  3 11] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 11.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  3  0  3 11  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 11.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  3  0  3 11  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 11.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
adversary victory points: -6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 11.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
adversary victory points: -6
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[54.29953 ]
 [49.642254]
 [53.131535]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8.  3. 11.] 
cards in discard: [ 6.  3.  0. 29.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  2.  8.  4.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: buy - action -1
Learning step: -8.600196838378906
desired expected reward: 95.27880096435547



action possibilites: [-1] 
expected returns: [[-9.002006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -62 

action type: gain_card_n - action 5
Learning step: -5.669667720794678
desired expected reward: 41.67278289794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-8.650296]
 [-8.483485]
 [-8.869144]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1
Learning step: -3.294548511505127
desired expected reward: -12.296554565429688



buy possibilites: [-1] 
expected returns: [[43.361988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action 0.0
Learning step: -3.641840696334839
desired expected reward: -12.292134284973145






Player: 1 
cards in hand: [16.  3.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8. 11.  8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  0  3 11  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  3  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  3  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 0. 8. 0.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 0.9344585]
 [-1.0556122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1
Learning step: -6.210019111633301
desired expected reward: 37.15196990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-2.1382082 ]
 [-1.5269829 ]
 [-3.383116  ]
 [ 0.07332397]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 26. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -4.0473480224609375
desired expected reward: -4.8114333152771



buy possibilites: [-1] 
expected returns: [[17.491858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 0.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 25. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -62 

action type: buy - action 3.0
Learning step: -2.630084276199341
desired expected reward: -4.1570634841918945






Player: 1 
cards in hand: [16.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  3  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 25. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3] -> size -> 27 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  3  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 25. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3] -> size -> 27 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  3  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 30. 30. 24. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  6.] 
adversary cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3] -> size -> 27 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[55.180088]
 [52.98598 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  6.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 30.  8.  2.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: buy - action -1
Learning step: -3.7101428508758545
desired expected reward: 13.78171443939209



action possibilites: [-1] 
expected returns: [[35.819744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6  -80    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -371 

action type: gain_card_n - action 3
Learning step: -20.0247859954834
desired expected reward: 25.58980369567871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[28.378757]
 [33.086636]
 [31.596655]
 [21.211649]
 [37.208836]
 [30.725634]
 [40.72325 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  3.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1
Learning step: -4.6064372062683105
desired expected reward: 31.213306427001953



buy possibilites: [-1] 
expected returns: [[31.645468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 6.  3.  0. 29.  6.  6. 11.  0. 11.  6.  6.  8.  3.  3.  6.  6.  0.  8.
  0.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  3  0  0  3] -> size -> 7 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -53 

action type: buy - action 11.0
Learning step: -3.7984185218811035
desired expected reward: 33.41041564941406






Player: 1 
cards in hand: [ 0.  0. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  3  0  0  3] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0  0  3  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  8. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.  8.] 
expected returns: [[19.705364]
 [16.638884]
 [11.603747]
 [16.638884]
 [11.603747]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6
 11  0  3  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3  0] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1
Learning step: -5.350959777832031
desired expected reward: 26.29450798034668



action possibilites: [-1] 
expected returns: [[40.724735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3  0] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: trash_cards_n_from_hand - action 4
Learning step: -1.9378107786178589
desired expected reward: -5.855465888977051





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.651186]
 [24.749931]
 [39.915997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3  0] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1
Learning step: -4.348032474517822
desired expected reward: 36.37670135498047






Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  0  0  3  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 8. 11. 11.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  0  0  0  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 8. 11. 11.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  0  0  0  1] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 24. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 8. 11. 11.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  0  0  0  1  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 8. 11. 11.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[40.836246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 8. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  0  1  3] -> size -> 8 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -5.182862281799316
desired expected reward: 34.73313903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.4366  ]
 [27.882994]
 [40.179314]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 8. 11. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  0  1  3] -> size -> 8 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -5.200363636016846
desired expected reward: 33.152442932128906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  0  0  0  1  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 29.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[4.079011 ]
 [1.8038929]
 [2.5193193]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 29.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6  0  8  6 11 29  0  8  6  6  6  0  0  6 11 11  6  6 11  0
  3  6 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -5.977878570556641
desired expected reward: 34.20143127441406



action possibilites: [-1] 
expected returns: [[48.23067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.6889923810958862
desired expected reward: -3.709049701690674





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[38.859417]
 [41.813564]
 [33.053593]
 [49.036022]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 23. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1
Learning step: -4.529084205627441
desired expected reward: 43.70158767700195



buy possibilites: [-1] 
expected returns: [[44.65868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0  0  3] -> size -> 6 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -42 

action type: buy - action 3.0
Learning step: -3.1858584880828857
desired expected reward: 38.62771224975586






Player: 1 
cards in hand: [ 0.  8.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  0  0  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 11.  0.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 11.  0.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 11.  0.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 11.  0.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.226515]
 [15.568902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 11.  0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0] -> size -> 4 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -5.298777103424072
desired expected reward: 39.359901428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[10.727716]
 [13.298493]
 [ 4.219535]
 [20.277094]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0] -> size -> 4 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -4.219649791717529
desired expected reward: 15.96229362487793



buy possibilites: [-1] 
expected returns: [[33.82269]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  0.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0] -> size -> 4 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -4.775375843048096
desired expected reward: 5.952346324920654






Player: 1 
cards in hand: [16.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 21. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 21. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  0. 11.  6.] 
adversary cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11.  6.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[29.271076]
 [26.610443]
 [26.610443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: buy - action -1
Learning step: -5.149027347564697
desired expected reward: 28.673662185668945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.378625]
 [ 6.231658]
 [27.999027]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  1.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action -1.0
Learning step: -4.891162395477295
desired expected reward: 20.8380184173584



buy possibilites: [-1] 
expected returns: [[7.1946373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  6.] 
cards in discard: [ 8. 11. 11.  6.  3.  3.  3.  6.  3.  8.  0.  0.  0.  0.  6.  6. 11.  0.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  3.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  3  0] -> size -> 5 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[  -5.    0.   -6.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -391.0 

action type: buy - action 6.0
Learning step: -19.699705123901367
desired expected reward: -13.468052864074707






Player: 1 
cards in hand: [16.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  8.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
adversary victory points: -6
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.700204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1
Learning step: -3.747821807861328
desired expected reward: 3.4468154907226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.29622364]
 [ 4.347275  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -3.8595211505889893
desired expected reward: 3.3364779949188232



buy possibilites: [-1] 
expected returns: [[19.101858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 6.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -101.0 

action type: buy - action 0.0
Learning step: -4.6053972244262695
desired expected reward: -4.901618003845215






Player: 1 
cards in hand: [16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [0. 3. 6. 0. 6. 6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0] -> size -> 29 
adversary victory points: -6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 11.] 
adversary cards in discard: [0. 3. 6. 0. 6. 6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0] -> size -> 29 
adversary victory points: -6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[39.575256]
 [37.726162]
 [37.726162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [0. 3. 6. 0. 6. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1
Learning step: -3.6863555908203125
desired expected reward: 15.415502548217773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[28.750021]
 [31.112364]
 [37.239265]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [0. 3. 6. 0. 6. 6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -4.688024044036865
desired expected reward: 32.835147857666016



buy possibilites: [-1] 
expected returns: [[33.088554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0. 11.] 
cards in discard: [0. 3. 6. 0. 6. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0] -> size -> 3 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -101.0 

action type: buy - action 0.0
Learning step: -5.743009090423584
desired expected reward: 23.007015228271484






Player: 1 
cards in hand: [16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
adversary victory points: -6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
adversary victory points: -6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
adversary victory points: -6
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[10.576261 ]
 [ 9.5230665]
 [ 9.5230665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1
Learning step: -5.044369220733643
desired expected reward: 28.044185638427734



action possibilites: [-1] 
expected returns: [[17.806187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -42 

action type: gain_card_n - action 7
Learning step: -1.7213172912597656
desired expected reward: -1.2821893692016602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[11.62079 ]
 [13.937297]
 [19.302158]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1
Learning step: -3.095045804977417
desired expected reward: 14.711140632629395



buy possibilites: [-1] 
expected returns: [[49.94826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -81.0 

action type: buy - action 0.0
Learning step: -3.5072038173675537
desired expected reward: 8.113585472106934






Player: 1 
cards in hand: [ 8.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 6. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 6. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 6. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 6. 6. 6.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.803238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1
Learning step: -5.332489013671875
desired expected reward: 44.61577224731445





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.742626]
 [31.14634 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 6.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  0] -> size -> 4 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -4.554666042327881
desired expected reward: 27.21973991394043



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-2.6100106]
 [-3.1994197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0] -> size -> 5 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -5.67207670211792
desired expected reward: 25.47426986694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.251799]
 [-2.67011 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0] -> size -> 5 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -3.9855313301086426
desired expected reward: -6.595546722412109



buy possibilites: [-1] 
expected returns: [[40.599678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 8. 3.] 
cards in discard: [ 0.  3.  6.  0.  6.  6.  0.  0. 11.  6.  0. 11. 10.  0. 11.  0. 11.  0.
  6.  3.  3.  6.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0] -> size -> 5 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -111.0 

action type: buy - action 0.0
Learning step: -4.473917484283447
desired expected reward: -7.725715637207031






Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[13.379551 ]
 [ 7.914442 ]
 [ 2.6659517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1
Learning step: -5.874155044555664
desired expected reward: 34.72552490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 0.40224075]
 [ 3.8838725 ]
 [14.805703  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0] -> size -> 6 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -4.587981224060059
desired expected reward: 9.377519607543945



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0 10] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.572845]
 [16.229103]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  6.  6.] 
cards in discard: [ 6.  0.  0. 11.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0 10] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -4.4394965171813965
desired expected reward: 10.366214752197266



action possibilites: [-1.] 
expected returns: [[-1.0953408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0 10] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -60 

action type: take_action - action 10.0
Learning step: -3.7274487018585205
desired expected reward: 10.328620910644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-3.5912132]
 [-1.9794852]
 [ 1.9839659]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 29. 30. 20. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0 10] -> size -> 7 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -3.015690803527832
desired expected reward: -4.111031532287598



buy possibilites: [-1] 
expected returns: [[9.794532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [ 6.  0.  0. 11.  8.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 19. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0 10] -> size -> 7 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -42 

action type: buy - action 3.0
Learning step: -1.7806482315063477
desired expected reward: -3.760146141052246






Player: 1 
cards in hand: [ 0.  0. 10.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 16.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0 10] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 19. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3  0  0  3] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3  0  0  3] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  2.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  3  0  0  3 11] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  3.  6. 11.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 0.11286902]
 [-4.7062263 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  6. 11.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: buy - action -1
Learning step: -4.676421642303467
desired expected reward: 5.118110179901123





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.849456]
 [ -8.205168]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  6. 11.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  3  0  0  3 11] -> size -> 8 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -80 

action type: take_action - action -1.0
Learning step: -3.898986577987671
desired expected reward: -10.5624418258667



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  3  0  0  3 11] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 29. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0  3 11  1] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0  3 11  1] -> size -> 8 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[7.6521635]
 [6.123106 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -2.6835644245147705
desired expected reward: -15.881857872009277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[0.62987924]
 [1.945133  ]
 [5.443426  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -3.8168561458587646
desired expected reward: 3.835314989089966



buy possibilites: [-1] 
expected returns: [[8.548779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -4.839147567749023
desired expected reward: -4.209251403808594






Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0] -> size -> 35 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0  3 11  1  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 28. 30. 18. 30.  8.  0.  8.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0] -> size -> 35 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 18. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0] -> size -> 35 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.776365]
 [22.24838 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 18. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -3.3958497047424316
desired expected reward: 5.152928829193115



action possibilites: [-1] 
expected returns: [[-0.14725828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0  -1   0   0   4   0] 
sum of rewards: -36 

action type: gain_card_n - action 2
Learning step: -2.436285972595215
desired expected reward: 10.22316837310791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.8597293 ]
 [-0.41426015]
 [ 1.1983938 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 17. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -1.9407247304916382
desired expected reward: -2.0879831314086914



buy possibilites: [-1] 
expected returns: [[9.734779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 28. 30. 17. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -50.   0.   0.  20. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -71.0 

action type: buy - action 0.0
Learning step: -3.287980794906616
desired expected reward: -4.147717475891113






Player: 1 
cards in hand: [ 0. 16.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  0  3 11  1  0 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.  3.  0. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0  3  0] -> size -> 37 
adversary victory points: -4
player victory points: 1 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 0 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 4 
Chapel: 5 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  3.  0.  0. 11.] 
cards in discard: [ 6.  0.  0. 11.  8.  3. 10.  0.  3.  6.  6.  0.  0.  6.  3.  6. 11.  0.
  0.  0. 11.  6.  6.  3.  0. 11.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  6  0  8  6 11  0  8  6  6  6  0  0  6 11 11  6  6 11  0  3  6
 11  3  0  6  0  0 10  0  0  3  0  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  0.  7.  1.  0. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3.] 
adversary cards in discard: [0.] 
adversary owned cards: [16  0  0  0  3 11  1  0 16  0] -> size -> 10 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4  -50    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -559 

action type: buy - action -1
Learning step: -28.43674087524414
desired expected reward: -18.701961517333984



