 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[65.24412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action -1.0
Learning step: 1.9104808568954468
desired expected reward: -30.851543426513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.798927]
 [62.973   ]
 [59.507507]
 [22.877928]
 [84.63962 ]
 [69.63599 ]
 [66.17051 ]
 [63.999725]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.60121154785156



buy possibilites: [-1] 
expected returns: [[69.15486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.63960266113281






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[68.78362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.15486145019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[49.32176 ]
 [67.42443 ]
 [63.993164]
 [27.831179]
 [66.11559 ]
 [88.94475 ]
 [74.019905]
 [89.894646]
 [51.229828]
 [70.58863 ]
 [69.38183 ]
 [68.454834]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.69354248046875



buy possibilites: [-1] 
expected returns: [[90.336655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 89.89463806152344






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.57159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.33665466308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 63.956474]
 [ 82.7343  ]
 [ 79.184555]
 [ 41.104546]
 [104.94223 ]
 [ 89.55601 ]
 [ 86.00627 ]
 [ 83.81045 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.96228790283203



buy possibilites: [-1] 
expected returns: [[61.247383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 104.9422378540039






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  1.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.22139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.24738311767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 60.45449 ]
 [ 79.27724 ]
 [ 75.70238 ]
 [ 38.669487]
 [ 77.92229 ]
 [101.461655]
 [ 86.137886]
 [102.48072 ]
 [ 62.5067  ]
 [ 82.56303 ]
 [ 81.34516 ]
 [ 80.4818  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.02103424072266



buy possibilites: [-1] 
expected returns: [[96.40837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.48072814941406






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 29.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[58.270424]
 [76.40915 ]
 [77.329445]
 [77.329445]
 [76.40915 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.40837097167969



action possibilites: [-1. 11. 29. 11.] 
expected returns: [[ 92.079865]
 [110.147934]
 [111.05368 ]
 [110.147934]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.67359924316406



action possibilites: [-1. 11. 11.] 
expected returns: [[116.57045]
 [134.71213]
 [134.71213]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.05366516113281



action possibilites: [-1] 
expected returns: [[133.43362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 137.0093994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[120.19128]
 [135.00099]
 [132.18562]
 [104.59776]
 [101.88541]
 [133.94356]
 [152.74559]
 [140.47289]
 [170.29362]
 [153.60095]
 [121.84611]
 [130.21039]
 [137.59314]
 [115.40064]
 [136.65584]
 [136.12718]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.43362426757812



buy possibilites: [-1] 
expected returns: [[148.79706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [10. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 170.2936248779297






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  1. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  1. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 0.  1. 11.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[166.98271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.79705810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.75246]
 [163.80765]
 [131.27066]
 [172.73682]
 [168.03828]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 163.31332397460938



buy possibilites: [-1] 
expected returns: [[141.63748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11.  0. 11.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 172.73681640625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 91.6021 ]
 [129.49872]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.63748168945312



action possibilites: [-1] 
expected returns: [[85.66835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 1. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.4410400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 70.14417 ]
 [ 83.970375]
 [ 81.32727 ]
 [ 53.576195]
 [ 82.97906 ]
 [101.59584 ]
 [ 89.2726  ]
 [102.47434 ]
 [ 71.65304 ]
 [ 86.42344 ]
 [ 85.544495]
 [ 85.11264 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 1. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.66835021972656



buy possibilites: [-1] 
expected returns: [[111.88028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29. 11.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 1. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.47433471679688






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 11.] 
cards in discard: [3. 3. 0. 0. 1. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 11.] 
cards in discard: [3. 3. 0. 0. 1. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3. 11.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[123.024826]
 [124.617096]
 [141.22385 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 11.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.88027954101562



action possibilites: [-1] 
expected returns: [[99.620255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.93479919433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 88.40324]
 [100.70505]
 [ 69.39428]
 [109.14081]
 [104.78636]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.62025451660156



buy possibilites: [-1] 
expected returns: [[97.00294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 109.14080810546875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  8.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.  8. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  8.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.  8. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [ 3.  3.  0.  0.  1.  3.  6.  0.  0.  1.  0. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29.  8.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.  8. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 86.9268  ]
 [105.09186 ]
 [ 91.394356]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  8.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 11. 10.  8. 11. 10.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.00293731689453



action possibilites: [-1.  8. 25.] 
expected returns: [[106.321945]
 [110.471466]
 [139.78973 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.70082092285156



action possibilites: [-1] 
expected returns: [[130.18088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 139.78973388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.89043 ]
 [124.66528 ]
 [121.84962 ]
 [ 91.41215 ]
 [142.87305 ]
 [130.07053 ]
 [127.22769 ]
 [125.930466]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.18087768554688



buy possibilites: [-1] 
expected returns: [[119.27619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  8. 29.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.873046875






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [11.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[128.40721]
 [133.1012 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.27619171142578



action possibilites: [-1] 
expected returns: [[88.598114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 127.11346435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.61832 ]
 [57.153458]
 [92.16411 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.59811401367188






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  6.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 10. 29.] 
adversary cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[118.99762]
 [120.56664]
 [137.18816]
 [120.56664]
 [138.1708 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10. 29.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.16410827636719



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[150.78107]
 [152.50122]
 [170.07819]
 [152.50122]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  0.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  8.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.34146118164062



action possibilites: [-1] 
expected returns: [[118.15404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 173.63644409179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[103.34716 ]
 [120.19843 ]
 [116.98511 ]
 [ 82.580215]
 [140.10764 ]
 [126.35225 ]
 [123.138916]
 [121.44075 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  5.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.15403747558594



buy possibilites: [-1] 
expected returns: [[142.16763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11. 29. 25.  0.  3.  3.  8. 29.  0.  8. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 140.1076202392578






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 6.  0. 11.  6.  3.  0.  0. 11.  3. 10.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 11.] 
expected returns: [[59.349533]
 [74.185005]
 [74.185005]
 [62.982704]
 [73.42493 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.16763305664062



action possibilites: [-1. 29.  8. 11.] 
expected returns: [[70.627884]
 [88.07309 ]
 [74.54461 ]
 [87.150665]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.01380920410156



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[104.237366]
 [108.46153 ]
 [120.824615]
 [120.824615]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.07308197021484



action possibilites: [-1] 
expected returns: [[121.589485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.05184936523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.02052 ]
 [124.50992 ]
 [121.56131 ]
 [ 90.02612 ]
 [123.4039  ]
 [143.01938 ]
 [130.22589 ]
 [143.93642 ]
 [110.76755 ]
 [127.218155]
 [126.25694 ]
 [125.772156]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.58948516845703



buy possibilites: [-1] 
expected returns: [[122.216965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 143.93641662597656






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 29. 10. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 8. 11. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 10. 10.] 
expected returns: [[136.2892 ]
 [141.2499 ]
 [155.15793]
 [156.15929]
 [137.98085]
 [137.98085]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.21696472167969



action possibilites: [-1.  8. 11. 10. 10. 10.] 
expected returns: [[138.0856 ]
 [142.95103]
 [156.48412]
 [139.77626]
 [139.77626]
 [139.77626]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 152.0572052001953



action possibilites: [-1] 
expected returns: [[109.41201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 159.6030731201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.30937]
 [ 69.50458]
 [108.5426 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.4120101928711






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 3. 0. 0. 0. 1. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[57.992332]
 [73.47038 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.5426025390625



action possibilites: [-1] 
expected returns: [[41.562714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.12484741210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.048265 ]
 [35.9682   ]
 [11.4148445]
 [43.197258 ]
 [39.237442 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  8.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.562713623046875



buy possibilites: [-1] 
expected returns: [[40.75083]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  8.  0. 11. 10. 29. 11.  8. 10. 10. 10. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  7.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0.  1.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 43.19727325439453






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [10.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.  0.] 
cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  7.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 11.] 
cards in discard: [1. 3. 0. 0. 0. 1. 3. 0. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  7.  9.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  7.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  7.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[60.159973]
 [76.539856]
 [61.42959 ]
 [91.98398 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  8. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.750831604003906



action possibilites: [-1] 
expected returns: [[45.411346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  7. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.8019790649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.409372]
 [12.911737]
 [40.575768]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 10.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  7. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  6.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.411346435546875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  6.  0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  7. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  1.  3.  0.  0.  3.  3.  0. 14.  8. 10. 11.  0.  1.
  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0. 11.  8.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [29.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[51.824265]
 [68.77657 ]
 [67.90506 ]
 [56.047115]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  8.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.57577133178711



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[60.924103]
 [74.9077  ]
 [64.63193 ]
 [62.21485 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8. 10.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.7765884399414



action possibilites: [-1] 
expected returns: [[46.09644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [1. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.32479095458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.411797]
 [44.80882 ]
 [42.82401 ]
 [21.417051]
 [57.23491 ]
 [48.60164 ]
 [46.61685 ]
 [45.649124]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  4.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [1. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.096439361572266



buy possibilites: [-1] 
expected returns: [[49.643486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [1. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 57.234920501708984






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [1. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 10. 29. 10.  3.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 28. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 10. 29. 10.  3.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 1.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [29. 10. 29. 10.  3.] 
adversary cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [29. 10. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[22.206211]
 [36.61    ]
 [23.362074]
 [36.61    ]
 [23.362074]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29. 10.  3.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.64348602294922



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[17.675707]
 [18.85641 ]
 [30.737368]
 [18.85641 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  3.  0.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.60999298095703



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[ 8.105017]
 [ 9.005714]
 [ 9.005714]
 [10.839424]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  8.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 11 29 11 29 10 25  8 29 10  8 11 10 11 10 29 10 10  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.73737907409668



action possibilites: [-1] 
expected returns: [[52.13569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 21.389070510864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.259987]
 [48.20472 ]
 [45.474037]
 [17.65539 ]
 [65.5474  ]
 [53.501495]
 [50.69759 ]
 [49.330036]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  3.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.13568878173828



buy possibilites: [-1] 
expected returns: [[46.82006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  3. 29. 10.  0. 10. 11. 10. 11. 29. 11.  0.  0.  8. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  2.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 6. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.54740905761719






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [3. 1. 0. 6. 0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  2.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [3. 1. 0. 6. 0. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 27. 30.  8.  6. 10.  2.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [3. 1. 0. 6. 0. 1. 4.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10. 11. 11. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11] -> size -> 24 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10. 11. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.  8.] 
expected returns: [[32.570152]
 [33.543587]
 [45.449917]
 [45.449917]
 [33.543587]
 [35.805035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  2. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.82006072998047



action possibilites: [-1] 
expected returns: [[44.594566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  8.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.49778747558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.869478]
 [16.753284]
 [44.554947]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  8.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 1. 0. 3.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.594566345214844






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 6. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 0. 3.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11.] 
expected returns: [[11.29911  ]
 [22.928715 ]
 [12.0995655]
 [22.928715 ]
 [22.259329 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29. 11.] 
cards in discard: [10. 11. 10. 11. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.554931640625



action possibilites: [-1. 10. 29. 11. 11.] 
expected returns: [[24.184517]
 [25.14609 ]
 [38.02371 ]
 [37.262985]
 [37.262985]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11. 11.] 
cards in discard: [10. 11. 10. 11. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.9287052154541



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[26.941652]
 [28.059439]
 [40.644993]
 [40.644993]
 [28.059439]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 10.] 
cards in discard: [10. 11. 10. 11. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.02369689941406



action possibilites: [-1] 
expected returns: [[53.475082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.096839904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[40.21283 ]
 [51.8     ]
 [49.584267]
 [26.569807]
 [65.9374  ]
 [56.031696]
 [52.775986]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  2.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.47508239746094



buy possibilites: [-1] 
expected returns: [[58.535122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  1.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.9374008178711






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  6. 10.  1.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  8. 11.  0.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  6. 10.  1.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  8. 11.  0.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 29.  8.  6. 10.  1.  6.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  8. 11.  0.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  6. 10.  1.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [11. 25.  8. 11.  0.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [11. 25.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 11.] 
expected returns: [[45.03855 ]
 [57.97141 ]
 [71.264145]
 [48.43776 ]
 [57.97141 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  8. 11.  0.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  6. 10.  1.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  0.  8.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8] -> size -> 33 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.53512191772461



action possibilites: [-1] 
expected returns: [[14.806505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  0.  0.  8.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  0.  8.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8  6] -> size -> 34 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.26414489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  1.8782501]
 [ 10.843267 ]
 [-11.389561 ]
 [ 17.140203 ]
 [ 13.902662 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  0.  0.  8.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  5.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  0.  8.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8  6] -> size -> 34 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.80650520324707



buy possibilites: [-1] 
expected returns: [[-1.7549193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  0.  0.  8.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 6.  3. 14.  0.  8.] 
adversary cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8  6] -> size -> 34 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -119 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 17.140207290649414






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.  0.  8.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
 14  8  6  6  3  4  0  3  8  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8. 25. 11.
  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8. 25. 11.
  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8. 25. 11.
  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3.  1.  0.  6.  0.  1.  4.  1. 11.  0.  0.  0.  0.  3.  6.  1.  0.  3.
  3.  8. 11.  3. 10.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [10.  3.  0. 29. 29.] 
adversary cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8. 25. 11.
  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[ 0.30219793]
 [ 1.0022335 ]
 [10.43852   ]
 [10.43852   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29. 29.] 
cards in discard: [10. 11. 10. 11. 10.  8. 10. 11. 29. 29. 11.  0. 10. 11. 10.  8. 25. 11.
  8. 11.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.7549192905426025



action possibilites: [-1. 29. 11.] 
expected returns: [[46.946148]
 [60.60466 ]
 [59.889183]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.514195442199707



action possibilites: [-1. 11. 11.] 
expected returns: [[52.559868]
 [67.91254 ]
 [67.91254 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.96541213989258



action possibilites: [-1] 
expected returns: [[58.928123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [10.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -1 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.61048126220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[44.91486 ]
 [58.10795 ]
 [55.58016 ]
 [28.858515]
 [74.020294]
 [62.962845]
 [59.07068 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [10.  3. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  1.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.928123474121094



buy possibilites: [-1] 
expected returns: [[51.688072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [10.  3. 15. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 11.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.02030181884766






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  5. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 29. 11. 29.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 8. 11. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29. 11. 29.] 
expected returns: [[29.072931]
 [31.906183]
 [40.067757]
 [40.70582 ]
 [40.067757]
 [40.70582 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29. 11. 29.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.688072204589844



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[25.318977]
 [28.387522]
 [37.938156]
 [26.323698]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.251619338989258



action possibilites: [-1] 
expected returns: [[24.318525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 28.387521743774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.940649  ]
 [-0.82982016]
 [23.700518  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.318525314331055






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 10. 10.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 26. 29.  8.  4. 10.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 10. 10.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 10. 10.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 8. 11. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10. 10.] 
expected returns: [[-6.9135723]
 [-4.5875587]
 [ 2.730966 ]
 [-6.237533 ]
 [-6.237533 ]
 [-6.237533 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 10. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.70051383972168



action possibilites: [-1] 
expected returns: [[8.467337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -4.58755350112915





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -3.4460459]
 [-17.118778 ]
 [  8.194605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.467336654663086






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11.  0. 25.] 
adversary cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[41.614407]
 [43.609016]
 [43.609016]
 [46.126926]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 25.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  4.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.194608688354492



action possibilites: [-1] 
expected returns: [[10.465982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.12690734863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 3.918078 ]
 [ 9.582445 ]
 [ 8.477995 ]
 [-3.5383315]
 [11.613371 ]
 [10.367893 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  4.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.465982437133789



buy possibilites: [-1] 
expected returns: [[9.847685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0.  0.  8.] 
cards in discard: [10.  3. 15. 11. 29. 29. 11.  0. 11. 11. 29. 15. 29. 11.  8. 10. 15. 11.
  8. 10. 10. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 0. 3. 8.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    4.    0.] 
sum of rewards: -101.0 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.61335563659668






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 8.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 8.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 29.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8. 10. 10.] 
expected returns: [[10.718927]
 [10.981348]
 [21.74248 ]
 [13.244907]
 [11.507692]
 [11.507692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.847684860229492



action possibilites: [-1. 15. 10.] 
expected returns: [[31.838816]
 [32.141556]
 [32.75808 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.933778762817383



action possibilites: [-1. 15. 11.] 
expected returns: [[37.115005]
 [37.48013 ]
 [50.676548]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.] 
cards in discard: [ 8. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 32.75806427001953



action possibilites: [-1. 15.] 
expected returns: [[24.41943]
 [24.63009]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11
 10 10 11  8 15 11 15 15  8 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 40.59457778930664



action possibilites: [-1] 
expected returns: [[24.352379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 24.630083084106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[12.405235  ]
 [22.857012  ]
 [20.766874  ]
 [-0.23993635]
 [22.07862   ]
 [26.938128  ]
 [36.67903   ]
 [13.58103   ]
 [24.143894  ]
 [23.779295  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.352378845214844



buy possibilites: [-1] 
expected returns: [[27.522966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 10. 15. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10. 11. 15.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.679039001464844






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  8. 11. 15. 15.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  9.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  8. 11. 15. 15.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [25.  8. 11. 15. 15.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [25.  8. 11. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11. 15. 15.] 
expected returns: [[17.344738]
 [36.5225  ]
 [19.543503]
 [26.12163 ]
 [17.526588]
 [17.526588]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 11. 15. 15.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  3.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.522966384887695



action possibilites: [-1] 
expected returns: [[1.3650961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15. 15. 10. 10.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.52250289916992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.2680273]
 [-14.196182 ]
 [  1.2382455]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 15. 15. 10. 10.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6] -> size -> 40 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.365096092224121






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 1. 3.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 29.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 1. 3.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 25. 29.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 1. 3.] 
cards in discard: [ 6. 11.  1.  0.  6.  3. 16.  0.  6.  0.  0.  0.  3.  3.  0.  0.  3.  6.
  6.  3.  6.  0.  3.  8. 25.  1.  0. 10.  0.  0.  6.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 11.  0.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [10. 10. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[ 4.3789525]
 [ 5.435638 ]
 [ 5.435638 ]
 [ 5.435638 ]
 [16.166655 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.  0.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11.  4.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 41 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.2382473945617676



action possibilites: [-1] 
expected returns: [[3.254109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  4.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 41 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 7.478374004364014





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.417432 ]
 [-16.510952 ]
 [  2.8054671]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [11.  4.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 41 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.2541089057922363






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [11.  4.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  1  0 10  3  6  1  6  0 11  0  1  3
  8  6  6  3  4  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [29.  0.  8. 11. 29.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [29.  0.  8. 11. 29.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [29.  0.  8. 11. 29.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  8. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 29.] 
expected returns: [[-12.320322]
 [ -5.237122]
 [-10.763592]
 [ -5.678297]
 [ -5.237122]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 11. 29.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.805459499359131



action possibilites: [-1.  8. 11.] 
expected returns: [[-7.8236904]
 [-6.3206625]
 [-0.8490267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.04351806640625



action possibilites: [-1] 
expected returns: [[12.415047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -6.3206682205200195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.790397 ]
 [11.167089 ]
 [-0.5245886]
 [14.201071 ]
 [13.0971985]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  3.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.415046691894531



buy possibilites: [-1] 
expected returns: [[8.597809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 14.201055526733398






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 8.] 
cards in discard: [8. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6
  6  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [8. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [8. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [8. 3. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-15.85087  ]
 [ -9.981026 ]
 [ -9.981026 ]
 [-14.4876175]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.597808837890625



action possibilites: [-1] 
expected returns: [[-24.428896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -14.487621307373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-30.7554  ]
 [-37.747105]
 [-24.428888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  8.] 
cards in discard: [ 8. 10. 15. 29. 29. 10. 11. 15. 25.  8. 11. 15. 15. 10. 10. 15. 11. 10.
 10. 10.  0. 11. 29. 15.  8. 29. 11.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 6. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.428895950317383






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 15.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 15.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 3.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 15.  8. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 15.  8. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 29. 11.] 
expected returns: [[ 7.9581933]
 [ 9.857372 ]
 [ 8.037273 ]
 [ 9.857372 ]
 [16.61801  ]
 [16.09166  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8. 29. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -24.428895950317383



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[32.34528 ]
 [34.485672]
 [34.485672]
 [41.87056 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.] 
cards in discard: [15. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.159032344818115



action possibilites: [-1.  8.] 
expected returns: [[15.953238]
 [17.762148]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15. 11.  8. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.538576126098633



action possibilites: [-1] 
expected returns: [[15.472319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 11.  8. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 17.76213264465332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 4.7093596]
 [11.921192 ]
 [-5.199681 ]
 [17.368315 ]
 [14.536633 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11.  8. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  2.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.472318649291992



buy possibilites: [-1] 
expected returns: [[10.086815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11.  8. 29.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0 -40   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 17.36829948425293






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15.  0. 10.] 
adversary cards in discard: [15. 11.  8. 29.  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15.  0. 10.] 
adversary cards in discard: [15. 11.  8. 29.  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 6 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11. 15. 15.  0. 10.] 
adversary cards in discard: [15. 11.  8. 29.  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11. 15. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15. 10.] 
expected returns: [[21.806446]
 [29.792604]
 [21.888351]
 [21.888351]
 [22.275465]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15.  0. 10.] 
cards in discard: [15. 11.  8. 29.  8. 29. 29.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  3.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.086814880371094



action possibilites: [-1] 
expected returns: [[-9.405721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0. 10.] 
cards in discard: [15. 11.  8. 29.  8. 29. 29.  8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: -31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 23.69914436340332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-17.181318]
 [-25.20089 ]
 [ -9.878365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0. 10.] 
cards in discard: [15. 11.  8. 29.  8. 29. 29.  8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.405720710754395






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 10. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8. 29.  8. 29. 29.  8. 15. 11. 15. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8 15] -> size -> 40 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  1.  8.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [15. 10. 15. 10. 15.] 
adversary cards in discard: [15. 11.  8. 29.  8. 29. 29.  8. 15. 11. 15. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8 15] -> size -> 40 
adversary victory points: 1
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 7 
Witch: 1 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 10. 15. 10. 15.] 
cards in discard: [15. 11.  8. 29.  8. 29. 29.  8. 15. 11. 15. 15.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 29 11 29 25  8 29  8 11 10 11 10 29 10 10  8 10 11 11 10
 10 11  8 15 11 15 15  8 15 29 15 15  8 15  8 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 28.  8.  2.  9.  0.  0.  8.  5.  9. 10.  0. 10.  2.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3. 0. 8. 3. 6. 6. 0. 3. 6. 3. 0. 3. 0. 3. 1. 0. 0. 1. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  1  0 10  3  6  1  6  0  0  1  3  8  6  6
  3  0  3  8  6  0  6 16  3  6 25  6  4  0  0  0  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000065 

action type: buy - action -1.0
Learning step: -120002.1953125
desired expected reward: -120012.0703125



