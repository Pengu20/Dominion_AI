 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.78183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0       20        0
        0        0        0      -20        0     -300        0        0] 
sum of rewards: -3000635 

action type: buy - action 6.0
Learning step: -120024.734375
desired expected reward: -120041.3125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.55965 ]
 [116.68385 ]
 [111.57709 ]
 [ 94.67871 ]
 [118.85601 ]
 [115.754166]
 [110.64738 ]
 [113.08009 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.44773864746094



buy possibilites: [-1] 
expected returns: [[106.104706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.85602569580078






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  0.  0.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.23829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.10470581054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.032196]
 [114.222336]
 [109.20256 ]
 [ 92.00946 ]
 [112.39865 ]
 [116.4015  ]
 [113.23925 ]
 [118.8648  ]
 [ 99.23772 ]
 [108.21946 ]
 [107.48671 ]
 [111.789314]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.45736694335938



buy possibilites: [-1] 
expected returns: [[109.17155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 118.86479187011719






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.69437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.17154693603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.821884]
 [104.54193 ]
 [ 99.32607 ]
 [ 81.80559 ]
 [102.54748 ]
 [106.956085]
 [103.44805 ]
 [109.48569 ]
 [ 88.86939 ]
 [ 98.23344 ]
 [ 97.53908 ]
 [102.89836 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.35440063476562



buy possibilites: [-1] 
expected returns: [[134.27565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.48568725585938






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [8. 0. 3. 3. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 3. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 3. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 3. 3. 8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[114.28932]
 [119.55874]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.27565002441406



action possibilites: [-1] 
expected returns: [[133.9215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.91871643066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.1378 ]
 [136.64178]
 [130.87111]
 [111.17277]
 [139.21393]
 [135.48064]
 [129.70995]
 [134.91632]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.92149353027344



buy possibilites: [-1] 
expected returns: [[147.6288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 139.2139129638672






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[108.22897]
 [116.07221]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.62879943847656



action possibilites: [-1.] 
expected returns: [[115.08339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.9725341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[102.70705 ]
 [111.40167 ]
 [106.12149 ]
 [ 88.2799  ]
 [109.44447 ]
 [113.80084 ]
 [110.342224]
 [116.438416]
 [ 95.62027 ]
 [105.06203 ]
 [104.314896]
 [109.21532 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.08338928222656



buy possibilites: [-1] 
expected returns: [[146.43608]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 116.43840789794922






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  3.] 
cards in discard: [11.  0.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  8  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [11.  0.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [11.  0.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[133.10664]
 [137.46706]
 [130.09454]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.4360809326172



action possibilites: [-1] 
expected returns: [[146.31822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.43673706054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[140.12126]
 [147.58516]
 [143.14944]
 [127.60054]
 [149.65604]
 [146.64691]
 [142.20576]
 [146.32811]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.31822204589844



buy possibilites: [-1] 
expected returns: [[169.30211]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 149.6560516357422






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[116.75672 ]
 [119.52759 ]
 [121.644165]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.30210876464844



action possibilites: [-1. 11.] 
expected returns: [[ 99.00711 ]
 [103.823135]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.49022674560547



action possibilites: [-1] 
expected returns: [[137.77158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.11195373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[131.86333]
 [140.0292 ]
 [135.19043]
 [119.58463]
 [138.09158]
 [142.39177]
 [138.9733 ]
 [144.68013]
 [125.65956]
 [134.16197]
 [133.55093]
 [139.32985]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.77157592773438



buy possibilites: [-1] 
expected returns: [[142.81096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.68011474609375






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  8  8  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  8  8 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  8  8 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 8. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[132.5602 ]
 [134.49126]
 [127.00923]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.8109588623047



action possibilites: [-1] 
expected returns: [[151.6353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.88172912597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.4724 ]
 [148.94382]
 [132.51787]
 [152.35262]
 [154.09297]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.6352996826172






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  8  8  8 11  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 11.] 
expected returns: [[128.15538]
 [133.06725]
 [133.06725]
 [122.62975]
 [130.5843 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.0929718017578



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[142.62296]
 [148.04305]
 [135.41626]
 [145.32259]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 132.95899963378906



action possibilites: [-1. 10. 11.] 
expected returns: [[137.02502]
 [129.81572]
 [139.69728]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.0430450439453



action possibilites: [-1] 
expected returns: [[163.82509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 145.2038116455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[154.59459]
 [164.06453]
 [158.56349]
 [138.9086 ]
 [161.7561 ]
 [166.89545]
 [162.75139]
 [169.61873]
 [147.1714 ]
 [157.30074]
 [156.67198]
 [163.39973]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.82508850097656



buy possibilites: [-1] 
expected returns: [[196.14946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.  3.  0.  0. 10. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 169.6187286376953






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10.  8. 11.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 29.] 
expected returns: [[145.58705]
 [147.96713]
 [150.18579]
 [139.87799]
 [150.18579]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 196.1494598388672



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[147.43634]
 [150.4823 ]
 [142.7748 ]
 [152.66954]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 149.8716583251953



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[163.52602]
 [166.7641 ]
 [160.06636]
 [168.68448]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 152.66954040527344



action possibilites: [-1. 11. 10.] 
expected returns: [[163.95723]
 [168.10277]
 [160.93979]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.6844940185547



action possibilites: [-1] 
expected returns: [[179.25395]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 172.4226531982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[173.39691]
 [180.3424 ]
 [176.15233]
 [165.84941]
 [161.52377]
 [178.76503]
 [182.25844]
 [179.503  ]
 [191.81662]
 [184.26915]
 [167.76543]
 [173.97295]
 [175.31294]
 [167.02745]
 [174.71092]
 [178.67482]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 179.2539520263672



buy possibilites: [-1] 
expected returns: [[178.3513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 191.816650390625






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  8  8  8 11  0 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[158.46631]
 [162.76042]
 [160.16493]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 178.35130310058594



action possibilites: [-1. 11. 10.] 
expected returns: [[164.24152]
 [165.68613]
 [156.79654]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 164.87510681152344



action possibilites: [-1] 
expected returns: [[188.97527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 170.6073760986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[177.33643]
 [185.158  ]
 [180.83609]
 [165.17844]
 [187.69481]
 [183.99054]
 [179.73267]
 [187.27997]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  7.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 188.9752655029297



buy possibilites: [-1] 
expected returns: [[143.34122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 187.69480895996094






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11.  0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8 11  0 11] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8.  0.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8.  0.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [ 8.  0.  8. 14.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[184.89983]
 [179.94379]
 [179.94379]
 [187.93352]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 29.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.34121704101562



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[152.35866]
 [149.12589]
 [149.12589]
 [154.01967]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 11.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 188.72023010253906



action possibilites: [-1] 
expected returns: [[177.59218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 156.9052276611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[174.23692]
 [180.10965]
 [176.45464]
 [165.1811 ]
 [181.75436]
 [179.39981]
 [175.7876 ]
 [178.21124]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 177.59217834472656



buy possibilites: [-1] 
expected returns: [[199.17564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0. 10.  3.  0. 10. 11. 29. 11.  3.  0.  0. 10.
 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 181.7543487548828






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5.  9. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.] 
cards in discard: [14.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 10. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[182.94554]
 [190.34279]
 [177.61311]
 [177.61311]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 199.17564392089844



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[199.84981]
 [194.36987]
 [194.36987]
 [201.57753]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 189.67208862304688



action possibilites: [-1] 
expected returns: [[182.63454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 205.7268524169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[175.05077]
 [178.5091 ]
 [162.20131]
 [181.89186]
 [183.82286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.63453674316406






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 14.] 
cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [10. 11. 29.  0. 10.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [14.  3. 11. 11.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  3.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [14.  3. 11. 11.  0.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [11.  0. 10.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[233.57777]
 [235.85829]
 [228.29602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 769   0] 
sum of rewards: 764 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 211.5662078857422



action possibilites: [-1] 
expected returns: [[198.09756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 240.1966552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[191.14305]
 [179.20674]
 [198.01973]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 198.09756469726562






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8 11  0 11 14  3 14  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11. 29. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11. 29. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11. 29. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 11. 29. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 11. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29. 29.] 
expected returns: [[242.42018]
 [235.78343]
 [243.32199]
 [243.32199]
 [245.19824]
 [245.19824]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 29. 29.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14. 11.  3. 11.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 198.0196990966797



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[246.22792]
 [242.17558]
 [249.23944]
 [249.23944]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 14. 11.  3. 11.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 241.36312866210938



action possibilites: [-1] 
expected returns: [[238.3908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  3. 11.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 253.7321014404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[231.95438]
 [234.95123]
 [220.27103]
 [238.12323]
 [238.97592]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 14. 11.  3. 11.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 238.3907928466797






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  3. 11.] 
cards in discard: [0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [25. 29.  0.  0.  0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 11.] 
cards in discard: [0. 8. 8. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[258.76367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 878   0] 
sum of rewards: 903 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 263.0435485839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[248.92064]
 [254.8857 ]
 [251.5898 ]
 [239.35245]
 [256.72018]
 [254.05098]
 [256.04306]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  2.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 258.763671875



buy possibilites: [-1] 
expected returns: [[237.0514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 256.7201843261719






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  7.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.] 
adversary cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[231.16998]
 [224.00703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3. 14.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0. 11.  3.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 905   0] 
sum of rewards: 930 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 253.6109161376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[221.15051]
 [209.5309 ]
 [230.64273]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [10. 29. 11. 10. 10.  3.  0. 10. 29. 15. 11.  0. 10. 29. 15. 29. 11. 10.
 11.  0. 25. 29. 11.  0.  0.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [11.  3. 14.  0. 11.] 
adversary cards in discard: [ 8. 14.  8.  0. 11.  3.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 231.1699676513672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11.  3. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.  0. 11.] 
cards in discard: [ 8. 14.  8.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  0. 11.] 
cards in discard: [ 8. 14.  8.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  0. 11.] 
cards in discard: [ 8. 14.  8.  0. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 25.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 10.] 
expected returns: [[204.53934]
 [198.11655]
 [216.25328]
 [198.11655]
 [198.11655]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [14. 11.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 230.6427459716797



action possibilites: [-1] 
expected returns: [[223.17508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 10. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [14. 11.  0.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8  0  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 214.72608947753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.08037]
 [197.80687]
 [223.03691]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10. 10. 29. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [14. 11.  0.  8.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8  0  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 223.17507934570312






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [14. 11.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0.  8.  1.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  8 11  0 11 14  3 14  3 11  0  1  8  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10.  3. 29.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10.  3. 29.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10.  3. 29.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 11. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[221.56429]
 [223.74689]
 [221.83235]
 [214.12755]
 [223.74689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  3. 29.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  0. 14.] 
adversary cards in discard: [ 6.  8. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 223.0369110107422



action possibilites: [-1. 11. 29.] 
expected returns: [[185.85704]
 [186.56432]
 [188.43346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  0. 14.] 
adversary cards in discard: [ 6.  8. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 219.91639709472656



action possibilites: [-1. 11. 10.] 
expected returns: [[196.92287]
 [198.61977]
 [190.44868]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  0. 14.] 
adversary cards in discard: [ 6.  8. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 184.4292755126953



action possibilites: [-1] 
expected returns: [[193.2661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  3.  0. 14.] 
adversary cards in discard: [ 6.  8. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 179 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 203.44371032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[186.16705]
 [189.43877]
 [173.06715]
 [193.02257]
 [193.49698]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  3.  0. 14.] 
adversary cards in discard: [ 6.  8. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 193.26609802246094






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0. 14.] 
cards in discard: [ 6.  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 14.] 
cards in discard: [ 6.  8. 14. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 14.] 
cards in discard: [ 6.  8. 14. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 29. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[245.86453]
 [249.64198]
 [241.61052]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 10.  0.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 193.4969482421875



action possibilites: [-1. 10. 10.] 
expected returns: [[250.02785]
 [244.88983]
 [244.88983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 246.08497619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[241.75096]
 [247.90099]
 [244.4187 ]
 [232.62683]
 [249.77057]
 [247.03279]
 [248.72446]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  1.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 250.02786254882812



buy possibilites: [-1] 
expected returns: [[272.22714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  0.  0.  8.] 
adversary cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
adversary owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 249.7705841064453






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  8.] 
cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0 11 14  3 14  3 11  0  8  0  6 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  8. 14. 16. 11.  8.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 11.  0. 10.  0.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[225.0287 ]
 [225.18982]
 [225.18982]
 [219.21964]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10.  0.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 14.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 272.2271423339844



action possibilites: [-1] 
expected returns: [[267.12717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 14.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 223.32627868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[260.1157 ]
 [263.03452]
 [249.91635]
 [265.65323]
 [268.19327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 14.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 267.1271667480469






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [16. 14.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0 14 14  3 11  0  8  0  6 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15. 11.  0. 11.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15. 11.  0. 11.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15. 11.  0. 11.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15. 11.  0. 11.] 
adversary cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 15. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 11.] 
expected returns: [[197.46257]
 [198.56813]
 [190.85182]
 [198.56813]
 [198.56813]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11.  0. 11.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8.  6.] 
adversary cards in discard: [ 0.  8. 14.  3.] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 268.1932678222656



action possibilites: [-1] 
expected returns: [[252.73738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 11.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8.  6.] 
adversary cards in discard: [ 0.  8. 14.  3.] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 196.3953399658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[246.98099]
 [239.45343]
 [253.01997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0. 11.] 
cards in discard: [25. 10.  3. 10. 10. 29. 29. 10.  0. 15. 29. 29. 11.  3. 10.  3. 11. 29.
  0. 10.  0. 10.  1. 11. 11.  0. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  8.  6.] 
adversary cards in discard: [ 0.  8. 14.  3.] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 252.7373809814453






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8.  6.] 
cards in discard: [ 0.  8. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6.] 
cards in discard: [ 0.  8. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6.] 
cards in discard: [ 0.  8. 14.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6.] 
cards in discard: [ 0.  8. 14.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 15. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15. 10.] 
expected returns: [[164.85718]
 [169.92224]
 [157.17717]
 [157.17717]
 [157.81555]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 253.02003479003906



action possibilites: [-1. 15. 15.] 
expected returns: [[188.63626]
 [182.59612]
 [182.59612]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.] 
cards in discard: [10. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 162.2535400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[181.16595]
 [184.47351]
 [168.3831 ]
 [187.92772]
 [189.29387]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.] 
cards in discard: [10. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 188.63624572753906






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 11.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  0.  1. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[155.70476]
 [149.93391]
 [150.2429 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  8.  3. 11.  0.] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0  -20    0    0
 1112    0] 
sum of rewards: 1177 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 219.73471069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.20587]
 [150.95737]
 [138.94489]
 [153.55797]
 [155.55507]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  8.  3. 11.  0.] 
adversary owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 155.5195770263672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 14.] 
cards in discard: [ 0. 14.  8.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14 14  3 11  0  8  0  6  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 25. 10. 29.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 14.  8.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14  3 11  8  6  0  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 25. 10. 29.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 14.  8.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14  3 11  8  6  0  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 25. 10. 29.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 25. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 29.] 
expected returns: [[183.37135]
 [185.01372]
 [196.29947]
 [176.56438]
 [187.31491]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 29.  0.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  9.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14  3 11  8  6  0  0  0  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.55506896972656



action possibilites: [-1] 
expected returns: [[176.4171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0.  3. 10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8 14  3 11  8  6  0  0  0  0  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 196.29946899414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[169.7646 ]
 [158.26202]
 [177.52077]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 29.  0.  3. 10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8  8 14  3 11  8  6  0  0  0  0  6] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 176.41709899902344






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14  3 11  8  6  0  0  0  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 29.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[153.90897]
 [155.7786 ]
 [157.64696]
 [148.88596]
 [148.88596]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 10. 10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [6. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 177.52076721191406



action possibilites: [-1. 10. 10.] 
expected returns: [[172.66118]
 [166.2289 ]
 [166.2289 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [6. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 153.7670440673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[164.84502]
 [157.7791 ]
 [172.7918 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [6. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 172.66114807128906






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8. 11.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  3. 10.  0. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [6. 0. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 28. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 11.] 
cards in discard: [6. 0. 8. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  0.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[197.1397 ]
 [191.71808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0  -20    0    0
 1112    0] 
sum of rewards: 1147 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 202.3472137451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[187.9018 ]
 [194.63824]
 [190.82591]
 [178.21498]
 [193.71405]
 [195.33133]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 197.1396942138672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0. 11.  0. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  8.  9.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 11. 11.] 
adversary cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[202.97563]
 [208.07222]
 [206.18634]
 [206.18634]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [16. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0  -20    0    0
 1104    0] 
sum of rewards: 1139 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 205.34793090820312



action possibilites: [-1. 10.] 
expected returns: [[214.22154]
 [210.96751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [16. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 204.3970947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[209.8202 ]
 [205.74998]
 [214.22154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10. 11. 29. 15. 15.  0.  0. 11. 15. 10.  1. 25. 11. 10. 29.  0.  3. 10.
 11. 29. 29.  3. 10. 10.  3. 11.  1. 10.  0.  0.  0. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [16. 14.  8. 11.  0.  0.] 
adversary owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3 16] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 214.22154235839844






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 3.] 
cards in discard: [16. 14.  8. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 14  3 11  8  0  0  0  0  6  0  3 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [16. 14.  8. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [16. 14.  8. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [16. 14.  8. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[146.42725]
 [151.20479]
 [140.92041]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 214.22154235839844



action possibilites: [-1. 10.] 
expected returns: [[171.24574]
 [165.52818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 151.8247528076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[163.32315]
 [170.78711]
 [166.48149]
 [151.72581]
 [168.93135]
 [169.76572]
 [175.16919]
 [157.89864]
 [165.05705]
 [171.50995]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  5.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 171.24574279785156



buy possibilites: [-1] 
expected returns: [[196.2064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 3. 11. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 175.16920471191406






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 25. 11.  0. 10.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 25. 11.  0. 10.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11. 10.] 
expected returns: [[148.66786]
 [151.41039]
 [158.6789 ]
 [149.60783]
 [142.69177]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 11.  0. 10.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  8.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [3. 8. 0. 3. 6.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 196.20640563964844



action possibilites: [-1] 
expected returns: [[159.152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10. 10. 11.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [3. 8. 0. 3. 6. 6.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.5578155517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[150.3461 ]
 [137.42012]
 [160.59467]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10. 10. 11.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [3. 8. 0. 3. 6. 6.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.15199279785156






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [3. 8. 0. 3. 6. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 29. 29.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [3. 8. 0. 3. 6. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 29. 29.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[167.08307]
 [170.72766]
 [170.72766]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 29.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.59466552734375



action possibilites: [-1. 29.] 
expected returns: [[217.8462]
 [220.8907]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 167.24501037597656



action possibilites: [-1.] 
expected returns: [[209.96965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 217.4351043701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[202.67894]
 [208.51642]
 [205.31216]
 [193.82152]
 [206.9774 ]
 [207.58939]
 [212.01816]
 [198.6252 ]
 [204.27226]
 [210.70116]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  4.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 209.9696502685547



buy possibilites: [-1] 
expected returns: [[196.09335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 212.01817321777344






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 10. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 10. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 16.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 10. 10. 15.  3.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 10. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[141.9793 ]
 [136.76942]
 [136.76942]
 [136.5053 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 15.  3.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 14.  3.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  0. 16.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 196.09335327148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[134.63174]
 [125.98326]
 [141.21722]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 15.  3.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 14.  3.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  0. 16.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 141.97927856445312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  0.  0.] 
cards in discard: [ 3. 11.  8.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 15. 11. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  3.  0.  0.] 
cards in discard: [ 3. 11.  8.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 15. 11. 11.  0.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 15. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11. 11.] 
expected returns: [[186.10716]
 [186.19972]
 [185.65585]
 [189.86736]
 [189.86736]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11. 11.  0.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 141.2172088623047



action possibilites: [-1] 
expected returns: [[149.31763]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 11.  0.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 189.05674743652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[145.95648]
 [138.40443]
 [149.31761]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 11.  0.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.317626953125






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15.  0. 11. 10.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1. 11. 10. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 15.  0. 11. 10.] 
adversary cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1. 11. 10. 15. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1] -> size -> 40 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 15.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 10.] 
expected returns: [[148.14192]
 [149.18217]
 [143.88927]
 [149.18217]
 [144.18843]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 11. 10.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1. 11. 10. 15. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14. 16.  6.  3.  0.] 
adversary cards in discard: [3. 3. 6. 0. 8.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.317626953125



action possibilites: [-1] 
expected returns: [[130.93819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 10.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1. 11. 10. 15. 11.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14. 16.  6.  3.  0.] 
adversary cards in discard: [3. 3. 6. 0. 8.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 147.6835479736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.7141 ]
 [112.56457]
 [130.93819]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 11. 10.] 
cards in discard: [ 3. 11. 29. 29.  1. 10.  0. 25. 29. 11.  0. 10. 10. 11.  0. 10.  0.  3.
 29. 29. 29.  1.  0. 10. 10. 15.  3.  1. 11. 10. 15. 11.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14. 16.  6.  3.  0.] 
adversary cards in discard: [3. 3. 6. 0. 8.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.9381866455078






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [14. 16.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  6.  3.  0.] 
cards in discard: [3. 3. 6. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 15. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  0.] 
cards in discard: [3. 3. 6. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.] 
adversary cards in discard: [ 3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3.  0.] 
cards in discard: [3. 3. 6. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  6.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.] 
adversary cards in discard: [ 3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  3.  0.] 
cards in discard: [3. 3. 6. 0. 8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 10.] 
adversary cards in discard: [ 3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[132.81804]
 [139.30806]
 [128.30836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.] 
cards in discard: [ 3. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3  8] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0  -60    0    0
 1278    0] 
sum of rewards: 1273 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 267.8778381347656



action possibilites: [-1. 10.] 
expected returns: [[142.93318]
 [138.85817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 15.  0. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3  8] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.9754638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.05168]
 [126.02345]
 [143.1373 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 15.  0. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
adversary owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3  8] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 142.93316650390625






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3 11  8  0  0  0  6  0  3 16  0  6  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11. 29.  1.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11. 29.  1.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  6.  0.  8.  8. 14. 16.  6.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 11. 29.  1.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11. 11. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[148.11336]
 [149.00172]
 [149.00172]
 [150.50493]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.13726806640625



action possibilites: [-1. 11. 10.] 
expected returns: [[141.80733]
 [143.18839]
 [137.4281 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 147.33665466308594



action possibilites: [-1] 
expected returns: [[125.442444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 141.48727416992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[120.796524]
 [123.30237 ]
 [109.76938 ]
 [126.29024 ]
 [126.258316]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  5.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.44244384765625



buy possibilites: [-1] 
expected returns: [[145.88557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [14.  6. 16.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 126.29023742675781






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [14.  6. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 16.  8.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  6  0  3 16  0  6  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 16.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3. 15.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
expected returns: [[190.02246]
 [184.23526]
 [192.83784]
 [191.14632]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 29. 11.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [ 0.  8. 14. 16.  0.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.8855743408203



action possibilites: [-1. 15.] 
expected returns: [[191.0229 ]
 [183.22943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [ 0.  8. 14. 16.  0.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 194.7877655029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[178.47835]
 [187.25726]
 [182.22398]
 [166.86409]
 [185.08415]
 [185.99306]
 [192.35396]
 [172.45824]
 [180.5313 ]
 [188.31927]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  3.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [ 0.  8. 14. 16.  0.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 191.0229034423828



buy possibilites: [-1] 
expected returns: [[205.92482]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [ 0.  8. 14. 16.  0.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 192.3539581298828






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [ 0.  8. 14. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [ 0.  8. 14. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 25. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 11. 10.] 
expected returns: [[175.03267]
 [170.14613]
 [179.68373]
 [170.14613]
 [174.2526 ]
 [170.14613]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 11. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  7.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 205.92481994628906



action possibilites: [-1] 
expected returns: [[212.455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10. 11.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 179.68374633789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[204.3562 ]
 [207.18687]
 [195.75749]
 [209.42488]
 [212.45499]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 10. 11.  1.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 212.4550018310547






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  0. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 11.  0. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[143.32445]
 [142.23312]
 [139.66914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8. 16.  0.  3.] 
adversary cards in discard: [6. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 212.4550018310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[138.20024]
 [141.27519]
 [140.1089 ]
 [132.42934]
 [140.60623]
 [140.84175]
 [142.85551]
 [135.38237]
 [139.66534]
 [143.32445]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8. 16.  0.  3.] 
adversary cards in discard: [6. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 143.32443237304688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 16.  0.  3.] 
cards in discard: [6. 0. 0. 3. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  3  8  0  3 16  0  6  3  8  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [6. 0. 0. 3. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [6. 0. 0. 3. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 29.  0. 10.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[91.06685]
 [86.50726]
 [92.73424]
 [86.50726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.32443237304688



action possibilites: [-1. 10. 10.] 
expected returns: [[128.72615]
 [124.17435]
 [124.17435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.94499206542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.62836 ]
 [114.665825]
 [128.72615 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 128.7261505126953






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 16.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  8. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  0  3 16  0  6  3  8  0  6  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29. 29.
  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29. 29.
  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29. 29.
  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 15.  0. 29. 11.] 
adversary cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29. 29.
  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 15.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 11.] 
expected returns: [[184.88112]
 [185.12097]
 [180.24747]
 [185.12097]
 [184.16768]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0. 29. 11.] 
cards in discard: [ 3. 15.  0. 10. 29. 10. 11.  1.  1.  8. 29. 11.  0. 10.  3. 11. 29. 29.
 15.  0.  1. 25. 10. 10. 11. 10. 11.  1.  1.  0. 11.  0. 10.  0. 29. 29.
  3. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.7261505126953



action possibilites: [-1. 15. 29. 10.] 
expected returns: [[126.832794]
 [120.34228 ]
 [129.41928 ]
 [120.697495]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 10.] 
cards in discard: [ 0. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 186.16355895996094



action possibilites: [-1. 15.] 
expected returns: [[110.88158]
 [104.97083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0. 11. 10. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 125.55500793457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[103.447426]
 [106.16424 ]
 [ 95.05559 ]
 [108.556206]
 [110.94966 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0. 11. 10. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  8.  8. 14.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.88158416748047






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 0.  8.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 11.  1. 29. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [ 0.  8.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29. 11.  1. 29. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 11.  1. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 10.] 
expected returns: [[185.62506]
 [185.34148]
 [184.40868]
 [185.34148]
 [180.33682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1. 29. 10.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 110.94967651367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[178.11577]
 [180.15552]
 [171.97832]
 [181.5181 ]
 [184.77425]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  1. 29. 10.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 185.6250457763672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 10. 25. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 10. 25. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10. 10. 25. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 10. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 25. 10.] 
expected returns: [[148.09439]
 [142.75218]
 [142.75218]
 [142.75218]
 [154.14241]
 [142.75218]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 25. 10.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  6.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 3. 8. 3. 6. 6.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 184.7742462158203



action possibilites: [-1] 
expected returns: [[168.46442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.  3.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 3. 8. 3. 6. 6. 6.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.14242553710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[159.64624]
 [147.88005]
 [168.30402]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 10.  3.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 3. 8. 3. 6. 6. 6.] 
adversary owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0  0  6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 168.46441650390625






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [0. 3. 8. 3. 6. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14  8  3  0  6  3  8  0  6  3  0  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 3. 8. 3. 6. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  0  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 3. 8. 3. 6. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  0  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 3. 8. 3. 6. 6. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3. 11.  8.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[184.18924]
 [185.71288]
 [185.71288]
 [182.7592 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  8.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.30406188964844



action possibilites: [-1] 
expected returns: [[148.52695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 183.65589904785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[140.14728]
 [132.26051]
 [147.29665]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  0  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.52694702148438






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  0  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  1.  0. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  1.  0. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  1.  0. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 29.  1.  0. 10.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 29.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[195.43349]
 [192.80003]
 [193.44255]
 [189.36955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1.  0. 10.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  8.  8.  3. 14.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.29664611816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[188.07828]
 [191.5087 ]
 [190.00966]
 [184.11406]
 [190.86865]
 [195.43349]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  1.  0. 10.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  8.  8.  3. 14.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 195.43348693847656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 0.  8.  8.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 15.  1.  0. 29.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [ 0.  8.  8.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 15.  1.  0. 29.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 15.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[112.313  ]
 [107.21719]
 [111.0238 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.  0. 29.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 195.43348693847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[106.029945]
 [109.15139 ]
 [107.66793 ]
 [103.19758 ]
 [101.91823 ]
 [108.229965]
 [108.5771  ]
 [114.35051 ]
 [111.0238  ]
 [104.299805]
 [106.916   ]
 [103.99861 ]
 [107.217186]
 [112.31301 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  0. 29.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  9.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 112.31300354003906



buy possibilites: [-1] 
expected returns: [[152.61351]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.  0. 29.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 8. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0 -110    0    0
  250    0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 114.35049438476562






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25] -> size -> 46 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[153.24434]
 [154.16505]
 [149.08954]
 [154.16505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 14.  3.] 
adversary cards in discard: [3. 8. 3. 0. 6.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.61351013183594



action possibilites: [-1] 
expected returns: [[84.166855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 14.  3.] 
adversary cards in discard: [3. 8. 3. 0. 6.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 152.6565399169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.46286 ]
 [79.33431 ]
 [72.19732 ]
 [80.85585 ]
 [84.166855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  6. 14.  3.] 
adversary cards in discard: [3. 8. 3. 0. 6.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.16685485839844






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.  3.] 
cards in discard: [3. 8. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.  1.  3.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 14.  3.] 
cards in discard: [3. 8. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 30. 25. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.  1.  3.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 14.  3.] 
cards in discard: [3. 8. 3. 0. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.  1.  3.] 
adversary cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1. 11. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [15. 29. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29.] 
expected returns: [[155.299  ]
 [149.5143 ]
 [155.21175]
 [155.21175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29.  1.  3.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1. 11. 10. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.16685485839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.05586]
 [150.31708]
 [141.4154 ]
 [151.89989]
 [155.299  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29. 29.  1.  3.] 
cards in discard: [ 0. 11. 10. 10. 29. 29. 15. 29. 11.  1. 29. 10. 25. 10. 10. 10. 10.  3.
  0.  1. 11.  3. 11.  8.  0. 11. 29.  1.  0. 10. 25.  1. 15.  1.  0. 29.
  1. 11. 10. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 155.2989959716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  1. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  1. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  1. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  1. 11.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 15.] 
expected returns: [[106.036255]
 [107.08269 ]
 [107.08269 ]
 [103.9829  ]
 [ 99.69856 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  8. 15.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 8.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.2989959716797



action possibilites: [-1] 
expected returns: [[98.58809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8. 15.] 
cards in discard: [1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 8.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 104.95832824707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[92.77331 ]
 [95.41325 ]
 [82.681244]
 [98.318954]
 [98.46443 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8. 15.] 
cards in discard: [1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [0. 3. 6. 3. 6. 8.] 
adversary owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.58808898925781






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 0.] 
cards in discard: [0. 3. 6. 3. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  6  3  8  6  3  0  6  0  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 3. 6. 3. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 3. 6. 3. 6. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 29.  1. 10. 11.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 29.  1. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 11.] 
expected returns: [[134.48584]
 [130.30553]
 [137.58948]
 [130.30553]
 [136.05615]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  1. 10. 11.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.46442413330078



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[125.95296]
 [121.84872]
 [121.84872]
 [130.71104]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 134.3604736328125



action possibilites: [-1. 10.] 
expected returns: [[105.28223]
 [ 99.91456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 119.89697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.2883  ]
 [101.079666]
 [ 91.12061 ]
 [103.80283 ]
 [105.53276 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.28221130371094






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  1. 15.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  1. 15.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  0. 14.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [29.  1.  1. 15.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[174.59074]
 [177.81114]
 [168.80608]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 15.  0.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.53276062011719



action possibilites: [-1. 15.] 
expected returns: [[194.53435]
 [190.16911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 15.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 173.97964477539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[188.99947]
 [195.85524]
 [191.86261]
 [181.72198]
 [177.92001]
 [194.44658]
 [195.0645 ]
 [205.73299]
 [199.27788]
 [183.49042]
 [189.64803]
 [182.81464]
 [190.40288]
 [194.83202]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 15.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  8.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 194.5343475341797



buy possibilites: [-1] 
expected returns: [[143.28227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 15.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -140    0    0
  250    0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 205.73297119140625






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0. 14.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 1. 29. 10.  3. 10.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 1. 29. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[147.33455]
 [148.33177]
 [143.3814 ]
 [143.3814 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10.  3. 10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.2822723388672



action possibilites: [-1. 10. 10.] 
expected returns: [[167.89378]
 [162.66719]
 [162.66719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 146.0972137451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.50496]
 [156.78775]
 [167.89378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 6. 3. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 167.89378356933594






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 11.  0. 25. 25.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 11.  0. 25. 25.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [15. 11.  0. 25. 25.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 11.  0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25. 25.] 
expected returns: [[174.40097]
 [171.66264]
 [174.25345]
 [177.46182]
 [177.46182]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 25. 25.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  5.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 8.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.89378356933594



action possibilites: [-1] 
expected returns: [[148.25075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0. 25.  0.  3.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 8. 6.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.4618377685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.5601 ]
 [145.94676]
 [140.2538 ]
 [147.35956]
 [148.25072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0. 25.  0.  3.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 6. 3. 6. 8. 6.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.25074768066406






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 6. 3. 6. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 29. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 6. 3. 6. 8. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  2.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 29. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  8.  6. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 29. 10. 10.  0.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 29. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[72.22633 ]
 [75.426956]
 [69.081345]
 [69.081345]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 10.  0.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.25074768066406



action possibilites: [-1. 10. 10.] 
expected returns: [[105.15057]
 [100.27223]
 [100.27223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 72.56100463867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.78276]
 [100.95737]
 [ 91.50673]
 [102.73999]
 [105.15056]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.15055847167969






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 24. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  8. 14.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 29.] 
adversary cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[104.56362]
 [106.06636]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 29.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29.  6.  6.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.15055847167969



action possibilites: [-1.] 
expected returns: [[85.897865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29.  6.  6.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.57696533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[76.948105]
 [81.913315]
 [79.35991 ]
 [72.79175 ]
 [70.98905 ]
 [80.44151 ]
 [81.00138 ]
 [90.777756]
 [84.993866]
 [74.23431 ]
 [78.13789 ]
 [73.85534 ]
 [78.58821 ]
 [85.897865]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  7.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29.  6.  6.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.89786529541016



buy possibilites: [-1] 
expected returns: [[69.73731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1. 11.  1. 11.  8. 15.  1. 11. 10. 10. 29. 29. 10.  0. 29. 25. 29.  1.
  1. 15.  1. 11. 29. 10.  3. 10. 25. 15. 11.  0. 25.  0.  3.  3. 10. 29.
 10.  0. 10.  0. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 29.  6.  6.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.] 
adversary owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -150    0    0
  250    0] 
sum of rewards: 205 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 90.77772521972656






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 29.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  6.  6.] 
cards in discard: [ 3.  0.  6.  0.  8. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [25.  1. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  8  6  3  0  6  0  0  3  0  0  0  0  6 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [25.  1. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [25.  1. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [25.  1. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [25.  1. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  1. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11. 11.] 
expected returns: [[128.50401]
 [138.45715]
 [131.24393]
 [129.5223 ]
 [129.5223 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 23. 30.  8.  4.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.  0. 29.  8.] 
adversary owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.73731231689453



action possibilites: [-1] 
expected returns: [[114.26016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 11. 11. 10.  1.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 23. 30.  8.  3.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.  0. 29.  8.  6.] 
adversary owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 138.4571533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[106.63093 ]
 [111.53215 ]
 [108.64715 ]
 [ 99.11295 ]
 [110.393456]
 [110.914665]
 [114.30142 ]
 [102.87541 ]
 [107.65389 ]
 [111.28253 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 11. 11. 10.  1.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30. 23. 30.  8.  3.  8.  0.  4.  6.  1.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.  0. 29.  8.  6.] 
adversary owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.26016235351562



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 1 
Witch: 4 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 29. 11. 11. 10.  1.] 
cards in discard: [29.] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 10 11 10 29 10 10 29 10
 25 10 11 10 11 10 15 15 11 15 11  1  1 29 29  1  1  1  8 29  1 25  1  1
 25 25 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 23. 30.  8.  3.  8.  0.  4.  6.  0.  8. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  6.  0.  8. 14.  0.  0.  0. 29.  8.  6.] 
adversary owned cards: [14  8  8  3  0  0  0  3  0  0  0  0  6 29  3  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0    -160       0       0      64       0] 
sum of rewards: 2999949 

action type: buy - action 29.0
Learning step: 119993.390625
desired expected reward: 120107.6953125



