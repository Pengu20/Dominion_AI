 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.03333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5  500    6   20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: 221 

action type: buy - action 6.0
Learning step: 8.019001960754395
desired expected reward: 68.63897705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[294.04602]
 [303.81174]
 [302.2298 ]
 [281.2287 ]
 [297.51135]
 [314.17654]
 [304.5269 ]
 [310.56522]
 [293.1754 ]
 [303.11008]
 [304.24188]
 [321.81384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.287928581237793
desired expected reward: 314.5954284667969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.42896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.415743827819824
desired expected reward: 313.3981018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[316.30362]
 [323.8665 ]
 [322.2853 ]
 [306.15106]
 [331.51627]
 [324.54697]
 [323.07712]
 [337.44388]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.959120750427246
desired expected reward: 335.5941467285156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.30872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.285286903381348
desired expected reward: 327.1585693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[288.20795]
 [297.79822]
 [296.32715]
 [279.27167]
 [275.6487 ]
 [291.62027]
 [308.1088 ]
 [298.49075]
 [314.29684]
 [304.53867]
 [287.43036]
 [291.4548 ]
 [297.18857]
 [280.5346 ]
 [298.35056]
 [315.83032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.714310646057129
desired expected reward: 309.7037048339844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.2447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.771800994873047
desired expected reward: 307.0585021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[309.06375]
 [316.41537]
 [298.91116]
 [318.4279 ]
 [335.89798]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.220240592956543
desired expected reward: 328.4336853027344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.93417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.342857360839844
desired expected reward: 325.5550842285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[283.00577]
 [292.74777]
 [291.2616 ]
 [270.32434]
 [286.47388]
 [303.22873]
 [293.44745]
 [299.59875]
 [282.22104]
 [292.13318]
 [293.31662]
 [310.9202 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.511117935180664
desired expected reward: 303.91290283203125



buy possibilites: [-1] 
expected returns: [[288.38812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -23.1774845123291
desired expected reward: 247.1468505859375






Player: 1 
cards in hand: [8. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[361.11932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.41540002822876
desired expected reward: 280.97271728515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[341.1544 ]
 [351.04025]
 [349.64948]
 [328.69577]
 [361.7903 ]
 [351.72314]
 [350.5095 ]
 [369.9134 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -11.182463645935059
desired expected reward: 351.2178039550781



buy possibilites: [-1] 
expected returns: [[320.37872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 11.0
Learning step: -11.130995750427246
desired expected reward: 350.65936279296875






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 3. 0. 3. 4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.64163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4] -> size -> 15 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -11.63532543182373
desired expected reward: 308.743408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[287.75354]
 [298.04987]
 [296.34958]
 [274.24454]
 [291.41156]
 [308.2492 ]
 [298.80386]
 [304.75754]
 [286.79288]
 [297.27234]
 [298.41843]
 [315.361  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4] -> size -> 15 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -11.4146728515625
desired expected reward: 301.19024658203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[330.5984 ]
 [322.53903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -11.006906509399414
desired expected reward: 304.35406494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[288.34586]
 [298.0162 ]
 [296.47803]
 [274.87106]
 [308.33237]
 [298.70398]
 [297.34186]
 [315.87723]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -11.235161781311035
desired expected reward: 298.0785827636719



buy possibilites: [-1] 
expected returns: [[289.63806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [0. 0. 0. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -51.0 

action type: buy - action 8.0
Learning step: -10.968342781066895
desired expected reward: 287.7356262207031






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 0 3 8 0 0 4 8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  8  0  0  4  8 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[276.7833]
 [269.6351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  3. 14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  8  0  0  4  8 14] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -10.907609939575195
desired expected reward: 278.7304382324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[249.94801]
 [257.3996 ]
 [238.64468]
 [259.1572 ]
 [275.1831 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  3.  0.  0.  3.  3. 14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  8  0  0  4  8 14] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -10.618254661560059
desired expected reward: 267.92694091796875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [4. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 8. 0.] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  3  8  0  0  4  8 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 14.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[275.891  ]
 [260.37744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [11.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -8.810328483581543
desired expected reward: 266.3727722167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[253.74338]
 [260.4282 ]
 [243.29057]
 [262.34744]
 [277.46875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [11.  0.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.888839721679688
desired expected reward: 266.3651123046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[322.87427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -7.742523193359375
desired expected reward: 269.7262268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[295.97592]
 [305.3733 ]
 [303.96448]
 [283.64645]
 [299.32126]
 [315.31894]
 [306.0052 ]
 [311.8109 ]
 [295.1361 ]
 [304.7682 ]
 [305.80408]
 [322.22836]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.300106048583984
desired expected reward: 313.29608154296875



buy possibilites: [-1] 
expected returns: [[281.26654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 9 

action type: buy - action 14.0
Learning step: -7.978308200836182
desired expected reward: 287.1578063964844






Player: 1 
cards in hand: [8. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 3.] 
cards in discard: [ 0.  0.  3. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  0  0  8 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  3. 11.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14] -> size -> 14 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  0.  3. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  3. 11.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  0.  3. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  3. 11.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[269.489  ]
 [253.80441]
 [262.18628]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  3. 11.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.735206604003906
desired expected reward: 272.5313415527344



action possibilites: [-1] 
expected returns: [[321.19043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 23 

action type: gain_card_n - action 10
Learning step: -4.271148204803467
desired expected reward: 248.6875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[293.7942 ]
 [301.41977]
 [282.3233 ]
 [303.79602]
 [320.548  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  9. 10.  9.  7. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.742646217346191
desired expected reward: 312.4477844238281



buy possibilites: [-1] 
expected returns: [[268.69235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0. 15.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -23.270587921142578
desired expected reward: 259.0527038574219






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.9875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [14.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.153217315673828
desired expected reward: 260.53912353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[266.57336]
 [273.60785]
 [256.34033]
 [275.30334]
 [290.59058]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [14.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.285161018371582
desired expected reward: 278.777099609375



buy possibilites: [-1] 
expected returns: [[266.14383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  3.] 
adversary cards in discard: [14.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -9.37011432647705
desired expected reward: 243.796875






Player: 1 
cards in hand: [ 3.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  3.] 
cards in discard: [14.  0.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 15.  0.] 
adversary cards in discard: [0. 3. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [14.  0.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [14.  0.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10. 10.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [14.  0.  8.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.76093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0  -60    0    0    0    0    0 -600
   25    0] 
sum of rewards: -659 

action type: discard_down_to_3_cards - action 8
Learning step: -36.66171646118164
desired expected reward: 170.14756774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[277.89832]
 [281.69254]
 [270.50778]
 [284.4961 ]
 [292.65475]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.482159614562988
desired expected reward: 285.1288146972656



buy possibilites: [-1] 
expected returns: [[334.42334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -9.070389747619629
desired expected reward: 268.827880859375






Player: 1 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  8. 14.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 30. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.] 
adversary cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[221.64243]
 [211.32278]
 [202.42291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.] 
cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [ 1. 29. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0  -90    0    0    0    0    0 -600
   25    0] 
sum of rewards: -689 

action type: discard_down_to_3_cards - action 1
Learning step: -39.26675033569336
desired expected reward: 154.1898956298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[200.89973]
 [191.7503 ]
 [218.3294 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.] 
cards in discard: [ 0.  3.  0.  6.  3.  0.  3. 15.  0.  6.  0.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 14.] 
adversary cards in discard: [ 1. 29. 14.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.505000591278076
desired expected reward: 213.27317810058594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 14.] 
cards in discard: [ 1. 29. 14.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 1. 29. 14.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 1. 29. 14.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 29. 29.  8.  8. 10.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 1. 29. 14.  3.  0.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[271.5147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0  -90    0    0    0    0    0 -600
   25    0] 
sum of rewards: -689 

action type: discard_down_to_3_cards - action 1
Learning step: -37.6114387512207
desired expected reward: 148.0083465576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.91988]
 [260.53204]
 [259.1034 ]
 [242.72502]
 [268.38367]
 [261.1107 ]
 [259.8134 ]
 [273.85663]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.808209419250488
desired expected reward: 263.17193603515625



buy possibilites: [-1] 
expected returns: [[297.8477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -8.64441967010498
desired expected reward: 244.27542114257812






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  6. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 29. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  6. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 28. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  6. 11.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [15.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[277.81628]
 [267.28207]
 [274.14212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6. 11.  0.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 14. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.377690315246582
desired expected reward: 287.4700012207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[259.55713]
 [265.0186 ]
 [249.7657 ]
 [267.37698]
 [276.9434 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6. 11.  0.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 14. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.568259239196777
desired expected reward: 269.2063293457031



buy possibilites: [-1] 
expected returns: [[262.30698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6. 11.  0.] 
cards in discard: [8. 0. 0. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 14. 29.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 3.0
Learning step: -8.099023818969727
desired expected reward: 256.9195861816406






Player: 1 
cards in hand: [ 3.  0. 14. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 14. 29.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 14.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 14. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 14. 16.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 14.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 16.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 27. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14. 16.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 27. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14. 16.] 
cards in discard: [3. 3. 0. 0. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.65744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -30    0    0    0 -120    0    0    0    0    0 -600
   25    0] 
sum of rewards: -728 

action type: discard_down_to_3_cards - action 9
Learning step: -44.29872131347656
desired expected reward: 186.47601318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[142.50987]
 [132.83957]
 [164.07167]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  0.  3. 15.  0.  6. 11.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.261446952819824
desired expected reward: 155.5170135498047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  7. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  0.  8.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[219.70619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 29.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -4.930629253387451
desired expected reward: 159.1410369873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[202.14047]
 [208.05206]
 [206.58766]
 [194.03835]
 [213.71432]
 [208.59949]
 [207.21591]
 [217.186  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 29.  8.  8.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 29.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.824826240539551
desired expected reward: 210.97315979003906



buy possibilites: [-1] 
expected returns: [[211.46999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [ 8. 29.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -22.143842697143555
desired expected reward: 171.89447021484375






Player: 1 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  6.  0.] 
adversary cards in discard: [6. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  6. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  6.  0.] 
adversary cards in discard: [6. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  6.  0.] 
adversary cards in discard: [6. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[257.03122]
 [240.48157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.  0.] 
cards in discard: [6. 6. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [ 8. 29.  3.  1.  0.  8.  8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -7.193702697753906
desired expected reward: 204.27627563476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[232.40578]
 [240.1885 ]
 [220.30867]
 [242.21027]
 [258.46677]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  6.  0.] 
cards in discard: [6. 6. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [ 8. 29.  3.  1.  0.  8.  8. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -9.248132705688477
desired expected reward: 243.21791076660156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 16.  0.  3.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.  8. 14.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 16.  0.  3.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.  8. 14.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 16.  0.  3.] 
cards in discard: [ 8. 29.  3.  1.  0.  8.  8. 14.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[169.68127]
 [160.54936]
 [165.74919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -11.419295310974121
desired expected reward: 247.04747009277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[157.28036]
 [161.51163]
 [149.8258 ]
 [163.43585]
 [172.39981]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -6.79866361618042
desired expected reward: 159.95361328125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 14.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.  3.  8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.  3.  8. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.  3.  8. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[121.424614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.  3.  8. 11.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [14.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -40    0    0    0  -90    0    0    0    0    0 -900
   25    0] 
sum of rewards: -1009 

action type: discard_down_to_3_cards - action 0
Learning step: -54.72137451171875
desired expected reward: 85.2801513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.88797 ]
 [112.39114 ]
 [110.92865 ]
 [101.542435]
 [118.09998 ]
 [112.909096]
 [111.483536]
 [122.45724 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  6.  0.  3.  0.  0.  0.  3. 15.  6.  0.  3.  8. 11.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [14.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -5.63315486907959
desired expected reward: 115.64249420166016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [14.  8.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  8.  0.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  8.  0.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[200.1791 ]
 [194.56638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  8. 29.  3.  3.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -3.92052960395813
desired expected reward: 118.53668212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[175.3027 ]
 [182.70155]
 [181.47612]
 [166.50352]
 [190.82826]
 [183.21962]
 [182.12953]
 [196.75522]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  8. 29.  3.  3.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.806959629058838
desired expected reward: 189.36990356445312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  8. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 29.  3.  3.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 25. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [15. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [15. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[231.50987]
 [216.49437]
 [206.89452]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  0.  8.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -7.098633766174316
desired expected reward: 189.65658569335938



action possibilites: [-1] 
expected returns: [[193.02888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 14.0
Learning step: -6.55042028427124
desired expected reward: 195.49681091308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[172.88322]
 [180.89925]
 [179.08922]
 [165.25761]
 [161.96632]
 [175.61496]
 [188.89424]
 [181.62221]
 [194.33977]
 [186.08849]
 [171.6916 ]
 [174.60439]
 [179.9429 ]
 [165.65306]
 [180.64294]
 [194.12814]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5. 10.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -6.673581123352051
desired expected reward: 186.3553009033203



buy possibilites: [-1] 
expected returns: [[235.53682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 26 

action type: buy - action 25.0
Learning step: -3.1174094676971436
desired expected reward: 191.22235107421875






Player: 1 
cards in hand: [3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  8.  0.  0.  0.  1.  3. 16.  0.  0.  3.  3.  8.  1. 29.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[65.94927]
 [57.1706 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6. 0.] 
cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -12.124293327331543
desired expected reward: 223.4125213623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.95204 ]
 [45.516346]
 [66.487854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 6. 0.] 
cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -3.4662063121795654
desired expected reward: 58.89704513549805



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29  1 16  3  3  8  8  0  1  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  9.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[135.49657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -2.001896858215332
desired expected reward: 64.48597717285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.78228 ]
 [122.76333 ]
 [121.64683 ]
 [111.12144 ]
 [128.76752 ]
 [123.158745]
 [122.13811 ]
 [133.12125 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -5.549914836883545
desired expected reward: 128.78329467773438



buy possibilites: [-1] 
expected returns: [[150.80653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 0.  3.  0.  0. 11. 25. 14. 15.  0.  0.  0.  6.  3.  8.  6.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 10.0
Learning step: -3.513758897781372
desired expected reward: 118.62435913085938






Player: 1 
cards in hand: [8. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 8.] 
cards in discard: [29.  0. 16.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 8.] 
cards in discard: [29.  0. 16.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10] -> size -> 23 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[246.59233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  9. 10.  9.] 
adversary cards in hand: [29. 14.  3.  3.  8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.797351837158203
desired expected reward: 147.00918579101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[232.5769 ]
 [237.84341]
 [236.8092 ]
 [225.21709]
 [243.56421]
 [238.27103]
 [237.3629 ]
 [247.81017]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  9. 10.  9.] 
adversary cards in hand: [29. 14.  3.  3.  8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.346056938171387
desired expected reward: 233.56394958496094



buy possibilites: [-1] 
expected returns: [[176.22618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [29. 14.  3.  3.  8.] 
adversary cards in discard: [29.  0. 16.  0.  0.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 10.0
Learning step: -8.703056335449219
desired expected reward: 228.65985107421875






Player: 1 
cards in hand: [29. 14.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  3.  3.  8.] 
cards in discard: [29.  0. 16.  0.  0.  3.  8.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  3.  3.  8.] 
cards in discard: [29.  0. 16.  0.  0.  3.  8.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 24 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[191.61705]
 [176.95924]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 6.] 
cards in discard: [10.  0.  6.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -6.3598952293396
desired expected reward: 169.8662872314453



action possibilites: [-1] 
expected returns: [[222.82538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [10.  0.  6.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 6
Learning step: -3.6983182430267334
desired expected reward: 145.53945922851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[213.63423]
 [205.68034]
 [229.3586 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [10.  0.  6.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -7.3905205726623535
desired expected reward: 215.4348602294922



buy possibilites: [-1] 
expected returns: [[146.30417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -10.139869689941406
desired expected reward: 203.494384765625






Player: 1 
cards in hand: [ 0.  0.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  8.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[196.95409]
 [197.82346]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  7.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 16.  3.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -40    0    0    0  -90    0    0    0    0    0 -900
   68    0] 
sum of rewards: -967 

action type: discard_down_to_3_cards - action 3
Learning step: -48.01353073120117
desired expected reward: 33.5047492980957



action possibilites: [-1] 
expected returns: [[277.30725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 16.  3.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -24 

action type: take_action - action 25.0
Learning step: -4.777629375457764
desired expected reward: 191.56321716308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[255.64005]
 [260.91626]
 [247.37709]
 [262.34912]
 [273.25723]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 16.  3.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -9.129511833190918
desired expected reward: 268.177734375



buy possibilites: [-1] 
expected returns: [[301.77695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 16.  3.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -8.742021560668945
desired expected reward: 246.8980255126953






Player: 1 
cards in hand: [ 0.  3. 14. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 16.  3.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  0. 10.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  3.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  8. 10.  9.] 
adversary cards in hand: [15. 14.  0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  3.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [15. 14.  0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[126.32211]
 [114.96365]
 [107.96187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.
 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  8.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0 -120    0    0    0    0    0 -600
   68    0] 
sum of rewards: -687 

action type: discard_down_to_3_cards - action 9
Learning step: -36.976806640625
desired expected reward: 69.99343872070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.03315]
 [101.87577]
 [127.73718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  0.] 
cards in discard: [10.  0.  6.  0.  0.  3.  0.  8.  0.  6.  0.  0.  0. 25.  0.  3.  6.  0.
 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 29.  8.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -5.3687238693237305
desired expected reward: 120.9533920288086



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  8.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 29 16  3  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[92.31484]
 [83.35574]
 [88.35776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  8.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -5.676078796386719
desired expected reward: 122.06107330322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.690125]
 [72.53716 ]
 [92.47395 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  8.] 
adversary cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.7777488231658936
desired expected reward: 85.65503692626953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  8.] 
cards in discard: [29. 14.  0.  0.  3.  1.  6. 10. 14.  0.  3. 16.  3.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  8 14  0 14 16  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  5.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  8.] 
adversary cards in discard: [ 0. 15.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[79.33685]
 [65.48574]
 [66.40716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [ 0. 15.  3.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29.  8.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -4.279415130615234
desired expected reward: 88.19453430175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.640083]
 [61.19082 ]
 [49.014023]
 [62.699   ]
 [75.83564 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  8.] 
cards in discard: [ 0. 15.  3.  6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 29.  8.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.510486602783203
desired expected reward: 72.18461608886719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  0.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 29.  8.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 29.  8.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 29.  8.] 
cards in discard: [ 8. 29.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[157.63997]
 [142.29327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3. 10.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -1.594559907913208
desired expected reward: 74.24105834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[143.67574]
 [149.06464]
 [147.77974]
 [136.49861]
 [154.58508]
 [149.52057]
 [148.30717]
 [157.95213]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3. 10.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.672828197479248
desired expected reward: 151.5431365966797



buy possibilites: [-1] 
expected returns: [[113.76464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  0. 14.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  3. 10.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -7 

action type: buy - action 1.0
Learning step: -5.243527412414551
desired expected reward: 143.82110595703125






Player: 1 
cards in hand: [14.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 10.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[213.0181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0    0  -90    0    0    0    0    0 -600
   59    0] 
sum of rewards: -656 

action type: discard_down_to_3_cards - action 2
Learning step: -29.135122299194336
desired expected reward: -6.574522018432617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.31543]
 [191.14206]
 [180.8084 ]
 [192.03873]
 [201.24272]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 24. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -7.0507049560546875
desired expected reward: 196.9105224609375



buy possibilites: [-1] 
expected returns: [[79.04966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 15.  3.  6. 11. 10.  0.  0.  3.  8.  1.  6.  0.  0.  0. 14.  0.  6.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3.  1.] 
adversary cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: -8.078485488891602
desired expected reward: 183.0635528564453






Player: 1 
cards in hand: [ 0.  0. 14.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  1.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14. 10. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  4.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14. 10. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 8. 29.  8.  0.  0.  6.  0.  3. 29.  8. 14.  0.  3. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14. 10. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [14. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 25.] 
expected returns: [[139.72728 ]
 [123.784424]
 [129.179   ]
 [139.27055 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 25.] 
cards in discard: [0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -10    0    0    0  -90    0    0    0    0    0 -600
   63    0] 
sum of rewards: -641 

action type: discard_down_to_3_cards - action 1
Learning step: -31.190305709838867
desired expected reward: 11.660562515258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.91353]
 [117.09146]
 [138.9588 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10. 25.] 
cards in discard: [0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  6.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.569344997406006
desired expected reward: 132.35459899902344



buy possibilites: [-1] 
expected returns: [[168.55008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10. 25.] 
cards in discard: [0. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -325 

action type: buy - action 6.0
Learning step: -18.312196731567383
desired expected reward: 98.77926635742188






Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6] -> size -> 27 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6] -> size -> 27 
adversary victory points: 0
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[64.58674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  6. 14. 10. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29. 10.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -8.245299339294434
desired expected reward: 160.30477905273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.18643 ]
 [45.425236]
 [45.00433 ]
 [33.483208]
 [42.114746]
 [52.104668]
 [45.680603]
 [49.41927 ]
 [39.957176]
 [45.38667 ]
 [46.106274]
 [58.660683]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  6. 14. 10. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  9.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29. 10.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.275458574295044
desired expected reward: 60.378074645996094



buy possibilites: [-1] 
expected returns: [[86.3122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29. 10.] 
adversary cards in discard: [3. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -20.5 

action type: buy - action 11.0
Learning step: -1.6882094144821167
desired expected reward: 50.416465759277344






Player: 1 
cards in hand: [ 0.  8.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29. 10.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  0 14  3  8  8  0  1  3  3 29  0 29  6 10  0  8  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [3. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [3. 0. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 8. 0.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 6. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[73.78955]
 [64.74827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 8. 0.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -3.9603536128997803
desired expected reward: 82.35185241699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[62.09362 ]
 [66.709076]
 [66.00357 ]
 [56.06359 ]
 [63.756775]
 [72.136055]
 [67.00106 ]
 [69.97933 ]
 [61.59092 ]
 [66.376755]
 [66.78816 ]
 [76.498886]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 8. 0.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  8.  0.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -3.342965841293335
desired expected reward: 70.44658660888672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  3.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  8.  0.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[106.497475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -2.67875075340271
desired expected reward: 73.82012939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.178665]
 [ 96.90316 ]
 [ 85.684715]
 [ 97.82735 ]
 [107.62269 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 23. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.29426383972168
desired expected reward: 102.20320892333984



buy possibilites: [-1] 
expected returns: [[71.11155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 1. 6.] 
adversary cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: -3.545147657394409
desired expected reward: 93.35800170898438






Player: 1 
cards in hand: [8. 3. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 1. 6.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  3  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  3.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  3.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  8.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  3.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6.] 
cards in discard: [ 3.  0.  8.  0.  0.  0.  8.  0. 10.  8. 14.  3.  0.  8.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  3.] 
adversary cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[89.30961]
 [77.09737]
 [83.97031]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 11.  3.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  5.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -1.8173017501831055
desired expected reward: 69.29425048828125



action possibilites: [-1] 
expected returns: [[34.26585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  3.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -295 

action type: gain_card_n - action 3
Learning step: -17.492717742919922
desired expected reward: 52.7812385559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.889252]
 [23.165497]
 [33.225437]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -0.7862801551818848
desired expected reward: 33.47956848144531



buy possibilites: [-1] 
expected returns: [[55.06493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.] 
cards in discard: [ 0.  0.  6. 14. 10. 25. 11.  0.  0.  3.  0.  0.  0.  6.  1.  8.  0.  3.
  0.  3.  0.  3.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -1.3055013418197632
desired expected reward: 24.583744049072266






Player: 1 
cards in hand: [ 8.  0.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29. 14.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[99.35849]
 [91.02184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  8.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -1.3749853372573853
desired expected reward: 53.689945220947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 90.284454]
 [ 94.23428 ]
 [ 93.48438 ]
 [ 85.808945]
 [ 98.92056 ]
 [ 94.576035]
 [ 93.86782 ]
 [102.18102 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  8.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.384227752685547
desired expected reward: 93.33210754394531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  6.  8.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  1.  8.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14. 25.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  1.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14. 25.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14. 25.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1.  8. 14.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 14. 25.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[44.715977]
 [32.27016 ]
 [43.20927 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14. 25.] 
cards in discard: [ 0.  0.  6.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 22. 29.  8.  4.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -4.909533500671387
desired expected reward: 97.27147674560547



action possibilites: [-1] 
expected returns: [[35.75698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 14.  3. 15.] 
cards in discard: [ 0.  0.  6.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: -1.1059309244155884
desired expected reward: 42.103328704833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.515148]
 [19.006798]
 [34.37097 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 14.  3. 15.] 
cards in discard: [ 0.  0.  6.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -0.8708524703979492
desired expected reward: 34.88612747192383



buy possibilites: [-1] 
expected returns: [[54.58184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 14.  3. 15.] 
cards in discard: [ 0.  0.  6.  0. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -1.1976665258407593
desired expected reward: 22.317489624023438






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  7.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[49.508907]
 [47.472042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.8775341510772705
desired expected reward: 52.704307556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.45171 ]
 [44.11507 ]
 [37.638844]
 [44.896675]
 [49.761047]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11] -> size -> 27 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.6811233758926392
desired expected reward: 47.82778549194336



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11. 11.  0.
  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11. 11.  0.
  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [ 0.  8.  0.  0. 29. 14.  0. 10.  6.  8.  1.  8. 14.  6. 15. 11. 11.  0.
  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[63.531643]
 [60.869984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 14. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -1.8247841596603394
desired expected reward: 47.93626022338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.878204]
 [59.09781 ]
 [58.38905 ]
 [51.633507]
 [57.083847]
 [62.034206]
 [59.35963 ]
 [61.02457 ]
 [55.561596]
 [58.698387]
 [58.95783 ]
 [64.62197 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 8. 14. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3] -> size -> 28 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -2.5467369556427
desired expected reward: 60.984920501708984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 14. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.
  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.
  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14. 10.  6.  8.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.
  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[43.605453]
 [40.651623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.
  0. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -3.0179479122161865
desired expected reward: 61.60403060913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.074284]
 [35.241337]
 [43.273792]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  6.  0. 10.  0. 25.  6.  0.  6. 14.  3. 15.  3.  0.  6. 11.  0.
  0. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -2.0102829933166504
desired expected reward: 41.59518051147461



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 21. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[55.08488 ]
 [50.781967]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  8.  1.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -2.2004592418670654
desired expected reward: 41.073333740234375



action possibilites: [-1.] 
expected returns: [[31.928247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  8.  1.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -1.8739855289459229
desired expected reward: 45.97343444824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.45521 ]
 [27.07616 ]
 [26.61083 ]
 [23.883877]
 [23.169043]
 [25.987059]
 [29.065136]
 [27.264978]
 [30.496946]
 [28.367165]
 [25.150684]
 [25.65717 ]
 [26.823446]
 [23.867384]
 [26.940464]
 [30.333014]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  2.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  8.  1.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.2072328329086304
desired expected reward: 30.72101402282715



buy possibilites: [-1] 
expected returns: [[-3.4707994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  8.  1.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -1.5913420915603638
desired expected reward: 25.67363929748535






Player: 1 
cards in hand: [14.  8.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  8.  1.  0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 15.  6.  0.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1. 0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1. 0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  6.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 1. 0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.935562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11. 11. 15.  3.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0    0  -60    0    0    0    0    0 -900
   38    0] 
sum of rewards: -947 

action type: discard_down_to_3_cards - action 2
Learning step: -46.339637756347656
desired expected reward: -43.62590789794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.878128]
 [32.86815 ]
 [51.021286]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11. 11. 15.  3.  0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11] -> size -> 31 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -2.7716832160949707
desired expected reward: 48.16387939453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 11. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  3.  0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  3.  0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  3.  0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.31535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0. 11. 11. 15.  3.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -1.5214693546295166
desired expected reward: 49.49982452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[85.53201 ]
 [89.13045 ]
 [88.49309 ]
 [82.137184]
 [81.087585]
 [86.80174 ]
 [92.941284]
 [89.424126]
 [95.30805 ]
 [91.58516 ]
 [85.12301 ]
 [86.5709  ]
 [88.85547 ]
 [82.485115]
 [89.20883 ]
 [95.65372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0. 11. 11. 15.  3.  0.] 
adversary owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.254913330078125
desired expected reward: 97.06044006347656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 3. 0.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0. 11. 11. 15.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0 14  8  8  0  1  3  3  0 29  6 10  0  8  0  8  0  8 11  0  0
  6 15 11  3  0  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3. 25.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0. 11. 11. 15.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3. 25.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8. 14. 10.  6.  8.  3.  0.  0.  3.  0. 29. 11. 14.  8.  8.  1.  0.
  0. 11. 11. 15.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  3. 25.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[61.099625]
 [54.374138]
 [58.016968]
 [60.45938 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3. 25.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.1897292137146
desired expected reward: 90.4639892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[51.7045  ]
 [47.513115]
 [61.6484  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3. 25.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.515559434890747
desired expected reward: 57.58406448364258



buy possibilites: [-1] 
expected returns: [[55.30249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3. 25.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action 0.0
Learning step: -4.590919017791748
desired expected reward: 47.11357879638672






Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  1.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  3. 11.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [14.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[89.901825]
 [78.443054]
 [86.949326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 11.  0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  0. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -2.5507867336273193
desired expected reward: 52.751705169677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[77.84417]
 [81.06814]
 [72.79413]
 [88.7315 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3. 11.  0.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  0. 29.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.3535475730896
desired expected reward: 85.54827880859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 29.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 11.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  7.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[49.086586]
 [41.53865 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  6. 10.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8. 14.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.128049373626709
desired expected reward: 83.60345458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.23236 ]
 [32.613564]
 [47.661987]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6. 10.] 
cards in discard: [ 8. 10.  0.  0.  3.  1.  0. 15.  0.  6.  6.  0.  0.  0.  0.  0.  0.  0.
  3.  8. 11.  3. 25. 14.  0.  3. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0.  8. 14.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.235275983810425
desired expected reward: 45.851318359375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 14.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [6. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.586668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29  0] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -30     0     0     0  -120     0     0     0     0
     0 -1200    38     0] 
sum of rewards: -1317 

action type: discard_down_to_3_cards - action 8
Learning step: -66.47531127929688
desired expected reward: -50.55510711669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.9818408]
 [0.1214726]
 [6.1064796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.] 
adversary owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29  0] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.0288872718811035
desired expected reward: 5.557780742645264



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 14. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14. 11.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  0 14  8  8  0  1  3  3  0 29 10  0  8  0  8  0  8 11  0  0  6 15 11
  3  0  3 11  0  8 29  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [25.  0.  8. 11.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [25.  0.  8. 11.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [25.  0.  8. 11.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [25.  0.  8. 11.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [25.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[32.491955]
 [31.806831]
 [27.71354 ]
 [30.314812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8. 11.  3.] 
cards in discard: [10.  3.  6.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.] 
adversary owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -1.347498893737793
desired expected reward: 4.758990287780762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.189037]
 [22.109402]
 [32.49439 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8. 11.  3.] 
cards in discard: [10.  3.  6.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [15.  8.  0.  0.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.] 
adversary owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.7152271270751953
desired expected reward: 29.776723861694336



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14 14  8  0  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3
 11  0  8 29  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  3.  6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  3.  6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  3.  6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 8. 10.  0.  0.  0.  0.  8.  0. 29. 29. 11.  6.  3.  3.  0. 14. 11.  0.
  8.  3.  0.  8. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 14.  8.  3.  6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[29.21637 ]
 [22.273642]
 [24.902832]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  3.  6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6 11  8 14 15  6  0  0  0  3  6 25 10 10  0  0
  1  3  6 11  3  6  0  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -2.763007402420044
desired expected reward: 29.731380462646484



action possibilites: [-1] 
expected returns: [[6.8293533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.0660488605499268
desired expected reward: 27.328136444091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.90089  ]
 [1.6778347]
 [6.575218 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  8.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -0.9782927632331848
desired expected reward: 5.851060390472412






Player: 1 
cards in hand: [14.  8.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [14 14  8  1  3  3  0 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11
  0  8 29  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  0.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  0.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 6. 10. 15.  0.  3.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[16.523575]
 [11.126047]
 [11.403812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 15.  0.  3.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [10.  8. 11. 29.  8.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -1.7496395111083984
desired expected reward: 4.825580596923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.400023]
 [ 6.425659]
 [17.292995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 15.  0.  3.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [10.  8. 11. 29.  8.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.2631797790527344
desired expected reward: 14.260398864746094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8. 11. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 29.  8.] 
cards in discard: [8. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  8.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  3  3 29 10  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 8.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 8.  6. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.017042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 15. 29.  0.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.] 
adversary owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -1.9842665195465088
desired expected reward: 15.308732986450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.71052 ]
 [22.865746]
 [18.768612]
 [22.181078]
 [17.268087]
 [16.308666]
 [20.800625]
 [26.399399]
 [28.697374]
 [25.093119]
 [19.260939]
 [20.405973]
 [22.536198]
 [17.402252]
 [22.799503]
 [28.769243]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 15. 29.  0.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.] 
adversary owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.5879921913146973
desired expected reward: 25.42905044555664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 15. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  3 29  0  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 20. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.87713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
adversary owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.791227340698242
desired expected reward: 25.978025436401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[28.370943]
 [32.73181 ]
 [32.05235 ]
 [22.673502]
 [29.946354]
 [37.357162]
 [35.627544]
 [27.893414]
 [32.426247]
 [32.824333]
 [40.723175]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  8.] 
adversary cards in hand: [14.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
adversary owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.433037281036377
desired expected reward: 36.444091796875



buy possibilites: [-1] 
expected returns: [[74.346405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [10.  3.  6.  0.  3. 25.  0.  8. 11.  3.  8.  3.  6.  6. 10. 15.  0.  3.
  0.  0.  0.  1.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [14.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
adversary owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0  3] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -13 

action type: buy - action 15.0
Learning step: -0.6184226870536804
desired expected reward: 32.20591354370117






Player: 1 
cards in hand: [14.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0.  3.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  3 29  8  0  8  0  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0
  0  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[41.769196]
 [39.483433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.550812244415283
desired expected reward: 69.79559326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[28.62202 ]
 [31.079556]
 [24.866938]
 [36.78296 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 19. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.8864219188690186
desired expected reward: 34.825843811035156



buy possibilites: [-1] 
expected returns: [[29.016762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 11.  3.  0.  0.] 
adversary cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: -1.7011016607284546
desired expected reward: 29.37847328186035






Player: 1 
cards in hand: [ 3. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  3.  3.  3. 15.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.  0.] 
cards in discard: [ 8.  6. 11.  0. 29.  8.  8.  8.  3. 15.  3. 29.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 6.  3.  3.  3. 15.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[7.751497]
 [4.816687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  3. 15.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -2.4942853450775146
desired expected reward: 26.522476196289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.4265366]
 [1.7336965]
 [8.009916 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  3. 15.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.4513992071151733
desired expected reward: 6.300097465515137



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [25.  0.  8. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  7. 10.  7.] 
adversary cards in hand: [25.  0.  8. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  8. 10.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [25.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[10.716408]
 [11.167248]
 [ 8.606405]
 [ 8.086397]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8. 10.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  3.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 15.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -1.3677667379379272
desired expected reward: 6.642153263092041



action possibilites: [-1] 
expected returns: [[41.459812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  8.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 15.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 25.0
Learning step: 0.22448329627513885
desired expected reward: 11.391733169555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[30.53806 ]
 [33.397717]
 [32.887356]
 [26.774843]
 [36.32773 ]
 [33.13702 ]
 [38.334007]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  8.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [29.  8. 15.  8. 14.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -1.4746912717819214
desired expected reward: 39.98512268066406






Player: 1 
cards in hand: [29.  8. 15.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15.  8. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 15.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8. 14.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.199284]
 [20.903894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  6. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.1086816787719727
desired expected reward: 36.22532272338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[16.29631 ]
 [17.32186 ]
 [16.875977]
 [14.835716]
 [18.352694]
 [17.010633]
 [19.433033]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  6. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -1.4503686428070068
desired expected reward: 21.74890899658203



buy possibilites: [-1] 
expected returns: [[34.286163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  6. 11.  3.  3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 10.0
Learning step: 0.12090673297643661
desired expected reward: 17.13154411315918






Player: 1 
cards in hand: [ 8.  6. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 11.  3.  3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 11.  3.  3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[85.90123]
 [76.86128]
 [81.83247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -0.5347005724906921
desired expected reward: 33.751461029052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[68.51224 ]
 [73.46922 ]
 [73.0524  ]
 [62.253056]
 [79.220764]
 [73.42249 ]
 [83.84035 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 18. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.2357451915740967
desired expected reward: 82.66548156738281



buy possibilites: [-1] 
expected returns: [[27.525442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
adversary owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: -2.0 

action type: buy - action 3.0
Learning step: -3.1332976818084717
desired expected reward: 69.91909790039062






Player: 1 
cards in hand: [0. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3
 10  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 1. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 1. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  6.  0. 15. 29.  8.  8. 14.  8.  6. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 1. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.830046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -0.9900960922241211
desired expected reward: 26.53534698486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[10.652803 ]
 [14.4814415]
 [13.872076 ]
 [ 6.0126023]
 [12.031408 ]
 [18.61078  ]
 [16.997438 ]
 [10.22014  ]
 [14.193642 ]
 [14.519081 ]
 [21.594126 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 27. 30. 17. 29.  8.  2.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.9489426016807556
desired expected reward: 22.881103515625



buy possibilites: [-1] 
expected returns: [[13.556002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 6.] 
cards in discard: [ 3.  3.  0.  0.  6. 11.  6.  3.  3.  3. 15. 25.  0.  8. 10.  0.  8.  0.
 10. 10.  0.  0.  3.  0.  3.  0. 15.  0.  0. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -316.0 

action type: buy - action 6.0
Learning step: -15.743939399719238
desired expected reward: -9.731338500976562






Player: 1 
cards in hand: [ 6.  0. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  8. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3 29  8  8  8  0  6 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.400412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -1.4412908554077148
desired expected reward: 12.114710807800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.255493]
 [13.455263]
 [13.103443]
 [ 7.559384]
 [ 6.611957]
 [11.429167]
 [17.184795]
 [19.26043 ]
 [15.757854]
 [10.05722 ]
 [11.457882]
 [13.355396]
 [ 8.106844]
 [13.682362]
 [20.090185]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 27. 30. 17. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.8072130680084229
desired expected reward: 17.593198776245117



buy possibilites: [-1] 
expected returns: [[14.3668995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 11.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.  -3.   0.   0.
   2.   0.] 
sum of rewards: -14.0 

action type: buy - action 3.0
Learning step: -1.0319172143936157
desired expected reward: 12.071531295776367






Player: 1 
cards in hand: [ 0. 14.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  0.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [3. 0. 0. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [ 0.  8.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  6.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [ 0.  8.  0. 11. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[37.758007]
 [36.16111 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[   -5     0     2   -10     0     0     0  -120     0     0     0    -3
     0 -1500    84     0] 
sum of rewards: -1552 

action type: discard_down_to_3_cards - action 1
Learning step: -76.5838623046875
desired expected reward: -80.10987854003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.993586]
 [30.828936]
 [37.287766]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 16. 29.  8.  1.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.7465969324111938
desired expected reward: 36.01141357421875



buy possibilites: [-1] 
expected returns: [[77.861855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -328.0 

action type: buy - action 6.0
Learning step: -16.189556121826172
desired expected reward: 14.639379501342773






Player: 1 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  3. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  3. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3.  0. 15.  3. 10.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[3.0530639]
 [1.0328708]
 [1.0156474]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3
  6 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.040856838226318
desired expected reward: 72.82099914550781



action possibilites: [-1] 
expected returns: [[-4.7941227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: -0.35951095819473267
desired expected reward: 0.6733524203300476





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.207858 ]
 [-4.5355043]
 [-4.400524 ]
 [-4.7107873]
 [-4.4305344]
 [-4.6129484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.05831897258758545
desired expected reward: -4.852441787719727






Player: 1 
cards in hand: [ 8.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.68123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 6.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  6. 29.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -0.25652483105659485
desired expected reward: -4.8694748878479





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.395628]
 [33.833664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 6.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  3. 10.  6. 29.] 
adversary cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -2.0437216758728027
desired expected reward: 29.637508392333984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6. 29.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0.  8.  0. 11. 29. 14.  0.  3.  8.  0.  0.  3.  8.  0.  3.  0.  8.  0.
  0.  8. 11. 10. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 0. 6. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.608538]
 [29.023088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 3.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.212637186050415
desired expected reward: 31.62102699279785





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.78197]
 [34.33275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 3.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -1.9734591245651245
desired expected reward: 28.635074615478516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 16. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.  3.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 15. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.  3.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 30. 15. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 10. 25.] 
adversary cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.  3.  0.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
adversary victory points: 1
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 0 
Workshop: 2 
Chapel: 2 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  0.  0. 10. 25.] 
cards in discard: [ 3.  0.  0.  1.  0.  6.  0. 10.  6.  3.  0. 11. 15.  3.  3. 10.  0.  3.
  6.  6.  6.  3.  0.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11  8 15  6  0  0  0  3  6 25 10 10  0  0  1  3  6
 11  3  6  0  0  8  0 15  3 10  3  6  3  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 15. 29.  8.  0.  9.  5.  0.  9.  5.  7. 10.  5. 10.  7.] 
adversary cards in hand: [3. 0. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [14  8  3  8  8  8  0 15 11  3  0  3 11  0  8 29  0  0  0  0  3 10  6  0
  0 29  0  0  3  0] -> size -> 30 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -30    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -534 

action type: buy - action -1.0
Learning step: -28.41663932800293
desired expected reward: 5.916101455688477



