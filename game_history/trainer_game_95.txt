 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.2481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    2  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -513 

action type: buy - action -1
Learning step: -26.867685317993164
desired expected reward: -2.514009475708008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[255.92581]
 [275.63812]
 [267.41992]
 [229.8594 ]
 [215.66481]
 [264.6034 ]
 [286.38513]
 [270.05148]
 [299.4907 ]
 [269.23978]
 [236.10498]
 [246.27477]
 [265.02548]
 [225.6262 ]
 [254.77505]
 [289.035  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.501225471496582
desired expected reward: 279.7864990234375



buy possibilites: [-1] 
expected returns: [[266.00928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.44803237915039
desired expected reward: 195.21676635742188






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[301.50082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.1856689453125
desired expected reward: 258.8236083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[273.59003]
 [284.03418]
 [232.36887]
 [287.28696]
 [303.53842]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.34912395477295
desired expected reward: 291.3084411621094



buy possibilites: [-1] 
expected returns: [[289.78796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 6 

action type: buy - action 3.0
Learning step: -7.381479740142822
desired expected reward: 276.6527099609375






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[271.2895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.001527786254883
desired expected reward: 280.78643798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[243.51482]
 [257.69592]
 [249.9248 ]
 [211.94283]
 [264.7876 ]
 [254.91937]
 [249.56863]
 [264.9758 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.443962097167969
desired expected reward: 262.1280822753906



buy possibilites: [-1] 
expected returns: [[273.21973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -7.098523139953613
desired expected reward: 247.82081604003906






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.06592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.017964363098145
desired expected reward: 264.2017517089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[231.38838]
 [241.28937]
 [199.19656]
 [242.69147]
 [258.05786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.482243537902832
desired expected reward: 246.76318359375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 10.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 10.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 10.] 
cards in discard: [3. 0. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[270.48102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -7.981973171234131
desired expected reward: 250.0758819580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[237.2662 ]
 [255.19046]
 [247.43779]
 [201.5269 ]
 [264.61005]
 [249.75925]
 [245.44524]
 [266.2868 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.856921195983887
desired expected reward: 258.739501953125



buy possibilites: [-1] 
expected returns: [[279.5811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -52.0 

action type: buy - action 0.0
Learning step: -8.172736167907715
desired expected reward: 229.0934600830078






Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [0. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[250.84798]
 [235.50298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.603727340698242
desired expected reward: 269.97735595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[221.48805]
 [230.10857]
 [184.21017]
 [233.47751]
 [249.50137]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [0. 3. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.42861270904541
desired expected reward: 241.0927276611328



buy possibilites: [-1] 
expected returns: [[220.43192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [0. 3. 0. 3. 0. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -20.438390731811523
desired expected reward: 163.7717742919922






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 10.  3.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[215.10654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.925699710845947
desired expected reward: 212.50621032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[190.40712]
 [207.49559]
 [199.59587]
 [151.50014]
 [197.8913 ]
 [216.58507]
 [203.04057]
 [202.00703]
 [170.24455]
 [198.1657 ]
 [188.18881]
 [217.7242 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 3 8 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.704967498779297
desired expected reward: 203.2237548828125



buy possibilites: [-1] 
expected returns: [[189.11253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -28.5 

action type: buy - action 10.0
Learning step: -7.078254222869873
desired expected reward: 191.0874786376953






Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [6. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[219.50519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.207906246185303
desired expected reward: 182.90463256835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[192.55931]
 [159.04524]
 [218.94217]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.12857723236084
desired expected reward: 209.54791259765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[229.59056]
 [210.99716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.  6.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -7.636634826660156
desired expected reward: 211.3055419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[200.96513]
 [222.17998]
 [212.37619]
 [156.41641]
 [234.27869]
 [216.34305]
 [210.69156]
 [236.93985]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.  6.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.189849853515625
desired expected reward: 219.93191528320312



buy possibilites: [-1] 
expected returns: [[183.16283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.  6.  3.  3.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 1.0
Learning step: -7.737834453582764
desired expected reward: 214.44212341308594






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  3.  3. 10.  0.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[141.20186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.649220943450928
desired expected reward: 175.51361083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[119.23982 ]
 [134.62712 ]
 [127.72845 ]
 [ 97.76569 ]
 [ 84.34655 ]
 [125.81002 ]
 [143.42818 ]
 [130.15112 ]
 [155.0989  ]
 [129.27681 ]
 [103.64834 ]
 [111.472244]
 [126.13636 ]
 [ 93.736374]
 [118.155426]
 [144.82208 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.78706693649292
desired expected reward: 134.60939025878906



buy possibilites: [-1] 
expected returns: [[172.49791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 6.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 17 

action type: buy - action 25.0
Learning step: -3.02374267578125
desired expected reward: 152.07516479492188






Player: 1 
cards in hand: [ 0.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  8.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[166.93991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [25.  0.  1.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  8.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.656314849853516
desired expected reward: 165.8415985107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[144.45453]
 [158.4431 ]
 [152.66653]
 [116.49503]
 [165.15028]
 [153.59709]
 [149.91737]
 [165.8467 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [25.  0.  1.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  8.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.231906414031982
desired expected reward: 154.59390258789062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  8.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  8.  0. 10.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  8.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  8.  0. 10.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  8.  0. 10.] 
adversary cards in discard: [25.  0.  1.  0.  0.  6.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[184.01651]
 [167.57747]
 [163.08783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 10.] 
cards in discard: [25.  0.  1.  0.  0.  6.  0.  3.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3. 10.  8.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -6.111894130706787
desired expected reward: 159.7348175048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.06737]
 [122.31873]
 [182.15373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8.  0. 10.] 
cards in discard: [25.  0.  1.  0.  0.  6.  0.  3.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  3. 10.  8.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -7.083364963531494
desired expected reward: 172.93585205078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.  8.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.  8.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  3. 10.  8.  0.  3.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[145.879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -7.482659339904785
desired expected reward: 174.6710662841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.250114]
 [126.44375 ]
 [ 91.527534]
 [127.2593  ]
 [140.88158 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.626763343811035
desired expected reward: 130.05638122558594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3. 6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 27. 30.  8.  8. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3. 6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3. 6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[180.19307]
 [169.91705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: discard_down_to_3_cards - action 3
Learning step: -0.6464502215385437
desired expected reward: 57.377655029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[159.20937]
 [166.22093]
 [133.15437]
 [167.67221]
 [177.99794]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.839696407318115
desired expected reward: 170.84136962890625



buy possibilites: [-1] 
expected returns: [[160.77097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 3.0
Learning step: -5.393701553344727
desired expected reward: 160.82725524902344






Player: 1 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [11. 14.  3.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 25.  3.  0.  6.] 
adversary cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [11. 14.  3.  0. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 25.  3.  0.  6.] 
adversary cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 25.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[157.5249]
 [145.2328]
 [167.5827]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  0.  6.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -5.63119649887085
desired expected reward: 155.1397705078125



action possibilites: [-1] 
expected returns: [[170.67905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6.  0.  0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 0 

action type: take_action - action 25.0
Learning step: -4.396036624908447
desired expected reward: 160.33026123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.4335  ]
 [163.71718 ]
 [158.03539 ]
 [124.176476]
 [171.46265 ]
 [156.5583  ]
 [152.89911 ]
 [171.88614 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6.  0.  0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -5.058419227600098
desired expected reward: 165.62062072753906



buy possibilites: [-1] 
expected returns: [[130.61458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6.  0.  0.] 
cards in discard: [0. 3. 6. 0. 3. 3. 0. 3. 8. 0. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -18.91999626159668
desired expected reward: 105.25648498535156






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.11503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -5.559446811676025
desired expected reward: 125.05513000488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.0995  ]
 [100.44361 ]
 [ 93.32245 ]
 [ 56.635735]
 [107.63596 ]
 [ 96.56886 ]
 [ 91.71085 ]
 [108.04822 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.324570655822754
desired expected reward: 111.17686462402344



buy possibilites: [-1] 
expected returns: [[78.92704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -18.255929946899414
desired expected reward: 38.37980651855469






Player: 1 
cards in hand: [ 0.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.  0.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8.  6.  6. 10.] 
adversary cards in discard: [6. 0. 6. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8.  6.  6. 10.] 
adversary cards in discard: [6. 0. 6. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8.  6.  6. 10.] 
adversary cards in discard: [6. 0. 6. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 3.] 
cards in discard: [11. 14.  3.  0. 10.  3.  0.  1.  3.  0.  0.  6.  3.  0.  8.  0.  0.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8.  6.  6. 10.] 
adversary cards in discard: [6. 0. 6. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25.  8.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[82.160065]
 [87.94507 ]
 [76.18596 ]
 [74.02619 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  6. 10.] 
cards in discard: [6. 0. 6. 3. 3. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -4.385017395019531
desired expected reward: 74.54202270507812



action possibilites: [-1. 25.  8.] 
expected returns: [[76.19279]
 [83.82839]
 [70.28465]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  6.  0.] 
cards in discard: [6. 0. 6. 3. 3. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  3  8  0  6 10  1 25  3  6  6] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8] -> size -> 25 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -2.9307048320770264
desired expected reward: 67.84857940673828



action possibilites: [-1. 25.] 
expected returns: [[84.67716]
 [91.58177]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [6. 0. 6. 3. 3. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  5. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 18 

action type: trash_cards_n_from_hand - action 3
Learning step: -1.399837851524353
desired expected reward: 88.40644073486328



action possibilites: [-1] 
expected returns: [[121.057205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [6. 0. 6. 3. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 38 

action type: take_action - action 25.0
Learning step: 0.044698335230350494
desired expected reward: 91.62647247314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.38247 ]
 [ 78.824844]
 [118.8395  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [6. 0. 6. 3. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -1.8139057159423828
desired expected reward: 119.24330139160156



buy possibilites: [-1] 
expected returns: [[97.148026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [6. 0. 6. 3. 3. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6] -> size -> 26 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -20.   0.   0.  60. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: -2.58329176902771
desired expected reward: 100.79915618896484






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 6. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.81576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -4.06654691696167
desired expected reward: 93.08148193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.78616 ]
 [65.15506 ]
 [59.93614 ]
 [33.504772]
 [57.960842]
 [69.51247 ]
 [60.737186]
 [59.79    ]
 [40.102356]
 [56.658752]
 [50.7414  ]
 [68.00175 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  9.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -2.367161989212036
desired expected reward: 59.44860076904297



buy possibilites: [-1] 
expected returns: [[127.75465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  3.  1.  0. 10.  8. 25.  0.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3. 10.  8.  3.  0.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 11.0
Learning step: -0.9761430621147156
desired expected reward: 68.53630828857422






Player: 1 
cards in hand: [ 3. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  3.  0.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3
  8  6 22] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[89.344246]
 [69.73399 ]
 [73.81946 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.315690040588379
desired expected reward: 122.43895721435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.556133]
 [73.18224 ]
 [66.3221  ]
 [32.579727]
 [80.79271 ]
 [67.31707 ]
 [62.914364]
 [82.13189 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 10.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -3.225867986679077
desired expected reward: 80.1257095336914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 10.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [11. 25.  1.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 10.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [11. 25.  1.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 25.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 95.8189 ]
 [ 95.57973]
 [105.47925]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  1.  0.  6.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -2.534733533859253
desired expected reward: 79.59716033935547



action possibilites: [-1] 
expected returns: [[82.67223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  6.] 
cards in discard: [10.  8.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: gain_card_n - action 0
Learning step: -2.7519500255584717
desired expected reward: 67.48954772949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.24128]
 [80.15137]
 [76.24342]
 [48.29964]
 [83.93598]
 [76.79489]
 [74.06979]
 [83.95268]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  6.] 
cards in discard: [10.  8.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 25. 30.  8.  4. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -2.0211329460144043
desired expected reward: 80.6511001586914



buy possibilites: [-1] 
expected returns: [[116.75975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  6.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  8.] 
adversary cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -14.937888145446777
desired expected reward: 33.36176300048828






Player: 1 
cards in hand: [ 0. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  8.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 6. 22.  0.  0.  1.  0.  0.  0. 10.  8.  3.  3.  8.  6.  3.  3.  0. 10.
 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.693245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.2748894691467285
desired expected reward: 110.48486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.644535 ]
 [21.15911  ]
 [ 8.0069895]
 [20.940823 ]
 [28.110645 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  6.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -2.2713234424591064
desired expected reward: 29.421920776367188



buy possibilites: [-1] 
expected returns: [[51.87281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 8.0
Learning step: -0.5301063656806946
desired expected reward: 20.41071128845215






Player: 1 
cards in hand: [ 8.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.783852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: discard_down_to_3_cards - action 3
Learning step: -1.2548015117645264
desired expected reward: 14.693960189819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.947956]
 [-3.238728]
 [32.456306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  8.  0.  0.  0.  0.  6. 11. 25.  1.  0.  6.  8.  3.  3.  6.  0.  0.
  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -2.249974489212036
desired expected reward: 28.533876419067383



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 25.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 25.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[16.236961]
 [23.451828]
 [12.698239]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  8  0 10  1 25  3  6  6  0 11  0  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  8.  0.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.3724238872528076
desired expected reward: 30.083887100219727



action possibilites: [-1] 
expected returns: [[48.581593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  8.  0.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.33029767870903015
desired expected reward: 1.586059808731079





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.351852]
 [12.615909]
 [49.521004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 6.  3. 11.  8.  0.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -2.323240041732788
desired expected reward: 46.25835418701172






Player: 1 
cards in hand: [ 6.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  8.  0.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  8.  0.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  8.  0.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.528507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [8. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  3.  6.  1.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -2.9146339893341064
desired expected reward: 46.606361389160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.164085]
 [53.15534 ]
 [48.315037]
 [28.609741]
 [21.007477]
 [46.72418 ]
 [57.497387]
 [49.407257]
 [64.715324]
 [48.526352]
 [31.578278]
 [37.507465]
 [46.136253]
 [26.504318]
 [40.99875 ]
 [57.171547]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [8. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  9. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  3.  6.  1.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -3.4267919063568115
desired expected reward: 52.63613510131836



buy possibilites: [-1] 
expected returns: [[26.93509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  6. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  3.  6.  1.] 
adversary cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 16 

action type: buy - action 25.0
Learning step: -1.8297260999679565
desired expected reward: 62.885581970214844






Player: 1 
cards in hand: [ 0. 22.  3.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  6.  1.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  1.  0.  3. 11.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  1.  0.  3. 11.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  5.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  1.  0.  3. 11.] 
cards in discard: [ 1. 14.  8.  0.  3.  3.  0.  0.  0.  0.  0.  0.  6.  3. 11.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[54.677258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -1.8165161609649658
desired expected reward: 25.118572235107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.46484 ]
 [53.24818 ]
 [32.65579 ]
 [53.542404]
 [58.215004]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -3.2868640422821045
desired expected reward: 51.3903923034668



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[51.08627 ]
 [41.668808]
 [51.26219 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -3.5163376331329346
desired expected reward: 54.69866943359375



action possibilites: [-1. 11.] 
expected returns: [[96.9274]
 [97.225 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  7.  9. 10.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -0.5485733151435852
desired expected reward: 41.120235443115234



action possibilites: [-1.] 
expected returns: [[55.484913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: 15 

action type: gain_card_n - action 9
Learning step: -2.9538590908050537
desired expected reward: 96.88188934326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.68518  ]
 [35.044422 ]
 [31.405005 ]
 [ 1.8779907]
 [25.909895 ]
 [46.083023 ]
 [28.059742 ]
 [27.493507 ]
 [10.932453 ]
 [28.19534  ]
 [21.960642 ]
 [48.816814 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  6.  9. 10.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.7673332691192627
desired expected reward: 53.71757888793945



buy possibilites: [-1] 
expected returns: [[34.918766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  6. 25.  1.  0.  0.  0.  3.  6.  3.  0.  6.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [3. 8. 3. 1. 0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 10.5 

action type: buy - action 10.0
Learning step: -0.09909410774707794
desired expected reward: 28.09623146057129






Player: 1 
cards in hand: [3. 8. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 11.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[7.326321 ]
 [7.3897624]
 [2.1814036]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0 11  0  6  8 25 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.3289926052093506
desired expected reward: 31.589773178100586



action possibilites: [-1] 
expected returns: [[87.94702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 2
Learning step: 1.4984310865402222
desired expected reward: -2.8940300941467285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.35658 ]
 [48.277508]
 [85.21435 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.480684757232666
desired expected reward: 84.46633911132812



buy possibilites: [-1] 
expected returns: [[57.813007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -4.517036437988281
desired expected reward: 67.83954620361328






Player: 1 
cards in hand: [ 6. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  8.  0.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  8.  0.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  8.  0.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10
  0] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[39.764053]
 [27.544819]
 [25.855518]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  0. 10.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0 10  1  3  6  6  0  0  6  8 25 10 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.853717088699341
desired expected reward: 53.95928955078125



action possibilites: [-1] 
expected returns: [[69.33805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.054778289049863815
desired expected reward: 18.242908477783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.365685]
 [62.70676 ]
 [32.16913 ]
 [62.54997 ]
 [72.63342 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  3. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -2.8179144859313965
desired expected reward: 66.52013397216797



buy possibilites: [-1] 
expected returns: [[78.617096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  6.  0.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -16.08957290649414
desired expected reward: 16.079551696777344






Player: 1 
cards in hand: [11.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  8.  0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1 11  6  3  8
  6 22  0 11  1  0  8  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[62.03021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [14.  8. 10.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -4.785175323486328
desired expected reward: 73.83192443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.43488 ]
 [54.050842]
 [50.516712]
 [26.174124]
 [59.027424]
 [49.780106]
 [47.060314]
 [59.28047 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [0. 8. 0. 3. 3. 6. 8. 6. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  5.  9. 10.] 
adversary cards in hand: [14.  8. 10.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.212239742279053
desired expected reward: 57.817970275878906



buy possibilites: [-1] 
expected returns: [[10.325861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [14.  8. 10.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -27 

action type: buy - action 10.0
Learning step: -3.470684051513672
desired expected reward: 43.589630126953125






Player: 1 
cards in hand: [14.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 10.  0.  3.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 10.  0.  3.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 10.  0.  3.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[16.708157 ]
 [12.0407505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 22.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.432631731033325
desired expected reward: 7.8932294845581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 8.138212]
 [14.950997]
 [13.331901]
 [-7.880306]
 [16.031025]
 [12.281502]
 [10.967047]
 [15.692248]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  7.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 22.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.8091671466827393
desired expected reward: 13.562308311462402



buy possibilites: [-1] 
expected returns: [[6.0157404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  6.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 22.] 
adversary cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -27 

action type: buy - action 11.0
Learning step: -2.0161972045898438
desired expected reward: 14.014827728271484






Player: 1 
cards in hand: [ 0.  0.  1.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 22.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  6.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6. 11. 10.
  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 22.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  6.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6. 11. 10.
  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 22.] 
cards in discard: [ 3.  8.  0.  3. 10.  1.  3.  8.  3.  1.  0.  0.  6. 11.  3.  0.  0.  0.
  8.  6.  0.  0. 14.  8. 10.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  5.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6. 11. 10.
  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-7.086315]
 [-8.379963]
 [-2.656157]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  6.  8.  6.  0.  0. 10.  1.  3.  0.  3.  6. 11. 10.
  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  2. 10.  5.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [14.  3.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.6718595027923584
desired expected reward: 3.3438808917999268



action possibilites: [-1] 
expected returns: [[47.931725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [14.  3.  6.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -24 

action type: take_action - action 25.0
Learning step: 0.011271846480667591
desired expected reward: -2.644890069961548





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[37.225407]
 [46.136208]
 [41.46208 ]
 [20.159782]
 [41.123096]
 [48.514923]
 [43.30245 ]
 [42.38963 ]
 [27.046535]
 [39.33319 ]
 [34.583366]
 [47.398937]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9. 10.] 
adversary cards in hand: [14.  3.  6.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -2.726332187652588
desired expected reward: 45.20539093017578



buy possibilites: [-1] 
expected returns: [[55.21099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.  6.] 
cards in discard: [15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [14.  3.  6.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 7 

action type: buy - action 15.0
Learning step: -0.1369212120771408
desired expected reward: 34.446449279785156






Player: 1 
cards in hand: [14.  3.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  3.  0.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [11.  0.  8.  1.  0.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  3.  0.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [11.  0.  8.  1.  0.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  3.  0.] 
cards in discard: [6. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [11.  0.  8.  1.  0.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  0.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-13.754381]
 [-13.055131]
 [-17.532684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  1.  0.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  1. 10.  0.  8.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.83554744720459
desired expected reward: 50.37544250488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.960726 ]
 [-11.8680105]
 [-14.43309  ]
 [-24.614517 ]
 [-15.240317 ]
 [ -9.690692 ]
 [-14.237601 ]
 [-14.735035 ]
 [-20.292534 ]
 [-15.565283 ]
 [-17.370262 ]
 [-10.521446 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  1.  0.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 25. 30.  8.  1. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  1. 10.  0.  8.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -1.384839653968811
desired expected reward: -15.139225959777832



buy possibilites: [-1] 
expected returns: [[35.1609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  1.  0.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  1. 10.  0.  8.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -15.278154373168945
desired expected reward: -39.892669677734375






Player: 1 
cards in hand: [ 3.  1. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  0.  8.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  3.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  8. 11.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  3.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  8. 11.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  5.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  3.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  8. 11.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  3.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[10.641024 ]
 [ 7.2701473]
 [ 5.782509 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.  3.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  0. 22.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -3.8683106899261475
desired expected reward: 31.29258918762207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 4.0298634]
 [10.753324 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 10.  3.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 11.  3.  0. 22.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -2.6509952545166016
desired expected reward: 7.990030288696289



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 22.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 22.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.605686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -2.329038381576538
desired expected reward: 8.424285888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.160071 ]
 [14.5878725]
 [15.319612 ]
 [21.756199 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.059419870376587
desired expected reward: 19.546266555786133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 10.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  0. 10.] 
adversary cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[12.248475]
 [12.047085]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 10.] 
cards in discard: [15. 25.  0. 10.  0.  0.  0.  6.  6. 11.  0.  8.  1.  0.  8.  0.  6. 10.
  3.  3.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.1140429973602295
desired expected reward: 18.642152786254883



action possibilites: [-1.] 
expected returns: [[28.84814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 10.0
Learning step: -1.2532716989517212
desired expected reward: 10.793825149536133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[19.14344 ]
 [23.42516 ]
 [24.306362]
 [29.601269]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -2.1756820678710938
desired expected reward: 26.67245864868164



buy possibilites: [-1] 
expected returns: [[-13.769964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -7 

action type: buy - action 3.0
Learning step: -1.651004672050476
desired expected reward: 18.172603607177734






Player: 1 
cards in hand: [0. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  1  6  3  8  6 22
  0 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  0.  6. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  0.  6. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  8.  0.  6. 11.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-5.2198973]
 [-8.213276 ]
 [-4.196583 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  6. 11.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  4.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -1.1863560676574707
desired expected reward: -14.956319808959961



action possibilites: [-1] 
expected returns: [[29.143784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -6 

action type: gain_card_n - action 4
Learning step: 1.0880837440490723
desired expected reward: -13.558889389038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.90945 ]
 [29.255527]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -1.6426432132720947
desired expected reward: 27.501140594482422



buy possibilites: [-1] 
expected returns: [[20.841215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: -2.7265450954437256
desired expected reward: 16.182903289794922






Player: 1 
cards in hand: [ 1.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [ 6.  0. 14.  3.  6.  3.  0. 11. 10.  3.  1.  0.  8. 11.  0. 11.  3.  0.
 22.  8.  8.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.421074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -1.657586693763733
desired expected reward: 19.18362808227539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[38.390682]
 [49.120068]
 [44.388504]
 [52.17624 ]
 [45.274467]
 [41.799557]
 [51.423862]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -3.207479953765869
desired expected reward: 47.213592529296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  6  3  8  6 22  0
 11  1  0  8  1  0  0  0 11  6  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 10. 15.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 10. 15.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  4.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 10. 15.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 10. 15.  0.] 
adversary cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[  2.4114213]
 [ -8.477101 ]
 [ -8.477101 ]
 [-12.072292 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 15.  0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -4.931140899658203
desired expected reward: 46.49272155761719



action possibilites: [-1. 10. 15. 25.] 
expected returns: [[ -9.382346 ]
 [-13.260689 ]
 [-15.559952 ]
 [ -7.8899674]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  0. 25.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -1.0694814920425415
desired expected reward: -9.546585083007812



action possibilites: [-1. 15. 25.  8.] 
expected returns: [[-10.281243 ]
 [-15.720621 ]
 [ -7.9818306]
 [-11.873887 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 25.  8.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0
  6 10 11 15  6  3 11  0] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: 0.17036032676696777
desired expected reward: -13.090319633483887



action possibilites: [-1. 25.] 
expected returns: [[-4.52692 ]
 [-1.928972]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.5359635353088379
desired expected reward: -7.521932125091553



action possibilites: [-1.] 
expected returns: [[-4.075214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  80   0   0   0   0   0   0   0   0   2] 
sum of rewards: 26 

action type: take_action - action 25.0
Learning step: 1.3047561645507812
desired expected reward: -0.6242151260375977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-11.0617075]
 [ -4.4890704]
 [ -6.3016706]
 [ -0.3303733]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 24 

action type: take_action - action -1.0
Learning step: 1.301857829093933
desired expected reward: -2.7733559608459473



buy possibilites: [-1] 
expected returns: [[30.60579]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 10.  6.  0.  3.  0.  3. 11.  0. 11.  6.  8.  0.  6.  6.  0.  3.  0.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.  8. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  80. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: 1.0104553699493408
desired expected reward: -10.051260948181152






Player: 1 
cards in hand: [3. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0] -> size -> 30 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [6. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0] -> size -> 30 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-3.0157595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [8. 8. 0. 0. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -4.398143768310547
desired expected reward: 26.207645416259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-7.3803477]
 [-2.24501  ]
 [-2.9814997]
 [-4.5675344]
 [-1.6026943]
 [-4.1771684]
 [-4.452345 ]
 [-9.9376335]
 [-4.7915792]
 [-5.9832354]
 [-1.7880952]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  3.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [8. 8. 0. 0. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.738424301147461
desired expected reward: -5.754183769226074



buy possibilites: [-1] 
expected returns: [[23.323732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 1.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [8. 8. 0. 0. 3. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 8.0
Learning step: -1.9663574695587158
desired expected reward: -6.143527984619141






Player: 1 
cards in hand: [ 0. 10.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 11.] 
cards in discard: [8. 8. 0. 0. 3. 3. 0. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [8. 6. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [8. 8. 0. 0. 3. 3. 0. 6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [8. 6. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [8. 6. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 3.  0.  8. 10.  0.] 
adversary cards in discard: [8. 6. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[ 2.5178714]
 [-4.309452 ]
 [-5.6241026]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  0.] 
cards in discard: [8. 6. 0. 0. 6. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 3. 10.  6. 22.  1.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.999917984008789
desired expected reward: 19.323814392089844



action possibilites: [-1.  8.] 
expected returns: [[1.6000633 ]
 [0.33199596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [8. 6. 0. 0. 6. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 3. 10.  6. 22.  1.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -1.4942779541015625
desired expected reward: -7.118386268615723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-0.20824957]
 [ 0.23740721]
 [-0.5555835 ]
 [ 0.624702  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [8. 6. 0. 0. 6. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 3. 10.  6. 22.  1.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -1.876818060874939
desired expected reward: -0.2767542600631714






Player: 1 
cards in hand: [ 3. 10.  6. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6. 22.  1.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6. 22.  1.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6. 22.  1.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-20.188166]
 [-19.251516]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -3.2728774547576904
desired expected reward: -2.6481716632843018



action possibilites: [-1. 10.] 
expected returns: [[18.133068]
 [15.171875]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 10.0
Learning step: -0.45624980330467224
desired expected reward: -19.70775604248047



action possibilites: [-1. 25.] 
expected returns: [[12.242537]
 [15.505564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action 10.0
Learning step: -1.2392715215682983
desired expected reward: 13.93260383605957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[10.206012]
 [12.565798]
 [11.058613]
 [12.696402]
 [11.795599]
 [10.375512]
 [12.141281]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.1472512483596802
desired expected reward: 11.095282554626465






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1
  0  8  1  0  0  0 11  6  0 11  8 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 11.  6.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 3.559156 ]
 [-3.2959723]
 [ 3.4535966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  3.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8.  1.  0. 14.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -3.3690109252929688
desired expected reward: 8.77226734161377





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.244567]
 [ 4.754422]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  6.  3.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8.  1.  0. 14.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.952486753463745
desired expected reward: 0.606675386428833



buy possibilites: [-1] 
expected returns: [[-1.0826576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  6.  3.  0.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 8.  1.  0. 14.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -4.1121320724487305
desired expected reward: -8.356693267822266






Player: 1 
cards in hand: [ 8.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 14.  0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0 14  8  8  3  8  6 22  0 11  1  0  8  1  0
  0  0 11  6  0 11  8 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 26. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[5.0652857]
 [5.220026 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [11.  3.  3.  8.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0  1] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.6298179626464844
desired expected reward: -3.712475538253784





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-1.1726153]
 [ 2.5489516]
 [ 1.199882 ]
 [ 4.6120834]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  2.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [11.  3.  3.  8.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0  1] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -3.0004830360412598
desired expected reward: 2.0648036003112793



buy possibilites: [-1] 
expected returns: [[-0.20974612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 8.  6.  0.  0.  6.  1. 10.  3.  0.  8.  0.  6. 10. 10.  0.  0.  0.  3.
 25.  0.  8. 11.  6.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [11.  3.  3.  8.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
adversary owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0  1] -> size -> 33 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -48 

action type: buy - action 8.0
Learning step: -2.433546781539917
desired expected reward: -1.2336809635162354






Player: 1 
cards in hand: [11.  3.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  8.  0.] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 10  3  3  0 10  0  0  8  8  3  8  6 22  0 11  1  0  8  1  0  0
  0 11  6  0 11  8 15  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  3.  3.  0.  6.  0. 15. 10. 11.  0.  3.  0. 11.  0.  3.
 10.  6. 22.  1.  8.  1.  8.  1.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-21.314577]
 [-23.926292]
 [-23.193644]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -2.296205520629883
desired expected reward: -2.5059516429901123



action possibilites: [-1] 
expected returns: [[26.996582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -7 

action type: gain_card_n - action 1
Learning step: 1.5015926361083984
desired expected reward: -23.381797790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[16.661299]
 [23.030588]
 [20.615416]
 [24.99344 ]
 [20.445988]
 [18.771173]
 [24.589178]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  1.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -1.6543606519699097
desired expected reward: 25.342222213745117



buy possibilites: [-1] 
expected returns: [[13.829419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [1. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -14.0 

action type: buy - action 8.0
Learning step: -1.4111372232437134
desired expected reward: 19.034847259521484






Player: 1 
cards in hand: [3. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0
 11  8 15  0  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [0. 6. 1. 0. 3.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 6. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.883436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0. 3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -1.341593623161316
desired expected reward: 12.487825393676758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[20.321196]
 [26.469336]
 [24.8832  ]
 [22.840275]
 [28.819067]
 [23.232271]
 [14.126962]
 [22.820257]
 [19.883791]
 [29.002493]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -2.195998430252075
desired expected reward: 26.687437057495117



buy possibilites: [-1] 
expected returns: [[-3.8592453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [8. 3. 0. 8.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.   -1.
   0.    0.    4.5   0. ] 
sum of rewards: -22.5 

action type: buy - action 10.0
Learning step: -2.3528454303741455
desired expected reward: 20.46739959716797






Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [8. 3. 0. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8 10] -> size -> 36 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [8. 3. 0. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8 10] -> size -> 36 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [ 8.  3.  0.  8. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8 10] -> size -> 36 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-11.719689]
 [-13.543689]
 [-12.663683]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 10.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10 10  0  6 10
 11  6  3 11  0  0  8  0  8  1  8 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [8. 1. 0. 3. 6.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -1.3874436616897583
desired expected reward: -5.2466888427734375



action possibilites: [-1] 
expected returns: [[-2.6021266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [8. 1. 0. 3. 6.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.19677522778511047
desired expected reward: -10.909686088562012





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.10569 ]
 [ -9.569524]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [8. 1. 0. 3. 6.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -0.4172346293926239
desired expected reward: -3.0193612575531006



buy possibilites: [-1] 
expected returns: [[11.191474]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [8. 1. 0. 3. 6.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
adversary owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action 0.0
Learning step: -0.8929075598716736
desired expected reward: -13.998594284057617






Player: 1 
cards in hand: [8. 1. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3. 6.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  3 10  0  0  8  8  3  8  6 22  0  1  0  8  1  0  0  0 11  6  0 11
  8 15  0  1  0 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6. 25.  3.  8.  0.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6. 25.  3.  8.  0.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6. 25.  3.  8.  0.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6. 25.  3.  8.  0.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[-6.59955 ]
 [-9.853853]
 [-7.985368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  3.  8.  0.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [15.  0. 11.  3. 10.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0] -> size -> 28 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -1.5360803604125977
desired expected reward: 9.655393600463867





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.2597594]
 [-6.7934637]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25.  3.  8.  0.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [15.  0. 11.  3. 10.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0] -> size -> 28 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -0.6270986795425415
desired expected reward: -7.226646900177002



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  3. 10.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3. 10.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 0.  6. 10.  6.  8.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[10.500716]
 [ 8.677567]
 [10.113964]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  6.  8.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0  1  3  6  6  0  0  6  8 25 10  0  6 10 11  6  3
 11  0  0  8  0  8  1  8 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -0.23740370571613312
desired expected reward: -7.030871868133545



action possibilites: [-1] 
expected returns: [[-13.05084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.3652303218841553
desired expected reward: 2.1877458095550537





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-19.53235 ]
 [-13.001867]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 1.0508540868759155
desired expected reward: -11.99998664855957



buy possibilites: [-1] 
expected returns: [[-12.09655]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: -0.04555473476648331
desired expected reward: -19.57790756225586






Player: 1 
cards in hand: [1. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-3.460453 ]
 [-7.757631 ]
 [-5.6483316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  8. 11.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 22.  1.  8. 10.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10. 10.  1.  0.  0.  0.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0.23781099915504456
desired expected reward: -11.858738899230957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.867107 ]
 [-6.1848063]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  8. 11.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 22.  1.  8. 10.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10. 10.  1.  0.  0.  0.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.24042825400829315
desired expected reward: -3.700892448425293



buy possibilites: [-1] 
expected returns: [[-4.97166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  8. 11.] 
cards in discard: [ 1.  8. 11. 10.  0.  0.  0. 10.  0.  6.  1.  0.  3.  0.  8.  3.  6. 25.
  3.  8.  0.  0.  8. 10.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6. 22.  1.  8. 10.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10. 10.  1.  0.  0.  0.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -35.0 

action type: buy - action 0.0
Learning step: -1.4185069799423218
desired expected reward: -10.285614013671875






Player: 1 
cards in hand: [ 6. 22.  1.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  1.  8. 10.] 
cards in discard: [ 8.  3.  0.  8. 14.  0.  0.  0. 11.  0.  0.  8.  6.  0.  0. 11. 15.  0.
  3. 10. 10.  1.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  1.  8.  0.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-18.47818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4171760678291321
desired expected reward: -5.38883638381958





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-24.674854]
 [-23.819643]
 [-20.89043 ]
 [-24.682806]
 [-21.146358]
 [-25.543287]
 [-22.253702]
 [-22.718147]
 [-22.10798 ]
 [-19.680553]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8. 10.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0.17546501755714417
desired expected reward: -18.302715301513672



buy possibilites: [-1] 
expected returns: [[10.909157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  9.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 2.8726203441619873
desired expected reward: -22.670663833618164






Player: 1 
cards in hand: [ 0. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  9.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  9.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  9.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 3.  8. 11.  3.  0.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-0.6670995]
 [-2.8238375]
 [ 1.5493746]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [29.  6.  0.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  9.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  8.  8.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8003849983215332
desired expected reward: 10.108772277832031



action possibilites: [-1] 
expected returns: [[-0.7855525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  8.  8.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 30 

action type: gain_card_n - action 5
Learning step: 1.7672010660171509
desired expected reward: -3.9303183555603027





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.100626 ]
 [-1.1791415]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  8.  8.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.7638024687767029
desired expected reward: -0.021750032901763916



buy possibilites: [-1] 
expected returns: [[27.722036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0.  8. 10.  8.  8.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -17.0 

action type: buy - action 0.0
Learning step: -0.17122291028499603
desired expected reward: -1.271848440170288






Player: 1 
cards in hand: [ 0.  8. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.  8.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0] -> size -> 37 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8.  8.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0] -> size -> 37 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.137321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.5655120611190796
desired expected reward: 26.156524658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[0.33297777]
 [2.419151  ]
 [4.3872147 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3273810148239136
desired expected reward: 2.4672412872314453



buy possibilites: [-1] 
expected returns: [[-11.838485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0.16267691552639008
desired expected reward: 2.581819772720337






Player: 1 
cards in hand: [11.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  8.  8. 10.  2.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-11.626503]
 [-10.451599]
 [-10.451599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: 0.6496692895889282
desired expected reward: -11.188815116882324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ -7.7413464]
 [ -5.87245  ]
 [ -6.565651 ]
 [ -7.4934344]
 [ -8.182373 ]
 [-11.7328005]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: 0.7119013667106628
desired expected reward: -10.9146146774292



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 8. 25.  8.  6. 10.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 23. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 8. 25.  8.  6. 10.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 8. 25.  8.  6. 10.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 10.] 
expected returns: [[ 7.994093 ]
 [ 6.0644846]
 [11.830529 ]
 [ 6.0644846]
 [ 4.0355043]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  6. 10.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8 25 10  0  6 10 11  6  3 11  0
  0  8  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [10.  0.  6. 11. 15.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.5689117312431335
desired expected reward: -11.16390323638916



action possibilites: [-1] 
expected returns: [[-14.29808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [10.  0.  6. 11. 15.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.1285412311553955
desired expected reward: 12.008148193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.210183]
 [-14.298082]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [10.  0.  6. 11. 15.] 
adversary cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: 1.1943788528442383
desired expected reward: -13.1037015914917






Player: 1 
cards in hand: [10.  0.  6. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6. 11. 15.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.  0.  8.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  1.  0. 10. 11.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6. 11. 15.] 
cards in discard: [ 0. 10.  6. 22.  1.  8.  0. 15.  0. 14.  0.  0.  0.  0.  8. 10.  8.  8.
 29. 11.  1.  0.  0.  0.  3.  0.  8.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 6.  1.  0. 10. 11.] 
adversary cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 6.  1.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[2.8080451]
 [0.7486727]
 [3.7386773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 10. 11.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.  8.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.5753517150878906
desired expected reward: -13.722728729248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.2727163 ]
 [ 2.0190213 ]
 [ 1.8693697 ]
 [ 2.9755838 ]
 [ 0.25171566]
 [ 2.4925735 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 10. 11.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.  8.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  3.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -0.30218562483787537
desired expected reward: 2.505851984024048



buy possibilites: [-1] 
expected returns: [[-6.3186007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 10. 11.] 
cards in discard: [29.  6.  0.  0.  0.  0. 29.  0. 11.  3.  8.  3.  0.  3.  6.  0.  3.  0.
  3.  0.  8.  0.  0.  8.  8.  8.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0 -2  0  0 18  0] 
sum of rewards: 12 

action type: buy - action 11.0
Learning step: 0.3090522289276123
desired expected reward: 3.284637451171875






Player: 1 
cards in hand: [ 0. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [29.  0.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [29.  0.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  2.  9.  7.] 
adversary cards in hand: [29.  0.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 15.] 
cards in discard: [10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [29.  0.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-12.813336]
 [-13.278112]
 [-12.896185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 14.  0.  8. 10.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3 10] -> size -> 36 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -0.17567653954029083
desired expected reward: -6.494277000427246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-13.5626745]
 [-12.975715 ]
 [-12.303761 ]
 [-13.343527 ]
 [-12.256997 ]
 [-13.356915 ]
 [-16.329405 ]
 [-12.988692 ]
 [-13.145327 ]
 [-12.905843 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 14.  0.  8. 10.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.] 
adversary owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3 10] -> size -> 36 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: 0.1456858217716217
desired expected reward: -12.667651176452637



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 14.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  8. 10.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10  3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0
  1  0 14  0  0  0 10  0 15 29  3 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [29.  0.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-17.56534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0.  0. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.05007205158472061
desired expected reward: -12.855772018432617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-18.062061]
 [-18.858183]
 [-16.894958]
 [-18.534777]
 [-17.76644 ]
 [-17.96642 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0.  0. 10.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 22. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: 0.27786383032798767
desired expected reward: -17.2874755859375



buy possibilites: [-1] 
expected returns: [[-8.07041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [29.  0.  0. 10.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 21. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0.  0.  0.  0.  0.  0. -3.  0.  0.  2.  0.] 
sum of rewards: 6.0 

action type: buy - action 3.0
Learning step: 0.9581896066665649
desired expected reward: -15.93677043914795






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 21. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 21. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [29.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [29.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-10.459877]
 [ -9.116486]
 [ -9.178804]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0.  0.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 6.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.03991198539733887
desired expected reward: -8.030497550964355



action possibilites: [-1.] 
expected returns: [[27.76684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 6.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: discard_n_cards - action 3
Learning step: 1.8755426406860352
desired expected reward: -6.140232086181641





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[18.311077]
 [22.67937 ]
 [21.54006 ]
 [20.190928]
 [24.621735]
 [20.329319]
 [11.984064]
 [19.993074]
 [17.8777  ]
 [24.578136]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  2.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 6.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.06425628811120987
desired expected reward: 27.70258331298828



buy possibilites: [-1] 
expected returns: [[-8.235338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  1.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 8. 3. 6.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.   0.   0.   0.  20.   0.   0.   0.   0.  -4.   0.   0.
  4.5  0. ] 
sum of rewards: 17.5 

action type: buy - action 11.0
Learning step: -0.5413817763328552
desired expected reward: 24.080350875854492






Player: 1 
cards in hand: [0. 3. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 6.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  1.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [11.  1.  3.  0. 10.] 
adversary cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11] -> size -> 39 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 6.] 
cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  1.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [11.  1.  3.  0. 10.] 
adversary cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11] -> size -> 39 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [11.  1.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[27.979237]
 [27.701494]
 [22.788795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0. 10.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11. 29.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  1.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.  0.
  3.  8.  3.  6.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.8582832217216492
desired expected reward: -7.3770551681518555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[19.819706]
 [23.782722]
 [23.32695 ]
 [25.740257]
 [21.611057]
 [26.376616]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0. 10.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11. 29.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  1.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.  0.
  3.  8.  3.  6.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -1.0086288452148438
desired expected reward: 26.970605850219727



Game is draw!



Player 0 bought cards:
Copper: 10 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 5 
Chapel: 5 
Witch: 2 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  1.  3.  0. 10.] 
cards in discard: [29.  0.  0. 10.  1.  3.  0.  0.  6.  0.  3.  8.  6. 11. 29.  0.  0.  0.
 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0  1  3  6  0  0  6  8  0  6 10 11  6  3 11  0  0  8
  0  8  1  8 10  0  0  0 29 29  0  3 11  3 11 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 20. 30.  8.  0. 10.  0.  0.  8.  7.  8. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  8.] 
adversary cards in discard: [10. 10.  0.  1.  0.  0. 15.  8.  6. 14.  0.  3.  8.  0.  0.  8.  0.  0.
  3.  8.  3.  6.] 
adversary owned cards: [ 3 10  0  8  8  3  8  6 22  0  0  8  1  0  0  0 11  6  0 11  8 15  0  1
  0 14  0  0  0 10  0 15 29  3 10  3] -> size -> 36 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0 -5  0  0  9  0] 
sum of rewards: 1 

action type: buy - action 11.0
Learning step: -1.2370126247406006
desired expected reward: 24.503238677978516



