 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.02858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action -1
Learning step: -119997.2578125
desired expected reward: -120190.6953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 51.07729 ]
 [ 88.376724]
 [ 64.30756 ]
 [ 12.99822 ]
 [-11.60145 ]
 [ 79.740234]
 [ 88.87463 ]
 [ 74.83205 ]
 [145.3937  ]
 [103.5208  ]
 [ 13.467306]
 [ 54.7742  ]
 [ 51.55109 ]
 [ 18.356024]
 [ 50.16002 ]
 [ 64.21986 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.2090835571289



buy possibilites: [-1] 
expected returns: [[75.6337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 145.39370727539062






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.422935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.63369750976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.698708 ]
 [72.76696  ]
 [ 1.8822241]
 [82.61087  ]
 [73.66421  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.73878479003906



buy possibilites: [-1] 
expected returns: [[74.0763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 82.61085510253906






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[71.628624]
 [83.56371 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.07630157470703



action possibilites: [-1] 
expected returns: [[44.705887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 89.27729034423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 27.33202 ]
 [ 41.236153]
 [-35.49419 ]
 [ 52.03135 ]
 [ 40.732323]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.70588684082031



buy possibilites: [-1] 
expected returns: [[49.563744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 52.03133773803711






Player: 1 
cards in hand: [ 3.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  0.] 
adversary cards in discard: [8. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 37.180584]
 [116.0823  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.  0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8] -> size -> 9 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.563743591308594



action possibilites: [-1] 
expected returns: [[43.035637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.64710998535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 32.583725 ]
 [ 67.86969  ]
 [ 45.58301  ]
 [ -3.7771683]
 [-25.373005 ]
 [ 60.03129  ]
 [ 68.4674   ]
 [ 55.468082 ]
 [118.20165  ]
 [ 81.63558  ]
 [ -3.2150865]
 [ 36.464546 ]
 [ 33.181427 ]
 [  1.205018 ]
 [ 31.901348 ]
 [ 46.009922 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [8. 8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  7.  9. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.03563690185547



buy possibilites: [-1] 
expected returns: [[28.016975]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8.  3.  0.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 118.20162200927734






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 3. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.34931]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.01697540283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 17.618404]
 [ 53.276623]
 [ 30.498272]
 [-45.553947]
 [ 45.25705 ]
 [ 53.71276 ]
 [ 40.628498]
 [ 67.04579 ]
 [-21.944012]
 [ 18.077461]
 [ 16.668116]
 [ 30.119122]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.281654357910156



buy possibilites: [-1] 
expected returns: [[47.782623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 67.04579162597656






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 25.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 25.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 25.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[ 38.011723]
 [ 46.634247]
 [ 46.634247]
 [110.56754 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 25.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.782623291015625



action possibilites: [-1] 
expected returns: [[42.243095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0.  3. 25.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.51841735839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.756737]
 [44.17541 ]
 [-8.798091]
 [51.85236 ]
 [45.641293]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0.  0.  3. 25.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10. 10.  7.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.24309539794922



buy possibilites: [-1] 
expected returns: [[57.82772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0.  0.  3. 25.] 
cards in discard: [29.  0.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 6.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 51.85234832763672






Player: 1 
cards in hand: [3. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [3. 3. 0. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [3. 3. 0. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 6.] 
cards in discard: [3. 3. 0. 0. 0. 3. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  3.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[-15.174349]
 [ 19.927353]
 [ -6.07816 ]
 [ -6.07816 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.827720642089844



action possibilites: [-1.  8.  8.] 
expected returns: [[-7.228766 ]
 [ 2.3497763]
 [ 2.3497763]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 25  8  8 25 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.95067596435547



action possibilites: [-1] 
expected returns: [[-3.6011894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 35.72515106201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-15.586282 ]
 [ -5.057691 ]
 [-64.31968  ]
 [  2.9442444]
 [ -4.7611103]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  6.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.601189374923706



buy possibilites: [-1] 
expected returns: [[-23.361708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 2.944230079650879






Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 25.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  8. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 25.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 25.  0. 25.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[-22.988714]
 [-13.699653]
 [ 51.988   ]
 [ 51.988   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0. 25.  0.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 8. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.36170768737793



action possibilites: [-1] 
expected returns: [[-20.875803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  0.  0.  3.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1 6] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.53287887573242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-29.123    ]
 [ -2.2434173]
 [-19.980413 ]
 [-64.00136  ]
 [ -1.741827 ]
 [-12.117517 ]
 [-28.64347  ]
 [-19.510744 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25.  0.  0.  3.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10. 10.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1 6] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.875802993774414



buy possibilites: [-1] 
expected returns: [[-8.124792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25.  0.  0.  3.] 
cards in discard: [ 8. 29.  8.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  9.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 8. 0. 6.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1 6] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -1.7418270111083984






Player: 1 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  9.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [1. 0. 0. 3. 8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 6 0 3 6 3 1 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  9.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  8.  0.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[-28.070656]
 [-17.824024]
 [ -5.632036]
 [ 42.845085]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  7. 10.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.124792098999023



action possibilites: [-1] 
expected returns: [[-58.78221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  6. 10.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.039371490478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -64.58882 ]
 [ -55.720192]
 [-101.28642 ]
 [ -48.80475 ]
 [ -53.839657]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  6. 10.  8.  5.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -58.78221130371094



buy possibilites: [-1] 
expected returns: [[-63.61569]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0. 29.  3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  6. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -48.804744720458984






Player: 1 
cards in hand: [8. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  6. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  6. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 3.] 
cards in discard: [6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  8.  0.] 
adversary cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[-33.562675]
 [ 19.7239  ]
 [-27.795906]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  8.  0.] 
cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -63.61568832397461



action possibilites: [-1] 
expected returns: [[-23.524181]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8. 0.] 
cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.83785629272461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-24.714302 ]
 [ -2.0045977]
 [-16.245117 ]
 [-62.36754  ]
 [ -7.013526 ]
 [ -1.4836769]
 [ -9.95285  ]
 [  7.336199 ]
 [-47.615658 ]
 [-24.193378 ]
 [-24.905956 ]
 [-15.253443 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8. 0.] 
cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  5. 10.  8.  4.  8.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -23.524181365966797



buy possibilites: [-1] 
expected returns: [[-7.4875407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8. 0.] 
cards in discard: [ 8. 25.  8. 11.  0.  0. 29.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 6. 3. 0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 7.336215019226074






Player: 1 
cards in hand: [1. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[-69.7361 ]
 [-51.51985]
 [-29.44802]
 [-66.07803]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.4875407218933105



action possibilites: [-1] 
expected returns: [[-44.778267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  4. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -30.3978271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-53.446888]
 [-25.916046]
 [-43.275223]
 [-88.54597 ]
 [-25.321028]
 [-35.598106]
 [-52.90604 ]
 [-42.229836]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  4. 10.  8.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.77826690673828



buy possibilites: [-1] 
expected returns: [[-44.724083]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  0.  3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -25.32102394104004






Player: 1 
cards in hand: [11.  0.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.  0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  8. 11.] 
adversary cards in discard: [11. 25.  0. 29.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  8. 11.] 
adversary cards in discard: [11. 25.  0. 29.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  8. 11.] 
adversary cards in discard: [11. 25.  0. 29.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [6. 0. 8. 3. 3. 3. 3. 6. 3. 1. 0. 6. 3. 0. 6. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  8. 11.] 
adversary cards in discard: [11. 25.  0. 29.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11.] 
expected returns: [[-1.2651696]
 [ 3.7889576]
 [ 3.7889576]
 [ 3.7889576]
 [12.558205 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  8. 11.] 
cards in discard: [11. 25.  0. 29.  0.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -44.724082946777344



action possibilites: [-1] 
expected returns: [[-3.200879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8.] 
cards in discard: [11. 25.  0. 29.  0.  8.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.258893966674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.892021  ]
 [-48.42993   ]
 [  0.14606094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 8.] 
cards in discard: [11. 25.  0. 29.  0.  8.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.2008790969848633






Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-72.24473 ]
 [-54.639004]
 [-38.728622]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  7.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10] -> size -> 25 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.1460862159729004



action possibilites: [-1] 
expected returns: [[-53.937637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  7.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -41.427188873291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-58.42897 ]
 [-36.031013]
 [-50.363297]
 [-91.91907 ]
 [-35.438034]
 [-44.430656]
 [-57.804646]
 [-48.738663]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  7.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -53.93763732910156



buy possibilites: [-1] 
expected returns: [[-31.611883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0.  8.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -35.43802261352539






Player: 1 
cards in hand: [ 3. 11.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  6.  3.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  8. 11. 11.  0.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11] -> size -> 19 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  6.  3.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  8. 11. 11.  0.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11] -> size -> 19 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 11.] 
expected returns: [[-36.14613 ]
 [-32.318775]
 [-32.318775]
 [-24.305174]
 [-24.305174]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 11.  0.] 
cards in discard: [11. 25.  3. 29.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -31.61188316345215



action possibilites: [-1] 
expected returns: [[-22.226942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0.] 
cards in discard: [11. 25.  3. 29.  0.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -16.834522247314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-29.118887]
 [-67.49228 ]
 [-20.245815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11.  0.] 
cards in discard: [11. 25.  3. 29.  0.  0.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -22.22694206237793






Player: 1 
cards in hand: [3. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 25. 10.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0.  0.  8. 10. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0. 25. 10.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0.  0.  8. 10. 11.  8.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25. 10.] 
expected returns: [[-40.95516  ]
 [-35.748417 ]
 [-22.022259 ]
 [ -0.9032712]
 [-47.48842  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 25. 10.] 
cards in discard: [11. 25.  3. 29.  0.  0.  0.  8. 10. 11.  8.  8. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  3. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -20.245773315429688



action possibilites: [-1] 
expected returns: [[-43.225372]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.9032769203186035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-50.70509 ]
 [-28.915232]
 [-41.686836]
 [-86.264206]
 [-27.790512]
 [-34.933   ]
 [-50.136616]
 [-40.28727 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  6.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -43.225372314453125



buy possibilites: [-1] 
expected returns: [[-39.291477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -27.79050636291504






Player: 1 
cards in hand: [0. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8. 11. 10.  0.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [10.  0.  6.  0.  0.  0.  6.  3. 11.  0.  6.  3.  3.  0.  3.  6.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  8. 11. 10.  0.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11] -> size -> 21 
adversary victory points: 1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  8. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
expected returns: [[-25.852512]
 [-14.087915]
 [-21.722973]
 [-14.087915]
 [-34.74699 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11. 10.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -39.29147720336914



action possibilites: [-1] 
expected returns: [[-39.002872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -5.52535343170166





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-46.78056]
 [-80.55349]
 [-38.10471]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -39.002872467041016






Player: 1 
cards in hand: [6. 6. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 1. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  6  0  3  6  3  1  6 11  6  0  6  3  6  0  3
 10  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  8.  8. 11.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  8.  8. 11.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  8.  8. 11.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  8.  8. 11.] 
adversary cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [25.  3.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8. 11.] 
expected returns: [[-40.87043   ]
 [  0.11687994]
 [-35.87054   ]
 [-35.87054   ]
 [-29.165499  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  8.  8. 11.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  2. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -38.10469436645508



action possibilites: [-1] 
expected returns: [[-71.90092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 11.  0.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.11685752868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -79.68496]
 [ -70.91659]
 [-109.91741]
 [ -65.43431]
 [ -71.03994]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 11.  0.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  4.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -71.90091705322266



buy possibilites: [-1] 
expected returns: [[-76.8713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  8. 11.  0.  0.] 
cards in discard: [11. 25.  8. 29.  0. 10.  0.  0. 10. 11.  8. 11. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [0. 8. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -65.43431091308594






Player: 1 
cards in hand: [3. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [0. 8. 6. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [0. 8. 6. 3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
adversary victory points: 1
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[-100.919914]
 [ -87.65789 ]
 [ -93.43984 ]
 [-106.70992 ]
 [ -87.65789 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -76.87129974365234



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-56.495544]
 [-42.60651 ]
 [-66.084206]
 [-33.711906]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -87.73810577392578



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[-60.531044]
 [-48.770542]
 [-68.78537 ]
 [-48.770542]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -33.71190643310547



action possibilites: [-1] 
expected returns: [[-60.69651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -36.28047180175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-65.60246 ]
 [-49.465706]
 [-59.5917  ]
 [-89.643265]
 [-53.027218]
 [-49.07217 ]
 [-55.115185]
 [-42.79985 ]
 [-80.23684 ]
 [-65.24118 ]
 [-65.753204]
 [-58.92569 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  8. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: -60.696510314941406



buy possibilites: [-1] 
expected returns: [[-5.9993706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  6.] 
adversary cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -42.79984664916992






Player: 1 
cards in hand: [ 0.  3. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  6.] 
cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29] -> size -> 25 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  6.] 
cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  3.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29] -> size -> 25 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  6.] 
cards in discard: [0. 8. 6. 3. 6. 3. 6. 6. 0. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10.  0.  8. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29] -> size -> 25 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 10.] 
expected returns: [[-41.599564]
 [-31.89574 ]
 [-48.002712]
 [-37.916435]
 [-48.002712]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.999370574951172



action possibilites: [-1] 
expected returns: [[-31.888145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -21.873716354370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-39.71504 ]
 [-66.91532 ]
 [-31.902683]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.888145446777344






Player: 1 
cards in hand: [6. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-26.49631 ]
 [-13.418545]
 [-20.535025]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -31.902671813964844



action possibilites: [-1] 
expected returns: [[-41.67752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.9420099258422852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-48.823914]
 [-42.274307]
 [-78.526634]
 [-36.837593]
 [-42.517788]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  2.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.677520751953125



buy possibilites: [-1] 
expected returns: [[-64.98818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -36.83759307861328






Player: 1 
cards in hand: [ 3. 11.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  6.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  1. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8.  8.  8. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.  8. 11.
  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8.  8.  8. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.  8. 11.
  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6.] 
cards in discard: [ 0.  8.  6.  3.  6.  3.  6.  6.  0.  3.  8.  0.  3. 10.  0.  6.  1.  6.
  0.  0.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [25.  8.  8.  8. 25.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.  8. 11.
  0.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25.  8.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.  8. 25.] 
expected returns: [[-58.154266]
 [-27.970898]
 [-54.352917]
 [-54.352917]
 [-54.352917]
 [-27.970898]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  8.  8. 25.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 10. 11. 10.  0.  8. 10. 10.  8. 11.
  0.  0.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -64.9881820678711



action possibilites: [-1] 
expected returns: [[-37.334297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -27.970897674560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-42.780468]
 [-36.84446 ]
 [-32.697   ]
 [-35.623253]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  1.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.33429718017578



buy possibilites: [-1] 
expected returns: [[-25.660076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 25.  0.  0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -32.696990966796875






Player: 1 
cards in hand: [6. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[-33.407547]
 [-16.562489]
 [-41.95775 ]
 [-22.14888 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10. 11.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.660076141357422



action possibilites: [-1. 11. 11.] 
expected returns: [[-48.325394]
 [-39.77104 ]
 [-39.77104 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -23.063350677490234



action possibilites: [-1] 
expected returns: [[-42.568336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -40.79469299316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-51.52083 ]
 [-46.815926]
 [-43.427704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.568336486816406






Player: 1 
cards in hand: [3. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 11.  8. 10.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.  8. 10.] 
expected returns: [[-66.33318 ]
 [-63.2588  ]
 [-52.260468]
 [-58.16026 ]
 [-63.2588  ]
 [-71.72415 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  8. 10.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -43.42768478393555



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-55.497627]
 [-51.35498 ]
 [-51.35498 ]
 [-51.35498 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25  8 25 29  8  8 11  8 29 11 10 11 10 11 10  8 10
 29 10 10  8  8  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -58.50120544433594



action possibilites: [-1] 
expected returns: [[-48.7257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -44.31662368774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-57.13717 ]
 [-49.667202]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  1. 10.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -48.72570037841797






Player: 1 
cards in hand: [ 6.  0.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10. 10.] 
adversary cards in hand: [29. 10.  3. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0.  1. 10.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29. 10.  3. 10. 11.] 
adversary cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 10.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11.] 
expected returns: [[-37.938446]
 [-13.048157]
 [-45.798607]
 [-45.798607]
 [-21.90596 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3. 10. 11.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -49.66719055175781



action possibilites: [-1. 10. 10.] 
expected returns: [[ -88.52772]
 [-100.33282]
 [-100.33282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -22.12904930114746





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-102.42434 ]
 [ -89.854225]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [ 8. 25.  8.  8.  8. 25.  0.  0.  0. 10.  1. 29. 11.  0. 11. 11. 10. 29.
  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -88.5277099609375






Player: 1 
cards in hand: [6. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-101.72321 ]
 [-107.106255]
 [-107.106255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  6.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15  0] -> size -> 34 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -89.8542251586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-106.3373  ]
 [-100.015724]
 [-103.04673 ]
 [ -99.13794 ]
 [-105.93299 ]
 [-100.265274]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  5.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  6.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15  0] -> size -> 34 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -101.72321319580078



buy possibilites: [-1] 
expected returns: [[-89.62458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  6.  3.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15  0] -> size -> 34 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -99.13792419433594






Player: 1 
cards in hand: [ 0. 11.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  6.  3.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6
  6  0  6  8  1  6 10  0 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 10. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 10.] 
expected returns: [[-60.67723]
 [-47.80726]
 [-51.8388 ]
 [-67.98084]
 [-67.98084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 10.] 
cards in discard: [11.  0.  0. 10. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -89.62458038330078



action possibilites: [-1. 10. 11.] 
expected returns: [[-28.457344]
 [-35.5063  ]
 [-19.24256 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -52.808082580566406



action possibilites: [-1] 
expected returns: [[-11.993246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -19.74871826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-19.352932]
 [-13.183426]
 [-11.803728]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.993246078491211






Player: 1 
cards in hand: [3. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6
  0  6  8  1  6 10  0 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 29. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 29. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 29. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [10.  6.  0.  0.  6.  0.  0.  3.  6.  0.  6.  3. 15.  6.  0.  0.  1. 10.
  0.  6.  0.  3.  3.  6.  8.  0. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 29. 10.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[-41.93885 ]
 [-38.208607]
 [-25.571396]
 [-48.852737]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 29. 10.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.803703308105469



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[-55.13839 ]
 [-50.940777]
 [-60.51786 ]
 [-60.51786 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 10 11 10 11 10  8 10 29 10
 10  8  8  1 11  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -32.32440185546875



action possibilites: [-1] 
expected returns: [[-33.6773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -45.137386322021484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-41.270653]
 [-33.582413]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 15.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -33.67729949951172






Player: 1 
cards in hand: [ 3. 15.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29.  1.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29.  1.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  6.  3.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29.  1.] 
adversary cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  8. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 29.] 
expected returns: [[-101.296  ]
 [ -99.23372]
 [ -81.19523]
 [ -99.23372]
 [ -88.22816]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8. 29.  1.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -33.58241271972656



action possibilites: [-1] 
expected returns: [[-70.82492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  1.  8.  0.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -81.19524383544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-83.16401 ]
 [-68.27981 ]
 [-75.90167 ]
 [-67.51157 ]
 [-82.403336]
 [-72.94738 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  1.  8.  0.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  4.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -70.82492065429688



buy possibilites: [-1] 
expected returns: [[-91.76749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  1.  8.  0.] 
cards in discard: [11.  0.  0. 10. 10.  0. 11. 10.  1. 29. 11.  0. 10.  0.  3. 29.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  0.  6.  0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -67.51156616210938






Player: 1 
cards in hand: [10.  8.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  6.  0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10. 11. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8. 25.] 
expected returns: [[-89.748665]
 [-94.679665]
 [-87.7803  ]
 [-87.7803  ]
 [-89.96464 ]
 [-80.5983  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -91.76748657226562



action possibilites: [-1] 
expected returns: [[-78.38695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -80.59830474853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-88.8296  ]
 [-78.050835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [10.  3.  3.  6.  6.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -78.38694763183594






Player: 1 
cards in hand: [10.  3.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  6.  6.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1. 25. 11. 29.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1. 25. 11. 29.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1. 25. 11. 29.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  1. 25. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11. 29.] 
expected returns: [[-54.75103 ]
 [-44.253372]
 [-31.069174]
 [-44.253372]
 [-40.343304]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25. 11. 29.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -78.0508041381836



action possibilites: [-1] 
expected returns: [[-27.586868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11. 29.  8. 10.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -31.069194793701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-34.834976]
 [-28.153778]
 [-26.728357]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 11. 29.  8. 10.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.586868286132812






Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  8.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  7. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  8.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  8.  8.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
adversary victory points: 1
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[-52.76512 ]
 [-36.378975]
 [-48.302032]
 [-48.302032]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  8.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -26.72837257385254



action possibilites: [-1.  8.] 
expected returns: [[-57.07389]
 [-53.3388 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8
  8  1 11  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -42.6319580078125



action possibilites: [-1] 
expected returns: [[-65.85737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8  8  1
 11  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -48.13607406616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-71.578705]
 [-65.017204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8  8  1
 11  1 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -65.85736846923828






Player: 1 
cards in hand: [ 6.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 11.] 
cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 11.  8.] 
adversary cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.  0.  8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8  8  1
 11  1 11] -> size -> 27 
adversary victory points: 1
player victory points: -4 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 8 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 10.  0. 11.  8.] 
cards in discard: [25. 10. 11. 11.  8.  0. 11. 25. 11.  1. 11. 29.  8. 10.  0.  8. 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25 25 29  8 11  8 29 11 11 11 10  8 10 29 10 10  8  8  1
 11  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0. 10.  3.  0.  8.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 15.  6.  3.  0.  0. 10.  8.  0.  6.  0.  3. 10.  3.  3.  6.  6.
  0. 29.  0.  6.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  8  0  3  6  3  6 11  6  0  6  3  6  0  3 10  6  6  0  6
  8  1  6 10  0 15  0  0  0  0 29 10] -> size -> 36 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[     -5 3000000       0     150       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000145 

action type: buy - action -1.0
Learning step: 120008.3984375
desired expected reward: 119943.3828125



