 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.492844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000185 

action type: buy - action -1.0
Learning step: -300036.125
desired expected reward: -299860.0





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.586624]
 [76.077736]
 [70.52562 ]
 [48.48015 ]
 [83.13562 ]
 [70.60327 ]
 [65.18262 ]
 [58.099815]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.80928039550781



buy possibilites: [-1] 
expected returns: [[49.30204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 83.1356201171875






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[66.18343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.302040100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 66.660065]
 [ 88.01368 ]
 [ 81.352   ]
 [ 54.062782]
 [ 76.348206]
 [ 96.41478 ]
 [ 81.44983 ]
 [107.21982 ]
 [ 68.72541 ]
 [ 74.822815]
 [ 90.13827 ]
 [ 66.07263 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.70996856689453



buy possibilites: [-1] 
expected returns: [[24.1819]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.21981811523438






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.370562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.181900024414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.814734]
 [44.67627 ]
 [40.352814]
 [22.835093]
 [50.1186  ]
 [40.398563]
 [36.105843]
 [30.737906]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 29.499399185180664



buy possibilites: [-1] 
expected returns: [[29.287188]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.11859893798828






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[62.575882]
 [91.89591 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.287187576293945



action possibilites: [-1] 
expected returns: [[58.020138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 99.14559173583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.78473 ]
 [81.35561 ]
 [74.32277 ]
 [45.775436]
 [90.20937 ]
 [74.40655 ]
 [67.4074  ]
 [58.24646 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.020137786865234



buy possibilites: [-1] 
expected returns: [[34.336292]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 90.20938873291016






Player: 1 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0. 8. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[16.085213]
 [37.180046]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.3362922668457



action possibilites: [-1.] 
expected returns: [[32.6868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.788597106933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.38206 ]
 [49.632225]
 [44.975353]
 [26.150162]
 [55.53796 ]
 [45.01075 ]
 [40.276325]
 [34.304195]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.686798095703125



buy possibilites: [-1] 
expected returns: [[28.97392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 55.537960052490234






Player: 1 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[31.732233]
 [37.19439 ]
 [51.490788]
 [51.490788]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.973920822143555



action possibilites: [-1] 
expected returns: [[4.778038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.474857330322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.496398 ]
 [14.915583 ]
 [-0.4437399]
 [14.795925 ]
 [ 6.968603 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.778038024902344



buy possibilites: [-1] 
expected returns: [[1.8574264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [11. 29.  3.  3.  0.  0.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 1. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 14.915580749511719






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 1. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 1. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 1. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.763374]
 [33.813866]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.857426404953003



action possibilites: [-1] 
expected returns: [[22.007418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.51982116699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.198889]
 [37.084   ]
 [33.53968 ]
 [18.173754]
 [42.01396 ]
 [33.46389 ]
 [29.919569]
 [25.445526]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  5.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.007417678833008



buy possibilites: [-1] 
expected returns: [[29.315748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.01396179199219






Player: 1 
cards in hand: [ 0.  3.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 11.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3. 29.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[28.485037]
 [41.93017 ]
 [46.635197]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3. 29.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.31574821472168



action possibilites: [-1. 11. 10.] 
expected returns: [[40.305664]
 [58.336906]
 [44.51648 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.40768051147461



action possibilites: [-1] 
expected returns: [[5.4649153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.74839782714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.898596 ]
 [19.977526 ]
 [ 4.9187756]
 [19.846016 ]
 [11.274338 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.4649152755737305



buy possibilites: [-1] 
expected returns: [[4.5869503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 19.97753143310547






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3] -> size -> 22 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3] -> size -> 22 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3] -> size -> 22 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-2.4166458]
 [ 6.015833 ]
 [ 6.015833 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.586950302124023



action possibilites: [-1] 
expected returns: [[20.165842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 9.31005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.375227]
 [29.285414]
 [11.848763]
 [28.64437 ]
 [22.340652]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.165842056274414



buy possibilites: [-1] 
expected returns: [[73.05824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 10.  3. 29. 11.  0.  3.  3. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.2854061126709






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  8.  0. 11.  0.  3.  3.  0.  3.  0. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[17.995531]
 [21.631613]
 [21.631613]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.05824279785156



action possibilites: [-1. 10.] 
expected returns: [[ 7.3924026]
 [10.485307 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 17.541467666625977



action possibilites: [-1. 10.] 
expected returns: [[23.84328 ]
 [27.801245]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 10.485305786132812



action possibilites: [-1.] 
expected returns: [[3.7849672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 4 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 27.801244735717773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.1743355 ]
 [18.904476  ]
 [15.4127865 ]
 [ 0.92240787]
 [11.889451  ]
 [23.978724  ]
 [15.15288   ]
 [29.158304  ]
 [ 8.393291  ]
 [11.719509  ]
 [20.296324  ]
 [ 8.034041  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.7849671840667725



buy possibilites: [-1] 
expected returns: [[-7.933792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.158300399780273






Player: 1 
cards in hand: [3. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0. 10.] 
adversary cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29] -> size -> 25 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0. 10.] 
adversary cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29] -> size -> 25 
adversary victory points: 6
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[31.255812]
 [32.848755]
 [32.848755]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0. 10.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  3.  0. 11.  3.] 
adversary cards in discard: [3. 8. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.9337921142578125



action possibilites: [-1. 10. 11.] 
expected returns: [[32.668587]
 [32.536797]
 [36.637623]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 11.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  3.  0. 11.  3.] 
adversary cards in discard: [3. 8. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 33.7669792175293



action possibilites: [-1. 10.] 
expected returns: [[41.04901 ]
 [41.273376]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [23.  3.  0. 11.  3.] 
adversary cards in discard: [3. 8. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.116310119628906



action possibilites: [-1.] 
expected returns: [[79.61665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [23.  3.  0. 11.  3.] 
adversary cards in discard: [3. 8. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 41.27336883544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.83527]
 [70.93306]
 [81.33982]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [23.  3.  0. 11.  3.] 
adversary cards in discard: [3. 8. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.61665344238281






Player: 1 
cards in hand: [23.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0. 11.  3.] 
cards in discard: [3. 8. 0. 1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0. 11.  3.] 
cards in discard: [3. 8. 0. 1. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0. 11.  3.] 
cards in discard: [3. 8. 0. 1. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[38.30652 ]
 [49.246338]
 [49.246338]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 11.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.33981323242188



action possibilites: [-1] 
expected returns: [[35.0632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 52.85557556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.308475]
 [26.318691]
 [36.91483 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [29. 10. 10. 10.  3.  0.  0.  0.  0. 10. 10. 11. 10.  3.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.063201904296875






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  8. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 23.  3.  0. 11.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 11.] 
expected returns: [[-18.782057]
 [ -6.354763]
 [ -6.354763]
 [-11.058675]
 [-11.058675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.91484069824219



action possibilites: [-1. 29. 11. 11. 11.] 
expected returns: [[-19.882032]
 [ -9.957824]
 [-11.675962]
 [-11.675962]
 [-11.675962]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -11.876157760620117



action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[-9.758818 ]
 [ 8.807289 ]
 [ 8.807289 ]
 [ 8.807289 ]
 [-5.4178143]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -9.957820892333984



action possibilites: [-1] 
expected returns: [[-19.661016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.62287712097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-22.2387  ]
 [-19.715101]
 [-19.75543 ]
 [-23.709173]
 [-18.297096]
 [-20.434164]
 [-20.522942]
 [-19.735863]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.6610164642334



buy possibilites: [-1] 
expected returns: [[35.31632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -18.297096252441406






Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[44.14758]
 [42.65518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  3.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.31631851196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.619995]
 [35.152893]
 [46.48046 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  3.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.1475944519043



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  8. 10.  9.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  2. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[68.21209]
 [85.38556]
 [71.82043]
 [85.38556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 23.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.48048782348633



action possibilites: [-1] 
expected returns: [[73.03601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 23.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.7881088256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[67.1832  ]
 [75.09921 ]
 [61.34957 ]
 [73.82823 ]
 [72.714096]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 23.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.0360107421875



buy possibilites: [-1] 
expected returns: [[60.733353]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 3. 23.  3.  0.  3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 75.09917449951172






Player: 1 
cards in hand: [ 3. 23.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  3.  0.  3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29] -> size -> 23 
action values: 0 
buys: 2 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
adversary victory points: 7
player victory points: 5 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
adversary victory points: 7
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10. 10.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[21.008873]
 [24.373762]
 [24.373762]
 [24.373762]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.73335266113281



action possibilites: [-1. 10. 10.] 
expected returns: [[49.534412]
 [54.923508]
 [54.923508]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 24.3737735748291



action possibilites: [-1. 10.] 
expected returns: [[ 99.92044]
 [108.25069]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 54.92350769042969



action possibilites: [-1.] 
expected returns: [[79.23631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 4 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 108.25070190429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 80.514206]
 [105.98802 ]
 [ 99.21219 ]
 [ 65.121605]
 [115.856384]
 [ 98.83081 ]
 [ 91.18344 ]
 [ 81.96908 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  2.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.23631286621094



buy possibilites: [-1] 
expected returns: [[15.764921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 29. 11. 11.  0. 11. 10.  0. 10.  3.  3.  3. 10.  3. 11. 10.
 11.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  1.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.85640716552734






Player: 1 
cards in hand: [ 8.  0. 11.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  1.  8.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  8  1  3  3  8  0 23  0  8 11 29  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [11.  0.  8.  0.  0.  3. 29.  0.  0.  0.  3.  0.  1.  0. 23.  3.  3.  0.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [10. 10. 29.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
adversary victory points: 7
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[18.737274]
 [18.9833  ]
 [18.9833  ]
 [28.741201]
 [18.9833  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  3. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.764921188354492



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[79.588455]
 [82.745804]
 [82.745804]
 [82.745804]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.305374145507812



action possibilites: [-1. 10. 10.] 
expected returns: [[68.55324]
 [70.07973]
 [70.07973]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 82.74581909179688



action possibilites: [-1. 10.] 
expected returns: [[54.427055]
 [57.476128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 3 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 70.07972717285156



action possibilites: [-1. 10.] 
expected returns: [[54.001923]
 [53.101006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 4 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 57.47612762451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[46.099083]
 [51.542107]
 [50.775562]
 [43.232952]
 [54.8291  ]
 [49.851017]
 [49.1338  ]
 [50.149757]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  1.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.001953125



buy possibilites: [-1] 
expected returns: [[104.64116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0 54  0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.82910919189453






Player: 1 
cards in hand: [ 0.  3. 29.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1. 23.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0] -> size -> 22 
action values: 0 
buys: 2 
player value: 4 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  7. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 0. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10. 10.] 
adversary cards in hand: [11. 29.  3. 10. 10.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 29.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[ 95.94481 ]
 [100.98541 ]
 [100.729485]
 [ 93.904465]
 [ 93.904465]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 10. 10.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.64115905761719



action possibilites: [-1] 
expected returns: [[94.92884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10. 10.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.7381362915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.17537 ]
 [85.183815]
 [95.2796  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 10. 10.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.92884063720703






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  9.] 
adversary cards in hand: [11. 11. 10.  3.  3.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15] -> size -> 34 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  9.] 
adversary cards in hand: [11. 11. 10.  3.  3.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15] -> size -> 34 
adversary victory points: 7
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 11. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[4.372381 ]
 [9.896912 ]
 [9.896912 ]
 [4.4170246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  3.  3.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  9.] 
adversary cards in hand: [11.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.27958679199219



action possibilites: [-1] 
expected returns: [[18.741365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  8.] 
adversary cards in hand: [11.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.090768814086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.36177 ]
 [12.471731]
 [19.055956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  3.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  8.] 
adversary cards in hand: [11.  8.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.741365432739258






Player: 1 
cards in hand: [11.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  1. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
adversary victory points: 7
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[94.23508 ]
 [91.060875]
 [89.713135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.055952072143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.89189 ]
 [92.325226]
 [72.71165 ]
 [90.03827 ]
 [92.2665  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 94.23503112792969



buy possibilites: [-1] 
expected returns: [[65.69923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 92.32515716552734






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0. 29.  0. 23. 29.  3.  1.  3.  3.  3.  0.  0.  0.  0. 10. 11.  8.  0.
 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 11. 11.] 
adversary cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[61.86846]
 [66.72534]
 [66.72534]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 11.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.69922637939453



action possibilites: [-1] 
expected returns: [[96.24176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 63.6658935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 91.2438  ]
 [100.565   ]
 [ 85.14266 ]
 [ 99.26895 ]
 [ 96.981316]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.24176025390625



buy possibilites: [-1] 
expected returns: [[82.6429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [11. 29. 10. 10. 10.  3.  3.  0.  0. 10. 15. 11. 29.  3. 10. 10. 15. 11.
 11. 10.  3.  3.  3. 11. 10.  3.  0.  0.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 100.56497192382812






Player: 1 
cards in hand: [ 8.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3] -> size -> 38 
adversary victory points: 9
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3] -> size -> 38 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 11. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3] -> size -> 38 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11. 11. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[116.66342 ]
 [125.65297 ]
 [125.65297 ]
 [125.65297 ]
 [114.337685]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.64289855957031



action possibilites: [-1] 
expected returns: [[49.173042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.  0.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 119.21833801269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.975945]
 [37.18714 ]
 [48.6855  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 10.  0.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [ 8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.17304229736328






Player: 1 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 8. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 22. 30.  8. 10. 10.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [ 8. 10.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[124.02106]
 [126.57893]
 [138.05763]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 15.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3
 29 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.68548583984375



action possibilites: [-1] 
expected returns: [[75.39302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 138.05763244628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[73.78331 ]
 [84.27413 ]
 [82.011955]
 [66.40908 ]
 [81.315605]
 [76.75816 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.39302062988281



buy possibilites: [-1] 
expected returns: [[95.121994]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 179 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 84.27410888671875






Player: 1 
cards in hand: [ 3.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 25. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 11.  3.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1] -> size -> 39 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 89.85811 ]
 [ 92.488846]
 [106.593765]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  3.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [23.  8.  0.  3.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.12199401855469



action possibilites: [-1] 
expected returns: [[147.96425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [23.  8.  0.  3.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 142 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 100.2354736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[142.6234 ]
 [135.40523]
 [147.96552]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [23.  8.  0.  3.  0.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.96424865722656






Player: 1 
cards in hand: [23.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  3.  0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0] -> size -> 26 
action values: 0 
buys: 2 
player value: 4 
card supply: [23. 24. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
adversary victory points: 9
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10.  3.  0. 15.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15.] 
expected returns: [[78.00587 ]
 [89.80426 ]
 [78.389465]
 [85.75986 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0. 15.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.9655303955078



action possibilites: [-1] 
expected returns: [[132.80017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 15.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 83.96643829345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[130.28511 ]
 [121.490875]
 [133.24486 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 15.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1] -> size -> 27 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.8001708984375






Player: 1 
cards in hand: [11.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 29.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8. 10.  9.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 29.] 
cards in discard: [ 8. 10.  0. 16.  3.  0.  0.  3.  1.  0.  3.  0.  0. 29.  0.  1. 23.  8.
  0.  3.  0.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 11. 11.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
adversary victory points: 9
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  1. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[127.580444]
 [145.47507 ]
 [145.47507 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11. 11.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.244873046875



action possibilites: [-1] 
expected returns: [[104.34068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 138.05625915527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.88076 ]
 [111.83345 ]
 [ 89.25838 ]
 [110.74362 ]
 [103.583084]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 21. 30. 22. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.34068298339844



buy possibilites: [-1] 
expected returns: [[72.7011]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 11.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 111.83345031738281






Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  0.  0. 10. 29.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
adversary victory points: 10
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 21. 30. 21. 30.  8. 10.  8.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  0.  0. 10. 29.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
adversary victory points: 10
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 21. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  0.  0. 10. 29.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
adversary victory points: 10
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[62.966858]
 [96.48445 ]
 [66.53347 ]
 [96.48445 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 29.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 21. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.70110321044922



action possibilites: [-1. 10. 29. 10.] 
expected returns: [[ 90.39958]
 [ 97.85278]
 [141.95381]
 [ 97.85278]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 21. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.64482879638672



action possibilites: [-1. 10.] 
expected returns: [[82.506516]
 [80.96944 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 21. 30. 21. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 83.91715240478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[73.94431 ]
 [84.9587  ]
 [67.34435 ]
 [83.03922 ]
 [82.506516]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3] -> size -> 43 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 21. 30. 21. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
adversary victory points: 4
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.50651550292969



buy possibilites: [-1] 
expected returns: [[100.04268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 171 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 84.95873260498047






Player: 1 
cards in hand: [16.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [16.  0.  3.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11 29  1  0 29  0 10  0
 16  0  1 16  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
adversary victory points: 11
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
adversary victory points: 11
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  7. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
adversary victory points: 11
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
adversary victory points: 11
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[146.32033]
 [165.90895]
 [147.59056]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.  0.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.04267883300781



action possibilites: [-1] 
expected returns: [[98.04301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 153.17892456054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[89.74275 ]
 [86.84929 ]
 [98.043045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11. 10.  0.  1. 15.  3.  3. 10.  1. 11.  0.  3. 10.  3.  1.
 11. 10.  3.  0. 15.  1.  3. 11.  3.  3.  1. 11.  0.  0. 10. 10.  3. 29.
 29. 10.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.04300689697266






Player: 1 
cards in hand: [ 0. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8] -> size -> 31 
action values: 0 
buys: 2 
player value: 7 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 


buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8 14  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  1. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[165.35013]
 [153.72264]
 [158.83623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  8. 29.  8.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8 14  0] -> size -> 33 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.04300689697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[157.69276]
 [158.4142 ]
 [162.06158]
 [155.7177 ]
 [159.94193]
 [166.7129 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  8. 29.  8.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8 14  0] -> size -> 33 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 165.3501739501953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  8.  0.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0  3  3  8  0 23  0  8 11  1  0 29  0 10  0 16
  0  1 16  0 16 15  8 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 11. 11.  1.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 11. 11.  1.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 11. 11.  1.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[64.59475 ]
 [73.804825]
 [73.804825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  1.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 16.  3.  3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.71292114257812



action possibilites: [-1] 
expected returns: [[114.10356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 16.  3.  3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 70.4014663696289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[115.04995 ]
 [123.709755]
 [122.16568 ]
 [110.371704]
 [119.0965  ]
 [121.692764]
 [128.5848  ]
 [116.31038 ]
 [124.65115 ]
 [117.78014 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 19. 30. 20. 30.  8. 10.  7.  0.  6. 10.  6.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 16.  3.  3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.10356140136719



buy possibilites: [-1] 
expected returns: [[173.47519]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 20. 30.  8. 10.  7.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 16.  3.  3.] 
adversary cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 128.58474731445312






Player: 1 
cards in hand: [ 0. 11. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  3.  3.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 20. 30.  8. 10.  7.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
adversary victory points: 11
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3.] 
cards in discard: [16.  0.  3.  0.  0.  1. 15.  8. 16.  0.  0.  0. 14.  0. 23.  0.  0.  0.
  0.  1.  8.  8. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 15.  0. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[78.808464]
 [85.782974]
 [78.11104 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29
 10 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.47518920898438



action possibilites: [-1] 
expected returns: [[42.588997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 85.78297424316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[38.061325]
 [40.361378]
 [42.60936 ]
 [36.00822 ]
 [38.368553]
 [40.906364]
 [35.5947  ]
 [39.47847 ]
 [41.14727 ]
 [45.043232]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.58899688720703






Player: 1 
cards in hand: [23.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 11. 11.  0.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 11. 11.  0.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0. 10. 11.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 11. 11.  0.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[70.329834]
 [83.58266 ]
 [83.58266 ]
 [83.58266 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.04322052001953



action possibilites: [-1] 
expected returns: [[134.03212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 77.829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.22853]
 [117.10356]
 [132.60686]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.03211975097656






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  6. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 15. 10.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[158.20085]
 [165.83478]
 [156.90656]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10
 10 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0. 16. 16.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 132.60682678222656



action possibilites: [-1] 
expected returns: [[100.14038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0. 16. 16.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 165.8347625732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 95.17122 ]
 [114.14604 ]
 [108.7739  ]
 [ 86.02407 ]
 [107.629875]
 [100.14034 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 18. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0. 16. 16.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.140380859375



buy possibilites: [-1] 
expected returns: [[83.321594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0. 16. 16.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 114.14607238769531






Player: 1 
cards in hand: [ 3.  0. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16. 16.  0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 10.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 16.  0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 10.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16. 16.  0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 10.  1.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[146.43524]
 [142.89906]
 [142.89906]
 [142.89906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.32159423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[139.0898 ]
 [144.58226]
 [136.76482]
 [142.9393 ]
 [146.43524]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 10.  1.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
adversary victory points: 3
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 146.4352264404297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  1. 11. 10.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 17. 30. 20. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 17. 30. 19. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
adversary victory points: 11
player victory points: 4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[45.819004]
 [52.52102 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 19. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  210    0    0    0    0    0    0    0 -120    0    0
  914    0] 
sum of rewards: 999 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 166.42503356933594



action possibilites: [-1.] 
expected returns: [[52.261215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 19. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 52.52104187011719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[46.61437 ]
 [68.26912 ]
 [39.360912]
 [66.93197 ]
 [52.261185]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 17. 30. 19. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
adversary victory points: 4
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.26121520996094



buy possibilites: [-1] 
expected returns: [[77.584076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  1.  0.  3. 16.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
adversary victory points: 4
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: 141 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 68.26917266845703






Player: 1 
cards in hand: [ 8.  1.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  3. 16.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16
  0 16 15  8 14  0 16  0  0  8  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 30.  8. 10.  6.  0.  5. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
adversary victory points: 12
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
adversary victory points: 12
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 17. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
adversary victory points: 12
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 17. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10. 10.  3. 11.] 
adversary cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
adversary victory points: 12
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[56.063595]
 [56.651817]
 [56.651817]
 [69.16174 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  3. 11.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 17. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3. 16. 15.  8.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.58407592773438



action possibilites: [-1] 
expected returns: [[203.44344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 16. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3. 16. 15.  8.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 63.01084899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[195.14127]
 [214.52031]
 [187.40396]
 [212.5727 ]
 [203.44344]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 16. 30. 18. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3. 16. 15.  8.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 203.4434356689453



buy possibilites: [-1] 
expected returns: [[230.05504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  3.] 
cards in discard: [ 0.  3.  1. 11. 10.  1. 29. 11.  3. 11.  1.  1. 15.  3.  0. 10.  1. 11.
 11. 11.  0.  3.  1. 15.  3.  3. 10.  3. 10. 10. 10.  1.  3. 11.  3. 10.
  1.  3.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  3. 16. 15.  8.] 
adversary cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
adversary victory points: 3
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -150    0    0
   16    0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 214.52032470703125






Player: 1 
cards in hand: [11.  3. 16. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 15.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 16. 15.  8.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
adversary victory points: 13
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 15.  8.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
adversary victory points: 13
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 15.  8.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
adversary victory points: 13
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16. 15.  8.] 
cards in discard: [ 0. 23.  0.  0. 10. 11.  8.  0.  0.  0.  0.  0.  0.  3.  0. 16. 16.  0.
  3. 14.  0.  0.  0.  0.  8.  0. 16.  8.  1.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
adversary victory points: 13
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[43.757896]
 [53.628094]
 [53.628094]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 230.05503845214844



action possibilites: [-1. 29. 11.] 
expected returns: [[47.33036 ]
 [60.49298 ]
 [55.426983]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.] 
cards in discard: [1. 1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.167694091796875



action possibilites: [-1.] 
expected returns: [[203.45723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1.  1.  0. 11.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.485328674316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[193.50237]
 [206.6024 ]
 [184.74364]
 [204.05353]
 [203.93332]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  1.  0. 11.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3] -> size -> 50 
action values: 1 
buys: 1 
player value: 2 
card supply: [15. 16. 30. 17. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 203.4572296142578



buy possibilites: [-1] 
expected returns: [[107.86074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  1.  0. 11.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -160    0    0
   16    0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 206.60240173339844






Player: 1 
cards in hand: [ 0.  0. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  3  3  8  0 23  0  8 11  1  0  0 10  0 16  0  1 16  0
 16 15  8 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10. 10.  1. 10.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
adversary victory points: 14
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10. 10.  1. 10.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
adversary victory points: 14
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10. 10.  1. 10.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
adversary victory points: 14
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10. 10.  1. 10.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
adversary victory points: 14
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 10.  1. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[179.80121]
 [174.13397]
 [174.13397]
 [174.13397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  1. 10.  1.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  8. 16.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.8607406616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[183.41283]
 [192.32729]
 [192.25374]
 [179.66168]
 [184.08597]
 [189.61523]
 [195.76753]
 [185.86404]
 [194.77849]
 [195.20892]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1. 10.  1.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  5.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  8. 16.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 179.80125427246094



buy possibilites: [-1] 
expected returns: [[262.6379]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  1. 10.  1.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  1.  8. 16.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  330    0    0    0    0    0    0    0 -170    0    0
  128    0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 195.7675323486328






Player: 1 
cards in hand: [ 0. 11.  1.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  8. 16.] 
cards in discard: [0. 8. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 23  0  8 11  0  0 10  0 16  0  1 16  0 16 15  8
 14  0 16  0  0  8  0  3  8  0  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
adversary victory points: 14
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [0. 8. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
adversary victory points: 14
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0. 8. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
adversary victory points: 14
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
adversary victory points: 14
player victory points: 3 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[161.47635]
 [157.75264]
 [164.22493]
 [168.18896]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 11.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 16. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15. 10.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 262.6379089355469



action possibilites: [-1] 
expected returns: [[79.969894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15. 10.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: 192 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 161.8420867919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.405396]
 [67.90068 ]
 [79.969864]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 15. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 15. 10.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.96989440917969






Player: 1 
cards in hand: [ 0.  8. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15. 10.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16
  0  0  8  0  3  8  0  0  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1. 11. 10.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
adversary victory points: 14
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 15. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1. 11. 10.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
adversary victory points: 14
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 15. 30. 16. 30.  8. 10.  6.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1. 11. 10.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
adversary victory points: 14
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 16. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [15. 10.  1. 11. 10.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
adversary victory points: 14
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15. 10.  1. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 10.] 
expected returns: [[100.03915]
 [128.47829]
 [103.4388 ]
 [138.28804]
 [103.4388 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1. 11. 10.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 15. 30. 16. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.96989440917969



action possibilites: [-1] 
expected returns: [[71.184525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1. 10.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 16. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -190    0    0
   27    0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 122.8045654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[58.835445]
 [77.22018 ]
 [41.20873 ]
 [74.65405 ]
 [71.18452 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1. 10.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 14. 30. 16. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
adversary victory points: 3
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.18452453613281



buy possibilites: [-1] 
expected returns: [[79.7701]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1. 10.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -200    0    0
   16    0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 77.2201919555664






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 14. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3] -> size -> 55 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 14. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3] -> size -> 55 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 14. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3] -> size -> 55 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[235.90071]
 [243.56317]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 14. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.77010345458984



action possibilites: [-1] 
expected returns: [[211.74384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -210    0    0
   27    0] 
sum of rewards: 192 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 237.28147888183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[203.59724]
 [204.95695]
 [211.74385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 13. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 211.74383544921875






Player: 1 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0
  0  8  0  3  8  0  0  0  0  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 15. 30.  8. 10.  5.  0.  4. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  1.  3.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 13. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  1.  3.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 13. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  1.  3.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 12. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11.  1.  3.  1.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  1.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[235.4723 ]
 [245.54405]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  1.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 12. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 211.74383544921875



action possibilites: [-1] 
expected returns: [[101.65316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 242.2897491455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 95.747284]
 [106.574646]
 [104.61053 ]
 [ 90.09013 ]
 [ 98.94405 ]
 [103.27829 ]
 [113.4401  ]
 [ 97.62114 ]
 [108.448494]
 [101.65318 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  4.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.65316009521484



buy possibilites: [-1] 
expected returns: [[111.214355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8. 16. 16.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -230    0    0
  128    0] 
sum of rewards: 273 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.4400863647461






Player: 1 
cards in hand: [ 0.  8. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16. 16.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  8  0 23  0  8 11  0  0 10  0  0 16  0 16 15  8 14  0 16  0  0
  8  0  3  8  0  0  0  0  0 16  0  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 10.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 10.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 10.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [11. 10.  3. 11.  3.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11. 10.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[280.82608]
 [292.21024]
 [279.68442]
 [292.21024]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 11.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 11. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  0. 14. 23.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.21435546875



action possibilites: [-1] 
expected returns: [[133.6562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  0. 14. 23.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 285.5099792480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[125.272385]
 [117.24653 ]
 [133.65623 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  8.  0. 14. 23.] 
adversary cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.6562042236328






Player: 1 
cards in hand: [ 0.  8.  0. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14. 23.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14. 23.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14. 23.] 
cards in discard: [ 0.  8.  0.  0.  8. 11. 16. 15.  8. 10.  0.  0.  0.  0.  3.  3.  0.  8.
  1. 16.  0.  0.  0.  0.  8. 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[250.3144 ]
 [246.18198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  1.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.6562042236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[242.2263 ]
 [241.375  ]
 [244.85185]
 [234.07349]
 [242.72517]
 [250.31438]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.  1.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 250.3143768310547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.  1.  0.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3. 10.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  9.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.  1.  0.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3. 10.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  3.  1.  0.] 
adversary cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3. 10.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[236.21349]
 [229.912  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  1.  0.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3. 10.  0.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0. 23.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 250.3143768310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[226.52692]
 [229.64987]
 [230.86057]
 [224.66644]
 [225.5276 ]
 [225.1936 ]
 [228.70131]
 [224.70006]
 [224.64294]
 [228.11334]
 [227.72859]
 [224.60559]
 [231.23145]
 [236.21352]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  1.  0.] 
cards in discard: [ 1.  1.  0. 11.  3. 29. 29.  3. 29. 10. 10.  1. 10.  1.  1. 11.  3. 10.
 15.  3.  1.  3. 11. 15. 10.  1. 10.  1. 11.  3.  0.  3.  3.  1. 29. 11.
  1.  3.  1.  3.  1. 11. 10.  3. 11.  3. 10.  0.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  0.  0.  0. 23.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 236.21348571777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 23.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
action values: 2 
buys: 1 
player value: 1 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14] -> size -> 38 
action values: 0 
buys: 2 
player value: 5 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[85.85888]
 [75.58698]
 [68.26405]
 [75.74129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 29. 11.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 236.21348571777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[71.75955 ]
 [71.086   ]
 [73.89404 ]
 [73.70349 ]
 [71.028595]
 [84.975174]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 29. 11.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 16.  1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 85.85884857177734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [10.  1.  1.  3. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3. 10.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [10.  1.  1.  3. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3.  9.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [10.  1.  1.  3. 11.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10.  1.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[175.59322]
 [174.75426]
 [187.94244]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  1.  3. 11.] 
cards in discard: [ 0. 10.  1. 29. 11.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 10. 30. 15. 30.  8. 10.  5.  0.  3.  9.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14. 16.  0.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.97509765625



action possibilites: [-1] 
expected returns: [[79.14671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  1.  3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14. 16.  0.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -250    0    0
   27    0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 180.5587615966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[72.39165]
 [80.83877]
 [80.73384]
 [68.83376]
 [73.07421]
 [78.26885]
 [83.58728]
 [74.69363]
 [83.14076]
 [83.41105]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  1.  3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  3.  7.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14. 16.  0.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.14671325683594



buy possibilites: [-1] 
expected returns: [[117.22778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  1.  3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29.] 
cards in deck: 49 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14. 16.  0.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -260    0    0
  128    0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 83.5872802734375






Player: 1 
cards in hand: [15. 14. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 16.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14. 16.  0.  8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 29.  3.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  3.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3. 29.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 87.07206]
 [124.61394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 42 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0    0    0    0    0    0 -260    0    0
 1381    0] 
sum of rewards: 1476 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 205.83099365234375



action possibilites: [-1.] 
expected returns: [[123.105896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 42 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 75.18147277832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.305214]
 [110.74246 ]
 [123.10589 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
adversary owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 42 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.10589599609375






Player: 1 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  0 23  0  8 11  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0
  3  8  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 11. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 11. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  2.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 11. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  1.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 11. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[119.9824 ]
 [128.19717]
 [117.98802]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  1.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  9. 30. 15. 30.  8. 10.  5.  0.  1.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 123.10589599609375



action possibilites: [-1] 
expected returns: [[161.69829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -270    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 122.56626892089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[153.90265]
 [161.00221]
 [153.06567]
 [160.64594]
 [150.71431]
 [149.8765 ]
 [154.81577]
 [158.80688]
 [165.7089 ]
 [163.10934]
 [155.79248]
 [158.70357]
 [151.49245]
 [162.7896 ]
 [161.69829]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1] -> size -> 62 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  9.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.6982879638672



buy possibilites: [-1] 
expected returns: [[82.78772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
adversary owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5.     0.     0.   360.     0.     0.    20.     0.     0.     0.
    0.  -280.     0.     0.    62.5    0. ] 
sum of rewards: 157.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 165.70896911621094






Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 23  0  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8
  0  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  3. 29.  3.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  3. 29.  3.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
adversary victory points: 15
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1.  3. 29.  3.  3.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
adversary victory points: 15
player victory points: 3 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[188.02275]
 [198.55959]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  3.  3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 16.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.7877197265625



action possibilites: [-1. 11.] 
expected returns: [[221.47943]
 [230.80116]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25] -> size -> 63 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9.  8. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 16.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 190.53111267089844



action possibilites: [-1] 
expected returns: [[163.00125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9.  7. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 16.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -290    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 222.8134307861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[154.48094]
 [176.16931]
 [171.96524]
 [142.26262]
 [170.2836 ]
 [163.00124]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1] -> size -> 64 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9.  7. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 16.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.00125122070312



buy possibilites: [-1] 
expected returns: [[107.32741]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  6. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 16.  8.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
adversary owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
adversary victory points: 3
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -300    0    0
   54    0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 176.16932678222656






Player: 1 
cards in hand: [ 8.  0.  3. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 16.  8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0
  0  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9.  6. 30. 15. 30.  8. 10.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 10.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
adversary victory points: 15
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9.  6. 30. 15. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 10.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
adversary victory points: 15
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9.  6. 30. 15. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 10.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
adversary victory points: 15
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [14.  0.  0.  0.  0.  3. 14.  0. 23. 10.  0.  0.  0.  0.  3. 25.  0.  0.
  0. 16.  1.  8. 14. 15. 16.  0.  8.  8.  8.  0.  0.  8.  0.  0.  8.  6.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8.  6. 30. 15. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 10.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
adversary victory points: 15
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[115.44155]
 [115.0168 ]
 [115.0168 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  6. 30. 15. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 23. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.32740783691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.638664]
 [122.17103 ]
 [100.07493 ]
 [120.3011  ]
 [115.44155 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8.  6. 30. 15. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 23. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 115.44149780273438



buy possibilites: [-1] 
expected returns: [[84.32512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1  3] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  6. 30. 14. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 23. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
adversary victory points: 1
player victory points: 16 

Reward from previous game state: 
[  -5    0    0  450    0    0    0    0    0    0    0 -310    0    0
   16    0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 122.17105102539062






Player: 1 
cards in hand: [ 8. 14.  0. 23. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 23. 16.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 23. 16.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  6. 30. 14. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  1.  3.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.  3.  3.  3.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1  3] -> size -> 66 
adversary victory points: 16
player victory points: 1 


action possibilites: [-1.  8. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8.  6. 30. 14. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  1.  3.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.  3.  3.  3.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1  3] -> size -> 66 
adversary victory points: 16
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0] -> size -> 41 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 8.  6. 30. 14. 30.  8.  9.  5.  0.  1.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 1. 10.  1.  3.  1.] 
adversary cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.  3.  3.  3.
 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1  3] -> size -> 66 
adversary victory points: 16
player victory points: 1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 13 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 1 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 10.  1.  3.  1.] 
cards in discard: [ 0. 10.  1. 29. 11.  1. 29. 11. 10.  1.  1.  3.  3.  1.  3.  3. 29.  3.
  1. 25. 11.  1. 10.  1.  1.  3.  3.  1.  1. 29. 11.  1.  3.  3.  3.  3.
 10. 10.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 10 11 11 10  3 10 11 10  3 10  3 29 10 10
 10 11 10  3 11 11 15 15  3  1  3  1  1  1  1  1  3  3  1  1 29  1  1  3
  1  3  3 29  1  1  3  1  1 29  1  1 29  1 25  1  1  3] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  6. 30. 14. 30.  8.  9.  5.  0.  0.  8.  2.  7.  9.  0. 10.  7.] 
adversary cards in hand: [ 8. 14.  0. 16.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  8 23  8  0  0 10  0  0  0 16 15  8 14  0 16  0  0  8  0  3  8  0  0
  0  0  0 16  0  8  1  0  0 14 14  0 25  8  8  6  0  8] -> size -> 42 
adversary victory points: 1
player victory points: 16 

Reward from previous game state: 
[     -5 3000000       0     450       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000445 

action type: buy - action -1
Learning step: 300036.09375
desired expected reward: 300120.40625



