 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.871155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000335 

action type: buy - action -1.0
Learning step: -120008.2890625
desired expected reward: -120135.96875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 62.179913]
 [ 87.19724 ]
 [ 73.705986]
 [ 30.460451]
 [ 78.427864]
 [ 92.0875  ]
 [ 80.08982 ]
 [103.27511 ]
 [ 47.352207]
 [ 66.67623 ]
 [ 71.642136]
 [ 78.997894]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.9955062866211



buy possibilites: [-1] 
expected returns: [[81.85325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.27507781982422






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.92585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.8532485961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 82.20497 ]
 [106.92887 ]
 [ 93.72953 ]
 [ 50.779354]
 [111.499756]
 [ 99.97516 ]
 [ 86.775826]
 [ 98.94378 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.27275848388672



buy possibilites: [-1] 
expected returns: [[87.455345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.49974060058594






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.7482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.4553451538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[54.870598]
 [81.315125]
 [67.03776 ]
 [21.658606]
 [86.33185 ]
 [73.73423 ]
 [59.661594]
 [72.629585]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.89371490478516



buy possibilites: [-1] 
expected returns: [[70.10258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 86.33185577392578






Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[68.09954]
 [81.67928]
 [92.0407 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.  0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.10257720947266



action possibilites: [-1. 11.] 
expected returns: [[102.6831 ]
 [116.73223]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.41121673583984



action possibilites: [-1] 
expected returns: [[107.30053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 130.0934295654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 93.77712 ]
 [118.78248 ]
 [105.43812 ]
 [ 61.180065]
 [110.09214 ]
 [123.412315]
 [111.7513  ]
 [133.29707 ]
 [ 78.48004 ]
 [ 98.406944]
 [103.411064]
 [110.76194 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.30052947998047



buy possibilites: [-1] 
expected returns: [[74.26719]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  3. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 133.29708862304688






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[31.765524]
 [52.71441 ]
 [43.644955]
 [52.71441 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.2671890258789



action possibilites: [-1. 11. 29. 11.] 
expected returns: [[39.534622]
 [50.902767]
 [59.585766]
 [50.902767]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.19104766845703



action possibilites: [-1. 11. 11.] 
expected returns: [[66.93266]
 [78.76702]
 [78.76702]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.58576583862305



action possibilites: [-1] 
expected returns: [[64.940605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.27294158935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.821453]
 [74.24064 ]
 [61.75118 ]
 [19.801218]
 [66.08227 ]
 [78.6329  ]
 [67.655075]
 [87.8481  ]
 [36.442093]
 [55.165646]
 [59.86128 ]
 [66.81658 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.94060516357422



buy possibilites: [-1] 
expected returns: [[110.98673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.84809112548828






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.782543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.98673248291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.248062]
 [74.09303 ]
 [64.05063 ]
 [33.9505  ]
 [77.88764 ]
 [68.336586]
 [59.351673]
 [67.63645 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.3296012878418



buy possibilites: [-1] 
expected returns: [[68.528694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 11.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 77.88764953613281






Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [3. 0. 3. 3. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[45.879215]
 [57.13498 ]
 [34.76376 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.52869415283203



action possibilites: [-1] 
expected returns: [[50.65617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 68.55567169189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.56089 ]
 [46.655617]
 [ 5.90918 ]
 [52.825043]
 [51.932842]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.65616989135742



buy possibilites: [-1] 
expected returns: [[77.56927]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 52.82503890991211






Player: 1 
cards in hand: [ 3.  3.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 10  8  3  3] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 83.61968]
 [103.80206]
 [ 72.66954]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 10.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.56926727294922



action possibilites: [-1. 10.] 
expected returns: [[113.485016]
 [101.664986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.6015853881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.071175]
 [124.176506]
 [111.241005]
 [ 69.788826]
 [115.70533 ]
 [128.71767 ]
 [117.291534]
 [138.33347 ]
 [ 85.72171 ]
 [104.50553 ]
 [109.29774 ]
 [116.32554 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.48499298095703



buy possibilites: [-1] 
expected returns: [[134.99248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 138.3334503173828






Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[104.62107 ]
 [117.17988 ]
 [127.015144]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.9924774169922



action possibilites: [-1. 11. 29.] 
expected returns: [[144.90039]
 [157.49434]
 [167.27702]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 29.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.46514129638672



action possibilites: [-1. 11. 11.] 
expected returns: [[151.9488]
 [164.8702]
 [164.8702]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 167.27700805664062



action possibilites: [-1] 
expected returns: [[138.15575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 178.4243927001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.632454]
 [147.70543 ]
 [133.7874  ]
 [ 89.14236 ]
 [138.64838 ]
 [152.52728 ]
 [140.37234 ]
 [162.60004 ]
 [106.04012 ]
 [126.45432 ]
 [131.66609 ]
 [139.29796 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  6. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.15574645996094



buy possibilites: [-1] 
expected returns: [[139.1007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.  8. 11.  3. 10.  0.  0. 29. 29.  3.  0. 10.  0.  0. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 162.6000213623047






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 0. 10.  8.  3. 23.  1.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[88.95339 ]
 [79.034325]
 [98.83914 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.10069274902344



action possibilites: [-1] 
expected returns: [[84.00511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.50980377197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[72.50543]
 [82.24882]
 [47.4198 ]
 [87.59185]
 [86.88924]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  8. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.00511169433594



buy possibilites: [-1] 
expected returns: [[109.70254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 23.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 87.59184265136719






Player: 1 
cards in hand: [ 0. 23.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 29. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  7.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 29. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  0.  3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  8. 10. 29. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 29.] 
expected returns: [[124.69901 ]
 [125.436806]
 [114.94364 ]
 [142.2978  ]
 [142.2978  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 29. 29.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.7025375366211



action possibilites: [-1.  8. 10. 29. 29.] 
expected returns: [[140.59335]
 [141.33076]
 [130.83458]
 [158.85635]
 [158.85635]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 29. 29.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.5888214111328



action possibilites: [-1.  8. 10. 29. 11.] 
expected returns: [[169.63948]
 [170.51907]
 [158.26888]
 [190.09409]
 [181.22925]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 29. 11.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 158.8563232421875



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[206.49971]
 [207.38184]
 [195.162  ]
 [218.06586]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 11.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 190.09408569335938



action possibilites: [-1] 
expected returns: [[180.59637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 230.25636291503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[165.43614]
 [189.29477]
 [176.18068]
 [136.9066 ]
 [180.57028]
 [194.1372 ]
 [182.18898]
 [205.2419 ]
 [151.96222]
 [169.70961]
 [174.32545]
 [181.29857]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  5. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.59637451171875



buy possibilites: [-1] 
expected returns: [[160.818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  3.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 205.2418670654297






Player: 1 
cards in hand: [ 0.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  3.] 
cards in discard: [11.  0. 23.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[108.22474]
 [ 97.08769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 160.8179931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.80734 ]
 [110.735634]
 [ 98.77231 ]
 [ 63.159534]
 [102.925354]
 [114.899506]
 [104.42271 ]
 [123.56684 ]
 [ 76.326195]
 [ 92.65276 ]
 [ 97.00087 ]
 [103.58201 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  4. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.2247314453125



buy possibilites: [-1] 
expected returns: [[106.6941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.56682586669922






Player: 1 
cards in hand: [0. 1. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.
 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.
 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  6.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.
 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11.  0. 23.  0.  0.  3. 10.  0.  3.  3.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.
 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 29.] 
expected returns: [[ 84.558876]
 [ 95.45808 ]
 [103.82082 ]
 [ 73.95307 ]
 [103.82082 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 10. 29.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 10. 29. 29. 29. 29. 11.  3.  8. 10.  0. 29.
 10.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.69409942626953



action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[161.0477 ]
 [169.74632]
 [152.38898]
 [176.43633]
 [176.43633]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 29. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.82080841064453



action possibilites: [-1. 11. 10. 29. 10.] 
expected returns: [[162.71118]
 [172.24503]
 [153.68748]
 [179.5649 ]
 [153.68748]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 29. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 176.43630981445312



action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[204.06883]
 [213.83644]
 [194.36661]
 [194.36661]
 [221.56126]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 179.56488037109375



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[245.05725]
 [255.61366]
 [234.55562]
 [234.55562]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 221.56124877929688



action possibilites: [-1] 
expected returns: [[238.91881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 266.9318542480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[226.62944]
 [248.03581]
 [236.54607]
 [210.46507]
 [199.72266]
 [240.5212 ]
 [252.04362]
 [241.97275]
 [277.60214]
 [260.359  ]
 [214.20615]
 [233.3981 ]
 [230.55473]
 [212.85287]
 [234.83252]
 [241.2255 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7. 10.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 238.91880798339844



buy possibilites: [-1] 
expected returns: [[262.09988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 23.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0 100   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 277.6021423339844






Player: 1 
cards in hand: [ 3. 23.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  0.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  0.  0.] 
cards in discard: [3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  3.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[164.64632]
 [178.26279]
 [165.16618]
 [157.10461]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8. 10.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 262.0998840332031



action possibilites: [-1.  8. 10.] 
expected returns: [[178.54149]
 [179.12477]
 [170.82825]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 10.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 10 29 11 10  8 29 10 29 10
  8 10 29 29 10 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 178.26280212402344



action possibilites: [-1] 
expected returns: [[178.66539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 194.35513305664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[165.86607]
 [174.70372]
 [141.46278]
 [179.48015]
 [178.80319]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  7.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.66539001464844



buy possibilites: [-1] 
expected returns: [[161.91072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -99 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 179.4801025390625






Player: 1 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3. 10.  9.  2. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  2. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 29.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 10.] 
expected returns: [[174.23409]
 [188.51816]
 [188.51816]
 [174.81116]
 [166.2949 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8.  0. 10.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.9107208251953



action possibilites: [-1. 29.  8. 10. 11.] 
expected returns: [[154.13475]
 [168.19131]
 [154.69359]
 [146.25574]
 [162.08173]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 10. 11.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 188.51820373535156



action possibilites: [-1.  8. 10. 11. 11.] 
expected returns: [[159.55817]
 [160.05397]
 [152.42258]
 [166.73825]
 [166.73825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11. 11.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.19129943847656



action possibilites: [-1] 
expected returns: [[108.55318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -68 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 174.69566345214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.118095]
 [113.47819 ]
 [105.82305 ]
 [ 82.515144]
 [116.15059 ]
 [109.44563 ]
 [101.79053 ]
 [108.949554]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  5.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.55317687988281



buy possibilites: [-1] 
expected returns: [[94.14275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 116.15059661865234






Player: 1 
cards in hand: [ 0.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [ 3.  3. 11.  3. 23.  0.  0. 14.  0.  3.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[100.43011 ]
 [ 94.321205]
 [ 94.321205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.14275360107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.61794 ]
 [103.88034 ]
 [ 97.34211 ]
 [ 75.580345]
 [106.16455 ]
 [100.43724 ]
 [ 93.90074 ]
 [100.00586 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  4.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.43009948730469



buy possibilites: [-1] 
expected returns: [[117.20799]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  3. 10. 10.  0.  8. 29.  8.  0. 10. 11. 29.
 29. 11.  8.  0. 10. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -101 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 106.16454315185547






Player: 1 
cards in hand: [ 8.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11 11  3  3 14  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 29. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 10.] 
expected returns: [[122.0489 ]
 [113.67231]
 [137.05495]
 [137.05495]
 [113.67231]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.20799255371094



action possibilites: [-1. 10. 29. 10. 10.] 
expected returns: [[137.12566]
 [128.51282]
 [152.52612]
 [128.51282]
 [128.51282]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 134.5813446044922



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[176.0778 ]
 [166.00406]
 [166.00406]
 [166.00406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 152.52613830566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[163.55399]
 [183.84097]
 [173.02052]
 [136.51282]
 [176.78195]
 [187.60513]
 [178.13857]
 [195.50803]
 [151.09744]
 [167.31816]
 [171.38441]
 [177.39189]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  3.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 176.07777404785156



buy possibilites: [-1] 
expected returns: [[197.74908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0.] 
cards in discard: [29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
  128    0] 
sum of rewards: -17 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 195.5080108642578






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  6.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 10.] 
expected returns: [[125.24462]
 [140.08589]
 [133.47691]
 [155.34763]
 [117.10395]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 25. 10.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8. 10. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1. 23.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 197.74908447265625



action possibilites: [-1] 
expected returns: [[171.50015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10. 29.  3.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1. 23.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.34764099121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[160.12492]
 [138.24678]
 [171.95424]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10. 29.  3.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  1. 23.] 
adversary cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.50015258789062






Player: 1 
cards in hand: [ 0.  0. 11.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1. 23.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  3.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  3.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6] -> size -> 22 
action values: 0 
buys: 2 
player value: 5 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  5.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 6 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  3.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  3.] 
cards in discard: [ 3. 10.  8.  0.  0.  3.  8.  3.  3.  0.  0.  0.  6.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
expected returns: [[75.061295]
 [75.50335 ]
 [86.023506]
 [81.25913 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29. 11.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 171.9542236328125



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[ 95.61225]
 [ 96.06643]
 [102.3251 ]
 [ 89.0519 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11. 10.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  1. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.02350616455078



action possibilites: [-1] 
expected returns: [[91.48843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 109.6189956665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[80.75234 ]
 [96.465996]
 [88.01382 ]
 [61.247448]
 [99.406265]
 [92.01542 ]
 [91.40529 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  3.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.4884262084961



buy possibilites: [-1] 
expected returns: [[93.99289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -61 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 99.4062728881836






Player: 1 
cards in hand: [ 0.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11] -> size -> 34 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 24. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11] -> size -> 34 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  3.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0. 11.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11] -> size -> 34 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[72.19665 ]
 [78.663055]
 [78.663055]
 [78.663055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 11.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  1. 23.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.99288940429688



action possibilites: [-1] 
expected returns: [[59.80618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.6541976928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.549747]
 [54.662975]
 [26.635786]
 [58.510983]
 [57.952877]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  4.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.80617904663086



buy possibilites: [-1] 
expected returns: [[58.991848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -10    0    0
   16    0] 
sum of rewards: -159 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 58.510982513427734






Player: 1 
cards in hand: [ 0.  1. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 23.  0.  8.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 8.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1 10  8  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0
  3] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3] -> size -> 22 
action values: 0 
buys: 2 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 23. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 29.  8. 29.] 
adversary cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 10. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.  8. 29.] 
expected returns: [[34.196983]
 [28.930017]
 [28.930017]
 [43.56242 ]
 [34.57867 ]
 [43.56242 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  8. 29.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.99184799194336



action possibilites: [-1. 10. 10. 29.  8.] 
expected returns: [[17.701567]
 [12.467264]
 [12.467264]
 [27.399767]
 [18.046911]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  8.] 
cards in discard: [29. 29. 29. 10. 10.  0. 10.  0. 25. 29. 11.  0. 10. 29.  3. 10. 11. 29.
 11.  8.  0.  0. 10. 15.  8. 11.  0. 11.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.53423309326172



action possibilites: [-1. 10.  8.  8.] 
expected returns: [[115.24876 ]
 [107.45023 ]
 [115.741905]
 [115.741905]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 10 29 11 10  8 29 10 29 10  8 10 29
 29 10 25  8 10 11 11 29 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.126859664916992



action possibilites: [-1] 
expected returns: [[107.42611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 119.6301498413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.72895 ]
 [103.8068  ]
 [ 72.68853 ]
 [108.165726]
 [107.593216]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  3.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.42610931396484



buy possibilites: [-1] 
expected returns: [[103.25119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [10.  3.  0.  6.  3.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   60    0    0    0    0  -10    0    0
   16    0] 
sum of rewards: -149 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 108.16571807861328






Player: 1 
cards in hand: [10.  3.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6.  3.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 25. 15. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 25. 15. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 25. 15. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 25. 15. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 15. 11.] 
expected returns: [[121.77288 ]
 [131.14746 ]
 [153.2446  ]
 [116.245346]
 [131.14746 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 15. 11.] 
cards in discard: [10.  8. 29. 29.  8.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  9. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3
  0] -> size -> 25 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.25119018554688



action possibilites: [-1] 
expected returns: [[126.55805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 11. 29.  8.] 
cards in discard: [10.  8. 29. 29.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3
  0  6] -> size -> 26 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.24461364746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.43835]
 [ 99.65052]
 [126.56951]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15. 11. 29.  8.] 
cards in discard: [10.  8. 29. 29.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 22. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.] 
adversary owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3
  0  6] -> size -> 26 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.55805206298828






Player: 1 
cards in hand: [ 3.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10. 10.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10. 10.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 22. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10. 10.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [ 3.  0.  0.  3. 14.  3.  0.  3. 23.  8.  0.  0. 10.  3.  0.  6.  3.  3.
  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29. 10. 10.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10.] 
expected returns: [[100.70202]
 [106.80525]
 [111.49716]
 [ 94.66055]
 [ 94.66055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 10.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  3. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.56951141357422



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[92.4253 ]
 [98.934  ]
 [86.03051]
 [86.03051]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  3. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.5450210571289



action possibilites: [-1] 
expected returns: [[99.16459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 106.28250885009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[89.767746]
 [96.39035 ]
 [70.509285]
 [99.96768 ]
 [99.479324]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  2.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.16458892822266



buy possibilites: [-1] 
expected returns: [[107.00828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  1.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  3. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0  -30    0    0
   16    0] 
sum of rewards: -159 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 99.96768188476562






Player: 1 
cards in hand: [ 8.  3. 23.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 23.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  1.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  3. 29. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  1.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  3. 29. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3] -> size -> 26 
action values: 0 
buys: 2 
player value: 3 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  1.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  3. 29. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  3. 29. 11.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  8.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 11.] 
expected returns: [[73.19564 ]
 [85.79556 ]
 [73.700836]
 [85.79556 ]
 [79.90829 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 29. 11.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.0082778930664



action possibilites: [-1.  8. 29. 10.] 
expected returns: [[88.01465 ]
 [88.437675]
 [99.03149 ]
 [82.27294 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 88.11634063720703



action possibilites: [-1. 10.] 
expected returns: [[50.647266]
 [45.46625 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.6827621459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[43.79485 ]
 [48.774242]
 [30.209383]
 [50.93374 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.647281646728516






Player: 1 
cards in hand: [10.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  0.] 
cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 8. 23.  8.  3.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  2.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  1.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  0.] 
adversary cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[60.278133]
 [70.36065 ]
 [65.98807 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  1.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [11.  8. 14.  0.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.93374252319336



action possibilites: [-1. 11.] 
expected returns: [[54.00265 ]
 [58.715275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  8. 10.  1.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [11.  8. 14.  0.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.8853645324707



action possibilites: [-1] 
expected returns: [[30.549292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.  0. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 21. 30.  8.  8. 10.  1.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [11.  8. 14.  0.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0  -40    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 56.89632797241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[23.965014]
 [33.79263 ]
 [28.331224]
 [12.930693]
 [35.699146]
 [30.549288]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.  0. 29.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 21. 30.  8.  8. 10.  1.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [11.  8. 14.  0.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.549291610717773



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 1 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0.] 
cards in discard: [10.  8. 29. 29.  8.  8. 25.  0. 11. 15. 11. 29.  8.  0. 15.  8. 29. 11.
 10. 10.  0.  3. 11.  8. 10. 29. 29. 10.  0. 29.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3 29 11 11 29 29 11 10  8 29 10 29 10  8 10 29 29
 10 25  8 10 11 11 29 10 11 15  8  8 15  8  1 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 21. 30.  8.  8. 10.  0.  0.  9.  2.  9.  9.  0. 10.  8.] 
adversary cards in hand: [11.  8. 14.  0.  0.] 
adversary cards in discard: [ 8. 23.  8.  3.  3.  0.  0. 11. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3 10  3  3  0 23  0 11  3  3 14  0  3  8  6  8  0  3  0  3  0
  6  3  8 11] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0       40        0
        0        0        0      -50        0        0       27        0] 
sum of rewards: -3000168 

action type: buy - action 11.0
Learning step: -120008.1484375
desired expected reward: -119972.453125



